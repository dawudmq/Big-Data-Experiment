FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Sheff, Mallory C.
   Bawah, Ayaga A.
   Asuming, Patrick O.
   Kyei, Pearl
   Kushitor, Mawuli
   Phillips, James F.
   Kachur, S. Patrick
TI Evaluating health service coverage in Ghana's Volta Region using a
   modified Tanahashi model
SO GLOBAL HEALTH ACTION
VL 13
IS 1
AR 1732664
DI 10.1080/16549716.2020.1732664
PD DEC 31 2020
PY 2020
AB Background: The United Nations 2030 Sustainable Development Goals have
   reaffirmed the international community's commitment to maternal,
   newborn, and child health, with further investments in achieving quality
   essential service coverage and financial protection for all. Objective:
   Using a modified version of the 1978 Tanahashi model as an analytical
   framework for measuring and assessing health service coverage, this
   paper aims to examine the system of care at the community level in
   Ghana's Volta Region to highlight the continued reforms needed to
   achieve Universal Health Coverage. Methods: The Tanahashi model
   evaluates health system coverage through five key measures that reflect
   different stages along the service provision continuum: availability of
   services; accessibility; initial contact with the health system;
   continued utilization; and quality coverage. Data from cross-sectional
   household and health facility surveys were used in this study.
   Immunization and antenatal care services were selected as tracer
   interventions to serve as proxies to assess systems bottlenecks.
   Results: Financial access and quality coverage were identified as the
   biggest bottlenecks for both tracer indicators. Financial accessibility,
   measured by enrollment in Ghana's National Health Insurance Scheme was
   poor with 16.94% presenting valid membership cards. Childhood
   immunization was high but dropped modestly from 93.8% at initial contact
   to 76.7% quality coverage. For antenatal care, estimates ranged from
   65.9% at initial visit to 25.1% quality coverage. Conclusion: Results
   highlight the difficulty in achieving high levels of quality service
   coverage and the large variations that exist within services provided at
   the primary care level. While vertical investments have been prioritized
   to benefit specific health services, a comprehensive systems approach to
   primary health care needs to be further strengthened to reach Ghana's
   Universal Health Coverage objectives.
OI Asuming, Patrick O./0000-0002-5010-3484
Z8 0
TC 0
ZS 0
ZB 0
ZR 0
Z9 0
EI 1654-9880
UT WOS:000519982100001
PM 32174254
ER

PT J
AU Chen, Bi Yu
   Kwan, Mei-Po
TI Special Issue on Spatiotemporal Big Data Analytics for Transportation
   Applications
SO TRANSPORTMETRICA A-TRANSPORT SCIENCE
VL 16
IS 1
SI SI
BP 1
EP 4
DI 10.1080/23249935.2018.1558306
PD DEC 20 2020
PY 2020
OI Chen, Bi Yu/0000-0003-3591-9968
ZB 0
ZS 0
TC 0
Z8 0
ZR 0
Z9 0
SN 2324-9935
EI 2324-9943
UT WOS:000508897200001
ER

PT J
AU Welch, Timothy F.
   Gehrke, Steven R.
   Widita, Alyas
TI Shared-use mobility competition: a trip-level analysis of taxi,
   bikeshare, and transit mode choice in Washington, DC
SO TRANSPORTMETRICA A-TRANSPORT SCIENCE
VL 16
IS 1
SI SI
BP 43
EP 55
DI 10.1080/23249935.2018.1523250
PD DEC 20 2020
PY 2020
AB The emergence of new shared-use mobility options such as bikeshare and
   ride-hailing services render the traditional dichotomy between personal
   vehicles and public transit somewhat irrelevant. Transportation planners
   and policymakers have yet to conclude whether these mobility
   technologies are complementing or competing against existing public
   transit services. The understanding of this relationship is vital given
   the increasing uncertainty of funding sources for transit services, but
   limited by the scarcity of meaningful data provided by the private
   ride-hailing industry. This study applies big data analytic tools on a
   unique travel data set to uncover the predictors motivating a
   half-billion transit, taxi, and bikeshare trips in rail station
   walksheds across Washington, DC. Study findings indicate travel cost and
   natural environment factors as well as land use diversity and network
   connectivity metrics significantly impact the likelihood for an
   individual to travel via taxi or bikeshare rather than rail.
OI Gehrke, Steven/0000-0001-9355-5571
ZR 0
Z8 0
TC 2
ZB 0
ZS 0
Z9 2
SN 2324-9935
EI 2324-9943
UT WOS:000508897200004
ER

PT J
AU Zhao, Pengxiang
   Liu, Xintao
   Kwan, Mei-Po
   Shi, Wenzhong
TI Unveiling cabdrivers' dining behavior patterns for site selection of
   'taxi canteen' using taxi trajectory data
SO TRANSPORTMETRICA A-TRANSPORT SCIENCE
VL 16
IS 1
SI SI
BP 137
EP 160
DI 10.1080/23249935.2018.1505972
PD DEC 20 2020
PY 2020
AB In recent years, some big cities in China have established a number of
   'taxi canteens,' which are special cafeterias intended only for
   cabdrivers to dine and rest. To dine and rest at the appropriate time is
   one of the most concerned problems for cabdrivers, since long dining
   delay may affect their health and driving safety, and arbitrary parking
   for dining will be fined and may even cause dangerous traffic accidents.
   The establishment of 'taxi canteens' is expected to mitigate these
   problems. But little has been done to examine and optimize the site
   selection of taxi canteens. This paper presents a data-driven approach
   to allocate 'taxi canteens' throughout a city with the main objective of
   minimizing the total distance between all dining demand locations
   identified from taxi GPS trajectories and the corresponding closest
   'taxi canteen' locations. We propose a dining event detection method
   that considers four features using support vector machine and further
   identifies the spatiotemporal patterns of cabdrivers' dining. A
   constrained optimization model is proposed to select locations for 'taxi
   canteens.' A case study is conducted in Wuhan, China, to evaluate how
   the identification of cabdrivers' dining behavior patterns can support
   the site selection of 'taxi canteens.' The results indicate that the
   proposed method has superior performance.
RI SHI, Wenzhong/; LIU, Xintao/F-6744-2017
OI SHI, Wenzhong/0000-0002-3886-7027; LIU, Xintao/0000-0002-7323-9878
ZB 0
ZS 0
Z8 0
ZR 0
TC 2
Z9 2
SN 2324-9935
EI 2324-9943
UT WOS:000508897200009
ER

PT J
AU [Anonymous]
TI General Practice and the Community: Research on health service, quality
   improvements and training. Selected abstracts from the EGPRN Meeting in
   Vigo, Spain, 17-20 October 2019 Abstracts
SO EUROPEAN JOURNAL OF GENERAL PRACTICE
VL 26
IS 1
BP 42
EP 50
DI 10.1080/13814788.2020.1719994
PD DEC 16 2020
PY 2020
AB Background: Social isolation, loneliness and anxiety-depressive states
   are emerging health conditions in the elderly. Research question: To
   assess whether a 4-month programme of physical activity in a group
   improves the emotional, social and quality of life situation in a sample
   of subjects over 64 years old people. Methods: Multi-centre randomized
   clinical trial of two groups. Study population: Patients older than 64
   years assigned to three primary care teams from different locations.
   Inclusion criteria: Submit a score <32 on the DUKE-UNC-11 social support
   scale, or >12 on the Beck Depression Scale, or >10 on the Generalized
   Anxiety Scale (GAD-7), at the start of the study. The intervention group
   participated in a group physical activity program for 4-months that
   consisted of progressively walking sessions two days a week, 60-150
   minutes long depending on the physical condition of each participant.
   Results: Enrolled were 94 patients who met the inclusion criteria. Mean
   age was 74 years (SD 5.18) and 76.6% were women. No significant
   differences were found at the beginning of the study between the two
   groups in relation to the outcome of the scales evaluated. Once the
   intervention was completed, improvement in the quality of life and
   social support was detected in the intervention group (p<.05). Both
   groups improved the depression and anxiety clinic but the improvement in
   the participants of the intervention group was higher. Those with
   initial depression improved 8.6 points on the scale, compared to the
   control that improved 3.3 points, with the final average of 17.4. Those
   who presented initial anxiety improved 8 points (final average: 7.5
   points, cut-off point for the diagnosis of anxiety 10), compared to the
   control that improved 5.1 points. Conclusion: The results of this study
   indicate that the program developed has positive effects on improving
   the quality of life, social support and depression and anxiety clinic.
   Background: Tourism represents 45% gross domestic product in Balearic
   Islands. Working as a hotel housekeeper (HH) has been associated with
   important morbidity, especially musculoskeletal, chronic pain, a
   significant number of sick leaves, a high consumption of medication,
   poor psychological well-being and worse quality of life. Research
   question: Explore perceptions and opinions regarding the HH's work and
   health problems. Estimate and evaluate HH's health determinants, the
   exposition to several occupational risk factors, their lifestyles and
   health problems and their quality of life. Methods: Design: mixed
   methods: (1) exploratory qualitative study (QS) including 10
   semi-structured interviews and six focus groups; (2). descriptive study
   (DS): individual interviews and clinical medical records. Inclusion
   criteria: older than 18 years, had worked during the last summer season
   in the Balearic Islands. Analysis: QS: transcription and content
   analysis; DS: descriptive statistical analysis. Results: QS: Identified
   positive aspects of their work: timetables, relationship with
   co-workers, attending clients. Highlighted negative aspects: working
   conditions, hard physical workload, stressful duties and insufficiently
   rewarded. HH associated their health problems with their work; coping
   strategies: self-medication or visiting their general practitioner. DS:
   1.043 HH included. Mean age 43.3 years, mean working years as HH 10.7
   years. Mean rooms/day: 18.1 (+/- 6.5); mean beds/day: 44.6 (+/- 20.7).
   HH reported often pain during the last summer season: 68.2% (IC 95%
   65.3-71.0) low back pain; 60.9% (IC 95% 57.8-63.8) wrist and hands;
   55.3% (IC 95% 52.2-58.3) cervical. 41.6% and 35.1% self-reported regular
   and poor health status, respectively. Conclusion: HH perceived hard and
   stressful working conditions, partly justified by the number of rooms
   and beds made per day. They also perceived health problems related to
   their work. HH frequently reported pain during the last summer season.
   Moreover, they perceive regular or poor health status, weaker than women
   from the same social class do.
   Background: Gender-based violence (GBV) is a public health and human
   rights issue, being highly prevalent (12-51%), repetitive and having a
   severe impact on women's health, with a high sanitary and social cost.
   Primary care has a key role in detection and management. There is low
   detection and delay in diagnosis. There is a lack of preparation to
   recognize abuse, especially in the approach and action after detection.
   Greater awareness and sensitization is required. Research question: Can
   a brief specific training intervention in GBV imparted to primary health
   care professionals in their primary health centre increase knowledge,
   improve attitudes and skills? Methods: A cluster-randomized clinical
   trial was carried out in Vigo area primary health centres with at least
   20 health care professionals. A basal evaluation was made through a
   validated inquiry (PREMIS), which they had to retake after three months.
   In the intervention centres, a clinical session was imparted. pResults:
   Out of 264 primary health care professionals, 145 participated. There
   was a 63.5% loss out of 145 professionals. A statistically significant
   difference was detected in the field of knowledge, increasing an average
   of two points on a scale from 0 to 5 in these aspects: how to make
   appropriate questions; connections between GBV and pregnancy; why do not
   they leave their partners; risk determination and phases of GBV. There
   was also a decrease in the idea that if the patient does not recognize
   gender violence, there is very little that can be done. No significant
   differences were detected in the detection and follow-up. Conclusion:
   Significant differences were found in the knowledge and attitude
   sections after performing the intervention to the professionals. The
   results support the implementation of continuous brief training on GBV
   in primary care.
   Background: Out-of-hours (OOH) primary care is a topic of great interest
   in European countries. Reasons for this are similar across borders: to
   guarantee continuity of care with decreasing numbers of health care
   workers and to guard equity in OOHcare for all patients. In OOHcare
   research, valid and accessible research data are needed to fill the
   knowledge gap. iCAREdata aims to offer valid and immediately available
   information from OOHcare. Research question: How feasible is it to
   collect, store and link data of different OOH services in Belgium and to
   improve data quality registration? How useful are aggregated data to
   inform stakeholders, to evaluate (the quality of) services in OOH care
   and the effects of interventions? Methods: As a first achievement, data
   flows, encryption and encoding were carefully designed and implemented.
   Solid cooperation with the federal eHealth web services as a trusted
   third party was crucial. Ethical approval and approval by the data
   protection authority was obtained. Clear agreements were established
   concerning access control. A strict code of conduct was agreed upon. A
   steering committee was established to guard the procedures. Results:
   First data were collected in 2015. iCAREdata now receives +/- 3000
   unique patient contacts per weekend, spread over 14 general practice
   cooperatives, and covering about a quarter of the Flemish population.
   Aggregated data, directly processed, are provided weekly on . This
   portal site offers an overview of, among others, the latest diagnostics,
   drug prescriptions and workload. iCAREdata project also collects data
   from emergency departments in hospitals and community pharmacists and
   link them to evaluate further OOH primary care. Conclusion: Developing a
   research database on OOHcare is feasible. The iCAREdata project succeeds
   in an automated output every week, offering insights on the evolution of
   morbidity, services and effects of interventions. Careful validation and
   interpretation of the data is a crucial ongoing challenge.
   Background: More than half of decompensations of heart failure are
   attended in primary care setting. No score that helps to ascertain the
   short-term prognosis in these patients. Research question: To develop
   and validate a short-term score (30 days) to predict hospitalizations or
   death in patients attended in primary care as a consequence of
   decompensation of heart failure, based on variables easily measurable in
   primary care setting Methods: Prospective multinational cohort study
   including patients treated because of a heart failure decompensation in
   primary care setting. There were a derivation (Spain) and a validation
   cohort (nine European countries). Results: The derivation cohort
   included 561 patients, women were 56%, mean age was 82.2 (SD 8.03) years
   and 31.5% of patients were hospitalized or died in the first month. In
   the validation cohort, 238 patients were included, women were 54%, mean
   age was 79.0 (10.4) years and 26.9% of patients were hospitalized or
   died in the first month. According to the multivariate models, sex, age,
   hospital admission due to heart failure the previous year, and a heart
   rate greater than 100 beats/minute, orthopnoea, paroxysmal nocturnal
   dyspnoea, NYHA functional stage III or IV, saturation of oxygen lower
   than 90% or an increase in the dyspnoea at the consultation with the
   General practitioner were included in the HEFESTOS-SCORE. The
   multivariate model including these variables showed a good calibration
   (Hosmer-Lemeshow p=.35) and discrimination (AUC 0.81, 95% CI 0.77-0.85).
   In the validation cohort, the model presented an adequate external
   validation with good calibration (Hosmer-Lemeshow p=.35) and
   discrimination (AUC 0.74, 95% CI 0.67-0.82). Conclusion: The
   HEFESTOS-SCORE, based on clinical and demographical variables easily
   measurable in primary care is a useful tool to stratify the short-term
   hospitalization and mortality in patients attended because of a heart
   failure decompensation.
   Background: Despite recommendations against long-term benzodiazepine
   (BZD) use, they are often prescribed during months or years in primary
   care. Research question: To determine facilitators and barriers that
   explain the variation in implementation of a primary care educational
   and feedback intervention targeted to general practitioners (GPs) to
   reduce BZDs prescriptions. Methods: A hybrid type I clinical trial:
   qualitative data to evaluate the implementation outcomes. Three health
   districts of Spain: Balearic Islands, Tarragona-Reus district
   (Catalonia) and Arnau de Vilanova lliria district (Valencia). Forty
   stakeholders (GPs) participated in five focus groups; they were selected
   based on their effectiveness of the intervention results: high (three
   groups) or low (two groups) and individual interviews to two GP of low
   efficiency. The Consolidated Framework for Implementation Research
   (CFIR) was used to guide collection and analysis of qualitative data.
   Two researchers evaluated the qualitative data of the focus groups by
   the Codebook and Rating Rules of CFIR, independently. Results: Of the 31
   CFIR constructs assessed, three constructs strongly distinguished
   between GPs with low versus high success of the intervention
   (intervention complexity, individual state of change, key stakeholders
   engaging), seven additional constructs weakly distinguished
   (adaptability, external policy and incentives, implementation climate,
   compatibility, relative priority, self-efficacy, formally appointed
   internal implementation leaders), 10 had insufficient data to assess and
   11 were non-related to the success of the intervention. Conclusion: We
   identified the constructs that explain the variation in the
   effectiveness of the intervention; this information is relevant to
   redesign successful implementation strategies focused on these
   constructs to implement the BENZORED intervention in health services.
   Background: Despite recommendations against long-term benzodiazepine
   (BZD) use, they are often prescribed during months or years in primary
   care. Research question: To evaluate the effectiveness of a primary care
   educational and feedback intervention targeted to general practitioners
   (GPs) to reduce BZDs prescriptions. Methods: Design: A two-arm parallel
   cluster randomized clinical trial. Settings: Primary Healthcare centres
   from three health districts of Spain: Balearic Islands (IbSalut),
   Catalonia (Institut Catala de la Salut; Tarragona-Reus district) and
   Community of Valencia (Conselleria de Salut Universal; Arnau de Vilanova
   lliria district). Participants: All GPs from the health districts
   included were invited to participate. Ninety percent of the GPs accepted
   to participate. Intervention: GPs received an educational two hours
   workshop training about the rationale for prescribing BZDs and
   deprescribing strategies for long-term BZD users, audit and monthly
   feedback about their prescription and access to a support web page with
   information to help them and leaflets to give to the patients. Control
   group: GPs did not receive any component of the intervention. Outcomes:
   Defined daily dose (DDD)/1000 inhabitants/year (DHD) of BZDs prescribed
   by GP at 12 months. Proportion of long-term BZD users (>6 months) and in
   patients aged 65 or more at 12 months. Statistical analysis: Generalized
   mixed linear random effect models to account for clustering at the level
   of healthcare centre and all analyses were based on an intention to
   treat principle. Results: We included 749 GPs and 49 (6.5%) were lost to
   follow-up. Adjusted difference between groups in DHD at 12 months was
   -3.26 (-4.87;-1.65), p<.001. The differences in the proportion of
   long-term BZD users was -0.39 (-0.58;-0.19), p<.001 and in patients
   older than 65 was -0.87 (-1.35;-0.26), p=.004. Conclusion: An
   educational and feedback intervention targeted to GPs is effective to
   reduce BZD prescription in primary care.
   Background: Patients who might also go to the general practitioner (GP)
   frequently consult emergency departments (ED). This leads to decreased
   efficiency, high workload at the ED and additional costs for both
   government and patient. Research question: The primary outcome is the
   proportion of patients who enter the ED and are handled by the GP after
   triage. Secondary outcomes: Referral rate to the ED by the GP,
   proportion of patients not following the triage advice, compliance of
   the nurse to the triage-instructions and health insurance expenditures.
   Furthermore, facilitators and barriers will be studied and an incident
   analysis will be performed. Methods: This is a randomised controlled
   trial with weekends serving as clusters. Patients presenting at the ED
   during OOH are triaged and allocated to either ED or GP by a trained
   nurse using an extension to the Manchester Triage System (MTS). During
   control clusters, all patients remain at the ED. Data are collected
   using a database for OOH care (iCAREdata). Results: So far, 296 out of
   2733 (11%) patients were allocated to the GP. Two-thirds (194) of these
   patients did go to the GP leading to a primary outcome of 7% for 14
   intervention weekends. Only eight patients were referred back to the ED.
   Compliance of the nurse to the extended MTS was 93%, in 6% of the cases
   the nurse chose ED instead of GPC and in less than one percent GPC
   instead of ED. The nurses chose higher urgency categories and more
   discriminators, leading to the GP during intervention clusters. Using an
   automated system, these results are updated weekly, on our poster, we
   will show more results that are complete. Conclusion: These first
   results reveal a low efficiency but a high safety of the intervention.
   More prolonged data collection combined with a process analysis and cost
   efficiency study is necessary before definitive conclusions can be
   drawn.
   Background: Low back pain is a multifactorial condition with individual
   and societal impact. Psychosocial factors play a larger prognostic roll.
   Therefore, earlier multidisciplinary treatment strategy (physical,
   psychological and social/occupational) could be applied to search
   improvement in fear-avoidance beliefs with positive effect in the
   evolution of low back pain. Research question: Evaluate the
   effectiveness of a biopsychosocial multidisciplinary intervention
   (physiotherapy, cognitive-behavioural and pharmacological therapy)
   through the changes in fear-avoidance beliefs (FABs), in working
   population with sub-acute non-specific LBP, compared to usual clinical
   care at 3 and 12 months. Methods: A cluster randomised clinical trial,
   conducted in 39 Primary Health Care Centres (PHCC) in Barcelona.
   Participants between 18 and 65 years old (n = 369; control group =188,
   PHCC 26 and intervention group =181, PHCC 13). Control group received
   usual care, according to guidelines. Intervention group received usual
   care plus a biopsychosocial multidisciplinary intervention (sessions 10
   hours/total). The main outcome was the Fear-Avoidance Beliefs
   questionnaire (FABQ). Other outcomes: Evolution to chronicity.
   Assessment at baseline, 3 and 12 months. Analysis was by intention to
   treat and analyst blinded. Multiple imputations. Results: Of the 369
   enrolled patients with LBP, 421 (84.0%) provided data at the three
   months of follow-up, and 387 (77.2%) at 12 months. Mean age of study
   subjects at baseline was 45.1 (SD: 10.4) years-old and 61.2% were women.
   At baseline, there were no differences. Both groups showed a decrease in
   FABQ (FAB physical and FAB-work) at three months and twelve months, with
   a significant difference at long-term. At FAB-physical performance,
   there was no significant difference over the follow-up time and at
   FAB-Work, a substantial difference at 12 months between groups.
   Conclusion: A multidisciplinary biopsychosocial intervention showed a
   positive effect in FABs by improving fear behaviours and avoidance at
   work.
   Community participation in primary healthcare is enshrined in
   international policies since the 1970s and has been re-emphasised since
   then, most recently in the 2018 WHO Astana Declaration (). The concept
   comes from a social justice perspective. It emphasises that the
   participation of communities who experience poverty and social exclusion
   is essential to the development of primary health care services shaping
   these services and making them relevant to those with the greatest need.
   This is important if we are to address the well-documented Inverse Care
   Law. There is, however, a translational gap between policy and practice.
   The stability of policies for community participation in primary
   healthcare is patchy. The implementation of policies into conventional
   ways of working is patchy. Where implementation has occurred, the
   coverage of community participation initiatives can be patchy - not all
   community members are involved. The literature shows a pattern of
   exclusion whereby so-called 'hard to reach' groups are not adequately
   involved in primary healthcare decision-making. This is the case for
   refugees and migrants who arrive to settle and integrate into host
   countries in Europe. The recent WHO Strategy and Action Plan for Refugee
   and Migrant Health (2016; ) is a call for action to disrupt this pattern
   of exclusion and improve the health of refugees and migrants. Drawing on
   the rich tradition of participatory health research is a valuable way
   forward because it provides important concepts, tools and techniques for
   research that is more inclusive and primary care practice. This
   presentation will describe innovative examples of success in family
   practice settings from around Europe. These have brought together
   refugees and migrants with primary care stakeholders and enabled them to
   work together to introduce and sustain changes in clinical practice.
   This evidence can be used to guide and strengthen community
   participation in primary healthcare, for all.
   Background: Community participation is essential for effective
   implementation of research programmes in primary healthcare (PHC) but
   also appropriate interpretation of results and optimal delivery of
   subsequent care. Stakeholder engagement undertaken under defined and
   evaluated frameworks may be key for the establishment of concrete
   collaboration and communication between communities and other parties
   involved in research. This abstract aims to report on community and
   stakeholder engagement methodologies, plans and activities of European
   research projects conducted in Crete, Greece. Research question: Could a
   consensus be reached regarding the methods and tools for enhancing
   stakeholder engagement in community-oriented PHC research? Methods:
   Examined programmes included RESTORE (FP7), FRESH AIR (Horizon2020) and
   VIGOUR (Health Programme). Identified methodologies included
   Normalisation Process Theory, Participatory Learning and Action, Five
   Steps of Stakeholders' Engagement, establishment of Stakeholder
   Engagement Groups under the 9 C's model (commissioners, customers,
   collaborators, contributors, channels, commentators, consumers,
   champions, competitors) and Structured Democratic Dialogue. These were
   implemented to a range of stakeholders, including community members,
   patients, migrants, Roma populations, healthcare professionals and
   policy-makers. Qualitative research (focus groups, individual
   interviews) and Thematic Content Analysis were used for design and
   analysis of engagement activities. Results: In RESTORE, migrants and
   other stakeholders selected guidelines and training supporting
   cross-cultural communication in PHC consultations, based on their own
   needs and expectations. Community members, healthcare professionals and
   healthcare authorities were actively involved in FRESH AIR by
   identifying local priorities and contextual factors for designing
   project interventions, providing access to communities and supporting
   dissemination of project achievements. In VIGOUR, multidisciplinary
   stakeholders were brought together and formulated a joint ambition
   statement for the future of integrated care in Crete. Conclusion:
   Various stakeholder engagement methods with documented effects are
   currently available. Their systematic identification, appraisal,
   synthesis and consolidation may serve with enhancing community
   participation in PHC, sustaining research results and translating
   findings into appropriate actions.
   Background: Screening for prostate cancer remains controversial,
   implying a trade-off between benefits and harms, and a shared
   decision-making process has been advocated. Decision aids are
   evidence-based tools that improve decision quality. For limited-resource
   countries, translating and making cultural adaptations to high-quality
   decision aids is a reasonable alternative to developing new ones.
   Research question: We aimed to translate and culturally adapt an English
   language patient decision aid addressing prostate cancer screening, so
   that Portuguese men can use it. Methods: We followed the European Centre
   for Disease Prevention and Control's (ECDC) five-step, stakeholder-based
   approach to adapting health communication materials: (1) selection of
   materials and process coordinators; (2) early review; (3) translation
   and back translation; (4) comprehension testing with cognitive
   semi-structured interviews; (5) proofreading. Cognitive interviews were
   conducted with 15 men, ages 55-69, from the Oporto district local
   community to refine the decision aid after its translation. Content
   analysis was performed using Ligre (TM) software. Results: Five main
   themes are presented: informational content, information comprehension,
   socio-cultural appropriateness, feelings and primary message, and
   personal perspective concerning prostate cancer screening. For each
   theme, illustrative quotes extracted from men's interviews are
   presented. Most men found the translated version of the decision aid to
   be clear, comprehensive and appropriate for its target population,
   albeit some suggested that medical terms could be a barrier. The data
   collected from men's interviews allowed the researchers to clarify
   concepts and expand existing content. Conclusion: The final version of
   the decision aid can be used in the real world clinical setting and our
   ECDC based approach can be replicated by other workgroups to translate
   and culturally adapt decision aids.
   What are we talking about when we talk about value? In 2006, Michael
   Porter and Elizabeth O. Teisberg published; Redefining Health Care,
   Creating Value-Based Competition on Results, Harvard Business School
   Press. Affirming that payers and providers, including doctors and
   nurses, are very concerned in demonstrating that they work a lot, and
   very little, or nothing, in assessing what their work contributes to the
   health of people and communities. Michael Porter is famous in the
   business world for his work on competitiveness based on the value of
   products and services. He has introduced this concept in the provision
   of health services, all summarised in a phrase: Health systems should
   seek to obtain the maximum possible value for the health of people for
   every dollar they spend. However, to define the value in healthcare, the
   patient must be introduced into the equation, so, in Porterian terms,
   the value is the perception that people have about clinical
   effectiveness and the costs of therapeutic processes. Clinical
   effectiveness is measurable from epidemiology (to be readmitted to a
   hospital fewer times or living longer); value, on the other hand, is
   reflected by people's experience. We need to ask questions such as do
   patients with advanced diseases want to live longer, or they want to
   enjoy the highest quality of life possible. Depending on the response,
   we can develop different delivery models. What is value-based
   healthcare? According to NEJM Catalyst, Value-based healthcare is a
   healthcare delivery model in which providers, including hospitals and
   physicians, are paid based on patient health outcomes (). Under
   value-based care agreements, providers are rewarded for helping patients
   improve their health, reduce the effects and incidence of chronic
   disease, and live healthier lives in an evidence-based way. How to
   achieve a Value-Based Healthcare Model The following six drivers are the
   key to make a primary health care system a value-based healthcare model:
   1. Prioritising patient-centred care. 2. From clinical pathways to care
   delivery value chains. 3. Promoting the right care and reducing medical
   overuse. 4. Turning a fragmented model into another integrated model. 5.
   Creating the enabling environment for healthcare transformation. 6.
   Fostering community health. How to develop a Value-Based Community
   Health Michael Marmot states that if the determinants of health are
   mostly social, solutions must also be social, so to improve the quality
   of community life, political systems require economic, housing,
   education, security and infrastructure programs (Am J Public Health.
   2014;104:S517-S519). Nevertheless, the healthcare system must know how
   to adjust resources according to the social circumstances of each
   community and to understand how to provide a health-oriented vision of
   all the social programs. On the other hand, community health is an
   intervention model that aims to improve the health of a defined
   community that should operate from primary care services to adjust their
   actions to the social reality of each territory.
   Background: Geriatric care needs to be increased with growing elderly
   populations. The Borgholm jurisdiction in the Baltic Island of oland
   (Kalmar region) has an older than average senior population and had
   difficulties recruiting primary care physicians (PCPs) resulting in high
   elderly hospital care consumption. Research question: Could a new model
   of geriatric care be able to decrease the hospital care needs of
   Borgholm as compared to the rest of Kalmar region? Methods: A new model
   of care was developed in Borgholm 2016-2017 where the PCP list was
   limited to 1000 patients, daily slots for PCP home care visits could be
   booked by community nurses or ambulance nurses and PCPs had daily
   anticipatory care planning contacts with Kalmar hospital staff. Results:
   Between 2014 and 2018, Borgholm home care patients >75 years old
   increased by 70% vs. a 2% decrease for the rest of Kalmar region.
   Similarly, Kalmar emergency department visits decreased by 19% in
   Borgholm vs. 9% increase for the rest of Kalmar. Also, Kalmar hospital
   care episodes decreased 7% in Borgholm vs. 13% increase for the rest of
   Kalmar; Kalmar hospital outpatient visits decreased 8% in Borgholm vs.
   21% increase for the rest of Kalmar; total care consumption for >75
   years old decreased 4% in Borgholm vs. a 10% increase for the rest of
   Kalmar region. Conclusion: A new geriatric care model consisting of a
   comprehensive collaboration between strengthened primary care and
   community care, hospital care and ambulance care was associated with a
   reduction in total care consumption for senior citizens in a rural
   Swedish jurisdiction.
   Background: Primary health care, the general practitioner, plays a
   critical role for early identification and care of patients with
   dementia. Early diagnosis of dementia allows starting therapy and
   improving the quality of life of the patients. Research question: To
   estimate the prevalence and care of patients with dementia in North
   Macedonia. Methods: Forty-six general practitioners (GPs) surgeries from
   20 cities in Macedonia took part in the project. All individuals age
   over 65 years with a diagnosis of dementia were identified from GP
   electronic disease registers. Results: Based on the diagnosis, 450
   (3.5%) patients were identified from a total population of 12,926 over
   65s. The most common dementia was Alzheimer's dementia 294 (65.3%)
   followed by vascular dementia 27.11%. The average age of respondents in
   the study was 77.5 +/- 8.2 years, with 50% patients under the age of 79
   years, 65.6% were female and 68.4% were with elementary school. In the
   entire sample, most of the patients diagnosed with dementia 195 (43.3%)
   said they lived with another family member. The most common risk factor
   was hypertension (85.1%), followed by stroke/ transitory ischemic
   attacks (29.3%) and equal percentage, i.e. 26.4% of patients had high
   levels of cholesterol and diabetes. To 242 (53.8%) acetylcholinesterase
   inhibitors were prescribed (donepezil, rivastigmine, galantamine), 77
   (17.1%) memantine, while 247 (54.9%) another OTC therapy. 227 (50.4%)
   reported that they did not receive treatment. An additional analysis of
   the reasons for not receiving treatment was made on this sample of
   patients who did not receive treatment. It was found that in the
   majority of these patients (more than 50%) the reason for not receiving
   therapy was that it was not prescribed, in 142 (62.6%). Conclusion: This
   is the first national representative study of dementia prevalence in
   North Macedonia. Those data can provide information for healthcare needs
   people with dementia.
   Background: Emotional experience for medical students during clinical
   internships is often ignored. Yet, its influence on professional skills
   is certain. Research question: 'What is the emotional experience of
   second and third-year medical students during their first clinical
   internship? How do they perceive the management of their experience by
   their supervisors?' Methods: A qualitative study was conducted with 12
   students in their second or third year of medical training at the
   University of Lille, in France, between 2016 and 2019. Interviews were
   carried out comprehensively for a total of 17 hours. Following a
   grounded theory approach, the analysis terminated when data were
   sufficient to offer a conclusive model. Results: Emotional experience
   during clinical internship was rich and intense. It was most often
   ignored and was not taken into account in the development of
   professional skills. The organized management was deficient. Informal
   training existed: when a wilful student met a dedicated teacher.
   Students would have welcomed a possibility to experience intense
   emotions in a protective environment, and only then in an empowering
   environment. They expressed the same desire about early exchanges on the
   experiences of the internship. A modelling of the informants' emotional
   experiences was realized in the form of three diagrams. Conclusion:
   Students ask to be challenged to face patients, and then to be listened
   to about it. Possible interventions are trauma prevention and detection
   of malaise in the workplace; teaching of humanist values; providing
   experience and reflexivity through new pedagogical means (such as
   cinema, theatre, literature, writing), or relational means (such as
   exchange groups, companionship, solidarity commitment, immersive
   internships and tutoring); and training supervisors.
   Background: Oral anticoagulants (OAC) reduce the risk for stroke and
   death from all causes in patients with non-valvular atrial fibrillation
   (NVAF). Research question: To explore adherence rates to OAC among
   patients with NVAF and to compare head-to-head adherence rate of
   different medications in long-term chronic use. Methods: We conducted a
   population-based cohort study Clalit Health Services, Israel. All
   patients, 30 years and over, with a diagnosis of NVAF before 2016 and
   were treated with OAC were included. We included patients that filled at
   least one prescription per year in the three consecutive years
   2016-2018. We analysed all prescriptions that were filled for the
   medications from 1 January 2017 to 31 December 2017. We considered
   purchasing of at least nine monthly prescriptions during 2017 as 'good
   medication adherence.' Results: Twenty-six thousand and twenty-nine
   patients with NVAF who were treated with OAC were identified. Ten
   thousand and two hundred and eighty-four (39.5%) were treated with
   apixaban, 6321 (24.3%) were treated with warfarin, 6290 (24.1%) were
   treated with rivaroxaban 3134 (12.0%) were treated with dabigatran.
   Rates of good medication adherence were 88.9% for rivaroxaban, 84.9% for
   apixaban, 83.6% for dabigatran and 55.8% for warfarin (p<.0001). Good
   adherence with OAC was associated with lower LDL cholesterol and glucose
   levels. Advanced age was associated with higher adherence rates
   (p<.001). SES was not associated with medication adherence. Conclusion:
   Adherence rates to DOAC among patients with NVAF are high and are higher
   than the adherence rate to warfarin. It should be taken into
   consideration when choosing OAC treatment for NVAF.
   Background: In France, cervical cancer screening by pap-smears should be
   conducted triennially. Screening statistics are based on the number of
   cytology examinations of smears reimbursed by the Health Insurance
   appearing in the claim databases. The percentage of screened women is
   lower based on these data than on declarative surveys. If surveys are
   overestimating the number of screened women, it is likely that claim
   databases underestimate it. Research question: The primary objective was
   to determine the underestimation of screened women in claim databases.
   The secondary purpose was to estimate the proportion of female patients
   not reachable by their GP for a cervical cancer screening in an
   organized screening trial. Methods: The population was the 6327 female
   patients aged 30-65 years of the 24 GP investigators of the PaCUDAHL-Ge
   trial. We compared the lists of their female patients that had no
   cytology of Pap test reimbursed during the three prior years, extracted
   from the Health Insurance claim databases in 2015 and 2018. We selected
   the patients appearing on both lists meaning they had not responded to
   the invitation of their GP to be screened in the trial. We searched in
   the GPs' records valid reasons not to be screened (hysterectomy, history
   of cervical lesion, pregnancy, other conditions making screening
   irrelevant) or evidence of screening. Results: The total number of
   'unscreened' women in 2018 was 2731, 1737 patients appeared on both
   lists, 1522 could be included for analysing, 65 had been screened, 95
   had hysterectomy, three had a history of cervical lesion, nine were
   pregnant and 10 had other conditions making screening irrelevant, 166
   patients were lost to view. Conclusion: Based on GPs' records, health
   insurance claim databases underestimate the number of screened women by
   7.6%. The percentage of patients not responding to the invitation of
   their GP to be screened in the PaCUDAHL-Ge trial is 24.18%.
   Background: Over the past decade, the amount of digital data created by
   humans with or without connected tools has grown exponentially. The
   field of primary care (PC) did not escape this digitization, nor the use
   of Big Data algorithms. To evaluate the results of Big Data research in
   PC it seemed useful to identify which algorithms are used. Research
   question: What are the algorithms used for Big Data research in PC
   research and how are they described? Methods: Systematic review of the
   literature according to the recommendations of the PRISMA guide. A
   search equation using the following MeSH terms 'big data, data mining,
   Algorithms, Artificial Intelligence, Machine learning, Deep Learning,
   Neural Networks Natural Language Processing, general practice,
   electronic health records, health records' has been applied to the
   PUBMED database. After a selection of the titles and article summaries
   according to the inclusion criteria, the full versions of the eligible
   articles were read and analysed. Referenced articles of the sources
   articles were added to the analysis. The algorithms described in the
   articles were extracted and analysed. Results: In total, 778 articles
   were identified, 169 were eligible for full reading and 26 articles were
   finally selected. The algorithms listed in the articles are poorly
   described. The description is usually limited to a general explanation
   about how the algorithm works. Seven articles gave a partial description
   of the algorithm; a logic diagram was given in four articles and the
   codes in only two. Actually, only one article fully describes the
   algorithm with its mathematical description, its code and its logic
   diagram. Conclusion: Big Data algorithms in PC are not satisfactorily
   described. The lack of reproducibility is not compatible with a
   consistent scientific approach. Researchers should provide more
   information about the way they extract and analyse their data to give
   their readers more confidence in Big Data.
   Background: As a collaborative project of the Family Practice Depression
   and Multimorbidity group of European General Practice Research Network,
   the Hopkins Symptom Checklist-25 (HSCL-25) scale was identified as
   valid, reproducible, effective and easy to use. Subsequently, it has
   been translated and adapted to 13 languages, including Castilian.
   Currently, the scale is being validated in different languages. Research
   question: What are the psychometric properties of the Spanish version of
   HSCL-25 (HSCL-25e) for depression detection in Primary Care? Methods:
   HSCL-25e was administered to outpatients recruited by their physicians
   in six health centres involved in Spanish EIRA3 study, a trial to
   promote healthy behaviours in people aged from 45 to 75. Patients
   complimented HSCL-25 themselves. Sample size was calculated with R
   package (pROC). Statistical analysis: responsiveness was analysed with
   missing data and detecting ceiling and floor effects for the items.
   Principal component analysis (PCA) was done to determine the dimensions
   of HSCL-25e. Item-total correlation, Cronbach's alpha (global and
   dimensions coefficient) and squared multiple correlation were carried
   out to calculate internal consistency. Results: Seven hundred and
   sixty-nine patients out of 806 complimented HSCL-25e, 738 answered to
   all of the items. No patterns of missing answers were found. No ceiling
   effects, expected floor effect in item 18. Item 17 was the most
   consistent one and item 24 was the lower one. All items showed positive
   discrimination index for both cut-off points (1.55 and 1.75). PCA
   indicated two factors; 13 items corresponding to depression dimension
   and the other 12 items corresponding to anxiety subscale. Global
   Cronbach's alpha was 0.92 (0.88 calculated for depression dimension and
   0.84 for anxiety dimension). Conclusion: The HSCL-25e has excellent
   psychometric properties when applied to Primary Care population. It has
   two dimensions as the original version, although the items included are
   not exactly the same. There are more item coincidences with the French
   version.
   Background: Cardiovascular diseases (CVDs) are the first mortality cause
   worldwide with 17.5 million death in 2012. Spices (Scaling-up Packages
   of Interventions for CVD prevention in selected sites in Europe and
   Sub-Saharan Africa) gathered five countries around CVD primary
   prevention interventions, especially for populations with low access to
   prevention and health care system. In France, a rural area where people
   were more deprived and with a low settlement of general practitioners
   (GPs) fitted with the project. Research question: What are the barriers
   and the facilitators for cardiovascular primary prevention
   implementation from caregivers and patients' point of view of a deprived
   rural area? Methods: Semi-structured interviews were conducted until
   theoretical saturation of data. Purposive samplings of GPs, patients,
   patients' families, nurses and pharmacists were designed. Five interview
   guides explored cardiovascular prevention, cardiovascular health
   promotion in the setting, actors of CVD prevention, capacities for CVD
   prevention, patients' and healthcare professionals' representations,
   barriers and facilitators in implementing CVD prevention, possible
   solutions. Guides were adapted concurrently to the analysis. A blinded
   thematic analysis and a mind-mapping were achieved for each group.
   Results: Thirteen GPS, 11 pharmacists', 14 nurses, 12 patients' and 12
   patients' family members' interviews were achieved. Professionals
   highlighted a disconnection between them and national prevention
   programs, lack of time, payment and training for CVD prevention.
   Countryside was either protective or aggressive regarding CVD risk
   balancing gardening and space against isolation and lack of structures.
   GPs had poor connections with the community. Patients described their
   recklessness and feeling of invulnerability until their CVD appeared.
   Families could be a barrier to CVD prevention and lifestyle change.
   Risky behaviours were handed down from one generation to another.
   Conclusion: Innovative interventions for Spices should focus on these
   community specificities and individual behavioural strategies in
   contrast with the six national plans addressing CVD in France. These
   plans solely concentrate on dissemination of prevention messages and
   knowledge, which is of little use according to this survey.
Z8 0
TC 0
ZS 0
ZR 0
ZB 0
Z9 0
SN 1381-4788
EI 1751-1402
UT WOS:000517857100001
ER

PT J
AU Cheng, Qianshun
   Wang, HaiYing
   Yang, Min
TI Information-based optimal subdata selection for big data logistic
   regression
SO JOURNAL OF STATISTICAL PLANNING AND INFERENCE
VL 209
BP 112
EP 122
DI 10.1016/j.jspi.2020.03.004
PD DEC 2020
PY 2020
AB Technological advances have enabled an exponential growth in data
   volumes, and proven statistical methods are no longer applicable for
   extraordinary large data sets due to computational limitations. Subdata
   selection is an effective strategy to address this issue. In this study,
   we investigate existing sampling approaches and propose a novel
   framework of selecting subsets of data for logistic regression models.
   We show that, while the information contained in the subdata based on
   random sampling approaches is limited by the size of the subset, the
   information contained in the subdata based on the new framework
   increases as the size of the full data set increases. Performances of
   the proposed approach and those of other existing methods are compared
   under various criteria via extensive simulation studies. (C) 2020
   Elsevier B.V. All rights reserved.
ZB 0
Z8 0
ZR 0
TC 0
ZS 0
Z9 0
SN 0378-3758
EI 1873-1171
UT WOS:000531526500009
ER

PT J
AU Garrett, Brandon L.
TI DECLINING CORPORATE PROSECUTIONS
SO AMERICAN CRIMINAL LAW REVIEW
VL 57
IS 1
BP 109
EP 155
PD WIN 2020
PY 2020
AB In the aftermath of the Global Financial Crisis, people across the
   United States protested that "too big to jail" banks were not held
   accountable after the financial crisis. Little has changed. Newly
   collected data concerning enforcement during the Trump Administration
   has made it possible to assess what impact a series of new policies has
   had on corporate enforcement. To provide a snapshot comparison, in its
   last twenty months, the Obama Administration levied $14.15 billion in
   total corporate penalties by prosecuting seventy-one financial
   institutions and thirty-four public companies. During the first twenty
   months of the Trump Administration, corporate penalties declined to $3.4
   billion in total penalties, with seventeen financial institutions and
   thirteen public companies prosecuted. These trends build over time. In
   each year, blockbuster cases come and go, creating swings in fines.
   However, consistent with these data, this Article describes changes in
   written policy, practice, and informal statements from the Department of
   Justice that have cumulatively softened the federal approach to
   corporate criminals. This Article also describes continuity between
   administrations. A rise in corporate declinations, for example,
   represents a continuation of Obama Administration policy. A decline in
   use of corporate monitors similarly reflects prior policy. The steady
   and low level of individual charging in corporate cases reflects an
   ongoing lack of success in efforts to prioritize individual
   prosecutions, exemplified by the 2015 "Yates Memo." That policy, like
   others, has been formally relaxed. The series of DOJ corporate
   prosecution policy changes has also been accompanied by institutional
   shifts. For example, high-level vacancies within the DOJ and other
   enforcement agencies may compromise ability to coordinate resolution of
   complex cases. This Article concludes by proposing structural changes,
   such as independent corporate enforcement functions, to enhance capacity
   and prevent pendulum shifts in enforcement. How we handle corporate
   crime goes to the root of power imbalances in the economy that produced
   the financial crisis. If we still have not learned the lessons of the
   last financial crisis, the next one cannot be far ahead.
ZS 0
ZB 0
TC 0
Z8 0
ZR 0
Z9 0
SN 0164-0364
UT WOS:000510955600004
ER

PT J
AU Lee, JooChul
   Wang, HaiYing
   Schifano, Elizabeth D.
TI Online updating method to correct for measurement error in big data
   streams
SO COMPUTATIONAL STATISTICS & DATA ANALYSIS
VL 149
AR UNSP 106976
DI 10.1016/j.csda.2020.106976
PD SEP 2020
PY 2020
AB When huge amounts of data arrive in streams, online updating is an
   important method to alleviate both computational and data storage
   issues. The scope of previous research for online updating is extended
   in the context of the classical linear measurement error model. In the
   case where some covariates are unknowingly measured with error at the
   beginning of the stream, but then are measured without error after a
   particular point along the data stream, the updated estimators ignoring
   the measurement error are biased for the true parameters. Once the
   covariates measured without error are first observed, a method to
   correct the bias of the estimators, as well as to correct the biases in
   their variance estimator, is proposed; after correction, the traditional
   online updating method can then proceed as usual. Further, asymptotic
   distributions for the corrected and updated estimators are established.
   Simulation studies and a real data analysis with an airline on-time
   dataset are provided to illustrate the performance of the proposed
   method. (C) 2020 Elsevier B.V. All rights reserved.
ZB 0
Z8 0
TC 0
ZR 0
ZS 0
Z9 0
SN 0167-9473
EI 1872-7352
UT WOS:000531596000005
ER

PT J
AU Jiang, Guoyin
   Shang, Jennifer
   Liu, Wenping
   Feng, Xiaodong
   Lei, Junli
TI Modeling the dynamics of online review life cycle: Role of social and
   economic moderations
SO EUROPEAN JOURNAL OF OPERATIONAL RESEARCH
VL 285
IS 1
BP 360
EP 379
DI 10.1016/j.ejor.2020.01.054
PD AUG 16 2020
PY 2020
AB Online review system (ORS) can unite members who share similar interests
   in topic discussion or knowledge exchange that entails dynamics and
   complexity. In this work, we propose a multiagent system to replicate
   the evolution of social bonds and online reviews in ORS. To validate the
   proposed method, we use big data from a real-world ORS collected over a
   period of 153 months. Results show that the proposed agent-based model
   can accurately predict the construction of bonds and the volumes of
   online reviews. Moreover, social moderation, economic moderation, and
   the combined moderating mechanism can motivate ORS members to post
   reviews. The stage (phase) of the review life cycle and the degree of
   moderation significantly impact the effectiveness of the mechanisms.
   Depending on the stage of the review life cycle, social and economic
   moderators have different degrees of success in generating online
   reviews. In the early stage, economic moderation is effective, whereas
   social moderation works better in the late stage. When the moderating
   levels are medium or high, the combined social and economic moderation
   is much better than the stand-alone mechanism. Although social bonds are
   positively associated with more posting, none of the moderating
   mechanisms (economic, social, or combined) can significantly enhance the
   bond. To manage ORS effectively, managers need to switch from the
   conventional static view (relying on single theory) to the dynamic view.
   In addition, they should incorporate social exchange, motivation, and
   social network concepts at different stages of the ORS life cycle. (C)
   2020 Elsevier B.V. All rights reserved.
ZR 0
Z8 0
ZB 0
TC 0
ZS 0
Z9 0
SN 0377-2217
EI 1872-6860
UT WOS:000527279400027
ER

PT J
AU Pramanik, Md Ileas
   Lau, Raymond Y. K.
   Azad, Md Abul Kalam
   Hossain, Md Sakir
   Chowdhury, Md Kamal Hossain
   Karmaker, B. K.
TI Healthcare informatics and analytics in big data
SO EXPERT SYSTEMS WITH APPLICATIONS
VL 152
AR 113388
DI 10.1016/j.eswa.2020.113388
PD AUG 15 2020
PY 2020
AB Healthcare informatics and analytics (HCI&A), also known as healthcare
   information technology (HIT), healthcare IS (HIS), and so on, has
   rapidly evolved with the emerge of advanced data analytics technologies
   applied to the medical domain. Currently, HCI&A has emerged as an
   important area of study for both practitioners and academic researchers.
   Accordingly, this emerging field has prompted for an inquiry of the
   opportunities and challenges related to management of healthcare data,
   and the application of advanced data analytics to the contemporary
   healthcare industry. In order to contribute to the literature of
   healthcare informatics and analytics, this study proposes an HCI&A
   framework under the context of big data, which covers four important
   segments such as the underlying technologies, system applications,
   system evaluations, and emerging research areas. Based on the key
   features and capabilities of underpinning technologies, the evolution of
   HCI&A are conceptualized by three stages, namely HCI&A 1.0, HCI&A 2.0,
   and HCI&A 3.0. By analyzing the technological growth and current
   research trends, this study outlines the trend map of HCI&A for
   education and knowledge transfer. We also contributed to conduct a
   bibliographic study on healthcare informatics and healthcare information
   systems. To the best of our knowledge, our study is among the very few
   comprehensive bibliographic studies about HCI&A. We hope that our study
   can contribute to supplement contemporary thoughts on HCI&A research,
   and facilitate the related knowledge transfer to the healthcare
   industry. (C) 2020 Elsevier Ltd. All rights reserved.
ZR 0
ZS 0
TC 0
ZB 0
Z8 0
Z9 0
SN 0957-4174
EI 1873-6793
UT WOS:000532801200018
ER

PT J
AU Huarng, Kun-Huang
   Yu, Tiffany Hui-Kuang
TI A comparative study of online consumer behavior: a tale of two research
   methods
SO INTERNATIONAL JOURNAL OF EMERGING MARKETS
VL 15
IS 4
BP 716
EP 727
DI 10.1108/IJOEM-06-2019-0417
PD AUG 10 2020
PY 2020
AB Purpose
   The use of linear regression analysis is common in the social sciences.
   The purpose of this paper is to show the advantage of a qualitative
   research method, namely, structured qualitative analysis (SQA), over the
   linear regression method by using different characteristics of data.
   Design/methodology/approach
   Data were gathered from a study of online consumer behavior in Taiwan.
   The authors changed the content of the data to have different sets of
   data. These data sets were used to demonstrate how SQA and linear
   regression works individually, and to contrast the empirical analyses
   and empirical results from linear regression and SQA.
   Findings
   The linear regression method uses one equation to model different
   characteristics of data. When facing a data set containing a big and a
   small size of different characteristics, linear regression tends to
   provide an equation by modeling the characteristics of the big size data
   and subsuming those of the small size. When facing a data set containing
   similar sizes of data with different characteristics, linear regression
   tends to provide an equation by averaging these data. The major concern
   is that the one equation may not be able to reflect the data of various
   characteristics (different values of independent variables) that result
   in the same outcome (the same value of dependent variable). In contrast,
   SQA can identify various variable combinations (multiple relationships)
   leading to the same outcome. SQA provided multiple relationships to
   represent different sizes of data with different characteristics so it
   created consistent empirical results.
   Research limitations/implications
   Two research methods work differently. The popular linear regression
   tends to use one equation to model different sizes and characteristics
   of data. The single equation may not be able to cover different
   behaviors but may lead to the same outcome. Instead, SQA provides
   multiple relationships for different sizes of data with different
   characteristics. The analyses are more consistent and the results are
   more appropriate. The academics may re-think the existing literature
   using linear regression. It would be interesting to see if there are new
   findings for similar problems by using SQA. The practitioners have a new
   method to model real world problems and to understand different possible
   combinations of variables leading to the same outcome. Even the
   relationship obtained from a small data set may be very valuable to
   practitioners.
   Originality/value
   This paper compared online consumer behavior by using two research
   methods to analyze different data sets. The paper offered the
   manipulation of real data sets to create different data sizes of
   different characteristics. The variations in empirical results from both
   methods due to the various data sets facilitate the comparison of both
   methods. Hence, this paper can serve as a complement to the existing
   literature, focusing on the justification of research methods and on
   limitations of linear regression.
ZB 0
ZS 0
Z8 0
TC 1
ZR 0
Z9 1
SN 1746-8809
EI 1746-8817
UT WOS:000528234800005
ER

PT J
AU Yao, Rui
   Gao, Cunyuan
   Xia, Shixiong
   Zhao, Jiaqi
   Zhou, Yong
   Hu, Fuyuan
TI GAN-based person search via deep complementary classifier with
   center-constrained Triplet loss
SO PATTERN RECOGNITION
VL 104
AR 107350
DI 10.1016/j.patcog.2020.107350
PD AUG 2020
PY 2020
AB This paper addresses the person search task, which is a computer vision
   technology that finds the location of a pedestrian and retrieves it in a
   video taken by a single camera or multiple cameras. This task is much
   more challenging than the conventional settings for person
   re-identification or pedestrian detection since the search is
   susceptible to factors such as different resolutions, similar
   pedestrians, lighting, viewing angles and occlusion. Moreover, the
   person search task is a typical big data-small sample problem because
   each pedestrian only has a few images. It is difficult for the model to
   learn the discriminant features of pedestrians with a small quantity of
   pedestrian data. This paper proposes a framework for person search that
   uses the original training set without collecting extra data by
   implementing a generative adversarial network (GAN) to generate
   unlabeled samples. We propose a deep complementary classifier for
   pedestrian detection to leverage complementary object regions for
   pedestrian/non-pedestrian classification. In the re-identification
   section, we propose a center-constrained triplet loss that avoids the
   complicated triplet selection of the triplet loss and simultaneously
   pushes away all the distances of rather similar negative centers and the
   positive center. Experiments show that the GAN-generated data can
   effectively help to improve the discriminating ability of the CNN model.
   On the two large-scale datasets, CUHK-SYSU and PRW, we achieve a
   performance improvement over the baseline CNN. We additionally apply the
   proposed center-constrained triplet loss and complementary classifiers
   in the training model, and we achieve mAP improvements over the original
   method of +1.9% on CUHK-SYSU and +2.5% on PRW. (C) 2020 Elsevier Ltd.
   All rights reserved.
ZR 0
TC 0
ZB 0
ZS 0
Z8 0
Z9 0
SN 0031-3203
EI 1873-5142
UT WOS:000532701300021
ER

PT J
AU Wang, Zhaoyuan
   Zhang, Junbo
   Ji, Shenggong
   Meng, Chuishi
   Li, Tianrui
   Zheng, Yu
TI Predicting and ranking box office revenue of movies based on big data
SO INFORMATION FUSION
VL 60
BP 25
EP 40
DI 10.1016/j.inffus.2020.02.002
PD AUG 2020
PY 2020
AB Predicting box office revenue (BOR) of movies before releasing on big
   screens successfully becomes an emerging need, as it informs investment
   decisions on the stock market, the design of promotion strategies by
   advertisement companies, movie scheduling by cinemas, etc. However, the
   task is very challenging as it is affected by a lot of complex factors.
   In this paper, we first provide a strategic investigation of these
   influential factors. Then, we put forward a novel framework to predict a
   movie's BOR by modeling these factors using big data. Specifically, the
   framework consists of a series of feature learning models and a
   prediction and ranking model. In particular, there are two models
   devised for learning features: (1) a novel dynamic heterogeneous network
   embedding model to simultaneously learn latent representations of
   actors, directors, and companies, capable of capturing their cooperation
   relationship collectively; (2) a deep neural network-based model
   designed to uncover high-level representations of movie quality from
   trailers. Based on the learned features, we train a mutually-enhanced
   prediction and ranking model to obtain the BOR prediction results.
   Finally, we apply the framework to the Chinese film market and conduct a
   comprehensive performance evaluation using real-world data. Experimental
   results demonstrate the superior performance of both extracted knowledge
   and the prediction results.
TC 0
ZB 0
ZR 0
ZS 0
Z8 0
Z9 0
SN 1566-2535
EI 1872-6305
UT WOS:000531553100004
ER

PT J
AU Fan, Zhi-Ping
   Li, Guang-Ming
   Liu, Yang
TI Processes and methods of information fusion for ranking products based
   on online reviews: An overview
SO INFORMATION FUSION
VL 60
BP 87
EP 97
DI 10.1016/j.inffus.2020.02.007
PD AUG 2020
PY 2020
AB Over the past few years, more and more consumers have come to read
   online reviews when they shop online. To support consumers' purchase
   decisions, many scholars focus on ranking products based on online
   reviews and propose various methods and techniques. Generally, the
   process of information fusion for ranking products based on online
   reviews consists of three stages: product feature extraction, sentiment
   analysis, and ranking products. In this paper, we review the existing
   studies on processes and methods of information fusion for each stage.
   Furthermore, we briefly review the existing research on information
   fusion based on online reviews in other fields. Finally, we summarize
   the main conclusions of this paper and point out the future research
   direction.
TC 0
Z8 0
ZB 0
ZR 0
ZS 0
Z9 0
SN 1566-2535
EI 1872-6305
UT WOS:000531553100008
ER

PT J
AU Qiu, Yunhui
   Xie, Jinyu
   Lv, Hankun
   Yin, Wenbo
   Luk, Wai-Shing
   Wang, Lingli
   Yu, Bowei
   Chen, Hua
   Ge, Xianjun
   Liao, Zhijian
   Shi, Xiaozhong
TI FULL-KV: Flexible and Ultra-Low-Latency In-Memory Key-Value Store System
   Design on CPU-FPGA
SO IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS
VL 31
IS 8
BP 1828
EP 1844
DI 10.1109/TPDS.2020.2973965
PD AUG 1 2020
PY 2020
AB In-memory key-value store (IMKVS) has gained great popularity in data
   centers. However, big data brings great challenges in performance and
   power consumption because of the general-purpose Von Neumann computer
   architecture. Remote direct memory access (RDMA) technology supporting
   zero-copy networking could partly alleviate the problem but is still not
   efficient for KVS. To overcome this problem, we present a flexible and
   ultra-low-latency IMKVS system named FULL-KV, based on a CPU-FPGA
   heterogeneous architecture. The FPGA serves as a KVS accelerator that
   can bypass the CPU and implement both the network stacks and the KVS
   processing with a highly parallel hardware architecture. The system
   latency of FULL-KV can achieve as low as 1.5 mu s/2.2 mu s for the
   PUT/GET operation, which is 3.0x/1.5x faster than current
   state-of-the-art hardware-based KVS systems. Besides, FULL-KV can
   support 4x larger values (up to 4M bytes). Given a total Ethernet
   bandwidth of 20Gbps, the peak throughput of the single-node FULL-KV can
   reach 26.0 million key-value operations per second (Mops). In the
   two-node test system with a commercial Ethernet switch, the peak
   throughput can reach 52Mops, manifesting the system scalability and
   practicability.
OI Wang, Lingli/0000-0002-0579-3527; Qiu, Yunhui/0000-0003-2754-6655
ZR 0
ZB 0
ZS 0
Z8 0
TC 0
Z9 0
SN 1045-9219
EI 1558-2183
UT WOS:000522921000002
ER

PT J
AU van Dongen, Giselle
   Van den Poel, Dirk
TI Evaluation of Stream Processing Frameworks
SO IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS
VL 31
IS 8
BP 1845
EP 1858
DI 10.1109/TPDS.2020.2978480
PD AUG 1 2020
PY 2020
AB The increasing need for real-time insights in data sparked the
   development of multiple stream processing frameworks. Several
   benchmarking studies were conducted in an effort to form guidelines for
   identifying the most appropriate framework for a use case. In this
   article, we extend this research and present the results gathered. In
   addition to Spark Streaming and Flink, we also include the emerging
   frameworks Structured Streaming and Kafka Streams. We define four
   workloads with custom parameter tuning. Each of these is optimized for a
   certain metric or for measuring performance under specific scenarios
   such as bursty workloads. We analyze the relationship between latency,
   throughput, and resource consumption and we measure the performance
   impact of adding different common operations to the pipeline. To ensure
   correct latency measurements, we use a single Kafka broker. Our results
   show that the latency disadvantages of using a micro-batch system are
   most apparent for stateless operations. With more complex pipelines,
   customized implementations can give event-driven frameworks a large
   latency advantage. Due to its micro-batch architecture, Structured
   Streaming can handle very high throughput at the cost of high latency.
   Under tight latency SLAs, Flink sustains the highest throughput.
   Additionally, Flink shows the least performance degradation when
   confronted with periodic bursts of data. When a burst of data needs to
   be processed right after startup, however, micro-batch systems catch up
   faster while event-driven systems output the first events sooner.
OI Van den Poel, Dirk/0000-0002-8676-8103; van Dongen,
   Giselle/0000-0003-1605-724X
ZR 0
ZB 0
ZS 0
TC 0
Z8 0
Z9 0
SN 1045-9219
EI 1558-2183
UT WOS:000522921000003
ER

PT J
AU Ali, Munwar
   Jung, Low Tang
   Abdel-Aty, Abdel-Haleem
   Abubakar, Mustapha Y.
   Elhoseny, Mohamed
   Ali, Irfan
TI Semantic-k-NN algorithm: An enhanced version of traditional k-NN
   algorithm
SO EXPERT SYSTEMS WITH APPLICATIONS
VL 151
AR 113374
DI 10.1016/j.eswa.2020.113374
PD AUG 1 2020
PY 2020
AB The k-NN algorithm is one of the most renowned ML algorithms widely used
   in the area of data classification research. With the emergence of big
   data, the performance and the efficiency of the traditional k-NN
   algorithm is fast becoming a critical issue. The traditional k-NN
   algorithm is inefficient to solve the high volume multi-categorical
   training datasets Traditional k-NN algorithm has a constraint in
   filtering the training dataset to yield training data that are most
   relevant to the intended or the targeted test dataset/file. It has to
   scan through all the training datasets categories to classify the
   intended/targeted data. As such, traditional k-NN is considered not
   intelligent and consequently is suffering poor accuracy performance with
   high computational complexity. A Semantic-kNN (Sic-NN) algorithm for ML
   is thus proposed in this paper to address the limitations in the
   traditional k-NN. The proposed Sk-NN deploys a process by leveraging on
   the semantic itemization and bigram model to filter the training dataset
   in accordance with the relevant information engaged in the test dataset.
   It is aimed for general security applications such as finding (the
   confidentiality level of the data when the algorithm is trained with
   multiple training categories during the data classification phase.
   Ultimately, Sk-NN is to elevate the ML performance in pattern extraction
   and labeling in the big data context. (C) 2020 Elsevier Ltd. All rights
   reserved.
RI Abdel-Aty, Abdel-Haleem/F-7948-2016
OI Abdel-Aty, Abdel-Haleem/0000-0002-6763-2569
Z8 0
ZR 0
TC 0
ZB 0
ZS 0
Z9 0
SN 0957-4174
EI 1873-6793
UT WOS:000530070100016
ER

PT J
AU Corizzo, Roberto
   Ceci, Michelangelo
   Zdravevski, Eftim
   Japkowicz, Nathalie
TI Scalable auto-encoders for gravitational waves detection from time
   series data
SO EXPERT SYSTEMS WITH APPLICATIONS
VL 151
AR 113378
DI 10.1016/j.eswa.2020.113378
PD AUG 1 2020
PY 2020
AB Gravitational waves represent a new opportunity to study and interpret
   phenomena from the universe. In order to efficiently detect and analyze
   them, advanced and automatic signal processing and machine learning
   techniques could help to support standard tools and techniques. Another
   challenge relates to the large volume of data collected by the detectors
   on a daily basis, which creates a gap between the amount of data
   generated and effectively analyzed. In this paper, we propose two
   approaches involving deep auto-encoder models to analyze time series
   collected from Gravitational Waves detectors and provide a
   classification label (noise or real signal). The purpose is to discard
   noisy time series accurately and identify time series that potentially
   contain a real phenomenon. Experiments carried out on three datasets
   show that the proposed approaches implemented using the Apache Spark
   framework, represent a valuable machine learning tool for astrophysical
   analysis, offering competitive accuracy and scalability performances
   with respect to state-of-the-art methods. (C) 2020 Elsevier Ltd. All
   rights reserved.
OI Corizzo, Roberto/0000-0001-8366-6059
TC 0
ZR 0
ZB 0
Z8 0
ZS 0
Z9 0
SN 0957-4174
EI 1873-6793
UT WOS:000530070100018
ER

PT J
AU Zhou, Chunjie
   Li, Ali
   Hou, Aihua
   Zhang, Zhiwang
   Zhang, Zhenxing
   Dai, Pengfei
   Wang, Fusheng
TI Modeling methodology for early warning of chronic heart failure based on
   real medical big data
SO EXPERT SYSTEMS WITH APPLICATIONS
VL 151
AR 113361
DI 10.1016/j.eswa.2020.113361
PD AUG 1 2020
PY 2020
AB Heart failure (HF) is among the most costly diseases to our society, and
   the prevalence keeps on increasing these days. Early detection of HF
   plays a vital role in saving lives through adjusting lifestyles and drug
   interventions that can slow down disease progression or prevent HF.
   There are many cardiovascular risk factors associated with HF, and they
   often coexist. In this paper, we assess the predictive value of
   pathological factors for early HF detection through a social network
   based approach. We use electronic health records (collected from the
   project HeartCarer) and compute the similarity of risk factors. The
   similarity values are used to construct an unweighted and a weighted
   medical social network. The constructed medical social network is
   further divided into a HF high-risk group and HF low-risk group using a
   group division algorithm. Patients in the high-risk group will be
   suggested for early screening. To evaluate the prediction value of our
   method, we perform four experiments based on real world data. The
   results demonstrate the high effectiveness of our method on heart
   failure risk assessment, with the best accuracy close to 90%. (C) 2020
   Elsevier Ltd. All rights reserved.
Z8 0
ZB 0
ZR 0
TC 0
ZS 0
Z9 0
SN 0957-4174
EI 1873-6793
UT WOS:000530070100011
ER

PT J
AU Urban, Andras
   Groniewsky, Axel
   Maly, Milan
   Jozsa, Viktor
   Jedelsky, Jan
TI Application of big data analysis technique on high-velocity airblast
   atomization: Searching for optimum probability density function
SO FUEL
VL 273
AR 117792
DI 10.1016/j.fuel.2020.117792
PD AUG 1 2020
PY 2020
AB In this paper, the droplet size distributions of high-velocity airblast
   atomization were analyzed. The spray measurement was performed by a
   Phase-Doppler anemometer at several points and different diameters
   across the spray for diesel oil, light heating oil, crude rapeseed oil,
   and water. The atomizing gauge pressure and the liquid preheating
   temperature varied from 0.3 to 2.4 bar and 25 to 100 degrees C,
   respectively. Approximately 400 million individual droplets were
   recorded; therefore, a big data evaluation technique was applied. 18 of
   the most commonly used probability density functions (PDF) were fitted
   to the histogram of each measuring point and evaluated by their relative
   log-likelihood. Among the three-parameter PDFs, Generalized Extreme
   Value and Burr PDFs provided the most desirable result to describe a
   complete drop size distribution. With restriction to two-parameter PDFs,
   the Nakagami PDF unexpectedly outperformed all the others, including
   Weibull (RosinRammler) PDF, which is commonly used in atomization.
   However, if the spray is characterized by a single value, such as the
   Sauter Mean Diameter, i.e. an expected value-like parameter is of
   primary importance over the distribution, Gamma PDF is the best option,
   used in several papers of the atomization literature.
ZR 0
ZB 0
TC 0
ZS 0
Z8 0
Z9 0
SN 0016-2361
EI 1873-7153
UT WOS:000528188600004
ER

PT J
AU Chen, Xinyu
   Voigt, Tobias
TI Implementation of the Manufacturing Execution System in the food and
   beverage industry
SO JOURNAL OF FOOD ENGINEERING
VL 278
AR 109932
DI 10.1016/j.jfoodeng.2020.109932
PD AUG 2020
PY 2020
AB The Manufacturing Execution System (MES) is a production management
   system serving as the information center in the enterprise to improve
   manufacturing transparency. It is the middle layer connecting the
   manufacturing process on the shop floor and the business process on the
   Enterprise Resource Planning (ERP) level. On the one hand, the MES
   guides the execution of rough production plans into detailed operations
   on the shop floor. On the other hand, it provides the firm with critical
   key performance indicators (KPIs), enabling commercial decisions. The
   support from the MES, such as production fine planning, performance
   analysis, and product tracing, can help manufacturers to be efficient
   and gain more competitiveness in the global market. However, in the food
   and beverage industry, which faces strict regulations, growing
   competitiveness, customer demand changing, and suffer from low-profit
   margins, the implementation of the MES did not become widespread. This
   article intends to present the particular characteristics of the food
   and beverage manufacturing process, analyze the potential benefits and
   barriers of the MES implementation in the food and beverage industry
   through literature review. The solutions to solve the MES implementation
   issues and the research areas that need to be explored in order to meet
   the MES requirements from the food and beverage industry are also
   discussed in this article.
Z8 0
ZS 0
ZB 0
ZR 0
TC 0
Z9 0
SN 0260-8774
EI 1873-5770
UT WOS:000524365300011
ER

PT J
AU Cabalquinto, Earvin
   Hutchins, Brett
TI "It should allow me to opt in or opt out": Investigating smartphone use
   and the contending attitudes of commuters towards geolocation data
   collection
SO TELEMATICS AND INFORMATICS
VL 51
AR 101403
DI 10.1016/j.tele.2020.101403
PD AUG 2020
PY 2020
AB A valuable body of literature critiques the ways in which data generated
   by individuals through their smartphone and mobile media use are
   collected and controlled by governments, state-based institutions and
   corporations. However, alongside this much-needed critical scholarship,
   it is necessary to identify the specific attitudes of users towards
   locational data collection activities and, by extension, the differing
   levels of socio-technical literacy that exist among smartphone users.
   This article presents evidence of the attitudes of train commuters about
   the geolocation mapping of their movement via smartphone Wi-Fi signals.
   Involving significant methodological challenges, the study used Simple
   Observation combined with a three-question survey of 100 commuters
   completed at a major train station in Melbourne, Australia, over a
   three-day period. Based on the evidence collected and analysed, the
   findings show that attitudes are grouped into six categories: (1) in
   favour, (2) in favour with guarantees, (3) sceptical, (4) staunchly
   opposed, (5) confused, and (6) apathetic. We propose that publicly
   visible initiatives to raise awareness about the collection and
   utilisation of smartphone data are essential to inform citizens about
   their locational privacy, especially given the continuing spread of
   sensor-based monitoring systems in public spaces and so-called smart
   cities.
Z8 0
ZS 0
ZR 0
ZB 0
TC 0
Z9 0
SN 0736-5853
UT WOS:000528193500003
ER

PT J
AU Mehraliyev, Fuad
   Kirilenko, Andrei P.
   Choi, Youngjoon
TI From measurement scale to sentiment scale: Examining the effect of
   sensory experiences on online review rating behavior
SO TOURISM MANAGEMENT
VL 79
AR 104096
DI 10.1016/j.tourman.2020.104096
PD AUG 2020
PY 2020
AB The crucial role of sensory dimensions in customer experiences has been
   supported in literature. However, traditional self-reported sensory
   measurements have limited capacity in capturing the multi-dimensional
   experiences sensed by individuals and articulating the distinct effect
   of different sensory dimensions on actual behavior. This study is the
   first attempt to test the effects of positive and negative experiences
   involving all five senses (sight, smell, sound, taste, and touch) on
   customer ratings. The sensory experiences reported in social media
   reviews were captured and explored using text mining and sentiment
   analysis. The findings show that although the majority of customers'
   experiences were positive, the negative sensory experiences had higher
   effect on customer rating. Furthermore, the five senses had different
   weights in forming overall experience, which provides theoretical
   contributions to the literature on sensescapes, prospect theory, and
   discourses on satisfiers and dissatisfiers.
TC 0
ZR 0
ZB 0
Z8 0
ZS 0
Z9 0
SN 0261-5177
EI 1879-3193
UT WOS:000527847800014
ER

PT J
AU Geng, Yangli-ao
   Li, Qingyong
   Liang, Mingfei
   Chi, Chong-Yung
   Tan, Juan
   Huang, Heng
TI Local-Density Subspace Distributed Clustering for High-Dimensional Data
SO IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS
VL 31
IS 8
BP 1799
EP 1814
DI 10.1109/TPDS.2020.2975550
PD AUG 1 2020
PY 2020
AB Distributed clustering is emerging along with the advent of the era of
   big data. However, most existing established distributed clustering
   methods focus on problems caused by a large amount of data rather than
   caused by the large dimension of data. Consequently, they suffer the
   "curse" of dimensionality (e.g., poor performance and heavy network
   overhead) when high-dimensional (HD) data are clustered. In this
   article, we propose a distributed algorithm, referred to as Local
   Density Subspace Distributed Clustering (LDSDC) algorithm, to cluster
   large-scale HD data, motivated by the idea that a local dense region of
   a HD dataset is usually distributed in a low-dimensional (LD) subspace.
   LDSDC follows a local-global-local processing structure, including
   grouping of local dense regions (atom clusters) followed by subspace
   Gaussian model (SGM) fitting (flexible and scalable to data dimension)
   at each sub-site, merging of atom clusters at every sub-site according
   to the merging result broadcast from the global site. Moreover, we
   propose a fast method to estimate the parameters of SGM for HD data,
   together with its convergence proof. We evaluate LDSDC on both synthetic
   and real datasets and compare it with four state-of-the-art methods. The
   experimental results demonstrate that the proposed LDSDC yields best
   overall performance.
OI Chi, Chong-Yung/0000-0001-5004-7155; Geng, Yangli-ao/0000-0003-0173-4041
Z8 0
ZR 0
ZS 0
TC 0
ZB 0
Z9 0
SN 1045-9219
EI 1558-2183
UT WOS:000522194000004
ER

PT J
AU Arif, Dian Adhetya
   Prarikeslan, Widya
   Syaharani, Ladisa
TI ANALYSIS OF SHORELINE DYNAMICS FOR COASTAL MANAGEMENT PRACTICE IN
   PARIAMAN, WEST SUMATERA
SO INTERNATIONAL JOURNAL OF GEOMATE
VL 19
IS 72
BP 166
EP 172
DI 10.21660/2020.72.ICGeo19
PD AUG 2020
PY 2020
AB Coastal dynamics have a significant effect on the use of coastal
   resources where more than 60 percent of cities in the world develop in
   this region and use it for urban infrastructure, settlements, and
   economic development. shoreline change is one of many indicators of
   coastal dynamics which is the result of interaction between biotic,
   abiotic and human activities which further influences policy and
   management practices for coastal areas. This paper presents the results
   of study on shoreline dynamics in Pariaman, West Sumatra using vector
   analysis in DSAS 4.3 between 1988-2003 and 2003-2018. The shoreline is
   interpreted from three Landsat images, namely Landsat 5 TM 1988, Landsat
   7 ETM + 2003 and Landsat 8 OLI / TIRS 2018 that have been corrected
   (radiometric and geometric). The shorelines derived from Landsat
   combined with shoreline from topographic map by Badan Informasi
   Geospasial (BIG) as baseline for net shoreline movement (NSM) and end
   point rate (EPR) analysis. Then, The data of shoreline changes is used
   as a basis for qualitative analysis of local government policies on
   coastal management. The results show that shoreline changes occur
   dynamically wherein 1988-2003 abrasion occurred with an average rate of
   2.88 m/yr and accretion of 1.64 m/ yr while in the 2003-2018 an abrasion
   rate of 2.76 m/yr occurred and accretion rate 1.12 m/ yr. This condition
   occurs along with the increase of longshore current speed. Some of the
   locations also have faster abrasion and accretion rates due to
   structural built.
TC 0
ZS 0
Z8 0
ZR 0
ZB 0
Z9 0
SN 2186-2982
EI 2186-2990
UT WOS:000522671800025
ER

PT J
AU Ferreira, Catarina
   Morais, Ana Isabel
TI Analysis of the relationship between company characteristics and key
   audit matters disclosed
X1 Análise da relação entre características das empresas e os key audit
   matters divulgados
SO Revista Contabilidade & Finanças
VL 31
IS 83
BP 262
EP 274
DI 10.1590/1808-057x201909040
PD 2020-08
PY 2020
AB ABSTRACT The general objective of this study is to analyze whether the
   particularities of audited companies influence the volume of key audit
   matters (KAMs). Its specific objectives are to identify the number of
   KAMs disclosed by Brazilian companies and analyze the main factors
   associated with their disclosure. The paper aims to contribute to an
   area of investigation still lacking in studies that analyze the factors
   affecting KAM disclosure, which makes audit reports more individualized.
   The study contributes to understanding the main auditing issues in
   Brazilian companies that auditors consider relevant, by providing
   evidence on factors associated with their disclosure. This research is
   relevant for agencies that issue auditing standards and for financial
   information users. For issuers of auditing standards, the study is
   relevant because it identifies the factors associated with KAM
   disclosure, enabling it to be confirmed that the new audit report model
   has contributed to its destandardization. For financial information
   users, the study demonstrates that KAM disclosure varies from company to
   company, thus contributing to greater transparency of the audit report.
   Data were collected from the Audit Reports and Consolidated Financial
   Statements of the 447 Brazilian companies listed on the São Paulo
   Securities, Commodities, and Futures Exchange (BM&FBovespa), on December
   31st of 2016, and an ordinary least squares (OLS) regression was applied
   to the defined model. The results show a positive relationship between
   the number of KAMs disclosed and both the auditor being a Big 4 and the
   complexity of the audited company. The auditor’s fees and auditor’s
   opinion being modified show a negative relationship with the number of
   KAMs. The article is relevant for companies, auditors, and regulatory
   and supervisory bodies as it identifies company characteristics that
   influence KAM disclosure and are determinants for the
   non-standardization of the auditor’s report.
Y4 RESUMO O objetivo geral deste estudo é analisar se as particularidades
   das empresas auditadas influenciam o volume de key audit matters (KAMs).
   Como objetivos específicos, pretende-se identificar o número de KAMs
   divulgado pelas empresas brasileiras e analisar os principais fatores
   associados à sua divulgação. O estudo pretende contribuir para uma área
   de investigação ainda escassa que analisa os fatores que afetam a
   divulgação das KAMs e que, por isso, torna os relatórios dos auditores
   mais individualizados. Este estudo contribui para a compreensão dos
   principais assuntos de auditoria nas empresas brasileiras considerados
   relevantes pelos auditores, proporcionando evidência sobre fatores
   associados à sua divulgação. Este estudo é relevante para os organismos
   emissores de normas de auditoria e para os usuários da informação
   financeira. Para os emissores de normas de auditoria, este estudo é
   relevante porque identifica os fatores associados à divulgação das KAMs,
   permitindo confirmar que o novo modelo de relatório de auditoria
   contribuiu para sua despadronização. Finalmente, para os usuários da
   informação financeira, este estudo demonstra que a divulgação das KAM
   varia de empresa para empresa, contribuindo para a maior transparência
   do relatório de auditoria. Coletaram-se informações dos Relatórios de
   Auditoria e das Demonstrações Financeiras Consolidadas das 447 empresas
   brasileiras cotadas na Bolsa de Valores, Mercadorias e Futuros de São
   Paulo (BM&FBOVESPA) relativas a 31 de dezembro de 2016, aplicando-se a
   regressão ordinary least squares (OLS) ao modelo definido. Os resultados
   evidenciam relação positiva entre o número de KAMs divulgadas e o
   auditor ser uma Big 4 e a complexidade da empresa auditada. Já os
   honorários e a opinião do auditor ser modificada demonstram relação
   negativa com o número de KAM. O artigo é relevante para as empresas,
   auditores e órgãos de regulação e supervisão, uma vez que identifica
   características das empresas que afetam a divulgação de KAM e que são
   determinantes para a não padronização do relatório do auditor.
RI Morais, Ana Isabel/E-1369-2019
OI Morais, Ana Isabel/0000-0001-7251-6418
Z8 0
TC 0
ZS 0
ZB 0
ZR 0
Z9 0
SN 1808-057X
UT SCIELO:S1519-70772020000200262
ER

PT J
AU Hu, Zhiyao
   Li, Dongsheng
   Guo, Deke
TI Balance Resource Allocation for Spark Jobs Based on Prediction of the
   Optimal Resource
SO TSINGHUA SCIENCE AND TECHNOLOGY
VL 25
IS 4
BP 487
EP 497
DI 10.26599/TST.2019.9010054
PD AUG 2020
PY 2020
AB Apache Spark provides a well-known MapReduce computing framework, aiming
   to fast-process big data analytics in data-parallel manners. With this
   platform, large input data are divided into data partitions. Each data
   partition is processed by multiple computation tasks concurrently.
   Outputs of these computation tasks are transferred among multiple
   computers via the network. However, such a distributed computing
   framework suffers from system overheads, inevitably caused by
   communication and disk I/O operations. System overheads take up a large
   proportion of the Job Completion Time (JCT). We observed that excessive
   computational resources incurs considerable system overheads, prolonging
   the JCT. The over-allocation of individual jobs not only prolongs their
   own JCTs, but also likely makes other jobs suffer from under-allocation.
   Thus, the average JCT is suboptimal, too. To address this problem, we
   propose a prediction model to estimate the changing JCT of a single
   Spark job. With the support of the prediction method, we designed a
   heuristic algorithm to balance the resource allocation of multiple Spark
   jobs, aiming to minimize the average JCT in multiple-job cases. We
   implemented the prediction model and resource allocation method in ReB,
   a Resource-Balancer based on Apache Spark. Experimental results showed
   that ReB significantly outperformed the traditional max-min fairness and
   shortest-job-optimal methods. The average JCT was decreased by around
   10%-30% compared to the existing solutions.
ZB 0
ZR 0
TC 0
Z8 0
ZS 0
Z9 0
SN 1007-0214
EI 1878-7606
UT WOS:000517499500005
ER

PT J
AU Lei, Guangbin
   Li, Ainong
   Bian, Jinhu
   Zhang, Zhengjian
TI The roles of criteria, data and classification methods in designing land
   cover classification systems: evidence from existing land cover data
   sets
SO INTERNATIONAL JOURNAL OF REMOTE SENSING
VL 41
IS 14
BP 5062
EP 5082
DI 10.1080/01431161.2020.1724349
PD JUL 17 2020
PY 2020
AB The Land Cover Classification System (LCCS) is a fundamental element and
   representative feature for any Land Cover Data Set (LCDS). Although
   various LCCSs have been proposed during the past few decades,
   discrepancies of LCCSs have widely existed in various LCDSs, which have
   caused negative impacts on comprehensive comparison and integrated
   utilization of multiple LCDSs. This study attempted to summarize the
   independent diagnostic criteria hidden in the existing LCCSs based on
   the induction method, and to synchronously discover the roles of data
   sources and classification methods in designing LCCSs. A total of 13
   existing regional- or global-scale LCDSs were chosen. The analysis
   results show that phenology, coverage rate, vertical structure, and leaf
   type were the most frequently adopted criteria in the LCCSs of existing
   LCDSs. The decision of whether to adopt a diagnostic criterion in the
   LCCS of LCDS depended on the availability, effectiveness, and quality of
   the relevant data sources and classification methods. Currently, optical
   remote sensing images are still the prominent data source for regional-
   or global-scale LCDSs, and the potential of each diagnostic criterion
   could not be fully played. Multi-source and heterogeneous spatial data,
   ARD (Analysis Ready Data), and a fusion of optical, LiDAR (Light
   Detection And Ranging), radar, and other kinds of images have provided
   practical solutions. A lack of tools with high computing and storage
   capacities has been an alternative challenge. With the increasing
   advancement of new technologies, such as big earth data, crowdsourcing,
   deep learning, and cloud computing, more potential diagnostic criteria
   may be adopted for designing LCCS, and the richness and flexibility of
   the LCCS in the planned LCDS will gradually improve. This work not only
   offers beneficial references and revelations for the design of a new
   LCCS, but also provides insights for land cover mapping in large regions
   and the rational utilization of LCDSs.
ZR 0
ZB 0
TC 0
ZS 0
Z8 0
Z9 0
SN 0143-1161
EI 1366-5901
UT WOS:000526425300001
ER

PT J
AU Alguliyev, Rasim M.
   Aliguliyev, Ramiz M.
   Sukhostat, Lyudmila, V
TI Weighted consensus clustering and its application to Big data
SO EXPERT SYSTEMS WITH APPLICATIONS
VL 150
AR 113294
DI 10.1016/j.eswa.2020.113294
PD JUL 15 2020
PY 2020
AB The aim of this study is the development of a weighted consensus
   clustering that assigns weights to single clustering methods using the
   purity utility function. In the case of Big data that does not contain
   labels, the utility function based on the Davies-Bouldin index is
   proposed in this paper. The Banknote authentication, Phishing, Diabetic,
   Magic04, Credit card clients, Covertype, Phone accelerometer, and
   NSL-KDD datasets are used to assess the efficiency of the proposed
   consensus approach. The proposed approach is evaluated using the
   Euclidean, Minkowski, squared Euclidean, cosine, and Chebychev distance
   metrics. It is compared with single clustering algorithms (DBSCAN,
   OPTICS, CLARANS, k-means, and shared nearby neighbor clustering). The
   experimental results show the effectiveness of the proposed approach to
   the Big data clustering in comparison to single clustering methods. The
   proposed weighted consensus clustering using the squared Euclidean
   distance metric achieves the highest accuracy, which is a very promising
   result for Big data clustering. It can be applied to expert systems to
   help experts make group decisions based on several alternatives. The
   paper also provides directions for future research on consensus
   clustering in this area. (C) 2020 Elsevier Ltd. All rights reserved.
RI Sukhostat, Lyudmila/G-3437-2017
OI Sukhostat, Lyudmila/0000-0001-9449-7457
ZS 0
Z8 0
ZR 0
TC 0
ZB 0
Z9 0
SN 0957-4174
EI 1873-6793
UT WOS:000528193700036
ER

PT J
AU Jerez, Tomas
   Kristjanpoller, Werner
TI Effects of the validation set on stock returns forecasting
SO EXPERT SYSTEMS WITH APPLICATIONS
VL 150
AR 113271
DI 10.1016/j.eswa.2020.113271
PD JUL 15 2020
PY 2020
AB Deep neural networks are potentially suitable tools for time series
   forecasting due to their ability to extract complex patterns of
   nonlinear data and their versatility in terms of models and
   applications. Even though they are powerful instruments and well-behaved
   approaches for certain tasks, they are sometimes surpassed by data
   complexity, and thus struggle to find an error that generalizes well
   enough on unseen data, especially in cases like times series forecasting
   for stock trading strategies. In this paper, the complex characteristics
   of time series are addressed by separating data by means of simpler yet
   more relevant distinctions in order to create a single model for every
   existing or created category, with a focus on model validation. This
   creates models which are trained on the same data, but validated for a
   particular class so that the models' hyperparameters are specifically
   tuned to that class. Experiments on convolutional networks applied to
   the DJIA, Nasdaq and S&P 500 indices using volatility as a class or
   category indicator, have shown that it is possible to improve
   predictions after validating the model, obtaining the best model per the
   Model Confidence Set among different regression models on all time
   series datasets. Even the best and only model necessary for the DJIA and
   S&P 500 indices can be obtained at a significance value of 5% given that
   the level of volatility is known. The results highlight the importance
   of knowing the data and how to potentially separate them into simpler
   yet relevant classes. The results also reveal how model validation on
   different data is capable of creating models that better explain
   information just by tuning the model's architectural hyperparameters,
   even though the models where trained on the very same data. This finding
   could be applied to any task requiring validation without modifying the
   training set, which is usually bigger and more expensive to obtain. (c)
   2020 Elsevier Ltd. All rights reserved.
OI Kristjanpoller, Werner/0000-0002-5878-072X
ZR 0
ZS 0
ZB 0
TC 0
Z8 0
Z9 0
SN 0957-4174
EI 1873-6793
UT WOS:000528193700013
ER

PT J
AU Li, Mengmeng
   Wang, Haofeng
   Yang, Lifang
   Liang, You
   Shang, Zhigang
   Wan, Hong
TI Fast hybrid dimensionality reduction method for classification based on
   feature selection and grouped feature extraction
SO EXPERT SYSTEMS WITH APPLICATIONS
VL 150
AR 113277
DI 10.1016/j.eswa.2020.113277
PD JUL 15 2020
PY 2020
AB Dimensionality reduction is one basic and critical technology for data
   mining, especially in current "big data" era. As two different types of
   methods, feature selection and feature extraction each have their pros
   and cons. In this paper, we combine multi-strategy feature selection and
   grouped feature extraction and propose a novel fast hybrid dimension
   reduction method, incorporating their advantages of removing irrelevant
   and redundant information. Firstly, the intrinsic dimensionality of the
   data set is estimated by the maximum likelihood estimation method.
   Fisher Score and Information Gain based feature selection are used as
   multi-strategy methods to remove irrelevant features. With the
   redundancy among the selected features as clustering criterion, they are
   grouped into a certain amount of clusters. In every cluster, Principal
   Component Analysis (PCA) based feature extraction is carried out to
   remove redundant information. Four classical classifiers and
   representation entropy are used to evaluate the classification
   performance and information loss of the reduced set. The runtime results
   of different methods show that the proposed hybrid method is
   consistently much faster than the other three in almost all of the sets
   used. Meanwhile, the proposed method shows competitive classification
   performance, which has no significant difference basically compared with
   the other methods. The proposed method reduces the dimensionality of the
   raw data fast and it has excellent efficiency and competitive
   classification performance compared with the contrastive methods. (c)
   2020 Elsevier Ltd. All rights reserved.
Z8 0
TC 0
ZR 0
ZB 0
ZS 0
Z9 0
SN 0957-4174
EI 1873-6793
UT WOS:000528193700015
ER

PT J
AU Mousavi, Seyed Muhammad Hossein
   Charles, Vincent
   Gherman, Tatiana
TI An evolutionary Pentagon Support Vector finder method
SO EXPERT SYSTEMS WITH APPLICATIONS
VL 150
AR 113284
DI 10.1016/j.eswa.2020.113284
PD JUL 15 2020
PY 2020
AB In dealing with big data, we need effective algorithms; effectiveness
   that depends, among others, on the ability to remove outliers from the
   data set, especially when dealing with classification problems. To this
   aim, support vector finder algorithms have been created to save just the
   most important data in the data pool. Nevertheless, existing
   classification algorithms, such as Fuzzy C-Means (FCM), suffer from the
   drawback of setting the initial cluster centers imprecisely. In this
   paper, we avoid existing shortcomings and aim to find and remove
   unnecessary data in order to speed up the final classification task
   without losing vital samples and without harming final accuracy; in this
   sense, we present a unique approach for finding support vectors, named
   evolutionary Pentagon Support Vector (PSV) finder method. The
   originality of the current research lies in using geometrical
   computations and evolutionary algorithms to make a more effective
   system, which has the advantage of higher accuracy on some data sets.
   The proposed method is subsequently tested with seven benchmark data
   sets and the results are compared to those obtained from performing
   classification on the original data (classification before and after
   PSV) under the same conditions. The testing returned promising results.
   (C) 2020 Elsevier Ltd. All rights reserved.
TC 0
ZB 0
ZS 0
ZR 0
Z8 0
Z9 0
SN 0957-4174
EI 1873-6793
UT WOS:000528193700008
ER

PT J
AU Wang, Xiuyu
   Zhu, Xuantong
   Tao, Tao
   Leng, Binxin
   Xu, Wen
   Mao, Luhong
TI Structural inheritance and change from ZnSn(OH)(6) to ZnSnO3 compounds
   used for ethanol sensors: Effects of oxygen vacancies, temperature and
   UV on gas-sensing properties
SO JOURNAL OF ALLOYS AND COMPOUNDS
VL 829
AR 154445
DI 10.1016/j.jallcom.2020.154445
PD JUL 15 2020
PY 2020
AB Nano-sized ZnSn(OH)(6) crystalline particles were synthesized by
   co-precipitation method at room temperature, in which NaOH as
   precipitant and oxalic acid as organic functional reagent were used.
   Scanning electron microscopy and X-ray diffraction analysis suggest that
   the morphology, size and growth rate of the ZnSn(OH)(6) particles can be
   changed by oxalic acid, and those particles are polycrystalline based on
   selected area electron diffraction (SAED) and transmission electron
   microscope data. After dehydration of the ZnSn(OH)(6) polycrystalline
   precursors at high temperature, their ZnSnO3 counterparts were formed,
   showing an amorphous structure according to SAED analysis. In this
   process, the morphology, size and oxygen vacancy defects of the former
   are inherited by the latter except for the crystalline structure. The
   structural change from polycrystalline to amorphous phase is caused by
   newly formed oxygen vacancies, which are proved by X-ray photoelectron
   spectroscopy data, and reflected by ultraviolet (UV) absorption red
   shift. When the concentration of oxalic acid is 0.059 M in the
   synthesizing system, the resulting ZnSn(OH)(6) precursor has a biggest
   particle size and average crystalline size. Furthermore, its ZnSnO3
   counterpart is most sensitive to ethanol gas, achieving a gas response
   as high as 147 at 500 ppm under the co-effect of temperature (220
   degrees C) and UV. (C) 2020 Elsevier B.V. All rights reserved.
ZR 0
Z8 0
TC 0
ZS 0
ZB 0
Z9 0
SN 0925-8388
EI 1873-4669
UT WOS:000523555300112
ER

PT J
AU Chiappetta Jabbour, Charbel Jose
   Fiorini, Paula De Camargo
   Ndubisi, Nelson Oly
   Queiroz, Maciel M
   Piato, Ederson Luiz
TI Digitally-enabled sustainable supply chains in the 21st century: A
   review and a research agenda.
SO The Science of the total environment
VL 725
BP 138177
EP 138177
DI 10.1016/j.scitotenv.2020.138177
PD 2020-Jul-10
PY 2020
AB While the potential benefits of integrating digital technologies and
   supply chain management have been widely reported, less is known
   concerning the current state-of-the-art literature on big data-driven
   sustainable supply chains. Therefore, this study aims to systematise
   published studies which address the implications of big data for
   sustainable supply chain management. Through a systematic literature
   review, this work makes three significant contributions: (a) it provides
   an overview of extant literature on this topic in recent years; (b) it
   proposes seven gaps in the literature in order to foster future
   investigations on big data-driven sustainable supply chains; (c) it
   offers four lessons for business practitioners aiming to use big data
   for sustainable supply chain practices. These lessons suggest that:
   developing big data analytics capability has to become a business
   priority in order to effectively build competitive sustainable supply
   chains; big data has benefits for each of the dimensions of the
   triple-bottom-line in supply chains; the implementation of big data for
   sustainability in supply chains presents some challenges for firms; the
   development of complementary organizational capabilities is needed to
   overcome challenges and facilitate the benefits of big data technology
   for sustainable supply chain management.
RI Manoel Queiroz, Maciel/F-1274-2014; Chiappetta Jabbour, Charbel Jose/
OI Manoel Queiroz, Maciel/0000-0002-6025-9191; Chiappetta Jabbour, Charbel
   Jose/0000-0002-6143-4924
ZB 0
ZS 0
ZR 0
Z8 0
TC 0
Z9 0
EI 1879-1026
UT MEDLINE:32302825
PM 32302825
ER

PT J
AU Malhat, Mohamed
   El Menshawy, Mohamed
   Mousa, Hamdy
   El Sisi, Ashraf
TI A new approach for instance selection: Algorithms, evaluation, and
   comparisons
SO EXPERT SYSTEMS WITH APPLICATIONS
VL 149
AR 113297
DI 10.1016/j.eswa.2020.113297
PD JUL 1 2020
PY 2020
AB Several approaches for instance selection have been put forward as a
   primary step to increase the efficiency and accuracy of algorithms
   applied to mine big data. The instance selection task scales indeed big
   data down by removing irrelevant, redundant, and unreliable data, which,
   in turn, reduces the computational resources necessary for completing
   the mining task. The local density-based approaches are recently
   acknowledged as feasible approaches in terms of reduction rate,
   effectiveness, and computation time metrics. However, these approaches
   endure low classification accuracy results compared with other
   approaches.
   In this manuscript, we propose a new layered and operational approach to
   address these limitations as well as advance the state-of-the-art by
   balancing among classification accuracy, reduction rate, and time
   complexity. We commence by designing a new algorithm (called GDIS) that
   selects most relevant instances using a global density and relevance
   functions. This enable us to consider a global view overall a data set
   to get a better classification accuracy results than current
   density-based approaches. We design another novel algorithm (called
   EGDIS), which maintains the effectiveness results of the GDIS algorithm
   while improving reduction rate results. Moreover, we compare our
   algorithms against three state-of-the-art algorithms to validate their
   performance. We develop a Java toolkit called ISTK on the top of the
   GDIS and EGDIS algorithms, the density-based approaches, and the
   state-of-the-art algorithms. We also develop a suitable user interface
   and its management and validation capabilities to ease-of-use and
   visualize results and data sets. We evaluate and test the performance of
   our algorithms in terms of four metrics (reduction rate, classification
   accuracy, effectiveness, and computation time) using twenty-four
   standard data sets and conduct an intensive set of experiments. The
   experimental results proved that the GDIS algorithm outperforms the
   density-based approaches in terms of classification accuracy and
   effectiveness, the EGDIS algorithm outperforms the density-based
   approaches in terms of reduction rate and effectiveness, and the GDIS
   and EGDIS algorithms outperform the state-of-the-art algorithms in terms
   of achieving a good results in both the effectiveness and computation
   time metrics. We finally test the scalability and compute experimentally
   the polynomial-time complexity of our algorithms. (C) 2020 Elsevier Ltd.
   All rights reserved.
RI Elsisi, Ashraf/AAN-3191-2020
ZS 0
ZB 0
ZR 0
TC 0
Z8 0
Z9 0
SN 0957-4174
EI 1873-6793
UT WOS:000525819400028
ER

PT J
AU Pirmoradi, Saeed
   Teshnehlab, Mohammad
   Zarghami, Nosratollah
   Sharifi, Arash
TI The Self-Organizing Restricted Boltzmann Machine for Deep Representation
   with the Application on Classification Problems
SO EXPERT SYSTEMS WITH APPLICATIONS
VL 149
AR 113286
DI 10.1016/j.eswa.2020.113286
PD JUL 1 2020
PY 2020
AB Recently, deep learning is proliferating in the field of representation
   learning. A deep belief network (DBN) consists of a deep network
   architecture that can generate multiple features of input patterns,
   using restricted Boltzmann machines (RBMs) as a building block of DBN. A
   deep learning model can achieve extremely high accuracy in many
   applications that depend on the model structure. However, specifying
   various parameters of deep network architecture like the number of
   hidden layers and neurons is a difficult task even for expert designers.
   Besides, the number of hidden layers and neurons is typically set
   manually, while this method is costly in terms of time and computational
   cost, especially in big data. In this paper, we introduce an approach to
   determine the number of hidden layers and neurons of the deep network
   automatically during the learning process. To this end, the input vector
   is transformed from the feature space with a low dimension into the new
   feature space with a high dimension in a hidden layer of RBM. In the
   following, new features are ranked according to their discrimination
   power between classes in the new space, using the
   Separability-correlation measure for feature importance ranking
   algorithm. The algorithm uses the mean of weights as a threshold, so the
   neurons whose weights exceed the threshold are retained, and the others
   are removed in the hidden layer. The number of retained neurons is
   presented as a reasonable number of neurons. The number of layers is
   also determined in the deep model, using the validation data. The
   proposed approach acts as a regularization method since the neurons
   whose weights are lower than the threshold are removed; thus, RBM learns
   to copy input merely approximate. It also prevents over-fitting with a
   suitable number of hidden layers and neurons. Eventually, DBN can
   determine its structure according to the input data and is the
   self-organizing model. The experimental results on benchmark datasets
   confirm the proposed method. (C) 2020 Elsevier Ltd. All rights reserved.
ZR 0
Z8 0
TC 0
ZB 0
ZS 0
Z9 0
SN 0957-4174
EI 1873-6793
UT WOS:000525819400024
ER

PT J
AU Hua, Jiafeng
   Shi, Guozhen
   Zhu, Hui
   Wang, Fengwei
   Liu, Ximeng
   Li, Hao
TI CAMPS: Efficient and privacy-preserving medical primary diagnosis over
   outsourced cloud
SO INFORMATION SCIENCES
VL 527
BP 560
EP 575
DI 10.1016/j.ins.2018.12.054
PD JUL 2020
PY 2020
AB With the flourishing of ubiquitous healthcare and cloud computing
   technologies, medical primary diagnosis system, which forms a critical
   capability to link big data analysis technologies with medical
   knowledge, has shown great potential in improving the quality of
   healthcare services. However, it still faces many severe challenges on
   both users' medical privacy and intellectual property of healthcare
   service providers, which deters the wide adoption of medical primary
   diagnosis system. In this paper, we propose an efficient and
   privacy-preserving medical primary diagnosis framework (CAMPS). Within
   CAMPS framework, the precise diagnosis models are outsourced to the
   cloud server in an encrypted manner, and users can access accurate
   medical primary diagnosis service timely without divulging their medical
   data. Specifically, based on partially decryption and secure comparison
   techniques, a special fast secure two-party vector dominance scheme over
   ciphertext is proposed, with which CAMPS achieves privacy preservation
   of user's query and the diagnosis result, as well as the confidentiality
   of diagnosis models in the outsourced cloud server. Through extensive
   analysis, we show that CAMPS can ensure that users' medical data and
   healthcare service provider's diagnosis model are kept confidential, and
   has significantly reduce computation and communication overhead. In
   addition, performance evaluations via implementing CAMPS demonstrate its
   effectiveness in term of the real environment. (C) 2018 Elsevier Inc.
   All rights reserved.
TC 1
Z8 0
ZB 0
ZR 0
ZS 0
Z9 1
SN 0020-0255
EI 1872-6291
UT WOS:000532695700034
ER

PT J
AU Feng, Jun
   Yang, Laurence T.
   Gati, Nicholaus J.
   Xie, Xia
   Gavuna, Benard S.
TI Privacy-preserving computation in cyber-physical-social systems: A
   survey of the state-of-the-art and perspectives
SO INFORMATION SCIENCES
VL 527
BP 341
EP 355
DI 10.1016/j.ins.2019.07.036
PD JUL 2020
PY 2020
AB Cyber-physical-social systems (CPSSs) are leading digital revolutions in
   academia, industry and government. Due to the rise of big data
   analytics, tensor computations are currently used in CPSSs. With the
   increasing popularity of cloud computing or fog computing, big data in
   CPSSs are usually sent to clouds or fogs for computations. Recently,
   some studies about privacy-preserving computation have been conducted to
   address security concerns which enable data analysis and processing in
   cloud or fog environments in a privacy-preserving way. To fully
   understand the state-of-the-art advances and discover the research
   directions of this field, in this survey, both previous and current
   privacy-preserving schemes are comprehensively reviewed and studied. In
   addition, a novel privacy-preserving tensor computation framework, a
   case study, and several future research directions are presented for
   CPSSs. (C) 2019 Published by Elsevier Inc.
Z8 0
ZR 0
ZB 0
ZS 0
TC 0
Z9 0
SN 0020-0255
EI 1872-6291
UT WOS:000532695700020
ER

PT J
AU Chamikara, M. A. P.
   Bertok, P.
   Liu, D.
   Camtepe, S.
   Khalil, I
TI Efficient privacy preservation of big data for accurate data mining
SO INFORMATION SCIENCES
VL 527
BP 420
EP 443
DI 10.1016/j.ins.2019.05.053
PD JUL 2020
PY 2020
AB Computing technologies pervade physical spaces and human lives, and
   produce a vast amount of data that is available for analysis. However,
   there is a growing concern that potentially sensitive data may become
   public if the collected data are not appropriately sanitized before
   being released for investigation. Although there are more than a few
   privacy-preserving methods available, they are not efficient, scalable,
   or have problems with data utility, or privacy. This paper addresses
   these issues by proposing an efficient and scalable nonreversible
   perturbation algorithm, PABIDOT, for privacy preservation of big data
   via optimal geometric transformations. PABIDOT was tested for
   efficiency, scalability, attack resistance, and accuracy using nine
   datasets and five classification algorithms. Experiments show that
   PABIDOT excels in execution speed, scalability, attack resistance, and
   accuracy in large-scale privacy-preserving data classification when
   compared with two other, related privacy-preserving algorithms. (C) 2019
   Elsevier Inc. All rights reserved.
TC 2
ZS 0
ZR 0
ZB 0
Z8 0
Z9 2
SN 0020-0255
EI 1872-6291
UT WOS:000532695700026
ER

PT J
AU Zhang, Yushu
   Jiang, Jin
   Xiang, Yong
   Zhu, Ye
   Wan, Liangtian
   Xie, Xiyuan
TI Cloud-assisted privacy-conscious large-scale Markowitz portfolio
SO INFORMATION SCIENCES
VL 527
BP 548
EP 559
DI 10.1016/j.ins.2018.12.055
PD JUL 2020
PY 2020
AB The theory of Markowitz portfolio has had enormous value and extensive
   applications in finance since it came into being. With the advent of the
   Big-Data era and the increasingly complicated financial market, the
   resource consumption of computing portfolio investments is significantly
   increasing. Cloud computing offers a good platform to efficiently
   compute large-scale portfolio investments, in particular, for
   resource-limited investors. In this paper, a Markowitz model (MM) is
   taken into consideration for outsourcing to a public cloud in a
   privacy-conscious way. As in general computation outsourcing,
   outsourcing MM inevitably faces four issues, namely, input/output
   privacy, correctness, verification, and substantial computation gain for
   investors; it has consistent complexity with the original methods when
   the cloud solves the encrypted version. However, the proposed
   cloud-assisted privacy-conscious MM employs location-scrambling and
   value-alteration encryption operations, which can protect the MM's
   input/output privacy well. Moreover, the correctness of solving MM over
   an encrypted domain in the cloud side can be demonstrated and the
   results returned by the cloud can be verified. Furthermore, both
   theoretical and experimental analyses validate that the investor can
   obtain a huge amount of computational gain, and the cloud complexity
   consistent with that of the original case when solving the encrypted
   version. (C) 2019 Elsevier Inc. All rights reserved.
ZB 0
ZR 0
Z8 0
ZS 0
TC 1
Z9 1
SN 0020-0255
EI 1872-6291
UT WOS:000532695700033
ER

PT J
AU Shafiq, Asad
   Ahmed, Muhammad Usman
   Mahmoodi, Farzad
TI Impact of supply chain analytics and customer pressure for ethical
   conduct on socially responsible practices and performance: An
   exploratory study
SO INTERNATIONAL JOURNAL OF PRODUCTION ECONOMICS
VL 225
AR UNSP 107571
DI 10.1016/j.ijpe.2019.107571
PD JUL 2020
PY 2020
AB In the highly competitive global business environment, firms are being
   challenged by stakeholder groups-such as customers, NGOs, and
   regulators- to embrace sustainability and ensure that their supply
   chains are operating in a socially responsible manner. With the
   advancements in big data analytics, firms are increasingly investing in
   developing analytics capabilities to deliver operational improvements.
   However, the spillover effects of such technological solutions towards
   addressing stakeholder concerns and delivering on social performance are
   unclear. Drawing on stakeholder theory and RBV, this study investigates
   the role of supply chain analytics capability (SCAC) and customer
   pressure for ethical conduct (CPEC) towards the adoption of socially
   responsible practices by suppliers. The proposed relationships linking
   these constructs are empirically tested using data from a sample of 254
   U.S. manufacturing firms. Findings indicate that supply chain analytics
   capability synergistically interacts with the pressure from customers
   for ethical conduct to improve the social and financial performance of
   suppliers. Findings also provide important implications for supply chain
   executives.
Z8 0
TC 0
ZS 0
ZR 0
ZB 0
Z9 0
SN 0925-5273
EI 1873-7579
UT WOS:000532795300014
ER

PT J
AU Wang, Jiajia
   Lu, Xiaoman
   Yan, Yingting
   Zhou, Liguo
   Ma, Weichun
TI Spatiotemporal characteristics of PM 2.5 concentration in the Yangtze
   River Delta urban agglomeration, China on the application of big data
   and wavelet analysis
SO SCIENCE OF THE TOTAL ENVIRONMENT
VL 724
PD JUL 1 2020
PY 2020
ZB 0
TC 0
ZR 0
Z8 0
ZS 0
Z9 0
SN 0048-9697
EI 1879-1026
UT WOS:000532687000015
ER

PT J
AU Zhou, Yi
   Ni, Hongjian
   Shen, Zhonghou
   Zhao, Mengyun
TI Study on particle settling in supercritical carbon dioxide drilling and
   fracturing
SO JOURNAL OF PETROLEUM SCIENCE AND ENGINEERING
VL 190
AR 107061
DI 10.1016/j.petrol.2020.107061
PD JUL 2020
PY 2020
AB In this paper, a generalized and pragmatic model has been established to
   calculate the terminal velocity of particles (cuttings and proppants)
   during settling process in supercritical carbon dioxide (SC-CO2)
   drilling and completion. More specially, this model has considered the
   physical properties of carbon dioxide with temperature and pressure.
   Numerically, it is found that during the settling process, particles
   accelerated with the decrease of acceleration in SC-CO2 firstly, and
   ultimately moved with a constant velocity when the forces reached a
   balance. The effective gravity and the drag force are two dominant
   forces of the particles during the settling process and the virtual mass
   force and the basset force are two orders of magnitude smaller than that
   of the former two forces. Experimentally, the settling process of
   particles in SC-CO2 is described, while terminal velocity tests are
   conducted to examine the effect of pressure, temperature, particle size
   and particle type on the terminal velocity of particles in SC-CO2. The
   experimentally measured and numerically calculated terminal velocity are
   in good agreement under the same conditions. The terminal velocity is
   basically proportional to temperature, particle diameter and particle
   density while inversely proportional to pressure. The error of the
   settling model is the biggest near the critical point. The maximum error
   is 13.67% and minimum error is 2.94% in the comparative data, which
   verifies the accuracy of the model.
TC 0
ZR 0
ZS 0
ZB 0
Z8 0
Z9 0
SN 0920-4105
EI 1873-4715
UT WOS:000531640400005
ER

PT J
AU Zhang, Xinyu
   Ge, Zhiqiang
TI Automatic Deep Extraction of Robust Dynamic Features for Industrial Big
   Data Modeling and Soft Sensor Application
SO IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS
VL 16
IS 7
BP 4456
EP 4467
DI 10.1109/TII.2019.2945411
PD JUL 2020
PY 2020
AB Dynamic is one of the main bottlenecks in the industrial soft sensor
   application, due to the difficulties in representing and extracting
   dynamic data features. Meanwhile, an end-to-end deep network owns the
   ability to characterize sequence data information, but its fitting
   ability requires improvements in practical applications. In this
   article, an ensemble tree model with transferable and robust dynamic
   features extracted by a newly developed automatic dynamic feature
   extractor is proposed. First, the dynamic feature extractor with an
   encoding-decoding structure can provide effective dynamic features,
   which is equivalent to crossing and nonlinear mapping of sequences under
   the supervision of a decoder. Meanwhile, a new "regularization" method
   by smoothing dynamic features based on attention weights is proposed to
   denoise and alleviate the overfitting of the regressor after adding new
   features. Then, the extracted dynamic features can be transferred to the
   regressor with strong generalization ability, which takes into account
   the feature extraction of the deep network and the generalization of
   strong models. Finally, application results on a debutanizer
   distillation process show that the incorporation of robust dynamic
   features can significantly improve the soft sensing performance,
   compared to traditional methods. Moreover, the proposed model is further
   implemented through a cloud computing platform for industrial big data
   analytics.
ZB 0
ZS 0
Z8 0
ZR 0
TC 0
Z9 0
SN 1551-3203
EI 1941-0050
UT WOS:000522523000015
ER

PT J
AU Zhang, Tao
   Liu, Xiao-Yang
   Wang, Xiaodong
TI High Performance GPU Tensor Completion With Tubal-Sampling Pattern
SO IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS
VL 31
IS 7
BP 1724
EP 1739
DI 10.1109/TPDS.2020.2975196
PD JUL 1 2020
PY 2020
AB Data completion is a problem of filling missing or unobserved elements
   of partially observed datasets. Data completion algorithms have received
   wide attention and achievements in diverse domains including data
   mining, signal processing, and computer vision. We observe a ubiquitous
   tubal-sampling pattern in big data and Internet of Things (IoT)
   applications, which is introduced by many reasons such as high data
   acquisition cost, downsampling for data compression, sensor node
   failures, and packet losses in low-power wireless transmissions. To meet
   the time and accuracy requirements of applications, data completion
   methods are expected to be accurate as well as fast. However, the
   existing methods for data completion with the tubal-sampling pattern are
   either accurate or fast, but not both. In this article, we propose
   high-performance graphics processing unit (GPU) tensor completion for
   data completion with the tubal-sampling pattern. First, by exploiting
   the convolution theorem, we split a tensor least-squares minimization
   problem into multiple least-squares sub-problems in the frequency
   domain. In this way, massive parallelisms are exposed for many-core GPU
   architectures while still preserving high recovery accuracy. Second, we
   propose computing slice-level and tube-level tasks in batches to improve
   GPU utilization. Third, we reduce the data transfer cost by eliminating
   the accesses to the CPU memory inside algorithm loop structures. The
   experimental results show that the proposed tensor completion is both
   fast and accurate. Using synthetic data of varying sizes, the proposed
   GPU tensor completion achieves maximum $248.18 \times$248.18x, $7,403.27
   \times$7,403.27x, and $33.27 \times$33.27x speedups over the CPU MATLAB
   implementation, GPU element-sampling tensor completion in the
   cuTensor-tubal library, and GPU high-performance matrix completion,
   respectively. With a 50 percent sampling rate, the proposed GPU tensor
   completion achieves a recovery error of $1.40e$1.40e-5, which is
   comparable with that of the GPU element-sampling tensor completion and
   three orders of magnitude better than that of the GPU high-performance
   matrix completion. To utilize multiple GPUs in servers, we design a
   multi-GPU scheme for tubal-sampling tensor completion. The multi-GPU
   tensor completion achieves maximum $1.89 \times$1.89x speedup on two
   GPUs versus on a single GPU for medium or big tensors. We further
   evaluate the performance of the proposed GPU tensor completion in three
   real applications, namely, video transmission in wireless camera
   networks, RF fingerprint-based indoor localization, and seismic data
   completion, and it achieves maximum speedups of $448.68 \times$448.68x,
   $24.63 \times$24.63x, and $311.54 \times$311.54x, respectively. We
   integrate this high-performance GPU tensor completion implementation
   into the cuTensor-tubal library to support various applications.
OI Liu, Xiao-Yang/0000-0002-9532-1709
Z8 0
ZS 0
ZB 0
ZR 0
TC 0
Z9 0
SN 1045-9219
EI 1558-2183
UT WOS:000522197600002
ER

PT J
AU Aboelmaged, Mohamed
   Mouakket, Samar
TI Influencing models and determinants in big data analytics research: A
   bibliometric analysis
SO INFORMATION PROCESSING & MANAGEMENT
VL 57
IS 4
AR 102234
DI 10.1016/j.ipm.2020.102234
PD JUL 2020
PY 2020
AB Incorporating big data analytics into a particular context brings
   various challenges that rest on the model or framework through which
   individuals or organisations adopt big data to achieve their objectives.
   Although these models have recently triggered scholars' attention in
   various domains, in-depth knowledge of using each of these models in big
   data research is still blurred. This study enriches our knowledge on
   emerging models and theories that shape big data analytics adoption
   (BDAD) research through a bibliometric analysis of 229 studies (143
   journal articles and 86 conference papers) published in indexed sources
   between 2013 and 2019. As a result, twenty models on BDAD have emerged
   (e.g., "Dynamic Capabilities", "Resource-Based View", "Technology
   Acceptance Model", "Diffusion of Innovation", etc.). The analysis
   reveals that BDAD research to demonstrate attributes suggestive of a
   topic at an initial stage of development as it is broadly dispersed
   across different domains employs a wide range of models, some of which
   overlap. Most of the applied models are generic in nature focusing on
   variance-based relationships and snapshot prediction with little
   consensus. There is a conspicuous dearth of process models, firm-level
   analysis and cultural orientation in contemporary BDAD research.
   Insights of this bibliometric study could guide rigorous big data
   research and practice in various contexts. The study concludes with
   research implications and limitations that offer promising prospects for
   forthcoming research.
ZB 0
TC 0
Z8 0
ZS 0
ZR 0
Z9 0
SN 0306-4573
EI 1873-5371
UT WOS:000531082800016
ER

PT J
AU Fathi, Ramian
   Thom, Dennis
   Koch, Steffen
   Ertl, Thomas
   Fiedrich, Frank
TI VOST: A case study in voluntary digital participation for collaborative
   emergency management
SO INFORMATION PROCESSING & MANAGEMENT
VL 57
IS 4
AR 102174
DI 10.1016/j.ipm.2019.102174
PD JUL 2020
PY 2020
AB Virtual Operations Support Teams (VOSTs) are a novel form of organized
   intelligence-gathering effort that has recently appeared in the
   emergency management and disaster response domain. Using novel
   organizational strategies and advanced algorithmic tools, such teams are
   set up to master the challenge of data overload and to turn it into
   increased situational awareness for decision-makers. This paper contains
   an analysis of the structural, procedural and technical requirements of
   VOSTs for the collaborative deployment with emergency management
   agencies during the Grand Depart of the Tour de France 2017 in
   Dusseldorf. We had the unique opportunity to participate in the creation
   and initial deployments of a VOST, a new team assembled by the German
   Federal Agency for Technical Relief (THW). Based on our observations we
   will provide a structured investigation into the various tasks of a
   VOST, such as social media monitoring, information verification, and
   crisis mapping. Due to the specific nature of the challenges faced by a
   VOST, which inherently involve big data processing, we will discuss the
   technical requirements and future prospects of data mining tools
   developed for and employed within this context.
ZB 0
TC 0
Z8 0
ZS 0
ZR 0
Z9 0
SN 0306-4573
EI 1873-5371
UT WOS:000531082800001
ER

PT J
AU Bello, O.
   Dolberg, E. P.
   Teodoriu, C.
   Karami, H.
   Devegowdva, D.
TI Transformation of academic teaching and research: Development of a
   highly automated experimental sucker rod pumping unit
SO JOURNAL OF PETROLEUM SCIENCE AND ENGINEERING
VL 190
AR 107087
DI 10.1016/j.petrol.2020.107087
PD JUL 2020
PY 2020
AB Sucker rod pumps are one of the most popular solutions for artificial
   lift since their inception in the 19th century with minimum changes in
   design. Presently, companies are deploying digital technology in the
   field and, there has been a big push for a networked oilfield in recent
   years. This means technology is now able to control machines in remote
   places, evaluate their performances and control safety operating
   parameters. But these digital solutions are still not available in
   universities, causing a technological and technical gap for students and
   researchers.
   This study presents a prototype of a new dedicated Interactive Digital
   Sucker Rod Pumping Unit (ID-SRP) system at the University of Oklahoma
   with representative operating conditions. The prototype mimics sucker
   rod pump working principles and also imitates different realistic rod
   string motions. The application and solutions are focused on providing
   authentic learning experiences for petroleum engineers. The system is
   also designed to address and optimize SRP well performance and safety
   through Model Predictive Controller (MPC) implementation and meeting
   industrial requirements. It connects the physical and virtual
   interaction with learning technologies. The objective is to bridge the
   tangible and the abstract for a better understanding of sucker rod
   concept and implement existing theories into the digital system.
   Additionally, it aids our future petroleum engineers on how to apply
   basic industry principles and upsurge their problem-solving skills.
   The developed unit is capable of simulating any situations in real time
   and using Internet of Things (IoT) for data acquisition to create
   tailored diagnostic tools that students and laboratory staff can
   utilize. The software selected for the system is LabVIEW, which controls
   all the necessary equipment. This system can build personalized dynocard
   graphs, intake live data and export them to other programs live Excel,
   MATLAB, Python or any other programming languages.
TC 0
ZR 0
Z8 0
ZS 0
ZB 0
Z9 0
SN 0920-4105
EI 1873-4715
UT WOS:000531624100002
ER

PT J
AU Galan Otero, Maria Luisa
TI Big Data: Catching the Consumer
SO ANUARIO TURISMO Y SOCIEDAD
VL 27
BP 183
EP 186
DI 10.18601/01207555.n27.10
PD JUL-DEC 2020
PY 2020
ZB 0
Z8 0
TC 0
ZR 0
ZS 0
Z9 0
SN 0120-7555
EI 2346-206X
UT WOS:000531435300010
ER

PT J
AU Chiang, Sharon
   Haut, Sheryl R.
   Ferastraoaru, Victor
   Rao, Vikram R.
   Baud, Maxime O.
   Theodore, William H.
   Moss, Robert
   Goldenholz, Daniel M.
TI Individualizing the definition of seizure clusters based on temporal
   clustering analysis
SO EPILEPSY RESEARCH
VL 163
AR 106330
DI 10.1016/j.eplepsyres.2020.106330
PD JUL 2020
PY 2020
AB Objective: Seizure clusters are often encountered in people with poorly
   controlled epilepsy. Detection of seizure clusters is currently based on
   simple clinical rules, such as two seizures separated by four or fewer
   hours or multiple seizures in 24 h. Current definitions fail to
   distinguish between statistically significant clusters and those that
   may result from natural variation in the person's seizures. Ability to
   systematically define when a seizure cluster is significant for the
   individual carries major implications for treatment. However, there is
   no uniform consensus on how to define seizure clusters. This study
   proposes a principled statistical approach to defining seizure clusters
   that addresses these issues.
   Methods: A total of 533,968 clinical seizures from 1,748 people with
   epilepsy in the Seizure Tracker (TM) seizure diary database were used
   for algorithm development. We propose an algorithm for automated
   individualized seizure cluster identification combining cumulative sum
   change-point analysis with bootstrapping and aberration detection, which
   provides a new approach to personalized seizure cluster identification
   at user-specified levels of clinical significance. We develop a
   standalone user interface to make the proposed algorithm accessible for
   real-time seizure cluster identification (ClusterCalc (TM)). Clinical
   impact of systematizing cluster identification is demonstrated by
   comparing empirically-defined clusters to those identified by routine
   seizure cluster definitions. We also demonstrate use of the Hurst
   exponent as a standardized measure of seizure clustering for comparison
   of seizure clustering burden within or across patients.
   Results: Seizure clustering was present in 26.7 % (95 % CI, 24.5-28.7 %)
   of people with epilepsy. Empirical tables were provided for
   standardizing inter- and intra-patient comparisons of seizure cluster
   tendency. Using the proposed algorithm, we found that 37.7-59.4 % of
   seizures identified as clusters based on routine definitions had high
   probability of occurring by chance. Several clusters identified by the
   algorithm were missed by conventional definitions. The utility of the
   ClusterCalc algorithm for individualized seizure cluster detection is
   demonstrated.
   Significance: This study proposes a principled statistical approach to
   individualized seizure cluster identification and demonstrates potential
   for real-time clinical usage through ClusterCalc. Using this approach
   accounts for individual variations in baseline seizure frequency and
   evaluates statistical significance. This new definition has the
   potential to improve individualized epilepsy treatment by systematizing
   identification of unrecognized seizure clusters and preventing
   unnecessary intervention for random events previously considered
   clusters.
ZS 0
ZB 0
ZR 0
Z8 0
TC 0
Z9 0
SN 0920-1211
EI 1872-6844
UT WOS:000531077900007
PM 32305858
ER

PT J
AU Hamilton, Leah M.
   Lahne, Jacob
TI Fast and automated sensory analysis: Using natural language processing
   for descriptive lexicon development
SO FOOD QUALITY AND PREFERENCE
VL 83
AR 103926
DI 10.1016/j.foodqual.2020.103926
PD JUL 2020
PY 2020
AB As sensory evaluation relies upon humans accurately communicating their
   sensory experience, the diverse and overlapping vocabulary of flavor
   descriptors remains a major challenge. The lexicon generation protocols
   used in methods like Descriptive Analysis are expensive and
   time-consuming, while the post-facto analyses of natural vocabulary in
   "quick and dirty" methods like Free Choice or Flash Profiling require
   considerable subjective decision-making on the part of the analyst. A
   potential alternative for producing lexicons and analyzing the sensory
   attributes of products in nonstandardized text can be found in Natural
   Language Processing (NLP). NLP tools allow for the analysis of larger
   volumes of free text with fewer subjective decisions. This paper
   describes the steps necessary to automatically collect, clean, and
   analyze existing product descriptions from the web. As a case study,
   online reviews of international whiskies from two prominent websites
   (2309 reviews from WhiskyCast and 4289 reviews from WhiskyAdvocate) were
   collected, preprocessed to only retain potentially-descriptive nouns,
   adjectives, and verbs, and then the final term list was grouped into a
   flavor wheel using Correspondence Analysis and Agglomerative
   Hierarchical Clustering. The wheel is compared to an existing Scotch
   flavor wheel. The ease of collecting nonstandardized descriptions of
   products and the improved speed of automated methods can facilitate
   collection of descriptive sensory data for products where no lexicon
   exists. This has the potential to speed up and standardize many of the
   bottlenecks in rapid descriptive methods and facilitate the collection
   and use of very large datasets of product descriptions.
ZB 0
ZR 0
ZS 0
TC 0
Z8 0
Z9 0
SN 0950-3293
EI 1873-6343
UT WOS:000528541400024
ER

PT J
AU Liu, Rutian
   Simon, Eric
   Amann, Bernd
   Gancarski, Stephane
TI Discovering and merging related analytic datasets
SO INFORMATION SYSTEMS
VL 91
AR UNSP 101495
DI 10.1016/j.is.2020.101495
PD JUL 2020
PY 2020
AB The production of analytic datasets is a significant big data trend and
   has gone well beyond the scope of traditional IT-governed dataset
   development. Analytic datasets are now created by data scientists and
   data analysts using big data frameworks and agile data preparation
   tools. However, despite the profusion of available datasets, it remains
   quite difficult for a data analyst to start from a dataset at hand and
   customize it with additional attributes coming from other existing
   datasets. This article describes a model and algorithms that exploit
   automatically extracted and user-defined semantic relationships for
   extending analytic datasets with new atomic or aggregated attribute
   values. Our framework is implemented as a REST service in SAP HANA and
   includes a careful theoretical analysis and practical solutions for
   several complex data quality issues. (C) 2020 Elsevier Ltd. All rights
   reserved.
ZB 0
Z8 0
TC 0
ZR 0
ZS 0
Z9 0
SN 0306-4379
EI 1873-6076
UT WOS:000530715700006
ER

PT J
AU Tang, Zhuo
   Zeng, Ailing
   Zhang, Xuedong
   Yang, Li
   Li, Kenli
TI Dynamic memory-aware scheduling in spark computing environment
SO JOURNAL OF PARALLEL AND DISTRIBUTED COMPUTING
VL 141
BP 10
EP 22
DI 10.1016/j.jpdc.2020.03.010
PD JUL 2020
PY 2020
AB Scheduling plays an important role in improving the performance of big
   data-parallel processing. Spark is an in-memory parallel computing
   framework that uses a multi-threaded model in task scheduling. Most
   Spark task scheduling processes do not take the memory into account, but
   the number of concurrent task threads determined by the user. It emerges
   as a potential limitation for the performance. To overcome the
   limitations in the Spark-core source code, this paper proposes a dynamic
   Spark memory-aware task scheduler (DMATS), which not only treats memory
   and network I/O as a computational resource but also dynamically adjusts
   concurrency when scheduling tasks. Specifically, we first analyze the
   RDD based Spark execution engine to obtain the amount of task processing
   data and propose an algorithm for estimating the initial adaptive task
   concurrency, which is integrated with the known task input information
   and the executor memory. Then, a dynamic adjustment algorithm is
   proposed to change the concurrency dynamically through feedback
   information to optimally utilize the limited memory resources. We
   implement a dynamic memory-aware task scheduling (DMATS) in Spark 2.3.4
   and evaluate performance with two typical benchmarks, shuffle-light and
   shuffle-heavy. The results show that the algorithm not only reduces the
   execution time by 43.64%, but also significantly improves resource
   utilization. Experiments also show that our proposed method has
   advantages compared with other similar works such as WASP. (C) 2020
   Elsevier Inc. All rights reserved.
Z8 0
TC 0
ZR 0
ZS 0
ZB 0
Z9 0
SN 0743-7315
EI 1096-0848
UT WOS:000530200400002
ER

PT J
AU Liu, Qin
   Bhuiyan, Md Zakirul Alam
   Hu, Jiankun
   Wu, Jie
TI Preface: Security & privacy in social big data
SO JOURNAL OF PARALLEL AND DISTRIBUTED COMPUTING
VL 141
BP 59
EP 60
DI 10.1016/j.jpdc.2020.03.011
PD JUL 2020
PY 2020
AB This special issue assembles a set of 11 papers, which provide deep
   research results to report the advance of security and privacy
   technology in social big data. This preface provides overview of all
   articles in the viewpoint set. (C) 2020 Elsevier Inc. All rights
   reserved.
ZS 0
TC 0
ZR 0
ZB 0
Z8 0
Z9 0
SN 0743-7315
EI 1096-0848
UT WOS:000530200400006
ER

PT J
AU Jameel, Yusuf
   Valle, Denis
   Kay, Paul
TI Spatial variation in the detection rates of frequently studied
   pharmaceuticals in Asian, European and North American rivers.
SO The Science of the total environment
VL 724
BP 137947
EP 137947
DI 10.1016/j.scitotenv.2020.137947
PD 2020-Jul-01
PY 2020
AB Pharmaceutical consumption has expanded rapidly during the last century
   and their persistent presence in the environment has become a major
   concern. Unfortunately, our understanding of the distribution of
   pharmaceuticals in surface water and their effects on aquatic biota and
   public health is limited. Here, we explore patterns in the detection
   rate of the most frequently studied pharmaceuticals in 64 rivers from 22
   countries using bi-clustering algorithms and subsequently analyze the
   results in the context of regional differences in pharmaceutical
   consumption habits, social and environmental factors, and
   removal-efficiency of wastewater treatment plants (WWTP). We find that
   20% of the pharmaceuticals included in this analysis are pervasively
   present in all the surface waterbodies. Several pharmaceuticals also
   display low overall positive detection rates; however, they exhibit
   significant spatial variability and their detection rates are
   consistently lower in Western European and North America (WEOG) rivers
   in comparison to Asian rivers. Our analysis suggests the important role
   of pharmaceutical consumption and population in governing these
   patterns, however the role of WWTP efficiency appeared to be limited. We
   were constrained in our ability to assess the role of hydrology, which
   most likely also plays an important role in regulating pharmaceuticals
   in rivers. Most importantly though, we demonstrate the ability of our
   algorithm to provide probabilistic estimates of the detection rate of
   pharmaceuticals that were not studied in a river, an exercise that could
   be useful in prioritizing pharmaceuticals for future study.
OI Valle, Denis/0000-0002-9830-8876
ZR 0
ZS 0
TC 0
Z8 0
ZB 0
Z9 0
EI 1879-1026
UT MEDLINE:32408421
PM 32408421
ER

PT J
AU Wang, Jiajia
   Lu, Xiaoman
   Yan, Yingting
   Zhou, Liguo
   Ma, Weichun
TI Spatiotemporal characteristics of PM2.5 concentration in the Yangtze
   River Delta urban agglomeration, China on the application of big data
   and wavelet analysis.
SO The Science of the total environment
VL 724
BP 138134
EP 138134
DI 10.1016/j.scitotenv.2020.138134
PD 2020-Jul-01
PY 2020
AB PM2.5 pollution has been one of the main environmental issues of concern
   for the Yangtze River Delta Urban Agglomeration (YRDUA) during the
   recent decade. In this paper, allied with big data and wavelet analysis,
   spatiotemporal variations of PM2.5 and its influencing factors (air
   pollutants and meteorological factors) are studied based on hourly
   concentrations of PM2.5 from 2015 to 2018 in the YRDUA. Results showed
   that PM2.5 presented a step-shaped decline from northwest to southeast
   in space and significant multi-scale temporal variations in time. On the
   macroscopic level, PM2.5 concentrations decreased from 2015 to 2018,
   showing a U-shaped pattern within a year. On the microscopic level, it
   had a four-stage annual variation (January to March, April to June, July
   to September, October to December) and the mutation events mainly
   occurred in winter. There were two dominant periods of PM2.5, an annual
   cycle on the time scale of 250-480 d and a semi-annual cycle on the time
   scale of 130-220 d. In addition, PM2.5 showed time scale-dependent
   correlations with air pollutants and meteorological factors. Among air
   pollutants, the correlation between PM2.5 and CO was the most
   consistent, and the correlation between PM2.5 and SO2/NO2 improved with
   the increase of time scale, while the correlation between PM2.5 and O3
   was positive at shorter time scales but negative at broader time scales.
   Among meteorological factors, the correlations between PM2.5 and wind
   speed, precipitation, temperature, air pressure and relative humidity
   were mainly reflected at broader time scales. These findings would be
   helpful to improve the accuracy of prediction model and provide
   references for the ongoing joint prevention and control.
ZS 0
ZB 0
ZR 0
TC 0
Z8 0
Z9 0
EI 1879-1026
UT MEDLINE:32408437
PM 32408437
ER

PT J
AU Coulter, Rory
   Han, Qing-Long
   Pan, Lei
   Zhang, Jun
   Xiang, Yang
TI Code analysis for intelligent cyber systems: A data-driven approach
SO INFORMATION SCIENCES
VL 524
BP 46
EP 58
DI 10.1016/j.ins.2020.03.036
PD JUL 2020
PY 2020
AB Cyber code analysis is fundamental to malware detection and
   vulnerability discovery for defending cyber attacks. Traditional
   approaches resorting to manually defined rules are gradually replaced by
   automated approaches empowered by machine learning. This revolution is
   accelerated by big code from open source projects which support machine
   learning models with outstanding performance. In the context of a
   data-driven paradigm, this paper reviews recent analytic research on
   cyber code of malicious and common software by using a set of common
   concepts of similarity, correlation and collective indication. Sharing
   security goals in recognizing anomalous code that may be malicious or
   vulnerable. The ability to do so is not determined in isolation, rather
   drawn for code correlation and context awareness. This paper
   demonstrates a new research methodology of data driven cyber security
   (DDCS) and its application in cyber code analysis. The framework of the
   DDCS methodology consists of three components, i.e., cyber security data
   processing, cyber security feature engineering, and cyber security
   modeling. Some challenging issues are suggested to direct the future
   research. (C) 2020 Elsevier Inc. All rights reserved.
OI Pan, Lei/0000-0002-4691-8330
ZB 0
ZS 0
ZR 0
TC 0
Z8 0
Z9 0
SN 0020-0255
EI 1872-6291
UT WOS:000530095300004
ER

PT J
AU Abhishake
   Sivananthan, S.
TI Manifold regularization based on Nystrom type subsampling
SO APPLIED AND COMPUTATIONAL HARMONIC ANALYSIS
VL 49
IS 1
BP 152
EP 179
DI 10.1016/j.acha.2018.12.002
PD JUL 2020
PY 2020
AB In this paper, we study the Nystrom type subsampling for large-scale
   kernel methods to reduce the computational complexities of big data. We
   discuss the multi-penalty regularization scheme based on Nystrom type
   subsampling which is motivated from well-studied manifold regularization
   schemes. We develop a theoretical analysis of the multi-penalty
   least-square regularization scheme under the general source condition in
   vector-valued function setting, therefore the results can also be
   applied to multi-task learning problems. We achieve the optimal minimax
   convergence rates of the multi-penalty regularization using the concept
   of effective dimension for the appropriate subsampling size. We discuss
   an aggregation approach based on the linear function strategy to combine
   various Nystrom approximants. Finally, we demonstrate the performance of
   the multi-penalty regularization based on Nystrom type subsampling on
   the Caltech-101 dataset for multi-class image classification and NSL-KDD
   benchmark dataset for intrusion detection problem. (C) 2018 Elsevier
   Inc. All rights reserved.
RI Rastogi, Abhishake/A-2912-2019
OI Rastogi, Abhishake/0000-0001-5401-0990
TC 0
ZB 0
Z8 0
ZS 0
ZR 0
Z9 0
SN 1063-5203
EI 1096-603X
UT WOS:000528943000007
ER

PT J
AU Hu, Ting
   Wu, Qiang
   Zhou, Ding-Xuan
TI Distributed kernel gradient descent algorithm for minimum error entropy
   principle
SO APPLIED AND COMPUTATIONAL HARMONIC ANALYSIS
VL 49
IS 1
BP 229
EP 256
DI 10.1016/j.acha.2019.01.002
PD JUL 2020
PY 2020
AB Distributed learning based on the divide and conquer approach is a
   powerful tool for big data processing. We introduce a distributed kernel
   gradient descent algorithm for the minimum error entropy principle and
   analyze its convergence. We show that the L-2 error decays at a minimax
   optimal rate under some mild conditions. As a tool we establish some
   concentration inequalities for U-statistics which play pivotal roles in
   our error analysis. Published by Elsevier Inc.
ZB 0
ZS 0
Z8 0
ZR 0
TC 2
Z9 2
SN 1063-5203
EI 1096-603X
UT WOS:000528943000010
ER

PT J
AU Rouland, Quentin
   Hamid, Brahim
   Jaskolka, Jason
TI Formal specification and verification of reusable communication models
   for distributed systems architecture
SO FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE
VL 108
BP 178
EP 197
DI 10.1016/j.future.2020.02.033
PD JUL 2020
PY 2020
AB The development of distributed computing systems involves complex
   concerns related to integrating numerous communication styles,
   technologies (Internet of Things, cloud, big data, etc.), stakeholders
   (architects, developers, integrators, etc.) and addressing a multitude
   of application domains (smart cities, health, mobility, etc.). Existing
   architectural description languages fail to rigorously bridge the gap
   between the abstract representation of communication styles and those
   supported by existing execution infrastructures. In this paper, we
   propose an approach combining semi-formal and formal languages which
   considers modeling and formalization from both the structural and
   communication behavior perspectives. As a prerequisite, we build
   reusable model libraries to specify and verify communication styles for
   modeling software architectures of distributed systems. First, we
   propose a metamodel to describe high-level concepts of architecture in a
   component-port-connector fashion focusing on different communication
   styles. Then, we formalize those concepts and their semantics following
   some properties (specifications) to check architectural conformance. To
   validate our work, we provide a set of reusable connector libraries
   within a set of properties to define architectures for systems with
   explicit communication models that are common to most distributed
   systems including message passing, remote procedure calls, and
   distributed shared memory. Through reuse of these specified and verified
   connectors, we demonstrate how concrete software architectures for a
   given application domain can be developed. (C) 2020 Elsevier B.V. All
   rights reserved.
ZS 0
Z8 0
ZR 0
TC 0
ZB 0
Z9 0
SN 0167-739X
EI 1872-7115
UT WOS:000528199900013
ER

PT J
AU Li, Daming
   Deng, Lianbing
   Liu, Wenjian
   Su, Qinglang
TI Improving communication precision of IoT through behavior-based learning
   in smart city environment
SO FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE
VL 108
BP 512
EP 520
DI 10.1016/j.future.2020.02.053
PD JUL 2020
PY 2020
AB Internet of Things (IoT) is an emergent heterogeneous communication
   platform that provides ubiquitous access to resources and meets the user
   demands. Developing smart city paradigm employs this communication
   platform for providing services to the users and granting distributed
   resource sharing. Mitigating adversary device selection in this platform
   prevents irrelevant data exchange and eases information access and
   exchange. External and internal communication hindering factors needs to
   be addressed to sustain uninterrupted communication. To improve the
   precision in communication security, an observation-based security
   system is modeled in this manuscript. This security system observes the
   local and global behavioral change in IoT device communication. The
   local and global behavioral changes are defined using device attributes
   and behavior modeling. The device and service provider input
   observations are processed by a neural network-based learning scheme to
   identify errors in the resource access. The communicating users and IoT
   devices are secured by selecting reputed service providers and data
   sources to improve the distributed resource utilization in IoT based
   smart city. The performance of the proposed scheme balances between
   security and resource utilization requirements of the users by reducing
   response loss and non-reputed device selection. (C) 2020 Published by
   Elsevier B.V.
Z8 0
ZB 0
TC 0
ZR 0
ZS 0
Z9 0
SN 0167-739X
EI 1872-7115
UT WOS:000528199900037
ER

PT J
AU Gao, Ying
   Wu, Xiaoqiang
   Yan, Wei
   Zhang, Lei
   Wu, Tunhua
TI Dynamic network embedding enhanced advisor-advisee relationship
   identification based on internet of scholars
SO FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE
VL 108
BP 677
EP 686
DI 10.1016/j.future.2020.03.024
PD JUL 2020
PY 2020
AB Advisor-advisee relationship is a special social relationship and
   interpersonal relationship. In the era of scholarly big data, mining and
   analyzing this kind of academic relationships is of great significance.
   Though many studies explore the advisor-advisee relationships based on
   real-world dataset, the scale of their dataset is relatively small.
   Based on the assumption that advisor-advisee relationships are hidden in
   collaboration networks, this paper proposes a novel method by performing
   dynamic network embedding on internet of scholars. Specifically, we
   consider various scholar attributes and dynamic network embedding-based
   scholar vector as the input of supervised machine learning methods for
   advisor-advisee relationship identification. Experimental results on the
   real-world dataset show that our proposed method can achieve the best
   performance compared with several state-of-the-art methods. (C) 2020
   Elsevier B.V. All rights reserved.
ZS 0
ZR 0
ZB 0
TC 0
Z8 0
Z9 0
SN 0167-739X
EI 1872-7115
UT WOS:000528199900050
ER

PT J
AU Awaysheh, Feras M.
   Alazab, Mamoun
   Gupta, Maanak
   Pena, Tomas F.
   Cabaleiro, Jose C.
TI Next-generation big data federation access control: A reference model
SO FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE
VL 108
BP 726
EP 741
DI 10.1016/j.future.2020.02.052
PD JUL 2020
PY 2020
AB This paper discusses one of the most significant challenges of
   next-generation big data (BD) federation platforms, namely, Hadoop
   access control. Privacy and security on a federation scale remain
   significant concerns among practitioners in both industry and academia.
   Hadoop's current primitive access control presents security concerns and
   limitations, such as the complexity of deployment and the consumption of
   resources. However, this major concern has not been a subject of
   intensive study in the literature. This paper critically reviews and
   investigates these security limitations and provides a framework called
   BD federation access broker to address 8 main security limitations. This
   paper proposes the federated access control reference model (FACRM) to
   formalize the design of secure BD solutions within the Apache Hadoop
   stack. Furthermore, this paper discusses the implementation of the
   access broker and its usefulness for security breach detection and
   digital forensics investigations. The efficiency of the proposed access
   broker has not sustainably affected the performance overhead. The
   experimental results show only 1% of each 100 MB read/write operation in
   a WebHDFS. Overall, the findings of the paper pave the way for a wide
   range of revolutionary and state-of-the-art enhancements and future
   trends within Hadoop stack security and privacy. (C) 2020 Elsevier B.V.
   All rights reserved.
Z8 0
ZS 0
ZR 0
ZB 0
TC 0
Z9 0
SN 0167-739X
EI 1872-7115
UT WOS:000528199900054
ER

PT J
AU Sajid, Adnan
   Khalid, Bilal
   Ali, Mudassar
   Mumtaz, Shahid
   Masud, Usman
   Qamar, Farhan
TI Securing Cognitive Radio Networks using blockchains
SO FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE
VL 108
BP 816
EP 826
DI 10.1016/j.future.2020.03.020
PD JUL 2020
PY 2020
AB Due to the increase in industrial applications of Internet of Things
   (IoT), number of internet connected devices have been increased
   accordingly. This has resulted in big challenges in terms of
   accessibility, scalability, connectivity and adaptability. IoT is
   capable of creating connections between devices on wireless medium but
   the utilization of scarce spectrum in efficient manner for the
   establishment of these connections is the biggest concern. To
   accommodate spectrum allocation problem different radio technologies are
   being utilized. One of the most efficient technique being used is
   cognitive radio, which dynamically allocate the unlicensed spectrum for
   IoT applications. Spectrum sensing being the fundamental component of
   Cognitive Radio Network (CRN) is threatened by security attacks. Process
   of spectrum sensing is disturbed by the malicious user (MU) which
   attacks the primary signal detection and affects the accuracy of sensing
   outcome. The presence of such MU in system, sending false sensing data
   can degrade the performance of cognitive radios. Therefore, in this
   article a blockchain based method is proposed for the MU detection in
   network. By using this method an MU can easily be discriminated from a
   reliable user through cryptographic keys. The efficiency of the proposed
   mechanism is analyzed through proper simulations using MATLAB.
   Consequently, this mechanism can be deployed for the validation of
   participating users in the process of spectrum sensing in CRN for IoTs.
   (C) 2020 Elsevier B.V. All rights reserved.
OI Mumtaz, Dr Rao shahid/0000-0001-6364-6149
Z8 0
TC 0
ZS 0
ZB 0
ZR 0
Z9 0
SN 0167-739X
EI 1872-7115
UT WOS:000528199900060
ER

PT J
AU Pradeep, D.
   Sundar, C.
TI QAOC: Novel query analysis and ontology-based clustering for data
   management in Hadoop
SO FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE
VL 108
BP 849
EP 860
DI 10.1016/j.future.2020.03.010
PD JUL 2020
PY 2020
AB Bottleneck issues handled in the field of information retrieval are
   analysis of query and management of data storage. Hadoop is a large
   scale environment that is supported with larger storage and faster
   processing. Even though, it suffers from these challenging issues while
   the number of information requesters is higher. This paper addresses
   these two bottleneck issues in Hadoop by retrieving the information with
   the design of Query Analysis and Ontology-based Clustering (QAOC)
   architecture. In QAOC architecture, the components involved are query
   manager, scheduler and data management. Initially the query manager
   consolidates the query if they are similar; hereby the searching time is
   effectively minimized. Then the user query is scheduled in neuro-fuzzy
   by computing query arrival time, query length and query expiry time. The
   data management in the back-end is operated by weighted ontology-based
   clustering method to cluster the data based on their relevancy. The
   scheduled user query is searched in the ontology based balanced binary
   tree and lastly the relevant results are ranked using Okapi BM25 and
   delivered to user. This QAOC architecture is experimented on Hadoop 2.7
   and the results are compared in terms of execution time, processing
   speed and memory consumption. (C) 2020 Elsevier B.V. All rights
   reserved.
RI D, Pradeep/AAO-9763-2020
OI D, Pradeep/0000-0002-3629-9994
ZB 0
TC 0
ZS 0
Z8 0
ZR 0
Z9 0
SN 0167-739X
EI 1872-7115
UT WOS:000528199900062
ER

PT J
AU Bellavista, Paolo
   Ota, Kaoru
   Lv, Zhihan
   Mehmood, Irfan
   Rho, Seungmin
TI Towards smarter cities: Learning from Internet of Multimedia
   Things-generated big data
SO FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE
VL 108
BP 879
EP 881
DI 10.1016/j.future.2019.06.003
PD JUL 2020
PY 2020
AB In today's technological era, smart devices connected through the IoT
   and giant IoT infrastructures are playing a vital role in making daily
   life easier and simpler than it ever was. Numerous sensors including
   IoT-interconnected multimedia sensors communicating with each other
   generate a huge amount of data. In particular, IoT multimedia sensors
   play a vital role for green cities, providing secure and efficient
   analytics to monitor routine activities. Big data generated by these
   sensors contain dense information that needs to be processed for various
   applications such as summarization, security, and privacy. The
   heterogeneity and complexity of video data is the biggest hurdle and a
   pretty number of techniques are already developed for the efficient
   processing of big video data. IoT big data processing is an emerging
   field and many researchers are enthusiastic to contribute in making the
   cities smarter. Among all these methods, deep learning-based techniques
   are dominant over existing traditional multimedia data processing
   algorithms with convincing results emerged recently. This special issue
   targets the current problems in smart cities development and provides
   future challenges in this domain and invite researchers working in IoT
   domain to make cities smarter. It also focuses on some related
   technologies comprising Internet of Multimedia Things (IoMTs) and
   machine learning for big data. Furthermore, it covers deep
   learning-based solutions for real-time data processing, learning from
   big data, distributed learning paradigms with embedded processing, and
   efficient inference. (C) 2019 Published by Elsevier B.V.
ZR 0
ZB 0
TC 0
ZS 0
Z8 0
Z9 0
SN 0167-739X
EI 1872-7115
UT WOS:000528199900064
ER

PT J
AU Garcia-Valls, Marisol
   Calva-Urrego, Christian
   Garcia-Fornes, Ana
TI Accelerating smart eHealth services execution at the fog computing
   infrastructure
SO FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE
VL 108
BP 882
EP 893
DI 10.1016/j.future.2018.07.001
PD JUL 2020
PY 2020
AB Fog computing improves the execution of computationally intensive
   services for remote client nodes as part of the data processing is
   performed close to the location where the results will be delivered. As
   opposed to other services running on smart cities, a major challenge of
   eHealth services on the fog is that they typically span multiple
   computational activities performing big data processing over sensible
   information that must be protected. Using the capacities of current
   processors can improve the servicing of remote patient nodes. This paper
   presents the design and validation of a framework that improves the
   service time of selected activities at the fog servers; precisely, of
   those activities requested by remote patients. It exploits the
   capacities of current processors to parallelize specific activities that
   can be run on reserved cores, and it relies on the quality of service
   guarantees of data distribution platforms to improve communication and
   response times to mobile patients. The proposed approach is validated on
   a prototype implementation of simulated computationally-intensive
   eHealth interactions, decreasing the response time by 4x when core
   reservation is activated. (C) 2018 Elsevier B.V. All rights reserved.
ZB 0
ZS 0
Z8 0
TC 4
ZR 0
Z9 4
SN 0167-739X
EI 1872-7115
UT WOS:000528199900065
ER

PT J
AU Chen, Bo-Wei
TI Incomplete data classification-Fisher Discriminant Ratios versus Welch
   Discriminant Ratios
SO FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE
VL 108
BP 894
EP 908
DI 10.1016/j.future.2018.05.003
PD JUL 2020
PY 2020
AB This study focuses on incomplete data classification with the support of
   different partial discriminant analyses. When samples contain missing
   values, discriminant analyses such as Principal Component Analysis and
   Fisher Discriminant Analysis are inapplicable. Partial discriminant
   analyses that measure the importance of individual dimensions for
   incomplete data become necessary. Partial discriminant analyses do not
   rely on data imputation. The analyses can select and sort dimensions
   (i.e., predictors) based on discriminability in incomplete data.
   However, the typical approach Fisher Discriminant Ratios may result in
   biased estimation due to unequal variance of classes according to
   statistical literature. This study examines various partial discriminant
   ratios to discover effective approaches for relieving such a problem by
   considering different variance in computation. Experiments on an open
   dataset were carried out during the evaluation. Comparisons included
   discriminability of Partial Fisher Discriminant Ratios, Partial Welch
   Discriminant Ratios, and their derivatives in incomplete date
   classification. (C) 2018 Elsevier B.V. All rights reserved.
Z8 0
ZS 0
ZR 0
ZB 0
TC 1
Z9 1
SN 0167-739X
EI 1872-7115
UT WOS:000528199900066
ER

PT J
AU Tewari, Aakanksha
   Gupta, B. B.
TI Security, privacy and trust of different layers in Internet-of-Things
   (IoTs) framework
SO FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE
VL 108
BP 909
EP 920
DI 10.1016/j.future.2018.04.027
PD JUL 2020
PY 2020
AB Internet of Things (IoT) is playing an important role after its showing
   up, it covers from traditional equipment to general household objects
   such as WSNs and RFID. With the great potential of IoT, there come all
   kinds of challenges. This paper focuses on the security problems among
   all other challenges. As IoT is built on the basis of the Internet,
   security problems of the Internet will also show up in IoT. Moreover, as
   IoT contains three layers: perception layer, transportation layer and
   application layer, this paper will analyze the security problems of each
   layer separately and try to find new problems and solutions. This paper
   also analyzes the cross-layer heterogeneous integration issues and
   security issues in detail and discusses the security issues of IoT as a
   whole and tries to find solutions to them. In the end, this paper
   compares security issues between IoT and traditional network, and
   discusses opening security issues of IoT. (C) 2018 Elsevier B.V. All
   rights reserved.
ZR 0
ZS 0
Z8 0
TC 1
ZB 0
Z9 1
SN 0167-739X
EI 1872-7115
UT WOS:000528199900067
ER

PT J
AU Jindal, Anish
   Kumar, Neeraj
   Singh, Mukesh
TI A unified framework for big data acquisition, storage, and analytics for
   demand response management in smart cities
SO FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE
VL 108
BP 921
EP 934
DI 10.1016/j.future.2018.02.039
PD JUL 2020
PY 2020
AB With an increased usage of information and communication technologies
   (ICT) in the smart cities, the data generated from different smart
   devices has increased manifolds. This data is heterogeneous in nature
   which varies with respect to time and exhibits the properties of all
   essential V's for big data. Therefore, to handle such an enormous amount
   of data, various big data processing techniques are required. To cope up
   with these issues, this paper presents a tensor-based big data
   management technique to reduce the dimensionality of data gathered from
   the Internet-of-Energy (IoE) environment in a smart city. The core data
   is extracted out of the gathered data by using tensor operations such
   as-matricization, vectorization and tensorization with the help of
   higher-order singular value decomposition. This core data is then stored
   on the cloud in the reduced form. After reducing the dimensionality of
   data, it is used for providing many services in smart cities; and its
   application to provide demand response (DR) services has been discussed
   in this paper. For this purpose, support vector machine (SVM)-based
   classifier is used to classify the endusers (residential and commercial)
   into normal, overloaded and underloaded categories from the core data.
   Once such users are identified to take part in DR mechanism, utilities
   then generate commands to handle their DR in order to alter load
   requirements so that the overall load is optimized. Results obtained on
   Open Energy Information and PJM dataset clearly indicate the supremacy
   of the proposed tensor-based scheme over the traditional scheme for DR
   management. (C) 2018 Elsevier B.V. All rights reserved.
RI Kumar, Neeraj/L-3500-2016; Jindal, Anish/
OI Kumar, Neeraj/0000-0002-3020-3947; Jindal, Anish/0000-0002-3052-2892
ZB 0
ZS 0
TC 1
ZR 0
Z8 0
Z9 1
SN 0167-739X
EI 1872-7115
UT WOS:000528199900068
ER

PT J
AU Dey, Maitreyee
   Rana, Soumya Prakash
   Dudley, Sandra
TI Smart building creation in large scale HVAC environments through
   automated fault detection and diagnosis
SO FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE
VL 108
BP 950
EP 966
DI 10.1016/j.future.2018.02.019
PD JUL 2020
PY 2020
AB Modernization and retrofitting of older buildings has created a drive to
   install Building Energy Management Systems (BEMS) that can assist
   building managers in paving the way for smarter energy use and
   indirectly, using appropriate methods, occupant comfort understanding.
   BEMS may discover problems that can inform managers of building
   maintenance and energy wastage issues and in-directly, via repetitive
   data patterns appreciate user comfort requirements. The main focus of
   this paper is to describe a method to detect faulty Heating, Ventilation
   and Air-Conditioning (HVAC) Terminal Unit (TU) and diagnose them in an
   automatic and remote manner. For this purpose, a typical big-data
   framework has been constructed to process the very large volume of data.
   A novel feature extraction method encouraged by Proportional Integral
   Derivative (PID) controller has been proposed to describe events from
   multidimensional TU data streams. These features are further used to
   categorize different TU behaviours using unsupervised data-driven
   strategy and supervised learning is applied to diagnose faults. X-Means
   clustering has been performed to group diverse TU behaviours which are
   experimented on daily, weekly, monthly and randomly selected dataset.
   Subsequently, Multi-Class Support Vector Machine (MC-SVM) has been
   employed based on categorical information to generate an automated fault
   detection and diagnosis system towards making the building smarter. The
   clustering and classification results further compared with well-known
   and established algorithms and validated through statistical
   measurements. (C) 2018 Elsevier B.V. All rights reserved.
OI Dey, Maitreyee/0000-0002-6862-7032
ZS 0
ZR 0
Z8 0
ZB 0
TC 1
Z9 1
SN 0167-739X
EI 1872-7115
UT WOS:000528199900070
ER

PT J
AU Yang, Jiachen
   Han, Yurong
   Wang, Yafang
   Jiang, Bin
   Lv, Zhihan
   Song, Houbing
TI Optimization of real-time traffic network assignment based on IoT data
   using DBN and clustering model in smart city
SO FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE
VL 108
BP 976
EP 986
DI 10.1016/j.future.2017.12.012
PD JUL 2020
PY 2020
AB With the rapid development of the information age, smart city has
   gradually become the mainstream of urban construction. Dynamic
   transportation assignment has attracted more interest in the smart city
   construction under the new era of the Internet of things (IoT) because
   the urban road traffic is the heart of many problems in many fields,
   such as in the case of city congestion and processing center planning
   system. In this paper, we analyzed the processing center's economic
   indexes and optimized the dynamic transportation network assignment
   based on continuous big IoT input database, and a high performance
   computing model is proposed for the dynamic traffic planning.
   Specifically, while the previous methods exploited the geographical
   information system (GIS) or K-means separately, the proposed
   transportation planning is based on the real-time IoT and GIS data,
   which is processed by DBN and K-means to make the final solution close
   to the practice and meet the requirements of high performance computing
   and economic cost. which is regarded as the key target index. Moreover,
   considering the large data characteristic of real-time online stream,
   the deep belief network (DBN) model is built to preprocess the data to
   improve the clustering effect of the K-means. This study works on the
   example case of hotel service centers problem in Tianjin to evaluate the
   optimal dynamic traffic network planning result. The experiment test has
   proved that based on the performance of super high computing, the model
   is precisely helpful for the optimal planning of traffic network under
   real time mass data situation and low cost, and promoting the
   construction and development of the smart city. (C) 2017 Published by
   Elsevier B.V.
RI Song, Houbing/E-3628-2010
OI Song, Houbing/0000-0003-2631-9223
TC 1
Z8 0
ZS 0
ZB 0
ZR 0
Z9 1
SN 0167-739X
EI 1872-7115
UT WOS:000528199900072
ER

PT J
AU Ranjan, Rajiv
   Chen, Lydia Y.
   Jayaraman, Prem Prakash
   Zomaya, Albert Y.
TI A note on advances in scheduling algorithms for Cyber-Physical-Social
   workflows
SO FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE
VL 108
BP 1027
EP 1029
DI 10.1016/j.future.2019.05.073
PD JUL 2020
PY 2020
AB The Call for this Special Issue received a number of submissions. After
   a two-phase review process we accepted ten high quality papers. This
   includes one research survey paper that gives an interesting overview of
   the privacy aspects in cyber physical social environments. The other
   papers are related to scheduling algorithms and techniques for CPS-DS
   workflow applications. (C) 2019 Published by Elsevier B.V.
ZR 0
TC 0
ZS 0
Z8 0
ZB 0
Z9 0
SN 0167-739X
EI 1872-7115
UT WOS:000528199900076
ER

PT J
AU Wen, Yiping
   Liu, Jianxun
   Dou, Wanchun
   Xu, Xiaolong
   Cao, Buqing
   Chen, Jinjun
TI Scheduling workflows with privacy protection constraints for big data
   applications on cloud
SO FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE
VL 108
BP 1084
EP 1091
DI 10.1016/j.future.2018.03.028
PD JUL 2020
PY 2020
AB Nowadays, business or scientific processes with massive big data in
   Cyber-Physical-Social environments are springing up in cloud. Cloud
   customers' private information stored in cloud may be easily exposed and
   lead to serious privacy leakage issues in Cyber-Physical-Social
   environments. To avoid such issues, cloud customers' privacy or
   sensitive data may be restricted to being processed by some specific
   trusted cloud data centers. Therefore, a new problem is how to schedule
   workflow with such data privacy protection constraints, while minimizing
   both execution time and monetary cost for big data applications on
   cloud. In this paper, we model such problem as a multi-objective
   optimization problem and propose a Multi-Objective Privacy-Aware
   workflow scheduling algorithm, named MOPA. It can provide cloud
   customers with a set of Pareto tradeoff solutions. The problem-specific
   encoding and population initialization are proposed in this algorithm.
   The experimental results show that our algorithm can obtain higher
   quality solutions when compared with other ones. (C) 2019 Elsevier B.V.
   All rights reserved.
Z8 0
ZB 0
ZS 0
TC 6
ZR 0
Z9 6
SN 0167-739X
EI 1872-7115
UT WOS:000528199900081
ER

PT J
AU Bal, Henri
   Pal, Arindam
TI Parallel and Distributed Machine Learning Algorithms for Scalable Big
   Data Analytics
SO FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE
VL 108
BP 1159
EP 1161
DI 10.1016/j.future.2019.07.009
PD JUL 2020
PY 2020
AB This editorial is for the Special Issue of the journal Future Generation
   Computing Systems, consisting of the selected papers of the 6th
   International Workshop on Parallel and Distributed Computing for Large
   Scale Machine Learning and Big Data Analytics (ParLearning 2017). In
   this editorial, we have given a high-level overview of the 4 papers
   contained in this special issue, along with references to some of the
   related works. (C) 2019 Elsevier B.V. All rights reserved.
OI Bal, H.E./0000-0001-9827-4461
ZS 0
ZR 0
TC 0
Z8 0
ZB 0
Z9 0
SN 0167-739X
EI 1872-7115
UT WOS:000528199900087
ER

PT J
AU Parnell, Thomas
   Duenner, Celestine
   Atasu, Kubilay
   Sifalakis, Manolis
   Pozidis, Haralampos
TI Tera-scale coordinate descent on GPUs
SO FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE
VL 108
BP 1173
EP 1191
DI 10.1016/j.future.2018.04.072
PD JUL 2020
PY 2020
AB In this work we propose an asynchronous, GPU-based implementation of the
   widely-used stochastic coordinate descent algorithm for convex
   optimization. We define the class of problems that can be solved using
   this method, and show that it includes many popular machine learning
   applications. For three such applications, we demonstrate at least a 10x
   training speed-up relative to a state-of-the-art implementation that
   uses all available resources of a modern CPU. In order to train on very
   large datasets that do not fit inside the memory of a single GPU, we
   then consider techniques for distributed learning. We show that while
   such techniques do not necessarily allow one to achieve further
   speed-up, they do allow one to train on datasets that would otherwise
   not fit into memory. We thus propose a distributed learning system that
   uses the synchronous CoCoA framework to distribute the global
   optimization across GPUs, and our novel asynchronous algorithm to solve
   the corresponding local optimizations within each GPU. We benchmark such
   a system using a 200 GB dataset that consists of 1 billion training
   examples. We show by scaling out across 16 GPUs, we can train an SVM
   model to a high degree of accuracy in around 1 min: a 15x speed-up in
   training time compared to a state-of-the-art CPU-based implementation
   that uses 640 threads distributed across 8 CPUs. (C) 2018 Published by
   Elsevier B.V.
TC 0
ZB 0
ZR 0
ZS 0
Z8 0
Z9 0
SN 0167-739X
EI 1872-7115
UT WOS:000528199900089
ER

PT J
AU Zhang, Yin
   Abbas, Haider
TI Special issue: Cognitive Internet of Things assisted by cloud computing
   and big data
SO FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE
VL 108
BP 1214
EP 1216
DI 10.1016/j.future.2019.07.071
PD JUL 2020
PY 2020
RI Zhang, Yin/O-2149-2015; Abbas, Haider/G-1077-2014
OI Zhang, Yin/0000-0002-1772-0763; Abbas, Haider/0000-0002-2437-4870
ZS 0
ZB 0
TC 0
ZR 0
Z8 0
Z9 0
SN 0167-739X
EI 1872-7115
UT WOS:000528199900092
ER

PT J
AU Xu, Jian
   Wei, Laiwen
   Wu, Wei
   Wang, Andi
   Zhang, Yu
   Zhou, Fucai
TI Privacy-preserving data integrity verification by using lightweight
   streaming authenticated data structures for healthcare cyber-physical
   system
SO FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE
VL 108
BP 1287
EP 1296
DI 10.1016/j.future.2018.04.018
PD JUL 2020
PY 2020
AB Nowadays the healthcare system is undergoing a paradigm shift to
   integrate cloud computing and Internet-of-Things with physical medical
   equipments into a distributed network ensuring real-time and near
   real-time data transfer from the physical world to the cyber space for
   computation, storage and analysis. Namely, the healthcare system can be
   seen as a cyber-physical system (CPS) for patientcentric healthcare
   applications and services, called Health-CPS, based on cloud computing,
   Wireless Body Area Networks (WBANs) and big data analytics technologies.
   Health-CPS has played an important role in healthcare for improving
   treatment quality and patients' assistance speed. However, despite these
   advantages, the development of Health-CPS will be restricted by serious
   security threats, especially the security threats to the
   healthcare-related data. Because Health-CPS forward Electronic health
   records (EHRs), biomedical signals of patients and public health to the
   cloud which may operate in distributed and hostile environments, novel
   security mechanisms are required to prevent malicious interactions to
   the storage infrastructure. Therefore, the cloud providers must take
   strong security measures to protect the integrity and privacy of the
   healthcare related data. But most of the researchers do not
   simultaneously pay attention to both integrity and privacy for
   Health-CPS. Therefore, we proposed a privacy-preserving data integrity
   verification model by using lightweight streaming authenticated data
   structures for HealthCPS. We have given the design idea, architecture,
   formal definition, security definition, communication protocols of our
   model in detail. The key construction processes of our model which
   include initialization, data appending, scale expansion, data query and
   verification, are also given in this paper. Finally, the security and
   performance analysis show that our scheme is not only secure but also
   efficient. (C) 2018 Elsevier B.V. All rights reserved.
ZB 0
ZS 0
TC 4
ZR 0
Z8 0
Z9 4
SN 0167-739X
EI 1872-7115
UT WOS:000528199900098
ER

PT J
AU Din, Sadia
   Paul, Anand
TI Erratum to "Smart health monitoring and management system: Toward
   autonomous wearable sensing for Internet of Things using big data
   analytics [Future Gener. Comput. Syst. 91 (2019) 611-619]''
SO FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE
VL 108
BP 1350
EP 1359
DI 10.1016/j.future.2019.06.035
PD JUL 2020
PY 2020
AB The growing gap between users and the Big Data analytics requires
   innovative tools that address the challenges faced by big data volume,
   variety, and velocity. Therefore, it becomes computationally inefficient
   to analyze such massive volume of data. Recent advances and development
   in the field of Internet of Things (IoT) providing a unique way of
   exploiting the role of healthcare systems. Also, the role of healthcare
   in the IoT is studied widely since it plays a major role in the advances
   of human life that deals with the health regulations. The continuous
   involvement of heterogeneous devices in the IoT poses many challenges,
   i.e., empowering the IoT devices used for the healthcare system,
   aggregation and processing of real-time data. Therefore, based on such
   constraint, in this paper, we propose a novel architecture for a
   healthcare system based on energy harvesting technique that extends the
   device lifetime. Moreover, the healthcare system is supported by an
   architecture that welcomes both real-time and offline data. To handle
   such data, the architecture provides a novel decision model that process
   big data being generated by IoT devices. The data is considered as
   heterogeneous processed by the proposed layered architecture for the
   healthcare system. Furthermore, the feasibility and efficiency of the
   proposed system are implemented on Hadoop single node setup on UBUNTU
   14.04 LTS coreTMi5 machine with 3.2 GHz processor and 4 GB memory.
   Sample medical, sensory datasets are tested on the proposed system.
   Finally, the results show that the proposed system architecture
   efficiently process, analyze, and integrates different datasets
   efficiently and triggers an alarm to provide safety to the community.
   (C) 2019 Elsevier B.V. All rights reserved.
ZS 0
ZB 0
TC 0
Z8 0
ZR 0
Z9 0
SN 0167-739X
EI 1872-7115
UT WOS:000528199900104
ER

PT J
AU Liu, Guolong
   Gu, Jinjin
   Zhao, Junhua
   Wen, Fushuan
   Liang, Gaoqi
TI Super Resolution Perception for Smart Meter Data
SO INFORMATION SCIENCES
VL 526
BP 263
EP 273
DI 10.1016/j.ins.2020.03.088
PD JUL 2020
PY 2020
AB In this paper, we present the problem formulation and methodology
   framework of Super Resolution Perception (SRP) on smart meter data. With
   the widespread use of smart meters, a massive amount of electricity
   consumption data can be obtained. Smart meter data is the basis of
   automated billing and pricing, appliance identification, demand
   response, etc. However, the provision of high-quality data may be
   expensive in many cases. In this paper, we propose a novel problem - the
   SRP problem as reconstructing high-quality data from unsatisfactory data
   in smart grids. Advanced generative models are then proposed to solve
   the problem. This technology makes it possible for empowering existing
   facilities without upgrading existing meters or deploying additional
   meters. We first mathematically formulate the SRP problem under the
   Maximum a Posteriori (MAP) estimation framework. The dataset namely
   Super Resolution Perception Dataset (SRPD) is designed for this problem
   and released. A case study is then presented, which performs SRP on
   smart meter data. A network namely Super Resolution Perception
   Convolutional Neural Network (SR-PCNN) is proposed to generate
   high-frequency load data from low-frequency data. Experiments
   demonstrate that our SRP models can reconstruct high-frequency data
   effectively. Moreover, the reconstructed high-frequency data can lead to
   better appliance identification results. (C) 2020 Elsevier Inc. All
   rights reserved.
RI Wen, Fushuan/D-2470-2019
OI Wen, Fushuan/0000-0002-6838-2602
Z8 0
TC 0
ZS 0
ZB 0
ZR 0
Z9 0
SN 0020-0255
EI 1872-6291
UT WOS:000530096900016
ER

PT J
AU Wang, Jingjuan
   Chen, Qingkui
   Gong, Huilin
TI STMAG: A spatial-temporal mixed attention graph-based convolution model
   for multi-data flow safety prediction
SO INFORMATION SCIENCES
VL 525
BP 16
EP 36
DI 10.1016/j.ins.2020.03.040
PD JUL 2020
PY 2020
AB Spatiotemporal safety forecasting has various applications in the
   neuroscience, climate and transportation domains. It is challenging due
   to (1) the complex spatial dependency on networks, (2) non-linear
   temporal dynamics with changing conditions and (3) the inherent
   difficulty of long-term forecasting. To address these challenges, a
   safety prediction model called the Spatial-Temporal Mixed Attention
   Graph-based Convolution model (STMAG) is proposed. Specifically, STMAG
   captures spatial dependency using graph convolutional networks (GCN),
   and temporal dependency using the sequence-to-sequence (Seq2Seq)
   architecture with the mixed attention mechanisms. A case study on the
   implementation of this model in traffic safety prediction is given as an
   example. Traffic safety forecasting is one canonical example of such a
   learning task, which is also a crucial problem to improving
   transportation and public safety. A number of detailed features (such as
   vehicle type, braking state, whether changing lanes or not) and
   exogenous variables (such as weather, time and road condition) are
   extracted from our big datasets. Finally, we conduct extensive
   experiments to evaluate the STMAG framework on real-world large-scale
   road network traffic datasets. Extensive experiments on our dataset show
   that the STMAG framework makes reasonably accurate predictions and
   significantly improves the prediction accuracy over baseline approaches.
   (C) 2020 Elsevier Inc. All rights reserved.
Z8 0
ZR 0
ZB 0
TC 0
ZS 0
Z9 0
SN 0020-0255
EI 1872-6291
UT WOS:000530096400002
ER

PT J
AU Liu, Xiangjie
   Zhang, Hao
   Niu, Yuguang
   Zeng, Deliang
   Liu, Jizhen
   Kong, Xiaobing
   Lee, Kwang Y.
TI Modeling of an ultra-supercritical boiler-turbine system with stacked
   denoising auto-encoder and long short-term memory network
SO INFORMATION SCIENCES
VL 525
BP 134
EP 152
DI 10.1016/j.ins.2020.03.019
PD JUL 2020
PY 2020
AB The ultra-supercritical (USC) coal fired boiler-turbine unit is an
   advanced power generation system with low emissions and high efficiency.
   It is also a typical multivariable nonlinear system with great inertia.
   Generally, building an accurate analytic model using the conventional
   system identification methods are quite difficult. However, the big data
   generated by the monitoring system can reflect the USC unit's operation
   status and reveal the internal mechanism, if appropriate data analysis
   methods are developed. A deep neural network (DNN) is proposed in this
   paper to model a 1000 MW USC unit. In this DNN, stacked denoising
   auto-encoder is adopted to obtain the intrinsic features from the input
   data, while the long short-term memory network is in charge of
   outputting the expected normal behaviors of USC system along the time
   axis. Furthermore, to guarantee the convergence of this network, a
   reasonable intensity of added noise is identified via Lyapunov stability
   method. The DNN model is compared with the traditional multi-layer
   perception network, the stacked denoising auto-encoder, and two other
   random neural networks, to show the advantages in forecasting the
   dynamic behavior of USC unit. (C) 2020 Elsevier Inc. All rights
   reserved.
ZR 0
Z8 0
ZS 0
ZB 0
TC 0
Z9 0
SN 0020-0255
EI 1872-6291
UT WOS:000530096400010
ER

PT J
AU Zhang, Han
   Chen, Xuefeng
   Chen, Wei
   Shen, Zhixian
TI Collaborative sparse classification for aero-engine's gear hub crack
   diagnosis
SO MECHANICAL SYSTEMS AND SIGNAL PROCESSING
VL 141
AR 106426
DI 10.1016/j.ymssp.2019.106426
PD JUL 2020
PY 2020
AB It is a big challenge to robustly detect the early crack fault of the
   differential gear train's gear-hub of an aero-engine from the vibration
   signals of its engine casing, because of imprecise dynamic model
   guidance, extremely weak signature, complex modulation effects and
   limited training data. In this paper, a novel collaborative sparse
   classification framework (CSC), which collaborates the prior knowledge
   based sparse filtering and data-driven classification strategy, is
   proposed as a new endeavor for health condition assessment of
   aero-engine's gear-hub. The sparse filtering model collaborates the
   empirically established fault pattern and its intrinsic local
   self-similar properties, by which the feature to interference ratio is
   enhanced. Subsequently, a sparse classification method is adopted to
   further explore the latent discriminative signatures and thus the health
   conditions of gear-hub can be automatically recognized. This work can
   not only recognize the abnormal vibration with high accuracy but also
   locate is source component to some extent. The effectiveness,
   superiority, parameter robustness and generalization performance of the
   proposed framework are thoroughly demonstrated by enormous comparison
   experiments with the state-of-the-arts. (C) 2019 Elsevier Ltd. All
   rights reserved.
ZS 0
Z8 0
ZR 0
ZB 0
TC 1
Z9 1
SN 0888-3270
UT WOS:000529084500001
ER

PT J
AU Sun, Jianjun
TI Motor Imagery EEG Classification with Biclustering Based Fuzzy Inference
SO JOURNAL OF MEDICAL IMAGING AND HEALTH INFORMATICS
VL 10
IS 7
BP 1486
EP 1493
DI 10.1166/jmihi.2020.3040
PD JUL 2020
PY 2020
AB The rehabilitation of armless or footless patients is of great
   importance. One choice for such issue is using the electroencephalograph
   (EEG) brain computer interface to help the patients communicate with
   outside. Classifying the EEG signals generated from mental activity is
   one of the most important technologies. However, existing classification
   methods often suffer the overfitting problem caused by the small
   training data sets while big dimensionality of feature space. Fuzzy
   inference can imitate the human judgement, effectively dealing with
   uncertainty and small-sample learning problems. Besides, biclustering
   has shown excellent performance in constructing rule base. This paper
   proposes a novel biclustering based fuzzy inference method for EEG
   classification. It can be divided into five steps. The first step is
   generating features with common spatial pattern. The second step is
   searching local coherent patterns with column nearly constant
   biclustering. The third step is to transform the patterns to if-then
   rules with column averaging and majority voting strategy. Subsequent
   step is to employ Mamdani fuzzy inference to map the input feature
   vector into decimals. Finally, particle swarm optimization is utilized
   to generate optimal threshold for linear classification. Experiments on
   several commonly used data sets show that the proposed method has
   advantages over competitors in terms of classification accuracy.
ZS 0
ZB 0
Z8 0
TC 0
ZR 0
Z9 0
SN 2156-7018
EI 2156-7026
UT WOS:000528235600003
ER

PT J
AU Hamylton, S. M.
   Morris, R. H.
   Carvalho, R. C.
   Roder, N.
   Barlow, P.
   Mills, K.
   Wang, L.
TI Evaluating techniques for mapping island vegetation from unmanned aerial
   vehicle (UAV) images: Pixel classification, visual interpretation and
   machine learning approaches
SO INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMATION
VL 89
AR 102085
DI 10.1016/j.jag.2020.102085
PD JUL 2020
PY 2020
AB We evaluate three approaches to mapping vegetation using images
   collected by an unmanned aerial vehicle (UAV) to monitor rehabilitation
   activities in the Five Islands Nature Reserve, Wollongong (Australia).
   Between April 2017 and July 2018, four aerial surveys of Big Island were
   undertaken to map changes to island vegetation following helicopter
   herbicide sprays to eradicate weeds, including the creeper Coastal
   Morning Glory (Ipomoea cairica) and Kikuyu Grass (Cenchrus
   clandestinus). The spraying was followed by a large scale planting
   campaign to introduce native plants, such as tussocks of Spiny-headed
   Mat-rush (Lomandra longifolia). Three approaches to mapping vegetation
   were evaluated, including: (i) a pixel-based image classification
   algorithm applied to the composite spectral wavebands of the images
   collected, (ii) manual digitisation of vegetation directly from images
   based on visual interpretation, and (iii) the application of a machine
   learning algorithm, LeNet, based on a deep learning convolutional neural
   network (CNN) for detecting planted Lomandra tussocks. The uncertainty
   of each approach was assessed via comparison against an independently
   collected field dataset. Each of the vegetation mapping approaches had a
   comparable accuracy; for a selected weed management and planting area,
   the overall accuracies were 82 %, 91 % and 85 % respectively for the
   pixel based image classification, the visual interpretation /
   digitisation and the CNN machine learning algorithm. At the scale of the
   whole island, statistically significant differences in the performance
   of the three approaches to mapping Lomandra plants were detected via
   ANOVA. The manual digitisation took a longer time to perform than
   others. The three approaches resulted in markedly different vegetation
   maps characterised by different digital data formats, which offered
   fundamentally different types of information on vegetation character. We
   draw attention to the need to consider how different digital map
   products will be used for vegetation management (e.g. monitoring the
   health individual species or a broader profile of the community). Where
   individual plants are to be monitored over time, a feature-based
   approach that represents plants as vector points is appropriate. The CNN
   approach emerged as a promising technique in this regard as it leveraged
   spatial information from the UAV images within the architecture of the
   learning framework by enforcing a local connectivity pattern between
   neurons of adjacent layers to incorporate the spatial relationships
   between features that comprised the shape of the Lomandra tussocks
   detected.
Z8 0
ZS 0
ZR 0
ZB 0
TC 0
Z9 0
SN 0303-2434
UT WOS:000527895800005
ER

PT J
AU Esmaeilbeigi, M.
   Chatrabgoun, O.
   Hosseinian-Far, A.
   Montasari, R.
   Daneshkhah, A.
TI A low cost and highly accurate technique for big data spatial-temporal
   interpolation
SO APPLIED NUMERICAL MATHEMATICS
VL 153
BP 492
EP 502
DI 10.1016/j.apnum.2020.03.009
PD JUL 2020
PY 2020
AB The high velocity, variety and volume of data generation by today's
   systems have necessitated Big Data (BD) analytic techniques. This has
   penetrated a wide range of industries; BD as a notion has various types
   and characteristics, and therefore a variety of analytic techniques
   would be required. The traditional analysis methods are typically unable
   to analyse spatial-temporal BD. Interpolation is required to approximate
   the values between the already existing datapoints, yet since there
   exist both location and time dimensions, only a multivariate
   interpolation would be appropriate. Nevertheless, existing software are
   unable to perform such complex interpolations. To overcome this
   challenge, this paper presents a layer by layer interpolation approach
   for spatial-temporal BD. Developing this layered structure provides the
   opportunity for working with much smaller linear system of equations.
   Consequently, this structure increases the accuracy and stability of
   numerical structure of the considered BD interpolation. To construct
   this layer by layer interpolation, we have used the good properties of
   Radial Basis Functions (RBFs). The proposed new approach is applied to
   numerical examples in spatial-temporal big data and the obtained results
   confirm the high accuracy and low computational cost. Finally, our
   approach is applied to explore one of the air pollution indices, i.e.
   daily PM2.5 concentration, based on different stations in the contiguous
   United States, and it is evaluated by leave-one-out cross validation.
   (C) 2020 IMACS. Published by Elsevier B.V. All rights reserved.
RI Far, Amin Hosseinian/O-4146-2014; Daneshkhah, Alireza/
OI Far, Amin Hosseinian/0000-0002-2534-9044; Daneshkhah,
   Alireza/0000-0001-7751-4307
ZR 0
Z8 0
TC 0
ZB 0
ZS 0
Z9 0
SN 0168-9274
EI 1873-5460
UT WOS:000527660200030
ER

PT J
AU Kraemer, B M
TI Rethinking discretization to advance limnology amid the ongoing
   information explosion.
SO Water research
VL 178
BP 115801
EP 115801
DI 10.1016/j.watres.2020.115801
PD 2020-Jul-01
PY 2020
AB Limnologists often adhere to a discretized view of waterbodies-they
   classify them, divide them into zones, promote discrete management
   targets, and use research tools, experimental designs, and statistical
   analyses focused on discretization. By offering useful shortcuts, this
   approach to limnology has profoundly benefited the way we understand,
   manage, and communicate about waterbodies. But the research questions
   and the research tools in limnology are changing rapidly in the era of
   big data, with consequences for the relevance of our current
   discretization schemes. Here, I examine how and why we discretize and
   argue that selectively rethinking the extent to which we must discretize
   gives us an exceptional chance to advance limnology in new ways. To help
   us decide when to discretize, I offer a framework (discretization
   evaluation framework) that can be used to compare the usefulness of
   various discretization approaches to an alternative which relies less on
   discretization. This framework, together with a keen awareness of
   discretization's advantages and disadvantages, may help limnologists
   benefit from the ongoing information explosion.
ZS 0
ZR 0
ZB 0
TC 0
Z8 0
Z9 0
EI 1879-2448
UT MEDLINE:32348931
PM 32348931
ER

PT J
AU Sharma, Rohit
   Kamble, Sachin S.
   Gunasekaran, Angappa
   Kumar, Vikas
   Kumar, Anil
TI A systematic literature review on machine learning applications for
   sustainable agriculture supply chain performance
SO COMPUTERS & OPERATIONS RESEARCH
VL 119
AR 104926
DI 10.1016/j.cor.2020.104926
PD JUL 2020
PY 2020
AB Agriculture plays an important role in sustaining all human activities.
   Major challenges such as overpopulation, competition for resources poses
   a threat to the food security of the planet. In order to tackle the
   ever-increasing complex problems in agricultural production systems,
   advancements in smart farming and precision agriculture offers important
   tools to address agricultural sustainability challenges. Data analytics
   hold the key to ensure future food security, food safety, and ecological
   sustainability. Disruptive information and communication technologies
   such as machine learning, big data analytics, cloud computing, and
   blockchain can address several problems such as productivity and yield
   improvement, water conservation, ensuring soil and plant health, and
   enhance environmental stewardship. The current study presents a
   systematic review of machine learning (ML) applications in agricultural
   supply chains (ASCs). Ninety three research papers were reviewed based
   on the applications of different ML algorithms in different phases of
   the ASCs. The study highlights how ASCs can benefit from ML techniques
   and lead to ASC sustainability. Based on the study findings an ML
   applications framework for sustainable ASC is proposed. The framework
   identifies the role of ML algorithms in providing real-time analytic
   insights for pro-active data-driven decision-making in the ASCs and
   provides the researchers, practitioners, and policymakers with
   guidelines on the successful management of ASCs for improved
   agricultural productivity and sustainability. (C) 2020 Elsevier Ltd. All
   rights reserved.
OI Kumar, Anil/0000-0002-1691-0098
Z8 0
ZB 0
TC 0
ZS 0
ZR 0
Z9 0
SN 0305-0548
EI 1873-765X
UT WOS:000526116900003
ER

PT J
AU Liu, Kaiyang
   Peng, Jun
   Wang, Jingrong
   Liu, Weirong
   Huang, Zhiwu
   Pan, Jianping
TI Scalable and Adaptive Data Replica Placement for Geo-Distributed Cloud
   Storages
SO IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS
VL 31
IS 7
BP 1575
EP 1587
DI 10.1109/TPDS.2020.2968321
PD JUL 1 2020
PY 2020
AB In geo-distributed cloud storage systems, data replication has been
   widely used to serve the ever more users around the world for high data
   reliability and availability. How to optimize the data replica placement
   has become one of the fundamental problems to reduce the inter-node
   traffic and the system overhead of accessing associated data items. In
   the big data era, traditional solutions may face the challenges of long
   running time and large overheads to handle the increasing scale of data
   items with time-varying user requests. Therefore, novel offline
   community discovery and online community adjustment schemes are proposed
   to solve the replica placement problem in a scalable and adaptive way.
   The offline scheme can find a replica placement solution based on the
   average read/write rates for a certain period of time. The scalability
   can be achieved as 1) the computation complexity is linear to the amount
   of data items and 2) the data-node communities can evolve in parallel
   for a distributed replica placement. Furthermore, the online scheme is
   adaptive to handle the bursty data requests, without the need to
   completely override the existing replica placement. Driven by real-world
   data traces, extensive performance evaluations demonstrate the
   effectiveness of our design to handle large-scale datasets.
ZS 0
ZR 0
ZB 0
TC 0
Z8 0
Z9 0
SN 1045-9219
EI 1558-2183
UT WOS:000526542500003
ER

PT J
AU Kodapanakkal, Rabia, I
   Brandt, Mark J.
   Kogler, Christoph
   van Beest, Ilja
TI Self-interest and data protection drive the adoption and moral
   acceptability of big data technologies: A conjoint analysis approach
SO COMPUTERS IN HUMAN BEHAVIOR
VL 108
AR UNSP 106303
DI 10.1016/j.chb.2020.106303
PD JUL 2020
PY 2020
AB Big data technologies have both benefits and costs which can influence
   their adoption and moral acceptability. Prior studies look at people's
   evaluations in isolation without pitting costs and benefits against each
   other. We address this limitation with a conjoint experiment (N = 979),
   using six domains (criminal investigations, crime prevention, citizen
   scores, healthcare, banking, and employment), where we simultaneously
   test the relative influence of four factors: the status quo, outcome
   favorability, data sharing, and data protection on decisions to adopt
   and perceptions of moral acceptability of the technologies. We present
   two key findings. (1) People adopt technologies more often when data is
   protected and when outcomes are favorable. They place equal or more
   importance on data protection in all domains except healthcare where
   outcome favorability has the strongest influence. (2) Data protection is
   the strongest driver of moral acceptability in all domains except
   healthcare, where the strongest driver is outcome favorability.
   Additionally, sharing data lowers preference for all technologies, but
   has a relatively smaller influence. People do not show a status quo bias
   in the adoption of technologies. When evaluating moral acceptability,
   people show a status quo bias but this is driven by the citizen scores
   domain. Differences across domains arise from differences in magnitude
   of the effects but the effects are in the same direction. Taken
   together, these results highlight that people are not always primarily
   driven by self-interest and do place importance on potential privacy
   violations. The results also challenge the assumption that people
   generally prefer the status quo.
OI Kodapanakkal, Rabia/0000-0002-3113-332X; Kogler,
   Christoph/0000-0002-8443-6009; Brandt, Mark/0000-0002-7185-7031
TC 0
ZR 0
ZS 0
Z8 0
ZB 0
Z9 0
SN 0747-5632
EI 1873-7692
UT WOS:000525794200012
ER

PT J
AU Allal, Adel
   Halit, Mohamed
   Saib, Salima
   Azzouz, Lahcene
   Maabed, Said
   Bouchenafa, Mohamed
   Ahuja, Rajeev
TI A comparative theoretical investigation of optoelectronic and mechanical
   properties of KYS2 and KLaS2
SO MATERIALS SCIENCE IN SEMICONDUCTOR PROCESSING
VL 113
AR 105048
DI 10.1016/j.mssp.2020.105048
PD JUL 2020
PY 2020
AB The ternary sulfides KYS2 and KLaS2 are two promising candidates for
   numerous applications, as much as white LED, X-ray phosphor and
   transparent conductor materials. However, theoretical studies on these
   materials are lacking, and many of their physical properties are still
   unknown. The aim of this work is to investigate the physical properties
   of the ternary sulfides KYS2 and KLaS2 namely, structural, elastic,
   optoelectronic, thermodynamic analysis, and set the substitution effect
   of Y and La elements in the two compounds. The fundamental properties
   calculations are based on ab-initio pseudopotential framework, with both
   local density approximation (LDA) and generalized gradient
   approximations (GGA) along with an expanded set of plane waves. The
   Becke, 3-parameter, Lee-Yang-Parr (B3LYP) hybrid functional is also
   employed to describe the electronic structures and optical properties.
   The optimized crystal parameters are correlated very well with the
   existing experimental data. The predicted values of the elastic
   constants demonstrate that the two compounds are mechanically stable and
   can be classified as brittle materials. The band structure analysis
   reveals that both KYS2 and KLaS2 have indirect band gap. The optical
   properties, like the refractive index, extinction, absorption and
   reflectivity coefficients, are determined for various polarizations of
   incident light, while both compounds present optical anisotropy. The
   obtained optical properties indicate the high transparency of KYS2 and
   KLaS2 in the infrared and visible regions, which makes them promising
   candidates for many of transparent applications. The thermodynamic
   properties are investigated with the help of quasiharmonic Debye model
   approximation. KYS2 has a larger bulk modulus value, which make it more
   beneficial in engineering applications. Calculations of thermodynamical
   properties indicate that KYS2 compound has better thermal conductivity,
   stronger chemical bonds and bigger hardness.
TC 0
ZS 0
Z8 0
ZB 0
ZR 0
Z9 0
SN 1369-8001
EI 1873-4081
UT WOS:000523559300016
ER

PT J
AU Sihombing, Atmy Verani Rouly
   Subagio, Bambang Sugeng
   Hariyadi, Eri Susanto
   Yamin, Anwar
TI DEVELOPMENT OF RESILIENT MODULUS MODEL PROPOSED FOR BIO-ASPHALT AS
   MODIFIER IN ASPHALT CONCRETE CONTAINING RECLAIMED ASPHALT PAVEMENT
SO INTERNATIONAL JOURNAL OF GEOMATE
VL 19
IS 71
BP 130
EP 136
DI 10.21660/2020.71.68349
PD JUL 2020
PY 2020
AB The aim of this study was to determine the effect of bio-asphalt in
   AC-WC mixture containing reclaimed asphalt pavement (RAP), based on
   resilient modulus (Smix) of asphalt mixture with variations of RAP
   content were 10, 20, and 30% to the weight of the mixture. Bio-asphalt
   was produced by pyrolysis process from biomass of coconut shell (BioCS)
   used in asphalt mixture as a modifier with 23% content to the weight of
   RAP bitumen. Mixture was compared to AC-WC with fresh material by
   resilient modulus under OBC conditions using UMATTA. The conditions of
   testing were carried out by loading pulse width 250 ms, pulse repetition
   period 3000 ms and at test temperatures 20, 25, 35, and 40 degrees C.
   The test results showed that by increasing number of RA, the Smix was
   getting bigger. Although the Smix value was greater than the control
   mixture, the performance of BioCS was shown by the Smix production. The
   number of RAP increases indicating the activation of the RAP bitumen so
   that there was a bond between the bitumen and the aggregate. Based on
   these data, a Smix model for a mixture of ACWC + RAP with 23% BioCS was
   obtained. the use of coconut shell biomass as bioaspal has potential as
   a renewable and sustainable pavement material, this can be seen from the
   results of testing the effect on AC-WC hot asphalt mixture.
TC 0
ZB 0
ZS 0
ZR 0
Z8 0
Z9 0
SN 2186-2982
EI 2186-2990
UT WOS:000521935900019
ER

PT J
AU Ray, Anuradha
   Camiolo, Matthew
   Fitzpatrick, Anne
   Gauthier, Marc
   Wenzel, Sally E
TI Are We Meeting the Promise of Endotypes and Precision Medicine in
   Asthma?
SO Physiological reviews
VL 100
IS 3
BP 983
EP 1017
DI 10.1152/physrev.00023.2019
PD 2020-Jul-01
PY 2020
AB While the term asthma has long been known to describe heterogeneous
   groupings of patients, only recently have data evolved which enable a
   molecular understanding of the clinical differences. The evolution of
   transcriptomics (and other 'omics platforms) and improved statistical
   analyses in combination with large clinical cohorts opened the door for
   molecular characterization of pathobiologic processes associated with a
   range of asthma patients. When linked with data from animal models and
   clinical trials of targeted biologic therapies, emerging distinctions
   arose between patients with and without elevations in type 2 immune and
   inflammatory pathways, leading to the confirmation of a broad
   categorization of type 2-Hi asthma. Differences in the ratios, sources,
   and location of type 2 cytokines and their relation to additional immune
   pathway activation appear to distinguish several different
   (sub)molecular phenotypes, and perhaps endotypes of type 2-Hi asthma,
   which respond differently to broad and targeted anti-inflammatory
   therapies. Asthma in the absence of type 2 inflammation is much less
   well defined, without clear biomarkers, but is generally linked with
   poor responses to corticosteroids. Integration of "big data" from large
   cohorts, over time, using machine learning approaches, combined with
   validation and iterative learning in animal (and human) model systems is
   needed to identify the biomarkers and tightly defined molecular
   phenotypes/endotypes required to fulfill the promise of precision
   medicine.
OI wenzel, Sally/0000-0002-4242-0164
ZS 0
ZR 0
TC 0
ZB 0
Z8 0
Z9 0
EI 1522-1210
UT MEDLINE:31917651
PM 31917651
ER

PT J
AU Wang, Danchen
   Yu, Songlin
   Zou, Yutong
   Li, Honglei
   Cheng, Xinqi
   Qiu, Ling
   Xu, Tengda
TI Data mining: Seasonal fluctuations and associations between thyroid
   stimulating hormone and lipid profiles.
SO Clinica chimica acta; international journal of clinical chemistry
VL 506
BP 122
EP 128
DI 10.1016/j.cca.2020.03.012
PD 2020-Jul
PY 2020
AB OBJECTIVE: Thyroid stimulating hormone (TSH) is associated with lipid
   metabolism. In this study, we aimed to evaluate seasonal variations and
   the association between TSH and lipid profiles based on clinical big
   data.
   METHOD: This observational, retrospective big data study enrolled a
   total of 20,192 individuals who visited Peking Union Medical College
   Hospital for routine health check-ups from 2014 to 2018. Demographic,
   medical history, common biochemical analytes, and thyroid related test
   data were obtained. A Kruskal-wallis analysis was used to compare the
   differences in total cholesterol (TC), triglycerides (TG), high density
   lipoprotein cholesterol (HDL-C), and low-density lipoprotein cholesterol
   (LDL-C) by TSH quartiles. Spearman correlation analysis was used to
   evaluate the association between TSH and lipid profiles as well as
   temperature.
   RESULTS: TC and LDL did not vary significantly with TSH concentration;
   however, TG and HDL-C did. TSH concentration showed weak positive
   correlation with serum TC, TG, and HDL-C but not with LDL-C. Serum TC
   concentration was positively correlated with TG and LDL-C. TG was
   positively correlated with LDL-C but negatively correlated with HDL-C.
   HDL-C was negatively correlated with LDL-C. TSH and lipid profiles
   showed seasonal fluctuations. Monthly median TSH, TC, and LDL-C peaked
   in winter and dropped to a minimum in summer. The correlation
   coefficient (r) between the average monthly temperature and TSH, TC, TG,
   HDL-C, and LDL-C was -0.424 (p=0.001), -0.539 (p<0.001), -0.020
   (p=0.880), -0.199 (p=0.127), and -0.442 (p<0.001), respectively.
   CONCLUSION: Seasonal variation was observed in both TSH and lipids.
   Apart from the seasonal variation of TC and LDL-C, our results also have
   clinical interpretation. It suggested that it may not reflect the real
   status of lipids during and immediately after the Spring festival. Thus,
   in order to diagnosis of hypercholesterolemia, re-testing was needed
   later to provide the precision diagnostic, monitoring and treatment.
Z8 0
ZS 0
TC 0
ZB 0
ZR 0
Z9 0
EI 1873-3492
UT MEDLINE:32165124
PM 32165124
ER

PT J
AU Wan, Xiaole
   Qie, Xiaoqian
TI Poverty alleviation ecosystem evolutionary game on smart supply chain
   platform under the government financial platform incentive mechanism
SO JOURNAL OF COMPUTATIONAL AND APPLIED MATHEMATICS
VL 372
AR 112595
DI 10.1016/j.cam.2019.112595
PD JUL 2020
PY 2020
AB Artificial intelligence, machine learning and big data computing promote
   the development of smart supply chain. The cooperative poverty
   alleviation model with multi subject participation composed of
   cooperative, smart supply chain platform and the government was
   constructed. The evolutionary game method was used to explore the
   behavioral strategies of cooperative poverty alleviation ecosystem
   between the smart supply chain platform and the cooperative under the
   government financial platform subsidy mechanism. Particularly, the game
   equilibrium in the cooperation between the smart supply chain platform
   and the cooperative under the subsidy and non subsidy mechanisms of the
   government was analyzed. Finally, numerical simulation was implemented
   to analyze the effects of risks, intelligence degree, consumer
   preference and price on game equilibrium. The study results demonstrate:
   (1) In the range allowed by technology and cost, increasing the
   intelligence degree of the smart supply chain platform will benefit the
   cooperation between the smart supply chain platform and the cooperative;
   (2) Under high unsalable risks and unsalable losses, the cooperative
   will cooperate with the smart supply chain platform; (3) consumer
   preference influences not only the cooperative game between smart supply
   chain and cooperative, but also product demand and product price; and
   (4) under constant conditions, dependence on government subsidies is
   inversely proportional to the intelligence degree. In other words,
   enhancing the intelligence degree of the smart supply chain platform
   helps to transform the "blood transfusion" poverty alleviation to
   "hematopoietic" poverty alleviation, and decreases the dependence of
   poverty alleviation on government financial platform subsidies. (C) 2019
   Elsevier B.V. All rights reserved.
TC 0
ZB 0
ZS 0
Z8 0
ZR 0
Z9 0
SN 0377-0427
EI 1879-1778
UT WOS:000517659000029
ER

PT J
AU Majidifard, Hamed
   Adu-Gyamfi, Yaw
   Buttlar, William G.
TI Deep machine learning approach to develop a new asphalt pavement
   condition index
SO CONSTRUCTION AND BUILDING MATERIALS
VL 247
AR UNSP 118513
DI 10.1016/j.conbuildmat.2020.118513
PD JUN 30 2020
PY 2020
AB Pavement condition assessment provides information to make more
   cost-effective and consistent decisions regarding management of pavement
   network. Generally, pavement distress inspections are performed using
   sophisticated data collection vehicles and/or foot-on-ground surveys. In
   either approach, the process of distress detection is human-dependent,
   expensive, inefficient, and/or unsafe. Automated pavement distress
   detection via road images is still a challenging issue among pavement
   researchers and computer-vision community. In recent years, advancement
   in deep learning has enabled researchers to develop robust tools for
   analyzing pavement images at unprecedented accuracies. Nevertheless,
   deep learning models necessitate a big ground truth dataset, which is
   often not readily accessible for pavement field. In this study, we
   reviewed our previous study, which a labeled pavement dataset was
   presented as the first step towards a more robust, easy-to-deploy
   pavement condition assessment system. In total, 7237 google street-view
   images were extracted, manually annotated for classification (nine
   categories of distress classes). Afterward, YOLO (you look only once)
   deep learning framework was implemented to train the model using the
   labeled dataset. In the current study, a U-net based model is developed
   to quantify the severity of the distresses, and finally, a hybrid model
   is developed by integrating the YOLO and U-net model to classify the
   distresses and quantify their severity simultaneously. Various pavement
   condition indices are developed by implementing various machine learning
   algorithms using the YOLO deep learning framework for distress
   classification and U-net for segmentation and distress densification.
   The output of the distress classification and segmentation models are
   used to develop a comprehensive pavement condition tool which rates each
   pavement image according to the type and severity of distress extracted.
   As a result, we are able to avoid over-dependence on human judgement
   throughout the pavement condition evaluation process. The outcome of
   this study could be conveniently employed to evaluate the pavement
   conditions during its service life and help to make valid decisions for
   rehabilitation or reconstruction of the roads at the right time. (C)
   2020 Elsevier Ltd. All rights reserved.
OI Adu-Gyamfi, Yaw/0000-0002-1924-9792
TC 0
ZR 0
ZB 0
ZS 0
Z8 0
Z9 0
SN 0950-0618
EI 1879-0526
UT WOS:000528271000019
ER

PT J
AU Morris, M. A.
   Wilkins, E. L.
   Galazoula, M.
   Clark, S. D.
   Birkin, M.
TI Assessing diet in a university student population: a longitudinal food
   card transaction data approach
SO BRITISH JOURNAL OF NUTRITION
VL 123
IS 12
BP 1406
EP 1414
AR PII S0007114520000823
DI 10.1017/S0007114520000823
PD JUN 28 2020
PY 2020
AB Starting university is an important time with respect to dietary
   changes. This study reports a novel approach to assessing student diet
   by utilising student-level food transaction data to explore dietary
   patterns. First-year students living in catered accommodation at the
   University of Leeds (UK) received pre-credited food cards for use in
   university catering facilities. Food card transaction data were obtained
   for semester 1, 2016 and linked with student age and sex. k-Means
   cluster analysis was applied to the transaction data to identify
   clusters of food purchasing behaviours. Differences in demographic and
   behavioural characteristics across clusters were examined using chi(2)
   tests. The semester was divided into three time periods to explore
   longitudinal changes in purchasing patterns. Seven dietary clusters were
   identified: 'Vegetarian', 'Omnivores', 'Dieters', 'Dish of the Day',
   'Grab-and-Go', 'Carb Lovers' and 'Snackers'. There were statistically
   significant differences in sex (P < 0 center dot 001), with women
   dominating the Vegetarian and Dieters, age (P = 0 center dot 003), with
   over 20s representing a high proportion of the Omnivores and time of day
   of transactions (P < 0 center dot 001), with Dieters and Snackers
   purchasing least at breakfast. Many students (n 474, 60 center dot 4 %)
   changed dietary cluster across the semester. This study demonstrates
   that transactional data present a feasible method for dietary
   assessment, collecting detailed dietary information over time and at
   scale, while eliminating participant burden and possible bias from
   self-selection, observation and attrition. It revealed that student
   diets are complex and that simplistic measures of diet, focusing on
   narrow food groups in isolation, are unlikely to adequately capture
   dietary behaviours.
Z8 0
TC 0
ZS 0
ZR 0
ZB 0
Z9 0
SN 0007-1145
EI 1475-2662
UT WOS:000530062800010
PM 32131903
ER

PT J
AU Ahlert Pinno, Otto Julio
   Abed Gregio, Andre Ricardo
   De Bona, Luis C. E.
TI ControlChain: A new stage on the IoT access control authorization
SO CONCURRENCY AND COMPUTATION-PRACTICE & EXPERIENCE
VL 32
IS 12
SI SI
AR e5238
DI 10.1002/cpe.5238
PD JUN 25 2020
PY 2020
AB The IoT is changing the way we interact with the world. Very soon,
   almost all of our daily tasks will be made through self intelligent
   systems embedded in devices scattered all around us. Their mission is to
   turn our cities, transportation systems, buildings, homes, and bodies in
   smart environments. These environments will bring us more comfort,
   improve our performance, increase our profits, and take away
   time-consuming tasks. However, besides its great benefits, the IoT is
   also a big source of concerns, mainly because a good part of its devices
   will handle private and confidential information. Recently, cases of
   successful IoT invasions only worsen this scenario and show us that the
   today's adopted access control systems need to be replaced by more
   efficiently and secure ones. To overcome these access control problems,
   in this work, we present the ControlChain. The ControlChain is an access
   control authorization architecture that is heavily based on Blockchain
   technology. We also demonstrate the viability of the ControlChain
   through the E-ControlChain, a proof-of-concept developed to run over the
   Ethereum network. Our proposals follows the IoT tendency requirements
   and are user-transparent, user-friendly, fully decentralized, scalable,
   fault tolerant, and compatible with a wide range of today's access
   control models already used in the IoT. Finally, we also make a cost and
   a performance analysis of E-ControlChain, using a Raspberry Pi as an IoT
   device.
TC 1
ZS 0
ZR 0
Z8 0
ZB 0
Z9 1
SN 1532-0626
EI 1532-0634
UT WOS:000529224600005
ER

PT J
AU Huang, Xinyu
   Zhang, Yanli
   Wang, Yujun
   Ou, Yubo
   Chen, Duohong
   Pei, Chenglei
   Huang, Zuzhao
   Zhang, Zhou
   Liu, Tengyu
   Luo, Shilu
   Huang, Xiaoqing
   Song, Wei
   Ding, Xiang
   Shao, Min
   Zou, Shichun
   Wang, Xinming
TI Evaluating the effectiveness of multiple emission control measures on
   reducing volatile organic compounds in ambient air based on
   observational data: A case study during the 2010 Guangzhou Asian Games.
SO The Science of the total environment
VL 723
BP 138171
EP 138171
DI 10.1016/j.scitotenv.2020.138171
PD 2020-Jun-25
PY 2020
AB Volatile organic compounds (VOCs) play a crucial role in modulating air
   pollution by ozone and fine particles, particularly in urban areas.
   While in recent years short-term intervention actions for better air
   quality during big events in China did present good opportunities to
   examine the effectiveness of control measures in reducing anthropogenic
   VOCs emission, it is highly challenging to interpret the real effect of
   a specific control measure based on field monitoring data when a
   cocktail of control measures were adopted. Here we took the air quality
   intervention actions during the 16th Asian Games (AG) in Guangzhou as a
   case study to explore the impact of short-term multiple measures on VOCs
   reduction. The average mass concentrations of VOCs decreased by 52-68%
   during the AG. These percentages could not reflect emission reduction
   rates as the concentration might be also heavily impacted by dispersion
   conditions. Diagnostic ratios, such as methyl tert-butyl ether to carbon
   monoxide (MTBE/CO) and i-pentane/CO, decreased by over 60% during the
   AG, suggesting a substantial reduction in gasoline related emissions. A
   method linking emission reduction rates of two sources with their
   contribution percentages before and during the AG by using a receptor
   model was further formulated. With the available reduction rate of 34%
   for vehicular exhaust obtained during the traffic restriction drill in
   our previous study, VOCs emissions from gasoline evaporation and solvent
   use reduced by 45.7% and 13.6% during the AG, respectively. Total VOCs
   emissions decreased by 25.3% on average during the AG, and the emission
   control of vehicular exhaust, oil evaporation, and solvent use accounted
   for 17.0%, 6.3% and 2.0% of total VOCs emission reduction, respectively.
   This study presented an observed-based method with
   diagnostic/quantitative approaches to single out the effectiveness of
   each control measures in reducing VOCs emissions.
RI Zhang, Yanli/A-3225-2015; Liu, Tengyu/F-4686-2015
OI Zhang, Yanli/0000-0003-0614-2096; Liu, Tengyu/0000-0002-3137-5898
ZR 0
Z8 0
TC 0
ZS 0
ZB 0
Z9 0
EI 1879-1026
UT MEDLINE:32392684
PM 32392684
ER

PT J
AU Ali, Arshad
   Sanaei, Anvar
   Nalivan, Omid Asadi
   Ahmadaali, Khaled
   Pour, Mohsen Javanmiri
   Valipour, Ahmad
   Karami, Jalil
   Aminpour, Mohammad
   Kaboli, Hasan
   Askari, Yousef
TI Environmental filtering, predominance of strong competitor trees and
   exclusion of moderate-weak competitor trees shape species richness and
   biomass.
SO The Science of the total environment
VL 723
BP 138105
EP 138105
DI 10.1016/j.scitotenv.2020.138105
PD 2020-Jun-25
PY 2020
AB Strong competitor (i.e. big-sized) trees are globally crucial for
   promoting aboveground biomass. Still, we do not fully understand the
   simultaneous influences of different levels of competitor (i.e. strong,
   moderate, medium and weak) trees at stand level in shaping forest
   diversity and biomass along a climatic gradient. We hypothesized that
   few strong competitor trees shape the positive relationship between tree
   species richness and aboveground biomass better than moderate, medium
   and weak competitor trees along a climatic gradient. Using the forest
   inventory data (i.e. tree diameter, height and crown diameter), we
   quantified strong (i.e. 99th percentile; top 1%), moderate (i.e. 75th
   percentile; top 25%), medium (i.e. 50th percentile) and weak (i.e. 25th
   percentile) competitor trees as well as species richness and aboveground
   biomass of 248 plots (moist temperate, semi-humid, and semi-arid
   forests) across 12 sites in Iran. The main results from three piecewise
   structural equation models (i.e. tree diameter, height and crown based
   models) showed that, after considering the simultaneous fixed effects of
   climate and random effects of sites or forest types variation, strong
   competitor trees possessed strong positive effects on tree species
   richness and biomass whereas moderate, medium and weak competitor trees
   possessed negligible positive to negative effects. Also, different
   levels of competitor trees promoted each other in a top-down way but the
   effects of strong competitor trees on moderate, medium and weak
   competitor trees were relatively weak. This study suggests that the
   simultaneous interactions of different tree sizes at stand level across
   forest sites should be included in the integrative ecological modeling
   for better understanding the role of different levels of competitor
   trees in shaping positive forest diversity - functioning relationship in
   a changing environment.
RI Ali, Arshad/G-3988-2014
OI Ali, Arshad/0000-0001-9966-2917
ZR 0
ZB 0
ZS 0
TC 0
Z8 0
Z9 0
EI 1879-1026
UT MEDLINE:32224404
PM 32224404
ER

PT J
AU Deng, Zhonghua
   Tan, Chaochao
   Xiang, Yangen
   Pan, Jianhua
   Shi, Guomin
   Huang, Yue
   Xiong, Yican
   Xu, Keqian
TI Association between fine particle exposure and common test items in
   clinical laboratory: A time-series analysis in Changsha, China.
SO The Science of the total environment
VL 723
BP 137955
EP 137955
DI 10.1016/j.scitotenv.2020.137955
PD 2020-Jun-25
PY 2020
AB Most studies on the health effects of PM2.5 (fine particulate matter
   with diameter smaller than 2.5mum) use indirect indicators, such as
   mortality and number of hospital visits. Recent research shows that
   biomarkers can also be used to evaluate the health effects of PM2.5;
   however, these biomarkers are not very common. Clinical laboratories can
   provide a significant amount of test data that have been proven to have
   important diagnostic value. Therefore, we use big data analysis methods
   to find the associations between clinical laboratory common test items
   and PM2.5 exposure. Data related to air pollution and meteorological
   information between 2014 and 2016 were obtained from the China National
   Environmental Monitoring Centre and the China National Meteorological
   Information Center. Additionally, data of 27 common test items from the
   same period were collected from Changsha Central Hospital. Primary
   analyses included a generalized additive model to analyze the
   associations between PM2.5 concentration and common test items; the
   model was adjusted for time trends, weather conditions (temperature and
   humidity), and days of the week. Furthermore, we adjusted the effects of
   other air pollutants, such as PM10, SO2, NO2, CO, and O3. 17 items such
   as TP, ALB, ALT, AST, TBIL, DBIL, UREA, CREA, UA, GLU, LDL, WBC, K, Cl,
   Ca, TT, and FIB were significantly positively associated with PM2.5
   concentration (P<0.05) and have concentration-response relationship.
   After adjusting the effect of PM10+SO2+NO2+CO+O3, TP, ALB, ALT, AST,
   TBIL, DBIL, UREA, CREA, UA, GLU, WBC, Cl, and Ca were still
   significantly associated with PM2.5 concentration (P<0.05). This current
   study suggested that clinical laboratory common test items may be used
   to assess and predict the health effects of PM2.5 on the population.
ZS 0
ZR 0
Z8 0
TC 0
ZB 0
Z9 0
EI 1879-1026
UT MEDLINE:32220731
PM 32220731
ER

PT J
AU Kimm, Hyungsuk
   Guan, Kaiyu
   Gentine, Pierre
   Wu, Jin
   Bernacchi, Carl J.
   Sulman, Benjamin N.
   Griffis, Timothy J.
   Lin, Changjie
TI Redefining droughts for the US Corn Belt: The dominant role of
   atmospheric vapor pressure deficit over soil moisture in regulating
   stomatal behavior of Maize and Soybean
SO AGRICULTURAL AND FOREST METEOROLOGY
VL 287
AR UNSP 107930
DI 10.1016/j.agrformet.2020.107930
PD JUN 15 2020
PY 2020
AB The U.S. Corn Belt, the worlds biggest production region for corn and
   soybean combined, is prone to droughts. Currently 92% of the U.S. Corn
   Belt croplands are rainfed, and thus are sensitive to interannual
   climate variability and future climate change. Most prior studies
   identify the lack of soil moisture as the primary cause of agricultural
   drought impacts, although water-related stresses are also induced by
   high atmospheric water demands (i.e., vapor pressure deficit, VPD). Here
   we empirically attributed the variability of canopy-level stomatal
   conductance (Gs) and gross primary productivity (GPP) to VPD and soil
   water supply (i.e. volumetric soil water content, SWC), using
   eddy-covariance data from seven AmeriFlux eddy covariance sites in maize
   and soybean fields across the U.S. Corn Belt, which are well represented
   for the current rainfed part of the Corn Belt croplands. We used three
   independent approaches, including two statistical models (i.e. a
   multiple-linear regression model and a semi-empirical, non-linear model)
   and information theory, to quantify the relationship of Gs (or GPP) with
   VPD and SWC. The attribution result from the two models shows that VPD
   explains most of Gs variability (91% and 89%, respectively), and mutual
   information also attributed 91% of GPP variability to VPD. This finding
   was robust over the gradients of rainfall and temperature, crop types
   (maize vs. soybean), and management practices (whether irrigated or
   not). We reconciled our finding with the previously emphasized
   importance of precipitation and SWC, by conducting a path analysis,
   which revealed the causal relationships between precipitation, air
   temperature (Ta), relative humidity (RH), VPD, SWC, and Gs. We find that
   precipitation impacts on Gs through reduced RH and Ta to VPD (rather
   than directly through SWC). With increased VPD robustly projected under
   climate change, we expect increased crop water stress in the future for
   the U.S. Corn Belt.
OI Bernacchi, Carl/0000-0002-2397-425X
TC 0
ZB 0
ZS 0
ZR 0
Z8 0
Z9 0
SN 0168-1923
EI 1873-2240
UT WOS:000531095900005
ER

PT J
AU Ji, Ying
   Du, Jianhui
   Han, Xiaoya
   Wu, Xiaoqing
   Huang, Ripeng
   Wang, Shilei
   Liu, Zhimin
TI A mixed integer robust programming model for two-echelon inventory
   routing problem of perishable products
SO PHYSICA A-STATISTICAL MECHANICS AND ITS APPLICATIONS
VL 548
AR 124481
DI 10.1016/j.physa.2020.124481
PD JUN 15 2020
PY 2020
AB To solve the inventory routing problem of perishable products with time
   window constraints, a mixed integer linear programming (MILP) model is
   constructed to minimize the total cost. Due to the uncertainty of market
   demand, the MILP model is further transformed into mixed integer robust
   programming (MIRP) model by introducing uncertain sets (box, ellipsoid
   and polyhedron). Experiments with actual data show that as demand
   uncertainty increases, although MIRP models will pay corresponding
   robust costs, they can achieve better robustness. In addition, the
   comparison shows that the ellipsoid set MIRP model can achieve a higher
   level of logistics and distribution services. (C) 2020 Elsevier B.V. All
   rights reserved.
ZR 0
Z8 0
ZS 0
ZB 0
TC 0
Z9 0
SN 0378-4371
EI 1873-2119
UT WOS:000529798900029
ER

PT J
AU Park, Hae Min
   Lee, Jong Hyuk
   Kim, Kyung Doo
TI Wall temperature prediction at critical heat flux using a machine
   learning model
SO ANNALS OF NUCLEAR ENERGY
VL 141
AR 107334
DI 10.1016/j.anucene.2020.107334
PD JUN 15 2020
PY 2020
AB To determine heat transfer regimes of the pre and post CHF, the SPACE
   code calculates the wall temperature from a nucleate boiling heat
   transfer model at the given CHF. It needs iterations and consumes a
   large amount of computing time. To reduce the calculation time, this
   paper introduces the application of a machine learning method. Big data
   of the wall temperature at CHF was built by using the subprogram
   constructed as is in the SPACE code. Based on that database, the neural
   network models were trained and two neural network models having
   different configurations were suggested. The developed neural network
   models were implemented in the SPACE code and test calculations were
   performed. The neural network applied SPACE code properly predicted the
   wall temperature at CHF. In test calculations, the calculation time was
   also investigated. All suggested neural network models highly enhanced
   the calculation speed corresponding to a maximum 86% time reduction. (C)
   2020 Elsevier Ltd. All rights reserved.
Z8 0
ZS 0
ZR 0
TC 0
ZB 0
Z9 0
SN 0306-4549
UT WOS:000526111300057
ER

PT J
AU Hsieh, Ping Jung
   Lin, Chinho
   Chang, Shofang
TI The evolution of knowledge navigator model: The construction and
   application of KNM 2.0
SO EXPERT SYSTEMS WITH APPLICATIONS
VL 148
AR 113209
DI 10.1016/j.eswa.2020.113209
PD JUN 15 2020
PY 2020
AB The knowledge management (KM) maturity model provides a framework
   against which both old and new KM initiatives can be assessed to
   determine whether they are capable of generating new knowledge.
   Knowledge Navigator Model (KNM) proposed in 20 09 (Hsieh et al., 2009)
   has been promoted in Taiwan to assist organizations to evaluate their KM
   status, and also aided to be a diffusion platform for government,
   academic and practice to exchange their KM experience.
   However, for the past 10 years, the industrial environment has been
   constantly changing that has brought the developing of KM practice. This
   study described the evolution of KNM to become KNM 2.0 in terms of
   construction and application. Qualitative and quantitative research
   methods were conducted to construct the proposed three modules of KNM
   2.0. A 139 cases survey was employed and the results reveal the
   applicability of KNM 2.0.
   Our research contributes to the body of concepts on KM maturity models
   that could evaluate the readiness of service-oriented knowledge economy,
   big data and smart factory, and strategic KM performance. The proposed
   KNM 2.0, with these features which are novel and rapidly expanding
   fields, has been developed as an online Knowledge Management Evaluation
   (KM evaluation) website available for the practice to use to better
   understand their overall value brought by contemporary KM. Moving
   forward, by using KNM 2.0 to continually collect the data from the
   industries in Taiwan, it is expected to obtain more information about
   the practical KM that keeps developing with the trends, and also keep
   playing the role to distribute the contemporary concepts of KM. The KM
   experience could be referenced and the methodology could be applied to
   other countries. (C) 2020 Elsevier Ltd. All rights reserved.
ZB 0
TC 0
Z8 0
ZR 0
ZS 0
Z9 0
SN 0957-4174
EI 1873-6793
UT WOS:000525814900002
ER

PT J
AU Wang, Yanxin
   Wang, Quanrong
   Deng, Yamin
   Chen, Zhao
   Van Cappellen, Philippe
   Yang, Yijun
   Goldscheider, Nico
TI Assessment of the impact of geogenic and climatic factors on global risk
   of urinary stone disease.
SO The Science of the total environment
VL 721
BP 137769
EP 137769
DI 10.1016/j.scitotenv.2020.137769
PD 2020-Jun-15
PY 2020
AB Urinary Stone Disease (USD) or urolithiasis has plagued humans for
   centuries, and its prevalence has increased over the past few decades.
   Although USD pathology could vary significantly among individuals,
   previous qualitative assessments using limited survey data demonstrated
   that the prevalence of USD might exhibit a distinctive geographical
   distribution (the so-called "stone belt"), without any knowledge about
   the characteristics and contribution factors of the belt. Here, we argue
   that the spatial distribution of USD can at least partly be explained by
   geogenic and climatic factors, as it correlates with the ambient
   geo-environmental conditions modulated by lithology/mineralogy, water
   quality and climate. Using a Bayesian risk model, we assessed the global
   risk of USD based on updated big data of four key geogenic factors:
   phosphorite mines (inventory >1600 points), carbonate rocks (at the
   scale of 1:40 million), Ca2+/Mg2+ molar ratio of river water (1.27
   million samples distributed over 17,000 sampling locations), and mean
   air temperature (0.5o*0.5° resolution) representing the climate. We
   quantitatively identified possible contributions of the factors to USD
   and delineated the regions with the high USD risk which stretched from
   southern North America, via the Mediterranean region, northeastern
   Africa, southern China to Australia, and roughly coincide with the
   world's major areas of carbonate outcropping. Under current climate
   conditions, the areas with the probabilities for the USD prevalence of
   ≥50% and ≥30% covered 3.7% and 20% of the Earth's land surface,
   respectively. By the end of the 21st century, such total areas could
   rise to 4.4% and 25% as a result of global warming. Since the USD data
   used in this study were quite heterogeneous, the prediction results
   needed further calibration with additional high-quality prevalence data
   in the future.
ZR 0
ZB 0
ZS 0
Z8 0
TC 0
Z9 0
EI 1879-1026
UT MEDLINE:32172122
PM 32172122
ER

PT J
AU Rodrigues, Rafael D.
   Zhao, Liang
   Zheng, Qiusheng
   Zhang, Junbao
TI A tourist walk approach for internal and external outlier detection
SO NEUROCOMPUTING
VL 393
BP 203
EP 213
DI 10.1016/j.neucom.2018.10.113
PD JUN 14 2020
PY 2020
AB Outlier detection is a fundamental task for knowledge discovery in data
   mining, especially in the Big Data era. It aims to detect data items
   that deviate from the general pattern of a given data set. In this
   paper, we present a new outlier detection technique using tourist walks
   starting from each data sample and varying the memory size.
   Specifically, a data sample gets a higher outlier score if it
   participates in few tourist walk attractors, while it gets a low score
   if it participates in a large number of attractors. Experimental results
   on artificial and real data sets show good performance of the proposed
   method. In comparison to classical outlier detection methods, the
   proposed one shows the following salient features: (1) It finds out
   outliers by identifying the structure of the input data set instead of
   considering only physical features, such as distance, similarity or
   density. (2) It can detect not only external outliers as classical
   methods do, but also internal outliers staying among various normal data
   groups. (3) By varying the memory size, the tourist walks can
   characterize both local and global structures of the data set. (4) A
   parallel implementation is quite convenient due to the nature of large
   amount of independent walking of the algorithm. (5) The proposed method
   is a deterministic technique. Therefore, only one run is sufficient, in
   contrast to stochastic techniques, which require many runs. Moreover, in
   this work, we find, for the first time, that tourist walks can generate
   complex attractors in various crossing shapes. Such complex attractors
   reveal data structures in more details. Consequently, it can improve the
   outlier detection performance. (C) 2019 Elsevier B.V. All rights
   reserved.
ZR 0
Z8 0
ZB 0
ZS 0
TC 0
Z9 0
SN 0925-2312
EI 1872-8286
UT WOS:000531730500021
ER

PT J
AU Xu, Shi
   Lai, Mingche
   Dai, Yi
   Cao, Jijun
   Wang, Kefei
TI A scalable smart router architecture with intelligent adaptive routing
   and fault-tolerant management
SO NEUROCOMPUTING
VL 393
BP 126
EP 141
DI 10.1016/j.neucom.2017.12.073
PD JUN 14 2020
PY 2020
AB High-radix routers that switch and route packets across large-scale
   racks become increasingly important and can crucially determine the
   latency and bandwidth of the interconnection network for supercomputers
   and data centers. With the omnipresence of big data analysis there is a
   pressing need for scalable and self-diagnosing routers to construct more
   high-performance and reliable interconnect networks. This paper proposes
   an optimized aggregated-tile router micro-architecture with the
   reconfigurable multi-level routing and intelligent adaptive routing
   schemes to reduce the hardware requirement and optimize the router
   performance. The experiment results show that our approach achieves 98%
   throughput and maintains the same delay performance even better than
   YARC router while providing up to 40-50% reduction in memory consumption
   as well as global wire complexity. Moreover, by aggregating a built-in
   CPU and the intellectual network management structure, our router runs
   heuristic search algorithms to automatically reconstruct route tables
   for failure links or routers without any intervention of control plane,
   thereby implementing the automatical fault-tolerance and fault-recovery
   effects when maximizing the network performance. (C) 2019 Published by
   Elsevier B.V.
Z8 0
ZS 0
ZR 0
TC 0
ZB 0
Z9 0
SN 0925-2312
EI 1872-8286
UT WOS:000531730500014
ER

PT J
AU Tao, Qian
   Gu, Chunqin
   Wang, Zhenyu
   Jiang, Daoning
TI An intelligent clustering algorithm for high-dimensional multiview data
   in big data applications
SO NEUROCOMPUTING
VL 393
BP 234
EP 244
DI 10.1016/j.neucom.2018.12.093
PD JUN 14 2020
PY 2020
AB There are many high-dimensional multiview data in various big data
   applications. It is very difficult to deal with those high-dimensional
   multiview data for the classic clustering algorithms, which consider all
   features of data with equal relevance. To tackle this challenging
   problem, this paper aims at proposing a novel intelligent weighting
   k-means clustering (IWKM) algorithm based on swarm intelligence.
   Firstly, the degree of coupling between clusters is presented in the
   model of clustering to enlarge the dissimilarity of clusters. Various
   weights of views and features are used in the weighting distance
   function to determine the clusters of objects. Secondly, to eliminate
   the sensitivity of initial cluster centers, swarm intelligence is
   utilized to find initial cluster centers, weights of views, and weights
   of features by a global search. Lastly, a precise perturbation is
   proposed to improve optimization performance of swarm intelligence. To
   verify the performance of clustering for high-dimensional multiview
   data, the experiments were performed by the evaluation metrics of Rand
   Index, Jaccard Coefficient and Folkes Russe in five big data
   applications on the two different computational platforms of apache
   spark and single node. The experimental results show that IWKM is
   effective and efficient in clustering of high-dimensional multiview
   data, and can obtain better performance than the other 5 kinds of
   approaches in these complicated data sets with more views and higher
   dimensions on apache spark and single node. (C) 2019 Elsevier B.V. All
   rights reserved.
Z8 0
ZS 0
TC 1
ZR 0
ZB 0
Z9 1
SN 0925-2312
EI 1872-8286
UT WOS:000531730500024
ER

PT J
AU Castka, Pavel
   Searcy, Cory
   Mohr, Jakki
TI Technology-enhanced auditing: Improving veracity and timeliness in
   social and environmental audits of supply chains
SO JOURNAL OF CLEANER PRODUCTION
VL 258
AR 120773
DI 10.1016/j.jclepro.2020.120773
PD JUN 10 2020
PY 2020
AB Social and environmental audits (SEA) in supply chains prove to be
   difficult: costly, administratively challenging, retrospective and often
   lacking veracity and timeliness. The purpose of this paper is to explore
   the role of technology (such as blockchain, satellite imaging and
   others) in improving the veracity and timeliness of SEA in supply
   chains. We develop conceptualizations of veracity and timeliness
   appropriate to the SEA context. We also link veracity and timeliness to
   key steps in the auditing process (data collection, recording and
   sharing, and analysis and interpretation) and explore technology's role
   in these steps. We then contrast the traditional audit process to a
   technology-enhanced audit process and develop an organizing framework to
   generate a research agenda linking technology-enhanced auditing to
   veracity and timeliness of the audit process, and, in turn, enhancing
   social and environmental supply chain performance. The novelty and value
   of our work lie in its exploration of how technology-enhanced auditing
   relates to (1) issues related to scope/focus, firm motivations for SEA,
   and governance of the audit function, (2) three conditions under which
   the benefits of technology-enhanced audits are most likely, (3) the 4
   V's of data (volume, variety, velocity/timeliness and veracity); and (4)
   possible mechanisms by which veracity and timeliness affect social and
   environmental performance in the supply chain. (C) 2020 Elsevier Ltd.
   All rights reserved.
ZB 0
TC 0
ZS 0
Z8 0
ZR 0
Z9 0
SN 0959-6526
EI 1879-1786
UT WOS:000525323600167
ER

PT J
AU Gholizadeh, Hadi
   Fazlollahtabar, Hamed
   Khalilzadeh, Mohammad
TI A robust fuzzy stochastic programming for sustainable procurement and
   logistics under hybrid uncertainty using big data
SO JOURNAL OF CLEANER PRODUCTION
VL 258
AR 120640
DI 10.1016/j.jclepro.2020.120640
PD JUN 10 2020
PY 2020
AB Today, in many organizations, the debate about the difference in core
   capabilities has become an important factor for market competition.
   Companies, based on the field of activity, decide to strengthen some of
   their capabilities, capacities, and expertise. Therefore, the focus of
   an organization on the strengths and efforts to develop its
   sustainability will lead to a competitive advantage in the marketplace.
   Due to changes in environmental factors, organizations have focused on
   carbon emissions in procurement and transportation that have the highest
   carbon footprint. This paper proposes a multiobjective,
   eco-sustainability model for a supply chain. The objectives are to
   minimize overall costs, maximize the efficiency of transportation
   vehicles and minimize information fraud in the process of information
   sharing within supply chain elements. Big data is considered in the
   amount of information exchanged between customers and other elements of
   the proposed supply chain; since there are frauds in information sharing
   then using big data 5Vs the model is adapted to control the cost of
   information loss leading to customer dissatisfaction. Since uncertainty
   is inevitable in the real environments, in this research hybrid
   uncertainty is considered. Because two sources of uncertainty are
   considered in most of the parameters, thus it is necessary to robustify
   the decision-making process. The model is a mixed integer nonlinear
   program including big data for an optimal sustainable procurement and
   transportation decision. A heuristic method is used to solve the big
   data problem that makes use of a robust fuzzy stochastic programming
   approach. The proposed model can prevent disturbances by using a
   scenario-based stochastic programming approach. An effective hybrid
   robust fuzzy stochastic method is also employed for controlling
   uncertainty in parameters and risk taking out of outbound decisions. To
   solve the multi-objective model, augmented epsilon-constraint method is
   utilized. The model performance is investigated in a comprehensive
   computational study. (C) 2020 Elsevier Ltd. All rights reserved.
Z8 0
ZB 0
ZS 0
ZR 0
TC 0
Z9 0
SN 0959-6526
EI 1879-1786
UT WOS:000525323600022
ER

PT J
AU Park, Chankook
   Heo, WanGyu
TI Review of the changing electricity industry value chain in the ICT
   convergence era
SO JOURNAL OF CLEANER PRODUCTION
VL 258
AR 120743
DI 10.1016/j.jclepro.2020.120743
PD JUN 10 2020
PY 2020
AB We examine the changing aspects of the electricity industry and
   requirements for the industry development in the information and
   communications technology (ICT) convergence era based on the framework
   of value chain change in terms of the counter-flow,
   multi-dimensionalization, insertion, and removal of a value chain, away
   from the existing 'value chain elements'-centric approach. As a result,
   we confirmed various value chain changes and directions for the
   development of the electricity industry. Energy consumers are turning
   into prosumers and influential stakeholders. In addition, the importance
   of data has been highlighted and the influence of platforms has been
   expanded. With the changes come along, various market participants
   appear, and at the same time businesses that do not adapt to the changes
   are at risk in terms of their market power. It can be seen that the
   changes demand efforts to encourage consumer participation into the
   energy market, rational mechanism of energy data sharing, and setting up
   of an efficient regulatory system. This study contributes to the
   understanding of the new changes and the demands resulting from ICT
   convergence in the electricity sector. (C) 2020 Elsevier Ltd. All rights
   reserved.
TC 0
ZR 0
ZB 0
Z8 0
ZS 0
Z9 0
SN 0959-6526
EI 1879-1786
UT WOS:000525323600148
ER

PT J
AU Tiwari, Kamlesh
   Khan, Mohammad Shadab
TI Sustainability accounting and reporting in the industry 4.0
SO JOURNAL OF CLEANER PRODUCTION
VL 258
AR 120783
DI 10.1016/j.jclepro.2020.120783
PD JUN 10 2020
PY 2020
AB Industry 4.0 is the fourth industrial revolution. It is formed on the
   building blocks of Industrial Internet of Things, real-time data
   collection and predictive analytics using big data analytics, artificial
   intelligence, and cloud manufacturing. The complexity and value of
   Industry 4.0 is established by the existing research studies. Some of
   the research studies have proposed the design elements and contribution
   of Industry 4.0 to achieving sustainability objectives. This research
   delves deeper into this area to evolve a new research challenge on
   contribution of Industry 4.0 to sustainability accounting and reporting.
   Through a methodology of two focus group discussions and interviews,
   this research derived an empirical formulation presenting a mapping
   between Industry 4.0 attributes and selected material topics and their
   disclosures in Global Reporting Initiative framework. The empirical
   formulation divided the Industry 4.0 framework in India into three
   levels of maturity each mapped with the appropriate triple bottomline
   topics under the Global Reporting Initiative. This empirical formulation
   requires further research to establish its validity as it appears to be
   not-to-optimistic representation by the members of the two focus groups.
   The Interview respondents suggested cautious approach as AI-based
   predictive analytics and automation may need a long maturity path. Soft
   aspects of reluctance to complexity and new technology adoption may need
   continuous evolution of technical and other training programmes with the
   maturity of Industry 4.0 for sustainability accounting and reporting in
   an organisation. (C) 2020 Elsevier Ltd. All rights reserved.
ZS 0
TC 0
ZB 0
ZR 0
Z8 0
Z9 0
SN 0959-6526
EI 1879-1786
UT WOS:000525323600158
ER

PT J
AU Zheng, Chuanjun
   Yuan, Jingfeng
   Zhu, Lei
   Zhang, Yajing
   Shao, Qiuhu
TI From digital to sustainable: A scientometric review of smart city
   literature between 1990 and 2019
SO JOURNAL OF CLEANER PRODUCTION
VL 258
AR 120689
DI 10.1016/j.jclepro.2020.120689
PD JUN 10 2020
PY 2020
AB In recent years, smart city (SC) has attracted increasing attention from
   both academia and industry due to a mix of urbanization,
   informatization, and globalization. Although several literature reviews
   of SC research have been conducted, there still appears to be a lack of
   systematic quantitative and visual investigation and multidisciplinary
   scrutiny of the structure and evolution of this field. This paper
   conducts a scientometric review of the progressively synthesized network
   derived from 7840 bibliographic records from a topic search on SC in the
   period 1990-2019. Using CiteSpace, co-occurrence analysis of categories
   is conducted to explore the evolution of the disciplines engaged in SC
   research; co-word analysis of the keywords and document co-citation
   analysis associated with cluster analysis are further performed to
   reveal the development paths and research topics in terms of burst
   terms, text and citation-based clusters, citation structure, and pivotal
   points in the field. These scientometric techniques are combined to: (1)
   reveal the intellectual division of this developing field using a visual
   and comprehensive approach, (2) identify in chronological order the 10
   core research sub-topics in this area with burst references and terms,
   (3) identify Internet of Things, big data, and fog computing as the most
   promising technologies for SC planning and development, and (4) conclude
   that smart sustainable cities and sustainable smart cities are the two
   emerging trends in the domain. Overall, this paper provides a visual,
   quantitative, and longitudinal large-scale review of the most recent
   literature on SC research, providing a broad overview and system
   thinking for researchers and practitioners with respect to SC. (C) 2020
   Elsevier Ltd. All rights reserved.
ZS 0
ZB 0
Z8 0
ZR 0
TC 0
Z9 0
SN 0959-6526
EI 1879-1786
UT WOS:000525323600083
ER

PT J
AU Avinun, Reut
   Romer, Adrienne L.
   Israel, Salomon
TI Vitamin D polygenic score is associated with neuroticism and the general
   psychopathology factor
SO PROGRESS IN NEURO-PSYCHOPHARMACOLOGY & BIOLOGICAL PSYCHIATRY
VL 100
AR 109912
DI 10.1016/j.pnpbp.2020.109912
PD JUN 8 2020
PY 2020
AB Vitamin D, used here to refer to both 25-hydroxyvitamin D, the main
   circulating form of the vitamin, and 1,25-hydroxyvitamin D, the
   biologically active form, has been shown to influence brain development
   and function. Consistent with these findings, low levels of vitamin D
   have been implicated in various mental disorders, including depression,
   schizophrenia, and autism. Recently, a shared variance across multiple
   categories of mental health disorders has been identified and shown to
   be genetically influenced. This shared variance, thought to represent a
   general risk for psychopathology, has been termed the p factor.
   Individuals with high p factor scores are characterized by high
   neuroticism and low agreeableness and conscientiousness. Here, we
   investigated the links between vitamin D polygenic scores - derived from
   the latest genome-wide association study of circulating vitamin D
   (25-hydroxyvitamin D) levels - the Big Five personality traits
   (neuroticism, agreeableness, conscientiousness, openness-to-experience,
   and extraversion), and the p factor, in a sample of 522 (278 women, mean
   age 20 +/- 1 years) non-Hispanic Caucasians. Vitamin D polygenic scores
   were significantly and negatively associated with neuroticism and the p
   factor, even after correcting for multiple comparisons, and controlling
   for sex, age, ancestry, socioeconomic status, and body mass index. Based
   on previous research implicating neuroticism as a risk factor for
   psychopathology, mediation was tested. Results showed a significant
   indirect effect from the vitamin D polygenic score to the p factor via
   neuroticism. Our findings support a genetic link between vitamin D
   levels, neuroticism, and the p factor, but due to the cross-sectional
   nature of our data, future studies are needed to clarify the causal
   associations between these phenotypes.
Z8 0
ZR 0
TC 0
ZB 0
ZS 0
Z9 0
SN 0278-5846
EI 1878-4216
UT WOS:000522807700026
PM 32151694
ER

PT J
AU Pradhan, Tribikram
   Pal, Sukomal
TI A multi-level fusion based decision support system for academic
   collaborator recommendation
SO KNOWLEDGE-BASED SYSTEMS
VL 197
AR 105784
DI 10.1016/j.knosys.2020.105784
PD JUN 7 2020
PY 2020
AB In academia, researchers collaborate with their peers to improve the
   quality of research and thereby enhance academic profiles. However,
   information overload in big scholarly data poses a challenge in
   identifying potential researchers for fruitful collaboration. In this
   article, we introduce a multi-level fusion-based model for collaborator
   recommendation, DRACoR (Deep learning and Random walk based Academic
   Collaborator Recommender). DRACoR fuses deep learning and biased random
   walk model to provide the recommendation for potential collaborators
   that share similar research interests at the peer level. We run a topic
   model on abstracts and Doc2Vec on titles on year-wise publications to
   capture the dynamic research interests of researchers. Author-author
   cosine similarity is computed from the feature vectors extracted from
   abstracts and titles and is then used to weigh edges in the
   author-author graph (AAG). We also aggregate various meta-path features
   with profile-aware features to bias the random walk behavior. Finally,
   we employ a random walk with restart(RWR) to recommend top N
   collaborators where the edge weights are used to bias the random
   walker's behavior. Extensive experiments on DBLP and hep-th datasets
   demonstrate the effectiveness of our proposed DRACoR model against
   various state-of-the-art methods in terms of precision, recall,
   F1-score, MRR, and nDCG. (C) 2020 Elsevier B.V. All rights reserved.
ZB 0
ZS 0
TC 0
Z8 0
ZR 0
Z9 0
SN 0950-7051
EI 1872-7409
UT WOS:000528878400005
ER

PT J
AU Zhang, Tong
   Li, Yicong
   Yang, Hui
   Cui, Chenrong
   Li, Jing
   Qiao, Qinghua
TI Identifying primary public transit corridors using multi-source big
   transit data
SO INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE
VL 34
IS 6
SI SI
BP 1137
EP 1161
DI 10.1080/13658816.2018.1554812
PD JUN 2 2020
PY 2020
AB Effective public transit planning needs to address realistic travel
   demands, which can be illustrated by corridors across major residential
   areas and activity centers. It is vital to identify public transit
   corridors that contain the most significant transit travel demand
   patterns. We propose a two-stage approach to discover primary public
   transit corridors at high spatio-temporal resolutions using massive
   real-world smart card and bus trajectory data, which manifest rich
   transit demand patterns over space and time. The first stage was to
   reconstruct chained trips for individual passengers using multi-source
   massive public transit data. In the second stage, a shared-flow
   clustering algorithm was developed to identify public transit corridors
   based on reconstructed individual transit trips. The proposed approach
   was evaluated using transit data collected in Shenzhen, China.
   Experimental results demonstrated that the proposed approach is a
   practical tool for extracting time-varying corridors for many potential
   applications, such as transit planning and management.
ZS 0
ZB 0
Z8 0
TC 4
ZR 0
Z9 4
SN 1365-8816
EI 1362-3087
UT WOS:000533235000001
ER

PT J
AU Zhao, Pengxiang
   Liu, Xintao
   Shi, Wenzhong
   Jia, Tao
   Li, Wengen
   Chen, Min
TI An empirical study on the intra-urban goods movement patterns using
   logistics big data
SO INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE
VL 34
IS 6
SI SI
BP 1089
EP 1116
DI 10.1080/13658816.2018.1520236
PD JUN 2 2020
PY 2020
AB Movement patterns of intra-urban goods/things and the ways they differ
   from human mobility and traffic flow patterns have seldom been explored
   due to data access and methodological limitations, especially from
   systemic and long timescale perspectives. However, urban logistics big
   data are increasingly available, enabling unprecedented spatial and
   temporal resolutions to this issue. This research proposes an analytical
   framework for exploring intra-urban goods movement patterns by
   integrating spatial analysis, network analysis and spatial interaction
   analysis. Using daily urban logistics big data (over 10 million orders)
   provided by the largest online logistics company in Hong Kong (GoGoVan)
   from 2014 to 2016, we analyzed two spatial characteristics (displacement
   and direction) of urban goods movement. Results showed that the
   distribution of goods displaceFower law or exponential distribution of
   human mobility trends. The origin-destination flows of goods were used
   to build a spatially embedded network, revealing that Hong Kong became
   increasingly connected through intra-urban freight movement. Finally,
   spatial interaction characteristics were revealed using a fitting
   gravity model. Distance lacked substantial influence on the spatial
   interaction of goods movement. These findings have policy implications
   to intra-urban logistics and urban transport planning.
RI LIU, Xintao/F-6744-2017
OI LIU, Xintao/0000-0002-7323-9878
TC 5
Z8 0
ZR 0
ZS 0
ZB 0
Z9 5
SN 1365-8816
EI 1362-3087
UT WOS:000530991600002
ER

PT J
AU Barrientos, Andres F.
   Pena, Victor
TI Bayesian Bootstraps for Massive Data
SO BAYESIAN ANALYSIS
VL 15
IS 2
BP 363
EP 388
DI 10.1214/19-BA1155
PD JUN 2020
PY 2020
AB In this article, we present data-subsetting algorithms that allow for
   the approximate and scalable implementation of the Bayesian bootstrap.
   They are analogous to two existing algorithms in the frequentist
   literature: the bag of little bootstraps (Kleiner et al., 2014) and the
   subsampled double bootstrap (Sengupta et al., 2016). Our algorithms have
   appealing theoretical and computational properties that are comparable
   to those of their frequentist counterparts. Additionally, we provide a
   strategy for performing lossless inference for a class of functionals of
   the Bayesian bootstrap and briefly introduce extensions to the Dirichlet
   Process.
ZS 0
TC 0
ZR 0
Z8 0
ZB 0
Z9 0
SN 1931-6690
EI 1936-0975
UT WOS:000533646400002
ER

PT J
AU Zhang, Bohai
   Cressie, Noel
TI Bayesian Inference of Spatio-Temporal Changes of Arctic Sea Ice
SO BAYESIAN ANALYSIS
VL 15
IS 2
BP 605
EP 631
DI 10.1214/20-BA1209
PD JUN 2020
PY 2020
AB Arctic sea ice extent has drawn increasing interest and alarm from
   geoscientists, owing to its rapid decline. In this article, we propose a
   Bayesian spatio-temporal hierarchical statistical model for binary
   Arctic sea ice data over two decades, where a latent dynamic
   spatio-temporal Gaussian process is used to model the data-dependence
   through a logit link function. Our ultimate goal is to perform inference
   on the dynamic spatial behavior of Arctic sea ice over a period of two
   decades. Physically motivated covariates are assessed using autologistic
   diagnostics. Our Bayesian spatio-temporal model shows how parameter
   uncertainty in such a complex hierarchical model can influence
   spatio-temporal prediction. The posterior distributions of new summary
   statistics are proposed to detect the changing patterns of Arctic sea
   ice over two decades since 1997.
ZS 0
ZR 0
Z8 0
TC 0
ZB 0
Z9 0
SN 1931-6690
EI 1936-0975
UT WOS:000533646400011
ER

PT J
AU Misra, Biswapriya
TI Individualized metabolomics: opportunities and challenges
SO CLINICAL CHEMISTRY AND LABORATORY MEDICINE
VL 58
IS 6
SI SI
BP 939
EP 947
DI 10.1515/cclm-2019-0130
PD JUN 2020
PY 2020
AB The goal of advancing science in health care is to provide high quality
   treatment and therapeutic opportunities to patients in need. This is
   especially true in precision medicine, wherein the ultimate goal is to
   link disease phenotypes to targeted treatments and novel therapeutics at
   the scale of an individual. With the advent of -omics technologies, such
   as genomics, proteomics, microbiome, among others, the metabolome is of
   wider and immediate interest for its important role in metabolic
   regulation. The metabolome, of course, comes with its own questions
   regarding technological challenges. In this opinion article, I attempt
   to interrogate some of the main challenges associated with
   individualized metabolomics, and available opportunities in the context
   of its clinical application. Some questions this article addresses and
   attempts to find answers for are: Can a personal metabolome (n =1) be
   inexpensive, affordable and informative enough (i.e. provide predictive
   yet validated biomarkers) to represent the entirety of a population? How
   can a personal metabolome complement advances in other -omics areas and
   the use of monitoring devices, which occupy our personal space?
RI Misra, Biswapriya/H-5136-2013
OI Misra, Biswapriya/0000-0003-2589-6539
ZS 0
ZB 0
Z8 0
ZR 0
TC 3
Z9 3
SN 1434-6621
EI 1437-4331
UT WOS:000531021800009
PM 30951498
ER

PT J
AU Arjmandpanah-Kalat, Morteza
   Abbasinezhad-Mood, Dariush
   Mahrooghi, Hamid-Reza
   Aliabadi, Sobhan
TI Design and performance analysis of an efficient single flow IP traceback
   technique in the AS level
SO INTERNATIONAL JOURNAL OF COMMUNICATION SYSTEMS
VL 33
IS 9
AR e4382
DI 10.1002/dac.4382
PD JUN 2020
PY 2020
AB Network security is a major challenge for big and small companies. The
   Internet topology is vulnerable to Distributed Denial of Service (DDoS)
   attacks as it provides an opportunity to an attacker to send a large
   volume of traffic to a victim, which can limit its Internet
   availability. The main problem in the prevention of the DDoS attack,
   also known as the flooding attack, is how to find the source of traffic
   flooding. This is because the spoofed source Internet protocol (IP)
   address of packets is not affected on its routing. As a result, IP
   traceback techniques are proposed to find the source of attack and in
   general, to find the source of any packet. Doing so, the IP traceback
   techniques can help us to prevent the Denial of Service (DoS) and DDoS
   attacks. In this paper, we propose an efficient Single Flow IP Traceback
   (SFT) technique in the Autonomous System (AS) level. Furthermore, a path
   signature generation algorithm is presented for detecting and filtering
   the spoofed traffic. Our solution assumes a secure Border Gateway
   Protocol (BGP)-routing infrastructure for exchanging authenticated
   messages in order to learn the path signatures, and it uses a marking
   algorithm in the flow level for transmission of the traceback messages.
   Because in our technique less bits are required to mark the IP header
   packet, the required storage space for any unique path to the victim is
   significantly decreased. Compared with the other existing techniques,
   the obtained results demonstrate that our technique has the least
   marking rate, overhead processing on the middle nodes, and destination's
   computational cost while offering the highest accuracy in tracebacking
   attack.
OI Mahrooghi, Hamid Reza/0000-0001-6736-2020
ZB 0
ZR 0
Z8 0
TC 0
ZS 0
Z9 0
SN 1074-5351
EI 1099-1131
UT WOS:000528834500015
ER

PT J
AU Priyadarshini, Rojalina
   Barik, Rabindra Kumar
   Dubey, Harishchandra
TI Fog-SDN: A light mitigation scheme for DDoS attack in fog computing
   framework
SO INTERNATIONAL JOURNAL OF COMMUNICATION SYSTEMS
VL 33
IS 9
AR e4389
DI 10.1002/dac.4389
PD JUN 2020
PY 2020
AB Cloud computing is one of the most tempting technologies in today's
   computing scenario as it provides a cost-efficient solutions by reducing
   the large upfront cost for buying hardware infrastructures and computing
   power. Fog computing is an added support to cloud environment by
   leveraging with doing some of the less compute intensive task to be done
   at the edge devices, which reduces the response time for end user
   computing. But the vulnerabilities to these systems are still a big
   concern. Among several security needs, availability is one that makes
   the demanded services available to the targeted customers all the time.
   Availability is often challenged by external attacks like Denial of
   service (DoS) and distributed denial of service (DDoS). This paper
   demonstrates a novel source-based DDoS mitigating schemes that could be
   employed in both fog and cloud computing scenarios to eliminate these
   attacks. It deploys the DDoS defender module which works on a machine
   learning-based light detection method, present at the SDN controller.
   This scheme uses the network traffic data to analyze, predict, and
   filter incoming data, so that it can send the filtered legitimate
   packets to the server and blocking the rest.
RI Barik, Dr. Rabindra K/G-6004-2014; Dubey, Harishchandra/J-1954-2016
OI Barik, Dr. Rabindra K/0000-0003-3086-3782; Dubey,
   Harishchandra/0000-0003-0476-3884
ZB 0
ZS 0
ZR 0
Z8 0
TC 0
Z9 0
SN 1074-5351
EI 1099-1131
UT WOS:000528834500018
ER

PT J
AU Aletaha, Daniel
TI Precision medicine and management of rheumatoid arthritis
SO JOURNAL OF AUTOIMMUNITY
VL 110
AR 102405
DI 10.1016/j.jaut.2020.102405
PD JUN 2020
PY 2020
AB Precision medicine (PM) is a very commonly used term that implies a
   highly individualized and tailored approach to patient management. There
   are, however, many layers of precision, as for example taking an
   appropriate patient history, or performing additional lab or imaging
   tests are already helping to better tailor treatments to the right
   patient. All this adds to the narrower definition of PM, which implies
   using the unique molecular characteristics of a patient for management
   decisions. Big data has become an essential part of PM, including as
   much information as possible to improve precision of disease management,
   although integration of multi-source data continues to be a challenge in
   practical application. In research big data can identify new
   (sub-)phenotypes in unsupervised analyses, which ultimately advance
   precision by allowing new targeted therapeutic approaches.
   We will discuss the current status of PM in rheumatoid arthritis (RA) in
   the management areas of diagnosis, prognosis, selection of therapy, and
   decision to reduce therapy. PM markers for diagnosis of RA are usually
   markers of RA classification rather than diagnosis, and subtypes of RA
   are potentially underrecognized. Prognostic precision is well
   established for RA, including markers of disease activity or structure,
   as well as autoantibodies and genetics. The choice of the right compound
   in a patient identified to have a poor prognosis, however, remains
   widely arbitrary. Finally and most recently, the most reliable markers
   for a safe withdrawal of therapy continue to be lower levels of disease
   activity and longer presence of remission.
Z8 0
ZS 0
ZR 0
ZB 0
TC 0
Z9 0
SN 0896-8411
EI 1095-9157
UT WOS:000531020400012
PM 32276742
ER

PT J
AU Catalina, Michelle D.
   Owen, Katherine A.
   Labonte, Adam C.
   Grammer, Amrie C.
   Lipsky, Peter E.
TI The pathogenesis of systemic lupus erythematosus: Harnessing big data to
   understand the molecular basis of lupus
SO JOURNAL OF AUTOIMMUNITY
VL 110
AR 102359
DI 10.1016/j.jaut.2019.102359
PD JUN 2020
PY 2020
AB Systemic lupus erythematosus (SLE) is a chronic, systemic autoimmune
   disease that causes damage to multiple organ systems. Despite decades of
   research and available murine models that capture some aspects of the
   human disease, new treatments for SLE lag behind other autoimmune
   diseases such as Rheumatoid Arthritis and Crohn's disease. Big data
   genomic assays have transformed our understanding of SLE by providing
   important insights into the molecular heterogeneity of this multigenic
   disease. Gene wide association studies have demonstrated more than 100
   risk loci, supporting a model of multiple genetic hits increasing SLE
   risk in a non-linear fashion, and providing evidence of ancestral
   diversity in susceptibility loci. Epigenetic studies to determine the
   role of methylation, acetylation and non-coding RNAs have provided new
   understanding of the modulation of gene expression in SLE patients and
   identified new drug targets and biomarkers for SLE. Gene expression
   profiling has led to a greater understanding of the role of myeloid
   cells in the pathogenesis of SLE, confirmed roles for T and B cells in
   SLE, promoted clinical trials based on the prominent interferon
   signature found in SLE patients, and identified candidate biomarkers and
   cellular signatures to further drug development and drug repurposing.
   Gene expression studies are advancing our understanding of the
   underlying molecular heterogeneity in SLE and providing hope that
   patient stratification will expedite new therapies based on personal
   molecular signatures. Although big data analyses present unique
   interpretation challenges, both computationally and biologically,
   advances in machine learning applications may facilitate the ability to
   predict changes in SLE disease activity and optimize therapeutic
   strategies.
TC 0
ZB 0
ZS 0
ZR 0
Z8 0
Z9 0
SN 0896-8411
EI 1095-9157
UT WOS:000531020400002
PM 31806421
ER

PT J
AU Berglund, Emily Zechman
   Monroe, Jacob G.
   Ahmed, Ishtiak
   Noghabaei, Mojtaba
   Do, Jinung
   Pesantez, Jorge E.
   Fasaee, Mohammad Ali Khaksar
   Bardaka, Eleni
   Han, Kevin
   Proestos, Giorgio T.
   Levis, James
TI Smart Infrastructure: A Vision for the Role of the Civil Engineering
   Profession in Smart Cities
SO JOURNAL OF INFRASTRUCTURE SYSTEMS
VL 26
IS 2
AR 03120001
DI 10.1061/(ASCE)IS.1943-555X.0000549
PD JUN 1 2020
PY 2020
AB Smart city programs provide a range of technologies that can be applied
   to solve infrastructure problems associated with ageing infrastructure
   and increasing demands. The potential for infrastructure and urban
   improvement remains unrealized, however, due to technical, financial,
   and social constraints and criticisms that limit the implementation of
   smart cities concepts for infrastructure management. The discussion
   presented here provides a review of smart technologies including
   sensors, crowdsourcing and citizen science, actuators, data
   transmission, Internet of Things, big data analytics, data
   visualization, and blockchain, which can be used for infrastructure
   management. Smart infrastructure programs are reviewed to explore how
   enabling technologies have been applied across civil engineering
   domains, including transportation systems, water systems, air quality,
   energy infrastructure, solid waste management, construction engineering
   and management, structures, and geotechnical systems. Gaps in the
   application of smart technologies for infrastructure systems are
   identified, and we highlight how the civil engineering profession can
   adopt new roles toward the development of smart cities applications.
   These roles are: (1) master designer: civil engineers can identify ready
   applications of enabling technologies to improve the delivery of urban
   resources and services; (2) steward: civil engineers must account for
   both the environmental and societal impacts of smart infrastructure
   applications; (3) innovator and integrator: civil engineers should
   integrate across diverse sectors and groups of experts to develop smart
   infrastructure programs; (4) manager of risk: civil engineers should
   manage existing and growing risks of natural disasters, emergencies, and
   climate change; they should also manage new vulnerabilities in the
   privacy and security of individuals and households that are introduced
   through smart technologies; and (5) leader and decision maker: civil
   engineers can take a lead in smart infrastructure discussions and policy
   development.
OI Pesantez, Jorge/0000-0002-1537-6006; Han, Kevin/0000-0002-2995-8381;
   Noghabaei, Mojtaba/0000-0002-2248-1840; Ahmed,
   Ishtiak/0000-0002-2946-5392
ZB 0
Z8 0
TC 0
ZS 0
ZR 0
Z9 0
SN 1076-0342
EI 1943-555X
UT WOS:000528691800018
ER

PT J
AU Du, Sen
   Hou, Junjie
   Song, Shijin
   Song, Yuefeng
   Zhu, Yongxin
TI A geographical hierarchy greedy routing strategy for vehicular big data
   communications over millimeter wave
SO PHYSICAL COMMUNICATION
VL 40
AR 101065
DI 10.1016/j.phycom.2020.101065
PD JUN 2020
PY 2020
AB As the autonomous and intelligent driving technologies rapidly develop,
   vehicles are equipped with more sensors and produce more data. To cope
   with the challenge of big data, millimeter wave (mmWave) can achieve
   data rates of up to multiple gigabits per second. Though mmWave
   communications can provide wide bandwidths, mmWave is susceptible to
   blockage due to its poor diffraction capability and its high penetration
   loss. To overcome the limited communication range for vehicular
   applications in wide areas, a routing strategy is required to relay data
   in a multi-hop way. In this work, we propose a geographical hierarchy
   greedy routing algorithm for inter-vehicle mmWave communications. Also,
   we evaluate the channel characteristics and the throughput performance
   of mmWave working at 60 GHz. The proposed routing strategy makes use of
   geographical information for relay determination while maintaining the
   high throughput and ensuring the channel stability of mmWave. Based on
   the simulation results, it is found that mmWave is promising for the
   future big data vehicular applications. (C) 2020 Elsevier B.V. All
   rights reserved.
ZR 0
ZB 0
TC 0
Z8 0
ZS 0
Z9 0
SN 1874-4907
UT WOS:000533611300003
ER

PT J
AU Tian, Jinyan
   Wang, Le
   Yin, Dameng
   Li, Xiaojuan
   Diao, Chunyuan
   Gong, Huili
   Shi, Chen
   Menenti, Massimo
   Ge, Yong
   Nie, Sheng
   Ou, Yang
   Song, Xiaonan
   Liu, Xiaomeng
TI Development of spectral-phenological features for deep learning to
   understand Spartina alterniflora invasion
SO REMOTE SENSING OF ENVIRONMENT
VL 242
AR 111745
DI 10.1016/j.rse.2020.111745
PD JUN 1 2020
PY 2020
AB Invasive Spartina alterniflora (S. alterniflora), a native riparian
   species in the U.S. Gulf of Mexico, has led to serious degradation to
   the ecosystem and biodiversity as well as economic losses since it was
   introduced to China in 1979. Although multi-temporal remote sensing
   offers unique capability to monitor S. alterniflora over large areas and
   long time periods, three major hurdle exist: (1) in the coastal zone
   where S. alterniflora occupies, frequent cloud coverage reduces the
   number of available images that can be used; (2) prominent spectral
   variations exist within the S. alterniflora due to phonological
   variations; (3) poor spectral separability between S. alterniflora and
   its co-dominant native species is often presented in the territories
   where S. alterniflora intruded in. To articulate these questions, we
   proposed a new pixel-based phenological feature composite method (PpfCM)
   based on Google Earth Engine. The Ppf-CM method was brainstormed to
   battle the aforementioned three hurdles as the basic unit for extracting
   phonological feature is individual pixel in lieu of an entire image
   scene. With the Ppf-CM-derived phenological feature as inputs, we took a
   step further to investigate the performance of the latest deep learning
   method as opposed to that of the conventional support vector machine
   (SVM); Lastly, we strive to understand how S. alterniflora has changed
   its spatial distribution in the Beibu Gulf of China from 1995 to 2017.
   As a result, we found (1) the developed Ppf-CM method can mitigate the
   phonological variation and augment the spectral separability between S.
   alterniflora and the background species regardless of the significant
   cloud coverage in the study area; (2) deep learning, compared to SVM,
   presented better potentials for incorporating the new phenological
   features generated from the Ppf-CM method; and (3) for the first time,
   we discovered a S. alterniflora invasion outbreak occurred during
   1996-2001.
ZS 0
ZB 0
ZR 0
TC 0
Z8 0
Z9 0
SN 0034-4257
EI 1879-0704
UT WOS:000523965600013
ER

PT J
AU Esperanza, Jose Aquino
   Sarlabous, Leonardo
   de Haro, Candelaria
   Magrans, Rudys
   Lopez-Aguilar, Josefina
   Blanch, Lluis
TI Monitoring Asynchrony During Invasive Mechanical Ventilation.
SO Respiratory care
VL 65
IS 6
BP 847
EP 869
DI 10.4187/respcare.07404
PD 2020-Jun
PY 2020
AB Mechanical ventilation in critically ill patients must effectively
   unload inspiratory muscles and provide safe ventilation (ie, enhancing
   gas exchange, protect the lungs and the diaphragm). To do that, the
   ventilator should be in synchrony with patient's respiratory rhythm. The
   complexity of such interplay leads to several concerning issues that
   clinicians should be able to recognize. Asynchrony between the patient
   and the ventilator may induce several deleterious effects that require a
   proper physiological understanding to recognize and manage them.
   Different tools have been developed and proposed beyond the careful
   analysis of the ventilator waveforms to help clinicians in the
   decision-making process. Moreover, appropriate handling of asynchrony
   requires clinical skills, physiological knowledge, and suitable
   medication management. New technologies and devices are changing our
   daily practice, from automated real-time recognition of asynchronies and
   their distribution during mechanical ventilation, to smart alarms and
   artificial intelligence algorithms based on physiological big data and
   personalized medicine. Our goal as clinicians is to provide care of
   patients based on the most accurate and current knowledge, and to
   incorporate new technological methods to facilitate and improve the care
   of the critically ill.
TC 0
ZS 0
Z8 0
ZB 0
ZR 0
Z9 0
EI 1943-3654
UT MEDLINE:32457175
PM 32457175
ER

PT J
AU Smallwood, Craig D
TI Monitoring Big Data During Mechanical Ventilation in the ICU.
SO Respiratory care
VL 65
IS 6
BP 894
EP 910
DI 10.4187/respcare.07500
PD 2020-Jun
PY 2020
AB The electronic health record allows the assimilation of large amounts of
   clinical and laboratory data. Big data describes the analysis of large
   data sets using computational modeling to reveal patterns, trends, and
   associations. How can big data be used to predict ventilator
   discontinuation or impending compromise, and how can it be incorporated
   into the clinical workflow? This article will serve 2 purposes. First, a
   general overview is provided for the layperson and introduces key
   concepts, definitions, best practices, and things to watch out for when
   reading a paper that incorporates machine learning. Second, recent
   publications at the intersection of big data, machine learning, and
   mechanical ventilation are presented.
ZR 0
ZS 0
ZB 0
Z8 0
TC 0
Z9 0
EI 1943-3654
UT MEDLINE:32457178
PM 32457178
ER

PT J
AU Kaumbata, Wilson
   Banda, Liveness
   Meszaros, Gabor
   Gondwe, Timothy
   Woodward-Greene, M. J.
   Rosen, Benjamin D.
   Van Tassell, Curtis P.
   Soelkner, Johann
   Wurzinger, Maria
TI Tangible and intangible benefits of local goats rearing in smallholder
   farms in Malawi
SO SMALL RUMINANT RESEARCH
VL 187
AR 106095
DI 10.1016/j.smallrumres.2020.106095
PD JUN 2020
PY 2020
AB A study was conducted to determine tangible and intangible benefits of
   local goats to smallholders in low input crop-livestock production
   system where community-based goat breeding program (goat CBBP) is being
   implemented. Data was collected through a 12-month flock and household
   (137 households) monitoring study between August 2017 to July 2018. Data
   collected was analyzed using enterprise budgeting and cost-return
   analysis. The results showed that local goat enterprises in smallholder
   farms are profitable and economically viable. The mean annual net profit
   per flock and per goat was MK54,406 and MK11, 140 ((sic)1 = MK830.00),
   respectively. The average return on capital invested was 24.6%,
   exceeding the prevailing average commercial deposit rate (8%) by several
   folds. Goats accounted for 61.2% of the total livestock household income
   representing the biggest contributor, while cattle, pigs and chickens
   contributed 17.6%, 15.5% and 4.1%, respectively. Sale of live goats
   constituted the major (79.2%) proportion of the total offtake rate,
   suggesting that goats are primarily kept for generation of cash
   revenues. Inclusion of intangible benefits of goats significantly
   increased the mean annual net profit and the return on capital by 60.3%,
   reflecting the importance of socio-economic roles goats play in
   providing current and future economic stability to rural households'
   economy. Hence, programs like goat CBBPs are meant to harness the
   potentials of local goats to optimize their contributions towards
   reduction of rural poverty and hunger. Therefore, financing and
   supporting scaling up of such programs is a meaningful direct investment
   into the development of rural economy.
Z8 0
TC 0
ZS 0
ZB 0
ZR 0
Z9 0
SN 0921-4488
EI 1879-0941
UT WOS:000531078900006
ER

PT J
AU Shen, Tong
   Hong, Yu
   Thompson, Michelle M.
   Liu, Jiaping
   Hun, Xiaoping
   Wu, Lian
TI How does parking availability interplay with the land use and affect
   traffic congestion in urban areas? The case study of Xi'an, China
SO SUSTAINABLE CITIES AND SOCIETY
VL 57
AR 102126
DI 10.1016/j.scs.2020.102126
PD JUN 2020
PY 2020
AB Strategic development of parking spaces is considered as one of the
   leading solutions to alleviate urban congestion. However, few studies
   have quantified the interactions between land use and parking to
   investigate their emission impacts on traffic congestion. This study
   introduced a novel dimensionless ratio, the Extra Carbon Emission Index
   (ECEI) which estimates carbon dioxide (CO2) increments in the congestion
   condition of free-flowing traffic. Using a publicly accessible
   web-mapping service application, we collected the traffic speed data
   from dynamic urban road networks during peak hours of Xi'an city, China
   in 2017. A multiple regression model was applied to analyse the
   tripartite relationship among land use, parking availability and the
   ECEI. The results suggest that 1) supply-demand ratio of parking spaces,
   density and land use mix are negatively correlated to congestion; 2)
   parking availability is positively associated with spatial-temporal
   distribution of traffic flows, and this land use differentiates
   congestion in time and throughout the built environment; and 3)
   low-density parking lots and high-density parking spaces increase
   traffic congestion in residential districts, while adversely affect the
   compact land use towards sustainability. Compared to the reconstruction
   of land use, parking reform provides a more efficient way to alleviate
   congestion by coordinating the density of lots and spaces in residential
   districts.
TC 0
ZR 0
ZS 0
ZB 0
Z8 0
Z9 0
SN 2210-6707
EI 2210-6715
UT WOS:000533520900001
ER

PT J
AU Maboni, Grazieli
   Seguel, Mauricio
   Lorton, Ana
   Sanchez, Susan
TI Antimicrobial resistance patterns of Acinetobacter spp. of animal origin
   reveal high rate of multidrug resistance.
SO Veterinary microbiology
VL 245
BP 108702
EP 108702
DI 10.1016/j.vetmic.2020.108702
PD 2020-Jun
PY 2020
AB Antimicrobial resistance has been declared by the World Health
   Organization as one of the biggest threats to public health and
   Acinetobacter baumannii is a notable example. A. baumannii is an
   important human nosocomial pathogen, being along with other multidrug
   resistant (MDR) bacteria, one of the biggest public health concerns
   worldwide. In Veterinary Medicine, resistance patterns of Acinetobacter
   species other than A. baumanii are unclear, and the scarce information
   available is limited and fragmented. We applied a statistical modeling
   approach to investigate the occurrence, clinical relevance and
   antimicrobial resistant phenotypes of Acinetobacter spp. originated from
   animals. Seven Acinetobacter species were identified in clinical
   specimens of more than 15 different domestic, zoo and exotic animal
   species. We found a high rate of MDR A. baumannii of canine origin with
   some of these isolates originating from serious systemic or wound
   infections, which highlights their potential pathogenic profile and
   spread in the human environment. Data also revealed different
   antimicrobial resistance patterns of animal-origin Acinetobacter
   species, emphasizing the necessity to implement specific antimicrobial
   susceptibility recommendations for animal isolates as there are no such
   clinical breakpoints currently in place. This study provides substantial
   advancing in our understanding of Acinetobacter spp. in animal clinical
   specimens, and highlights the role of animals in the dynamics of
   multidrug resistance in bacteria. The data presented here is a valuable
   source of information for further establishment of clinical breakpoints
   for susceptibility testing of animal-associated Acinetobacter isolates.
ZB 0
Z8 0
ZS 0
ZR 0
TC 0
Z9 0
EI 1873-2542
UT MEDLINE:32456823
PM 32456823
ER

PT J
AU Aly-Tovar, Ramadan
   Bacache-Beauvallet, Maya
   Bourreau, Marc
   Moreau, Francois
TI Why would artists favor free streaming?
SO JOURNAL OF CULTURAL ECONOMICS
VL 44
IS 2
BP 255
EP 280
DI 10.1007/s10824-019-09358-z
PD JUN 2020
PY 2020
AB While streaming services are becoming the dominant way to consume
   recorded music, professional musicians remain divided in their opinion
   toward streaming, especially toward free (ad-supported) services that
   generate very low royalties. This paper is one of the first attempts to
   analyze empirically the drivers of the artists' opinion on free
   streaming. Using survey data from more than 1100 French professional
   musicians, we emphasize that beyond their individual preferences, four
   main determinants affect the opinion of artists on free streaming: (1)
   Free streaming stands as a discovery tool that helps consumers to
   explore the music catalogue beyond stars and already well-known artists;
   (2) free streaming generates a positive externality on the live music
   market; (3) the contractual situation of the artist also matters, since
   the biggest recording companies obtain much more favorable conditions in
   revenue sharing from streaming services; (4) the opinion of artists is
   also shaped by the consumption habits of their fans.
ZS 0
Z8 0
ZB 0
TC 0
ZR 0
Z9 0
SN 0885-2545
EI 1573-6997
UT WOS:000533456500003
ER

PT J
AU Adams, Freddy
   Adriaens, Mieke
TI The metamorphosis of analytical chemistry
SO ANALYTICAL AND BIOANALYTICAL CHEMISTRY
VL 412
IS 15
SI SI
BP 3525
EP 3537
DI 10.1007/s00216-019-02313-z
PD JUN 2020
PY 2020
AB Defining analytical chemistry as the measurement of isolated
   compositional features in a selected study object ignores the unique
   perspective that analytical chemists bring to twenty-first century
   science and society. In this feature article, we will discuss some of
   the existing preconceptions and misinterpretations of analytical
   chemistry that occur at present and will tackle them from the more
   up-to-date perspective of science in the Big Data Era. This will place
   their influence in context while simultaneously enlarging the scope of
   the discipline analytical chemistry to its well-deserved prevalent
   position in present-day science and technology.
   Graphical abstract
ZB 0
ZR 0
ZS 0
Z8 0
TC 0
Z9 0
SN 1618-2642
EI 1618-2650
UT WOS:000532794200003
PM 31848669
ER

PT J
AU Walton, Kate E.
   Cherkasova, Lina
   Roberts, Richard D.
TI On the Validity of Forced Choice Scores Derived From the Thurstonian
   Item Response Theory Model
SO ASSESSMENT
VL 27
IS 4
BP 706
EP 718
DI 10.1177/1073191119843585
PD JUN 2020
PY 2020
AB Forced choice (FC) measures may be a desirable alternative to single
   stimulus (SS) Likert items, which are easier to fake and can have
   associated response biases. However, classical methods of scoring FC
   measures lead to ipsative data, which have a number of psychometric
   problems. A Thurstonian item response theory (TIRT) model has been
   introduced as a way to overcome these issues, but few empirical validity
   studies have been conducted to ensure its effectiveness. This was the
   goal of the current three studies, which used FC measures of domains
   from popular personality frameworks including the Big Five and HEXACO,
   and both statement and adjective item stems. We computed TIRT and
   ipsative scores and compared their validity estimates. Convergent and
   discriminant validity of the scores were evaluated by correlating them
   with SS scores, and test-criterion validity evidence was evaluated by
   examining their relationships with meaningful outcomes. In all three
   studies, there was evidence for the convergent and test-criterion
   validity of the TIRT scores, though at times this was on par with the
   validity of the ipsative scores. The discriminant validity of the TIRT
   scores was problematic and was often worse than the ipsative scores.
ZS 0
ZR 0
TC 2
Z8 0
ZB 0
Z9 2
SN 1073-1911
EI 1552-3489
UT WOS:000532465100005
PM 31007043
ER

PT J
AU Trabucchi, Daniel
   Buganza, Tommaso
TI Fostering digital platform innovation: From two to multi-sided platforms
SO CREATIVITY AND INNOVATION MANAGEMENT
VL 29
IS 2
BP 345
EP 358
DI 10.1111/caim.12320
PD JUN 2020
PY 2020
AB Two-sided markets and digital platforms are becoming increasingly
   relevant in the modern scenario. Companies like Airbnb and Uber are
   inspiring many other firms in different fields that share their basic
   structure: they match two (or more) groups of customers. This research
   aims at exploring the innovation strategies companies such as these rely
   on to expand their basic structure towards more complex models. Being
   inspired by previous models in the field and considering the role that
   big data seems to play in these businesses, a first conceptual model is
   presented. Therefore, 100 companies-using mobile apps as the empirical
   setting-are explored in this research to understand the common behaviors
   concerning evolution. In the end, three strategies are presented: Supply
   (Side) Expansion, Transactional Advertising, and Data Trading. These
   strategies are further discussed to highlight two main directions of
   innovation-ecosystem innovation and data push innovation-which may be
   merged giving birth to multi-sided epiphanies. The paper contributes to
   the literature showing various strategies and their implication to
   foster innovation on two-sided platforms. Moreover, it shows possible
   ways to exploit the value embedded in the complex ecosystems of the
   relationships they create.
TC 0
ZB 0
ZR 0
ZS 0
Z8 0
Z9 0
SN 0963-1690
EI 1467-8691
UT WOS:000532923100011
ER

PT J
AU Ushakova, Anastasia
   Mikhaylov, Slava Jankin
TI Big data to the rescue? Challenges in analysing granular household
   electricity consumption in the United Kingdom
SO ENERGY RESEARCH & SOCIAL SCIENCE
VL 64
AR 101428
DI 10.1016/j.erss.2020.101428
PD JUN 2020
PY 2020
AB Rapid growth in smart meter installations has given rise to vast
   collections of data at a high time-resolution and down to an individual
   level. However, to enable efficient policy interventions, we need to be
   able to appropriately segment the population of users. The aim of this
   paper is to consider challenges and opportunities associated with large
   highly-granular temporal datasets that describe residential electricity
   consumption. In particular, the focus is on experiments relating to
   aggregation of smart meter time-series data in the context of clustering
   and prediction tasks that are often used for customer targeting and to
   gain insight on energy-use about sub populations. To cluster energy use
   profiles, we propose a novel framework based on a set of Gaussian based
   models which we use to encode individuals' energy consumption over time.
   The dataset consists of half hourly electricity consumption records from
   smart meters of households in the UK (2014-2015). The contribution of
   this paper comes from its investigation of how consumers or groups may
   be clustered according to model parameters in scenarios where additional
   data on consumers is not available to the researcher, or where anonymity
   preservation of the smart meter user is prioritised. A secondary aim is
   to invite greater awareness when data reduction is required to reduce
   the size of a large dataset for computational purposes. This may have
   implications for policy interventions acting at the individual or small
   group level, for instance, when designing incentives to encourage energy
   efficient behaviour or when identifying fuel poor customers.
Z8 0
ZB 0
ZR 0
TC 0
ZS 0
Z9 0
SN 2214-6296
EI 2214-6326
UT WOS:000532669700010
ER

PT J
AU Yasmin, Mariam
   Tatoglu, Ekrem
   Kilic, Huseyin Selcuk
   Zaim, Selim
   Delen, Dursun
TI Big data analytics capabilities and firm performance: An integrated MCDM
   approach
SO JOURNAL OF BUSINESS RESEARCH
VL 114
BP 1
EP 15
DI 10.1016/j.jbusres.2020.03.028
PD JUN 2020
PY 2020
AB This study explores the interdependence of big data analytics (BDA)
   capabilities and the impact of these capabilities on firm performance
   using an integrated multicriteria decision-making (MCDM) methodology.
   Drawing on a rich data set obtained from selected case study firms in
   Pakistan, three MCDM tools, namely, intuitionistic fuzzy decision-making
   trial and evolution laboratory (IF-DEMATEL), analytic network process
   (ANP), and simple additive weighting (SAW), are employed to assess the
   relative importance of BDA capabilities and the relationship of these
   capabilities with the firm performance. The results show that BDA
   capabilities are interdependent, and infrastructure capabilities are the
   highest-ranked among all, followed by management and human resource
   capabilities, respectively. The SAW results indicate an association
   between BDA capabilities and firm performance. Moreover, BDA
   capabilities are more strongly related to operational performance than
   to market performance.
ZS 0
Z8 0
TC 0
ZR 0
ZB 0
Z9 0
SN 0148-2963
EI 1873-7978
UT WOS:000532827900001
ER

PT J
AU Karami, Amir
   Shah, Vishal
   Vaezi, Reza
   Bansal, Amit
TI Twitter speaks: A case of national disaster situational awareness
SO JOURNAL OF INFORMATION SCIENCE
VL 46
IS 3
BP 313
EP 324
DI 10.1177/0165551519828620
PD JUN 2020
PY 2020
AB In recent years, we have been faced with a series of natural disasters
   causing a tremendous amount of financial, environmental and human
   losses. The unpredictable nature of natural disasters behaviour makes it
   hard to have a comprehensive situational awareness (SA) to support
   disaster management. Using opinion surveys is a traditional approach to
   analyse public concerns during natural disasters; however, this approach
   is limited, expensive and time-consuming. Luckily, the advent of social
   media has provided scholars with an alternative means of analysing
   public concerns. Social media enable users (people) to freely
   communicate their opinions and disperse information regarding current
   events including natural disasters. This research emphasises the value
   of social media analysis and proposes an analytical framework: Twitter
   Situational Awareness (TwiSA). This framework uses text mining methods
   including sentiment analysis and topic modelling to create a better SA
   for disaster preparedness, response and recovery. TwiSA has also
   effectively deployed on a large number of tweets and tracks the negative
   concerns of people during the 2015 South Carolina flood.
TC 3
ZR 0
ZS 0
Z8 0
ZB 0
Z9 3
SN 0165-5515
EI 1741-6485
UT WOS:000532403600002
ER

PT J
AU Edwards, Katie M.
   Rodenhizer, Kara Anne
   Eckstein, Robert P.
TI School Personnel's Bystander Action in Situations of Dating Violence,
   Sexual Violence, and Sexual Harassment Among High School Teens: A
   Qualitative Analysis
SO JOURNAL OF INTERPERSONAL VIOLENCE
VL 35
IS 11-12
BP 2358
EP 2369
DI 10.1177/0886260517698821
PD JUN 2020
PY 2020
AB We examined school personnel's engagement in bystander action in
   situations of teen dating violence (DV), sexual violence (SV), and
   sexual harassment (SH). We conducted focus groups with 22 school
   personnel from three high schools in New Hampshire. School personnel
   identified their own barriers to intervening in situations of teen DV,
   SV, and SH (e.g., not having the time or ability to intervene). School
   personnel also discussed the ways in which they intervened before (e.g.,
   talking with teens about healthy relationships), during (e.g., breaking
   up fights between dating partners) and after (e.g., comforting victims)
   instances of teen DV, SV, and SH. These data can be used to support the
   development of bystander training for school personnel as one component
   of comprehensive DV, SV, and SH prevention for teens. In addition, these
   data provide information that can be used to develop measures that
   assess school personnel bystander action barriers and behaviors in
   instances of teen DV, SV, and SH.
ZS 0
Z8 0
TC 2
ZB 0
ZR 0
Z9 2
SN 0886-2605
EI 1552-6518
UT WOS:000532349000012
PM 29294713
ER

PT J
AU Lev-On, Azi
   Steinfeld, Nili
TI "Objection, Your Honor": Use of Social Media by Civilians to Challenge
   the Criminal Justice System
SO SOCIAL SCIENCE COMPUTER REVIEW
VL 38
IS 3
SI SI
BP 315
EP 333
DI 10.1177/0894439318771523
PD JUN 2020
PY 2020
AB Social media constitute useful and effective platforms for miscarriage
   of justice campaigners to challenge state authorities and decisions
   taken by the criminal justice system. To characterize such endeavors,
   this study analyzes the activity in such a major group dedicated to the
   murder case of Tair Rada and the trial of Roman Zadorov, one of the most
   controversial legal cases in Israel's history. Using digital data
   extraction and linguistic analysis tools, we focus on five themes: (1)
   the central role of group administrators in directing the discourse and
   setting the group agenda; (2) correspondence of group activity with
   off-line events and mainstream media coverage; (3) skewed distribution
   of post publications per user and engagement measures per post; (4)
   prominent topics in group discussions, revolving around key figures,
   institutions and officials, making justice, considering alternative
   theories and examining investigative and forensic materials; and (5) the
   framing of key figures, institutions, and values in portraying a
   somewhat dichotomous image of a corrupted justice system, an innocent
   man wrongly convicted and a Facebook group in the search for the truth.
RI Steinfeld, Nili/AAB-9150-2020
OI Steinfeld, Nili/0000-0001-7857-6059
ZS 0
Z8 0
TC 1
ZB 0
ZR 0
Z9 1
SN 0894-4393
EI 1552-8286
UT WOS:000532344200005
ER

PT J
AU Wu, Guohua
   Peng, Wuxuan
   Hu, Xingchen
   Wang, Rui
   Chen, Huangke
TI Configuring differential evolution adaptively via path search in a
   directed acyclic graph for data clustering
SO SWARM AND EVOLUTIONARY COMPUTATION
VL 55
AR UNSP 100690
DI 10.1016/j.swevo.2020.100690
PD JUN 2020
PY 2020
AB As an efficient data mining technique, data clustering has been
   widely-used for data analysis and extracting valuable hidden
   information. Leveraging the simplicity and effectiveness, the
   evolutionary optimization-driven clustering algorithms have exhibited
   promising performance and attracted tremendous attention. Up to the
   present, how to enable these algorithms to escape from local optima and
   accelerate convergence rates is an ongoing challenge. In this paper, we
   propose a novel adaptive Differential Evolution (DE) variant to deal
   with the above challenge when clustering data. In the improved DE
   algorithm, the four interdependent components, including mutation
   strategy, crossover strategy, scaling factor value, and crossover rate,
   are adaptively configured in an integrated manner via ant colony
   optimization (ACO) during the problem-solving process. To be specific,
   the relationships of four components in the DE algorithm are modeled as
   a directed acyclic graph, and a path in the graph exactly corresponds to
   a configuration for DE. During the optimization process, ant colony
   optimization is employed to search for a reasonable path for each
   individual of DE in terms of pheromones on arcs. In this manner, the
   configuration of the four interdependent components of DE will be
   generated dynamically, which is then used to guide the successive search
   behaviors of individuals in DE. Each individual has a path, representing
   a configuration for each component. After each iteration, individuals
   that generate promising solutions are allowed to deposit pheromone on
   the paths, resulting in more pheromones on the arcs appearing in better
   algorithm configurations (paths) more frequently. Through this manner,
   the search strategies and parameters of DE are comprehensively adapted
   by ACO. The proposed algorithm is named ACODE for short. To verify its
   effectiveness, the proposed ACODE is compared with four representative
   data clustering algorithms on eight widely-used benchmark datasets. The
   experimental results demonstrate the advantages of ACODE over half of
   the datasets.
TC 0
ZR 0
ZS 0
ZB 0
Z8 0
Z9 0
SN 2210-6502
EI 2210-6510
UT WOS:000532741100011
ER

PT J
AU Masouleh, Mehdi Khoshboresh
   Shah-Hosseini, Reza
TI A hybrid deep learning-based model for automatic car extraction from
   high-resolution airborne imagery
SO APPLIED GEOMATICS
VL 12
IS 2
BP 107
EP 119
DI 10.1007/s12518-019-00285-4
PD JUN 2020
PY 2020
AB Automatic car extraction (ACE) from high-resolution airborne imagery
   (i.e., true-orthophoto) has been a hot research topic in the field of
   photogrammetry and machine learning. ACE from high-resolution airborne
   imagery is the most suitable method for control and monitoring practices
   in large cities such as traffic management. The use of deep
   learning-based feature extraction methods, such as convolutional neural
   networks, have been providing state-of-the-art performance in the last
   few years, particularly, these techniques have been successfully applied
   to automatic object extraction from images. In this paper, we proposed a
   novel hybrid method to take advantage of the semantic segmentation of
   high-resolution airborne imagery to ACE that is realized based on the
   combination of deep convolutional neural networks and restricted
   Boltzmann machine (RBM). This hybrid method is called RBMDeepNet. We
   trained and tested our model on the ISPRS Potsdam and Vaihingen
   benchmark datasets (non-big data) which is more challenging for ACE.
   Here, Potsdam data is a true-color dataset, and Vaihingen data is a
   false-color dataset. The results obtained in the present study showed
   that the proposed method for ACE from high-resolution airborne imagery
   achieves a 7% improvement in accuracy with about 10% improvement in
   processing time compared to similar methods.
TC 1
ZB 0
ZR 0
Z8 0
ZS 0
Z9 1
SN 1866-9298
EI 1866-928X
UT WOS:000532227200001
ER

PT J
AU Kitagawa, Megumi
   Uesugi, Yuko
   Kawata, Naomi
   Shimamura, Yasuhiro
TI Comparison of unpalatable meal contents between patients who underwent
   total and distal gastrectomies
SO CLINICAL NUTRITION ESPEN
VL 37
BP 134
EP 140
DI 10.1016/j.clnesp.2020.03.005
PD JUN 2020
PY 2020
AB Background: Unpalatable meal contents have several impacts on the
   dietary life of patients who undergo gastrectomy. However, few studies
   have focused on the unpalatable meal contents according to surgical
   procedure. This study aims to clarify the differences in the unpalatable
   meal contents between the patients who underwent total and distal
   gastrectomies (TG and DG, respectively).
   Methods: This study involved patients (n = 341) who underwent TG or DG
   within 5 years, and a questionnaire of unpalatable meal contents was
   used. The data on the demographics, operation types, Dysfunction After
   Upper Gastrointestinal Surgery 20 (DAUGS20) scoring system, and
   nutrition conditions were confirmed. Furthermore, these were analyzed
   using descriptive statistics and compared between TG (n = 180) and DG (n
   = 161) groups.
   Results: The unpalatable meal contents that were significantly different
   between two groups were big in size (p = 0.013), solid (p = 0.040),
   rough (p = 0.041), and dry (p = 0.045), which were more difficulty in
   the TG group. Furthermore, the strong sour taste was more difficulty in
   the DG group (p = 0.031).
   Discussion: The meals which the TG group had difficulty eating were
   characteristic of sticking or stagnating in the digestive tract, making
   the passage of food more difficult in the TG patients. This was because
   they had a smaller storage for foods and a narrower space at the
   anastomotic region than those who underwent DG.
   Conclusion: The meal contents were assumed to have been influenced by
   the surgical procedure. We conclude that the patients in the TG group
   felt more difficulty in eating the meal contents that could stagnate at
   the anastomotic region than those in the DG group. (C) 2020 The Authors.
   Published by Elsevier Ltd on behalf of European Society for Clinical
   Nutrition and Metabolism.
TC 0
ZR 0
Z8 0
ZS 0
ZB 0
Z9 0
SN 2405-4577
UT WOS:000531842500019
PM 32359735
ER

PT J
AU Fan, Minghui
   Billings, Andrew
   Zhu, Xiangyu
   Yu, Panfeng
TI Twitter-Based BIRGing: Big Data Analysis of English National Team Fans
   During the 2018 FIFA World Cup
SO COMMUNICATION & SPORT
VL 8
IS 3
BP 317
EP 345
DI 10.1177/2167479519834348
PD JUN 2020
PY 2020
AB Sports fans tend to associate themselves with a successful team
   (BIRGing), while disassociating themselves with unsuccessful teams
   (CORFing). This premise was applied to social media commentary within
   England's matches against Croatia and Colombia during the 2018
   Federation Internationale de Football Association World Cup, uncovering
   that English fans tended to perform Basking in Reflected Glory (BIRG)
   when England was leading or victorious and tended to engage in Cutting
   Off Reflected Failure (CORF) when England was trailing or defeated. In
   Method 1, team identification, national identification with England, and
   sentiment were significantly higher when England was leading or
   victorious than when they were trailing or defeated. In Method 2,
   machine learning generated trending graphs to detect that English fans
   BIRGed when they scored against Colombia; they also BIRGed more
   frequently during the match with Croatia, peaking several times when
   they scored a goal, saved a goal, or took a free kick. However, even
   though CORFing (i.e., lower team identification, lower national
   identification, and lower sentiment) occurred when the opposing team
   scored, English fans still BIRGed when they were finally defeated by
   Croatia, likely a function of the stage the game took place (World Cup
   semifinal), indicating that England had nonetheless succeeded in the
   World Cup as a whole.
ZB 0
Z8 0
ZR 0
TC 0
ZS 0
Z9 0
SN 2167-4795
EI 2167-4809
UT WOS:000532323000002
ER

PT J
AU Shokeen, Jyoti
   Rana, Chhavi
TI Social recommender systems: techniques, domains, metrics, datasets and
   future scope
SO JOURNAL OF INTELLIGENT INFORMATION SYSTEMS
VL 54
IS 3
BP 633
EP 667
DI 10.1007/s10844-019-00578-5
PD JUN 2020
PY 2020
AB With the evolution of social media, an enormous amount of information is
   shared every day. Recommender systems contribute significantly in
   handling big data and presenting relevant information, services and
   items to people. A substantial number of recommender system algorithms
   based on social media data have been proposed and applied to numerous
   domains in the literature. This paper presents a state-of-the-art survey
   of existing techniques of social recommender systems. We present
   different domains where the existing systems have been experimented. We
   also present a tabular representation of different metrics used by these
   papers. We discuss some frequently used datasets of these systems.
   Lastly, we discuss some of the future works in this area. The main aim
   of this paper is to provide a concise review of published papers to
   assist potential researchers in this field to devise new techniques.
ZS 0
TC 0
ZB 0
Z8 0
ZR 0
Z9 0
SN 0925-9902
EI 1573-7675
UT WOS:000532201200010
ER

PT J
AU Stefanova, Elka
   Dubljevic, Olga
   Herbert, Cornelia
   Fairfield, Beth
   Schroeter, Matthias L.
   Stern, Emily R.
   Urben, Sebastien
   Derntl, Birgit
   Wiebking, Christine
   Brown, Carina
   Drach-Zahavy, Anat
   Loeffler, Leonie Anne Kathrin
   Albrecht, Franziska
   Palumbo, Rocco
   Boutros, Sydney Weber
   Raber, Jacob
   Lowe, Leroy
TI Anticipatory feelings: Neural correlates and linguistic markers
SO NEUROSCIENCE AND BIOBEHAVIORAL REVIEWS
VL 113
BP 308
EP 324
DI 10.1016/j.neubiorev.2020.02.015
PD JUN 2020
PY 2020
AB This review introduces anticipatory feelings (AF) as a new construct
   related to the process of anticipation and prediction of future events.
   AF, defined as the state of awareness of physiological and
   neurocognitive changes that occur within an oganism in the form of a
   process of adapting to future events, are an important component of
   anticipation and expectancy. They encompass bodily-related interoceptive
   and affective components and are influenced by intrapersonal and
   dispositional factors, such as optimism, hope, pessimism, or worry. In
   the present review, we consider evidence from animal and human research,
   including neuroimaging studies, to characterize the brain structures and
   brain networks involved in AF. The majority of studies reviewed revealed
   three brain regions involved in future oriented feelings: 1) the insula;
   2) the ventromedial prefrontal cortex (vmPFC); and 3) the amygdala.
   Moreover, these brain regions were confirmed by a meta-analysis, using a
   platform for large-scale, automated synthesis of fMRI data. Finally, by
   adopting a neurolinguistic and a big data approach, we illustrate how AF
   are expressed in language.
RI Palumbo, Rocco/H-7375-2014
OI Palumbo, Rocco/0000-0002-2385-5840
ZB 0
ZR 0
TC 0
Z8 0
ZS 0
Z9 0
SN 0149-7634
EI 1873-7528
UT WOS:000531531100022
PM 32061891
ER

PT J
AU Nardecchia, Alessandro
   Fabre, Cecile
   Cauzid, Jean
   Pelascini, Frederic
   Motto-Ros, Vincent
   Duponchel, Ludovic
TI Detection of minor compounds in complex mineral samples from millions of
   spectra: A new data analysis strategy in LIBS imaging
SO ANALYTICA CHIMICA ACTA
VL 1114
BP 66
EP 73
DI 10.1016/j.aca.2020.04.005
PD JUN 1 2020
PY 2020
AB Today, Laser-Induced Breakdown Spectroscopy (LIBS) imaging is in full
   change. Indeed, always more stable instrumentations are developed, which
   significantly increases the signal quality and naturally the analytical
   potential of the technique for the characterization of complex and
   heterogeneous samples at the micro-scale level. Obviously, other
   intrinsic features such as a limit of detection in the order of ppm, a
   high field of view and high acquisition rate make it one of the most
   complete chemical imaging techniques to date. It is thus possible in
   these conditions to acquire several million spectra from one single
   sample in just hours. Managing big data in LIBS imaging is the challenge
   ahead. In this paper, we put forward a new spectral analysis strategy,
   called embedded k-means clustering, for simultaneous detection of major
   and minor compounds and the generation of associated localization maps.
   A complex rock section with different phases and traces will be explored
   to demonstrate the value of this approach. (C) 2020 Elsevier B.V. All
   rights reserved.
OI Jean, Cauzid/0000-0001-5587-9874; FABRE, Cecile/0000-0001-8627-4050;
   Duponchel, Ludovic/0000-0002-7206-4498
Z8 0
TC 0
ZS 0
ZB 0
ZR 0
Z9 0
SN 0003-2670
EI 1873-4324
UT WOS:000531607700008
PM 32359516
ER

PT J
AU Loghin, Dumitrel
   Cai, Shaofeng
   Chen, Gang
   Tien Tuan Anh Dinh
   Fan, Feiyi
   Lin, Qian
   Ng, Janice
   Ooi, Beng Chin
   Sun, Xutao
   Quang-Trung Ta
   Wang, Wei
   Xiao, Xiaokui
   Yang, Yang
   Zhang, Meihui
   Zhang, Zhonghua
TI The Disruptions of 5G on Data-Driven Technologies and Applications
SO IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING
VL 32
IS 6
BP 1179
EP 1198
DI 10.1109/TKDE.2020.2967670
PD JUN 1 2020
PY 2020
AB With 5G on the verge of being adopted as the next mobile network, there
   is a need to analyze its impact on the landscape of computing and data
   management. In this paper, we analyze the impact of 5G on both
   traditional and emerging technologies and project our view on future
   research challenges and opportunities. With a predicted increase of
   10-100x in bandwidth and 5-10x decrease in latency, 5G is expected to be
   the main enabler for smart cities, smart IoT and efficient healthcare,
   where machine learning is conducted at the edge. In this context, we
   investigate how 5G can help the development of federated learning.
   Network slicing, another key feature of 5G, allows running multiple
   isolated networks on the same physical infrastructure. However, security
   remains the main concern in the context of virtualization, multi-tenancy
   and high device density. Formal verification of 5G networks can be
   applied to detect security issues in massive virtualized environments.
   In summary, 5G will make the world even more densely and closely
   connected. What we have experienced in 4G connectivity will pale in
   comparison to the vast amounts of possibilities engendered by 5G.
OI Loghin, Dumitrel/0000-0002-8965-542X
ZS 0
ZR 0
Z8 0
ZB 0
TC 0
Z9 0
SN 1041-4347
EI 1558-2191
UT WOS:000531422700011
ER

PT J
AU Damron, Timothy A.
   Mann, Kenneth A.
TI Fracture risk assessment and clinical decision making for patients with
   metastatic bone disease
SO JOURNAL OF ORTHOPAEDIC RESEARCH
VL 38
IS 6
BP 1175
EP 1190
DI 10.1002/jor.24660
PD JUN 2020
PY 2020
AB Metastatic breast, prostate, lung, and other cancers often affect bone,
   causing pain, increasing fracture risk, and decreasing function.
   Management of metastatic bone disease (MBD) is clinically challenging
   when there is potential but uncertain risk of pathological fracture.
   Management of MBD has become a major focus within orthopedic oncology
   with respect to fracture and impending fracture care. If impending
   skeletal-related events (SREs), particularly pathologic fracture, could
   be predicted, increasing evidence suggests that prophylactic surgical
   treatment improves patient outcomes. However, current fracture risk
   assessment and radiographic metrics do not have high accuracy and have
   not been combined with relevant patient survival tools. This review
   first explores the prevalence, incidence, and morbidity of MBD and
   associated SREs for different cancer types. Strengths and limitations of
   current fracture risk scoring systems for spinal stability and long bone
   fracture are highlighted. More recent computed tomography (CT)-based
   structural rigidity analysis (CTRA) and finite element (FE) analysis
   methods offer advantages of increased specificity (true negative rate),
   but are limited in availability. Other fracture prediction approaches
   including parametric response mapping and positron emission
   tomography/computed tomography measures show early promise. Substantial
   new information to inform clinical decision-making includes measures of
   survival, clinical benefits, and economic analysis of prophylactic
   treatment compared to after-fracture stabilization. Areas of future
   research include use of big data and machine learning to predict SREs,
   greater access and refinement of CTRA/FE approaches, combination of
   clinical survival prediction tools with radiographically based fracture
   risk assessment, and net benefit analysis for fracture risk assessment
   and prophylactic treatment.
OI Damron, Timothy/0000-0001-9403-4030; Mann, Kenneth/0000-0003-1150-0740
TC 1
ZS 0
ZR 0
ZB 0
Z8 0
Z9 1
SN 0736-0266
EI 1554-527X
UT WOS:000531824600001
PM 32162711
ER

PT J
AU Shamshoddin, Sadaf
   Khader, Jameel
   Gani, Showkat
TI Predicting consumer preferences in electronic market based on IoT and
   Social Networks using deep learning based collaborative filtering
   techniques
SO ELECTRONIC COMMERCE RESEARCH
VL 20
IS 2
SI SI
BP 241
EP 258
DI 10.1007/s10660-019-09377-0
PD JUN 2020
PY 2020
AB Collaborative filtering plays an important role in predicting consumer
   preferences in the electronic market. Most of the users purchased the
   products in the electronic market with the help of the Internet of
   Things (IoT) and Social Networks. Predicting consumer preference with
   the consumer's history is a vital challenge in the recommendation
   systems. The researchers propose varieties of collaborative filtering
   techniques, but the accuracy of the results is poor. The main aim of
   this paper is to propose a deep learning with collaborative filtering
   technique for the recommendation system to Predicting User preferences
   from the IoT devices and Social Networks that are beneficial for users
   based on their preferences in electronic markets. In this paper
   similarity, neighborhood-based collaborative filtering model (SN-CFM) is
   introduced. The introduced model recommends the products by predicting
   consumer preferences based on the similarity of the consumers and
   neighborhood products. In addition, the introduced deep learning concept
   gets the information from the previous analysis before making rating to
   the items. The introduced SN-CFM model compared with other existing
   recommendation approaches. The results prove that the efficiency of the
   introduced model.
Z8 0
ZR 0
ZB 0
TC 0
ZS 0
Z9 0
SN 1389-5753
EI 1572-9362
UT WOS:000531154200002
ER

PT J
AU Weidman, Aaron C.
   Sun, Jessie
   Vazire, Simine
   Quoidbach, Jordi
   Ungar, Lyle H.
   Dunn, Elizabeth W.
TI (Not) Hearing Happiness: Predicting Fluctuations in Happy Mood From
   Acoustic Cues Using Machine Learning
SO EMOTION
VL 20
IS 4
DI 10.1037/emo0000571
PD JUN 2020
PY 2020
AB Recent popular claims surrounding virtual assistants suggest that
   computers will soon be able to hear our emotions. Supporting this
   possibility, promising work has harnessed big data and emergent
   technologies to automatically predict stable levels of one specific
   emotion, happiness, at the community (e.g., counties) and trait (i.e.,
   people) levels. Furthermore, research in affective science has shown
   that nonverbal vocal bursts (e.g., sighs, gasps) and specific acoustic
   features (e.g., pitch, energy) can differentiate between distinct
   emotions (e.g., anger, happiness) and that machine-learning algorithms
   can detect these differences. Yet, to our knowledge, no work has tested
   whether computers can automatically detect normal, everyday,
   within-person fluctuations in one emotional state from acoustic
   analysis. To address this issue in the context of happy mood, across 3
   studies (total N = 20,197), we asked participants to repeatedly report
   their state happy mood and to provide audio recordings-including both
   direct speech and ambient sounds-from which we extracted acoustic
   features. Using three different machine learning algorithms (neural
   networks, random forests, and support vector machines) and two sets of
   acoustic features, we found that acoustic features yielded minimal
   predictive insight into happy mood above chance. Neither multilevel
   modeling analyses nor human coders provided additional insight into
   state happy mood. These findings suggest that it is not yet possible to
   automatically assess fluctuations in one emotional state (i.e., happy
   mood) from acoustic analysis, pointing to a critical future direction
   for affective scientists interested in acoustic analysis of emotion and
   automated emotion detection.
OI Vazire, Simine/0000-0002-3933-9752; Weidman, Aaron/0000-0002-9395-4051;
   Sun, Jessie/0000-0001-6764-0721; Ungar, Lyle/0000-0003-2047-1443
ZR 0
ZS 0
ZB 0
TC 1
Z8 0
Z9 1
SN 1528-3542
EI 1931-1516
UT WOS:000527794500009
PM 30742458
ER

PT J
AU Zhang, Yitian
   Yu, Jiong
   Lu, Liang
   Li, Ziyang
   Meng, Zhao
TI L-Heron: An open-source load-aware online scheduler for Apache Heron
SO JOURNAL OF SYSTEMS ARCHITECTURE
VL 106
AR 101727
DI 10.1016/j.sysarc.2020.101727
PD JUN 2020
PY 2020
AB Apache Heron has emerged as a promising Data Stream Processing System
   (DSPS). However, it lacks intelligent scheduling strategy, which results
   in significant performance degradation for streaming applications in
   certain scenarios. In this paper, we first illustrate the inefficiencies
   and challenges of Heron default scheduling in current practice through
   experimental observations and analysis. Motivated by our observations,
   we propose L-Heron, an online scheduler based on Heron, which has the
   following features: (i) based on runtime information, it can improve the
   data processing efficiency by using the load-aware online scheduling,
   which heuristically minimizes the overall communication overhead by
   identifying the traffic load; (ii) it is load aware, which can
   effectively balance the workload of a topology to avoid heavy
   performance loss caused by overloading of worker nodes; (iii) it
   provides an online scheduling interface that is transparent to users,
   which allows users to focus on their scheduling logic and easily deploy
   them to the system. Additionally, we have evaluated L-Heron on
   well-known example topologies and a realistic application. Extensive
   experimental results show that the effectiveness of L-Heron is
   consistent among multiple metrics including the system completion
   latency, inter-node traffic, CPU utilization and throughput, with
   respect to Heron and recent related work.
TC 0
ZS 0
ZR 0
ZB 0
Z8 0
Z9 0
SN 1383-7621
EI 1873-6165
UT WOS:000531020300004
ER

PT J
AU Sabouri, Sadegh
   Brewer, Simon
   Ewing, Reid
TI Exploring the relationship between ride-sourcing services and vehicle
   ownership, using both inferential and machine learning approaches
SO LANDSCAPE AND URBAN PLANNING
VL 198
AR 103797
DI 10.1016/j.landurbplan.2020.103797
PD JUN 2020
PY 2020
AB Ride-sourcing services are getting more popular each year, and their
   markets are growing. Much has been speculated, but not much has been
   tested regarding the impacts of ride-sourcing services on the
   transportation system. In this study, we examine the relationship
   between ride-sourcing services and vehicle ownership of households, by
   using the most up-to-date (2017) national household travel survey data.
   To better capture the effect of ride-sourcing services on vehicle
   ownership, we controlled for the effect of socioeconomic characteristics
   of households and built environment variables, i.e., density, diversity,
   design, and distance to transit. Two approaches were used to model
   vehicle ownership: a probabilistic or inferential model (i.e.,
   multilevel Poisson), and a machine learning method (i.e., random
   forest). This is the first study to utilize such advanced methods to
   model vehicle ownership and capture non-linear relationships, using the
   largest sample of household travel records ever assembled for such a
   study. The results suggest that there is a negative correlation between
   using ride-sourcing services and vehicle ownership. Vehicle ownership is
   also negatively associated with the number of years Uber, as the biggest
   ride-sourcing service, has operated in a county. The relative
   contributions of ride-sourcing variables, however, are very limited
   compared to other variables controlled in this study which makes
   intuitive sense. For urban planning and design practices, this study
   suggests that the probability of car shedding will increase if the usage
   of ride-sourcing services becomes a habit, these services become more
   available, and built environments become more dense, connected, and
   transit-served.
OI Brewer, Simon/0000-0002-6810-1911
ZB 0
ZR 0
TC 1
Z8 0
ZS 0
Z9 1
SN 0169-2046
EI 1872-6062
UT WOS:000528059000019
ER

PT J
AU Johns, Brendan T
   Dye, Melody
   Jones, Michael N
TI Estimating the prevalence and diversity of words in written language.
SO Quarterly journal of experimental psychology (2006)
VL 73
IS 6
BP 841
EP 855
DI 10.1177/1747021819897560
PD 2020-Jun
PY 2020
AB Recently, a new crowd-sourced language metric has been introduced,
   entitled word prevalence, which estimates the proportion of the
   population that knows a given word. This measure has been shown to
   account for unique variance in large sets of lexical performance. This
   article aims to build on the work of Brysbaert et al. and Keuleers et
   al. by introducing new corpus-based metrics that estimate how likely a
   word is to be an active member of the natural language environment, and
   hence known by a larger subset of the general population. This metric is
   derived from an analysis of a newly collected corpus of over 25,000
   fiction and non-fiction books and will be shown that it is capable of
   accounting for significantly more variance than past corpus-based
   measures.
ZB 0
ZS 0
TC 0
ZR 0
Z8 0
Z9 0
EI 1747-0226
UT MEDLINE:31826715
PM 31826715
ER

PT J
AU Lee, Hyunju
   Chat, Ji Hwan
TI A new general class of discrete bivariate distributions constructed by
   using the likelihood ratio
SO STATISTICAL PAPERS
VL 61
IS 3
BP 923
EP 944
DI 10.1007/s00362-017-0969-6
PD JUN 2020
PY 2020
AB In statistics, stochastic orders formalize such a concept that one
   random variable is bigger than another. In this paper, we develop a new
   class of discrete bivariate distributions based on a stochastic order
   defined by the likelihood ratio. We derive general formula for the joint
   distributions belonging to the class. It will be seen that, from the
   proposed class, specific families of distributions can be efficiently
   generated just by specifying the 'baseline seed distributions'. An
   important feature of the proposed discrete bivariate model is that,
   unlike other discrete bivariate models already proposed in the
   literature such as the well-known and most popular bivariate Poisson
   distribution by Holgate, it can model both positive and negative
   dependence. A number of new families of discrete bivariate distributions
   are generated from the proposed class. Furthermore, the generated
   bivariate distributions are applied to analyze real data sets and the
   results are compared with those obtained from some conventional models.
Z8 0
ZB 0
ZS 0
ZR 0
TC 0
Z9 0
SN 0932-5026
EI 1613-9798
UT WOS:000531156900001
ER

PT J
AU Shin, D. -H.
   Bohlin, Erik
TI Demystifying big data: Anatomy of big data developmental process.
   Telecommunications Policy 40: 837-854
SO TELECOMMUNICATIONS POLICY
VL 44
IS 5
AR 101928
DI 10.1016/j.telpol.2020.101928
PD JUN 2020
PY 2020
TC 0
ZS 0
Z8 0
ZB 0
ZR 0
Z9 0
SN 0308-5961
EI 1879-3258
UT WOS:000531085700004
ER

PT J
AU Abioye, Emmanuel Abiodun
   Abidin, Mohammad Shukri Zainal
   Mahmud, Mohd Saiful Azimi
   Buyamin, Salinda
   Ishak, Mohamad Hafis Izran
   Abd Rahman, Muhammad Khairie Idham
   Otuoze, Abdulrahaman Okino
   Onotu, Patrick
   Ramli, Muhammad Shahrul Azwan
TI A review on monitoring and advanced control strategies for precision
   irrigation
SO COMPUTERS AND ELECTRONICS IN AGRICULTURE
VL 173
AR 105441
DI 10.1016/j.compag.2020.105441
PD JUN 2020
PY 2020
AB The demand for freshwater is on the increase due to the rapid growth in
   the world's population while the effect of global warming and climate
   change cause severe threat to water use and food security. Consequently,
   irrigation systems are tremendously utilized by many farmers all over
   the world with its associated high amount of water consumption from
   various sources posing a major concern. This necessitates the increased
   focus on improving the efficiency of water usage in irrigation
   agriculture. The advent and rapid successes of the Internet of Things
   (IoT) and advanced control strategies are being leveraged to achieve
   improved monitoring and control of irrigation farming. In this review, a
   thorough search for literature on irrigation monitoring and advanced
   control systems highlighting the research works within the past ten
   years are presented. Attention is paid on recent research works related
   to the monitoring and advance control concepts for precision irrigation.
   It is expected that this review paper will serve as a useful reference
   to enhance reader's knowledge on monitoring and advanced control
   opportunities related to irrigation agriculture as well as assist
   researchers in identifying directions and gaps to future research works
   in this field.
OI ABIOYE, ABIODUN EMMANUEL/0000-0002-9650-0397
TC 0
ZB 0
ZS 0
Z8 0
ZR 0
Z9 0
SN 0168-1699
EI 1872-7107
UT WOS:000531080400054
ER

PT J
AU Godara, Samarth
   Toshniwal, Durga
TI Sequential pattern mining combined multi-criteria decision-making for
   farmers' queries characterization
SO COMPUTERS AND ELECTRONICS IN AGRICULTURE
VL 173
AR 105448
DI 10.1016/j.compag.2020.105448
PD JUN 2020
PY 2020
AB Agricultural policymakers use various types of expert systems to
   identify agricultural problems and to explore their potential solutions.
   However, in the current scenario, there is no robust system that can be
   used to collect and analyze information regarding the problems faced by
   farmers of the developing countries on a large scale. This article
   outlines the possible mechanisms through which information and
   communication technology (ICT) with the use of Knowledge Discovery in
   Databases could facilitate agricultural adoption. The goal of this study
   is to explore data from a farmers' helpline center as a new medium to
   gain hidden insights in terms of association rules regarding the
   problems faced by Indian farmers. The dataset used in this study is
   collected from the "Kisan Call Center", a farmers' helpline center
   managed by the Ministry of Agriculture, Government of India. For this
   objective, we propose a new approach that uses association rule mining
   integrated with a multi-criteria decisionmaking technique, TOPSIS to
   extract only the most relevant patterns from the dataset. Later, we
   perform experiments in order to analyze the output of the proposed
   framework and verify the discovered knowledge against the validation
   data. The best experiment generates a rule-set, consisting of 702
   association rules, including insights from 25 states of India, with an
   average confidence value of 73.21% on the validation data. The extracted
   inference reveals many hidden patterns regarding associations among the
   farmers' issues from the remote states of India. Finally, we identify
   various potential applications of our work and conclude with some
   possible future developments in the proposed approach.
ZR 0
ZB 0
TC 0
ZS 0
Z8 0
Z9 0
SN 0168-1699
EI 1872-7107
UT WOS:000531080400060
ER

PT J
AU Nobrega, Luis
   Goncalves, Pedro
   Antunes, Mario
   Corujo, Daniel
TI Assessing sheep behavior through low-power microcontrollers in smart
   agriculture scenarios
SO COMPUTERS AND ELECTRONICS IN AGRICULTURE
VL 173
AR 105444
DI 10.1016/j.compag.2020.105444
PD JUN 2020
PY 2020
AB Automatic animal monitoring can bring several advantages to the
   livestock sector. The emergence of low-cost and low-power miniaturized
   sensors, together with the ability of handling huge amounts of data, has
   led to a boost of new intelligent farming solutions. One example is the
   SheepIT solution that is being commercialized by iFarmtec. The main
   objectives of the solution are monitoring the sheep's posture while
   grazing in vineyards, and conditioning their behaviour using appropriate
   stimuli, such that they only feed from the ground or from the lower
   branches of the vines. The quality of the monitoring procedure has a
   linear correlation with the animal condition capability of the solution,
   i.e., on the effectiveness of the applied stimuli. Thus, a Real-Time
   mechanism capable of identifying animal behaviour such as infraction,
   eating, walking or running movements and standing position is required.
   On a previous work we proposed a solution based on low-power
   microcontrollers enclosed in collars wearable by sheep. Machine Learning
   techniques have been rising as a useful tool for dealing with big
   amounts of data. From the wide range of techniques available, the use of
   Decision Trees is particularly relevant since it allows the retrieval of
   a set of conditions easily transformed in lightweight machine code.
   The goal of this paper is to evaluate an enhanced animal monitoring
   mechanism and compare it to existing ones. In order to achieve this
   goal, a real deployment scenario was availed to gather relevant data
   from sheep's collar. After this step, we evaluated the impact of several
   feature transformations and pre-processing techniques on the model
   learned from the system. Due to the natural behaviour of sheep, which
   spend most of the time grazing, several pre-processing techniques were
   tested to deal with the unbalanced dataset, particularly resorting on
   features related with stateful history. Albeit presenting promising
   results, with accuracy over 96%, these features resulted in unfeasible
   implementations. Hence, the best feasible model was achieved with 10
   features obtained from the sensors' measurements plus an additional
   temporal feature. The global accuracy attained was above 91%. Howbeit,
   further research shall assess a way of dealing with this kind of
   unbalanced datasets and take advantage of the insights given by the
   results achieved when using the state's history.
ZR 0
ZS 0
Z8 0
ZB 0
TC 0
Z9 0
SN 0168-1699
EI 1872-7107
UT WOS:000531080400057
ER

PT J
AU Miravalle, Michele
TI Problems and Concerns about the Use of Technical Tools in Criminal
   Justice: Towards a Judge as the Mouthpiece of Technology?
SO MATERIALI PER UNA STORIA DELLA CULTURA GIURIDICA
VL 50
IS 1
BP 301
EP 310
DI 10.1436/96635
PD JUN 2020
PY 2020
AB The article carries out a recognition of the debate on the use of
   technical tools in the field of criminal justice such as algorithms,
   Artificial Intelligence, robotic decisions, Big Data and neurocognitive
   data. Moving from the European ethical Charter on the use of Artificial
   Intelligence in judicial systems and their environment, adopted by the
   Council of Europe, the author makes a proposal for classification of
   these tools, based on the diagnostic or prognostic character and on the
   degree of autonomy with respect to human inputs, highlighting the main
   concerns, especially as regards the marginalization of the judicial
   culture.
TC 0
Z8 0
ZB 0
ZR 0
ZS 0
Z9 0
SN 1120-9607
UT WOS:000531070400015
ER

PT J
AU Ma, Chaochao
   Cheng, Xinqi
   Xue, Fang
   Li, Xiaoqi
   Yin, Yicong
   Wu, Jie
   Xia, Liangyu
   Guo, Xiuzhi
   Hu, Yingying
   Qiu, Ling
   Xu, Tengda
TI Validation of an approach using only patient big data from clinical
   laboratories to establish reference intervals for thyroid hormones based
   on data mining.
SO Clinical biochemistry
VL 80
BP 25
EP 30
DI 10.1016/j.clinbiochem.2020.03.012
PD 2020-Jun
PY 2020
AB BACKGROUND: While many studies have established reference intervals
   (RIs) for thyroid hormones using patient data, this approach has not
   been validated. Therefore, in this study, we aimed to validate an
   approach for establishing RIs for thyroid hormones only using patient
   data from clinical laboratories.
   METHODS: We established two derived databases: derived database* and
   derived database#. Reference individuals in derived database* were
   selected using strict exclusion criteria, and the RIs established by the
   database were considered standard RIs (RIs*). Individuals in derived
   database# were the physical examination population, whose information
   was downloaded directly from the Laboratory Information System, and RIs
   established from this database were evaluated (RIs#). The comparative
   confidence interval (CI) method and consistency of the decision results
   based on external databases were used to compare RIs* and RIs#.
   RESULTS: RIs# and RIs* for the thyroid hormones tested were similar. The
   90% CIs of the upper and lower limits of RIs for most thyroid hormones
   overlapped between RIs# and RIs*, and the limit of RIs# was within the
   90% CI of RIs*. The consistency rates for the results of the RIs* and
   RIs# in the external database were greater than 98% for all thyroid
   hormones tested.
   CONCLUSION: It was possible to establish RIs for thyroid hormones using
   only patient data from clinical laboratories after adopting appropriate
   statistical methods.
ZB 0
ZS 0
Z8 0
ZR 0
TC 0
Z9 0
EI 1873-2933
UT MEDLINE:32199936
PM 32199936
ER

PT J
AU Fertier, Audrey
   Barthe-Delanoe, Anne-Marie
   Montarnal, Aurelie
   Truptil, Sebastien
   Benaben, Frederick
TI A new emergency decision support system: the automatic interpretation
   and contextualisation of events to model a crisis situation in real-time
SO DECISION SUPPORT SYSTEMS
VL 133
AR 113260
DI 10.1016/j.dss.2020.113260
PD JUN 2020
PY 2020
AB This paper studies, designs and implements a new type of emergency
   decision support system that aims to improve the decision-making of
   emergency managers in crisis situations by connecting them to new,
   multiple data sources. The system combines event-driven and model-driven
   architectures and is dedicated to crisis cells. After its
   implementation, the system is evaluated using a realistic crisis
   scenario, in terms of its user interfaces, its ability to interpret data
   in real time and its ability to manage the 4Vs of Big Data. The input
   events correspond to traffic measurements, water levels, water flows,
   water predictions and flow predictions made available by French official
   services. The main contributions of this study are: (i) the connection
   between a complex event processing engine and a graph database
   containing the model of the crisis situation and (ii) the continuous
   updating of a common operational picture for the benefit of emergency
   managers. This study could be used as a framework for future research
   works on decision support systems facing complex, evolving situations.
TC 0
ZS 0
Z8 0
ZR 0
ZB 0
Z9 0
SN 0167-9236
EI 1873-5797
UT WOS:000530659200001
ER

PT J
AU Pourhabibi, Tahereh
   Ong, Kok-Leong
   Kam, Booi H.
   Boo, Yee Ling
TI Fraud detection: A systematic literature review of graph-based anomaly
   detection approaches
SO DECISION SUPPORT SYSTEMS
VL 133
AR 113303
DI 10.1016/j.dss.2020.113303
PD JUN 2020
PY 2020
AB Graph-based anomaly detection (GBAD) approaches are among the most
   popular techniques used to analyze connectivity patterns in
   communication networks and identify suspicious behaviors. Given the
   different GBAD approaches proposed for fraud detection, in this study,
   we develop a framework to synthesize the existing literature on the
   application of GBAD methods in fraud detection published between 2007
   and 2018. This study aims to investigate the present trends and identify
   the key challenges that require significant research efforts to increase
   the credibility of the technique. Additionally, we provide some
   recommendations to deal with these challenges.
Z8 0
ZR 0
ZB 0
ZS 0
TC 0
Z9 0
SN 0167-9236
EI 1873-5797
UT WOS:000530659200006
ER

PT J
AU Ma, Jun
   Cheng, Jack C. P.
   Jiang, Feifeng
   Chen, Weiwei
   Wang, Mingzhu
   Zhai, Chong
TI A bi-directional missing data imputation scheme based on LSTM and
   transfer learning for building energy data
SO ENERGY AND BUILDINGS
VL 216
AR UNSP 109941
DI 10.1016/j.enbuild.2020.109941
PD JUN 1 2020
PY 2020
AB Improving the energy efficiency of the buildings is a worldwide hot
   topic nowadays. To assist comprehensive analysis and smart management,
   high-quality historical data records of the energy consumption is one of
   the key bases. However, the energy data records in the real world always
   contain different kinds of problems. The most common problem is missing
   data. It is also one of the most frequently reported data quality
   problems in big data/machine learning/deep learning related literature
   in energy management. However, limited studied have been conducted to
   comprehensively discuss different kinds of missing data situations,
   including random missing, continuous missing, and large proportionally
   missing. Also, the methods used in previous literature often rely on
   linear statistical methods or traditional machine learning methods.
   Limited study has explored the feasibility of advanced deep learning and
   transfer learning techniques in this problem. To this end, this study
   proposed a methodology, namely the hybrid Long Short Term Memory model
   with Bi-directional Imputation and Transfer Learning (LSTM-BIT). It
   integrates the powerful modeling ability of deep learning networks and
   flexible transferability of transfer learning. A case study on the
   electric consumption data of a campus lab building was utilized to test
   the method. Results show that LSTM-BIT outperforms other methods with
   4.24% to 47.15% lower RMSE under different missing rates. (C) 2020
   Elsevier B.V. All rights reserved.
ZS 0
ZB 0
Z8 0
ZR 0
TC 1
Z9 1
SN 0378-7788
EI 1872-6178
UT WOS:000530656800001
ER

PT J
AU Gong, Shengjie
   Mei, Yong
   Amin, Muhammad Yasir
   Zhang, Botao
   Ma, Weimin
TI Orientation effect on heat transfer coefficient of a downward surface
   for flow boiling in a rectangular channel under low flow rate
SO INTERNATIONAL JOURNAL OF HEAT AND MASS TRANSFER
VL 153
AR 119594
DI 10.1016/j.ijheatmasstransfer.2020.119594
PD JUN 2020
PY 2020
AB Natural convection boiling in channel with Arc-Shaped will be
   encountered in the IVR-ERVC (In-Vessel Retention measure by External
   Reactor Vessel Cooling) system in nuclear power plant under severe
   accident. The flow and heat transfer characters in this situation is
   simulated by flow boiling of deionized water in an inclined rectangular
   channel under low flow rates. This paper aims to separate various
   parameters (such as orientation, mass flow rate and inlet quality, etc.)
   to investigate their individual effects on heat transfer coefficient
   (HTC) in a rectangular channel with cross section of 17 mm x 10 mm. By
   using a preheater at the inlet of the rectangular channel, the inlet
   quality could be controlled and the two-phase flow situation could be
   observed before the fluids entering into the main heater region on one
   side of the channel wall in downstream. Thus the characteristics of HTC
   on the main heater could be investigated at different flow patterns. The
   channel orientations vary from 15 to 90 degrees, the mass flow rates
   vary from 110 to 288 kg/(m(2)s) and the qualities vary from 0.003 to
   0.036, respectively. Experimental results show that the mass flow rate
   and quality effects on the HTC are very weak in this study. However, the
   orientation angle effect on HTC shows an transition region within 45
   degrees similar to 60 degrees, while it slowly changes when the
   orientation angle is smaller than 45 degrees and bigger than 60 degrees.
   Such tendency could be well formulated by the error function. Compared
   with different empirical formulas of saturated boiling HTC, it is found
   that the Liu & Winterton correlation can well predict the experimental
   HTC results in 90 degrees orientation channel. Based on such correlation
   and coupled with the error function, a new model was developed by
   considering the orientation effect, which has an error of +/- 15%
   comparing with the experimental data. (C) 2020 Elsevier Ltd. All rights
   reserved.
ZR 0
ZB 0
ZS 0
Z8 0
TC 0
Z9 0
SN 0017-9310
EI 1879-2189
UT WOS:000530718200046
ER

PT J
AU Shen, Yi
   Li, Xiaohu
   Liang, Xiao
   Xu, Hai
   Li, Chuanfu
   Yu, Yongqiang
   Qiu, Bensheng
TI A deep-learning-based approach for adenoid hypertrophy diagnosis.
SO Medical physics
VL 47
IS 5
BP 2171
EP 2181
DI 10.1002/mp.14063
PD 2020-Jun
PY 2020
AB PURPOSE: Adenoid hypertrophy is a pathological hyperplasia of adenoids
   and may cause snoring, apnea, and impede breathing during sleep. In
   clinical practice, radiologists diagnose the severity of adenoid
   hypertrophy by measuring the ratio of adenoid width (A) to
   nasopharyngeal width (N) according to the lateral cephalogram, which
   indicates the locations of four keypoints. The entire diagnostic process
   is tedious and time-consuming due to the acquisition of A and N. Thus,
   there is an urgent need to develop computer-aided diagnostic tools for
   adenoid hypertrophy.
   METHODS: In this paper, we first propose the use of deep learning to
   solve the problem of adenoid hypertrophy classification. Deep learning
   driven by big data has developed greatly in the image processing field.
   However, obtaining a large amount of training data is hard, making the
   application of deep learning to medical images more difficult. This
   paper proposes a keypoint localization method to incorporate more prior
   information to improve the performance of the model under limited data.
   Furthermore, we design a novel regularized term called VerticalLoss to
   capture the vertical relationship between keypoints to provide prior
   information to strengthen the network performance.
   RESULTS: To evaluate the performance of our proposed method, we
   conducted experiments with a clinical dataset from the First Affiliated
   Hospital of Anhui Medical University consisting of a total of 688
   patients. As our results show, we obtained a classification accuracy of
   95.6%, a macro F1-score of 0.957, and an average AN ratio error of
   0.026. Furthermore, we obtained a macro F1-score of 0.89, a
   classification accuracy of 94%, and an average AN ratio error of 0.027
   while using only half of the data for training.
   CONCLUSIONS: The study shows that our proposed method can achieve
   satisfactory results in the task of adenoid hypertrophy classification.
   Our approach incorporates more prior information, which is especially
   important in the field of medical imaging, where it is difficult to
   obtain large amounts of training data.
TC 0
Z8 0
ZR 0
ZS 0
ZB 0
Z9 0
EI 2473-4209
UT MEDLINE:32017124
PM 32017124
ER

PT J
AU Cui, Sunan
   Tseng, Huan-Hsin
   Pakela, Julia
   Ten Haken, Randall K
   El Naqa, Issam
TI Introduction to machine and deep learning for medical physicists.
SO Medical physics
VL 47
IS 5
BP e127
EP e147
DI 10.1002/mp.14140
PD 2020-Jun
PY 2020
AB Recent years have witnessed tremendous growth in the application of
   machine learning (ML) and deep learning (DL) techniques in medical
   physics. Embracing the current big data era, medical physicists equipped
   with these state-of-the-art tools should be able to solve pressing
   problems in modern radiation oncology. Here, a review of the basic
   aspects involved in ML/DL model building, including data processing,
   model training, and validation for medical physics applications is
   presented and discussed. Machine learning can be categorized based on
   the underlying task into supervised learning, unsupervised learning, or
   reinforcement learning; each of these categories has its own
   input/output dataset characteristics and aims to solve different classes
   of problems in medical physics ranging from automation of processes to
   predictive analytics. It is recognized that data size requirements may
   vary depending on the specific medical physics application and the
   nature of the algorithms applied. Data processing, which is a crucial
   step for model stability and precision, should be performed before
   training the model. Deep learning as a subset of ML is able to learn
   multilevel representations from raw input data, eliminating the
   necessity for hand crafted features in classical ML. It can be thought
   of as an extension of the classical linear models but with multilayer
   (deep) structures and nonlinear activation functions. The logic of going
   "deeper" is related to learning complex data structures and its
   realization has been aided by recent advancements in parallel computing
   architectures and the development of more robust optimization methods
   for efficient training of these algorithms. Model validation is an
   essential part of ML/DL model building. Without it, the model being
   developed cannot be easily trusted to generalize to unseen data.
   Whenever applying ML/DL, one should keep in mind, according to Amara's
   law, that humans may tend to overestimate the ability of a technology in
   the short term and underestimate its capability in the long term. To
   establish ML/DL role into standard clinical workflow, models considering
   balance between accuracy and interpretability should be developed.
   Machine learning/DL algorithms have potential in numerous radiation
   oncology applications, including automatizing mundane procedures,
   improving efficiency and safety of auto-contouring, treatment planning,
   quality assurance, motion management, and outcome predictions. Medical
   physicists have been at the frontiers of technology translation into
   medicine and they ought to be prepared to embrace the inevitable role of
   ML/DL in the practice of radiation oncology and lead its clinical
   implementation.
Z8 0
TC 0
ZR 0
ZB 0
ZS 0
Z9 0
EI 2473-4209
UT MEDLINE:32418339
PM 32418339
ER

PT J
AU Wu, Yilan
   Zhang, Jing
TI Building the electronic evidence analysis model based on association
   rule mining and FP-growth algorithm
SO SOFT COMPUTING
VL 24
IS 11
SI SI
BP 7925
EP 7936
DI 10.1007/s00500-019-04032-0
PD JUN 2020
PY 2020
AB In China's criminal procedure law, electronic data is a kind of
   independent evidence. With the development of big data technology, more
   and more attention has been paid to the examination and application of
   electronic evidence in criminal trials. In order to obtain hidden
   knowledge from confused electronic evidence, an electronic evidence
   analysis model based on data mining is proposed. The main research is to
   apply the association rule technology of data mining to the analysis of
   electronic evidence, analyze the shortcomings of the existing
   association rule mining algorithm, and put forward the improved
   algorithm of the existing algorithm and a new idea of the algorithm.
   Based on FP-growth algorithm, an improved algorithm (ISPO-tree
   algorithm) is put forward and the theoretical proof is given. This
   algorithm only needs to browse the database once and adds the function
   of supporting a small amount of modified evidence. This algorithm
   improves the time efficiency of data pre-processing by making similar
   rules to make unequal attribute values equal and can mine more
   association rules under the optimum conditions of support and
   redundancy, and it improves the effectiveness of electronic evidence and
   the accuracy of criminal trial.
Z8 0
ZB 0
ZR 0
TC 1
ZS 0
Z9 1
SN 1432-7643
EI 1433-7479
UT WOS:000530547900008
ER

PT J
AU Yang, Chao-Tung
   Chen, Shuo-Tsung
   Liu, Jung-Chun
   Sun, Pei-Lun
   Yen, Neil Y.
TI On construction of the air pollution monitoring service with a hybrid
   database converter
SO SOFT COMPUTING
VL 24
IS 11
SI SI
BP 7955
EP 7975
DI 10.1007/s00500-019-04079-z
PD JUN 2020
PY 2020
AB Air pollution has a severe impact on human health, pollution harms human
   health, and people start to pay attention to how to use the monitoring
   system in real-time recording for analysis. To maintain smooth
   monitoring and analysis, we have to manage the historical data separated
   from the incoming data. Historical data is used when we need to analyze
   the data, while real-time incoming data is used to visualize the real
   condition. To achieve this objective, we need to collect real-time data
   from environmental protection open data resource. However, the data
   might grow faster and become huge; in this case, the relational database
   was not designed to process a large amount of data. Therefore, we
   require a database technology that can handle massive volume data, that
   is not only Structured Query Language (NoSQL). This method raises an
   important point regarding how to dump the data to NoSQL without change
   relational database (RDB) system. Accordingly, this paper proposed an
   air pollution monitoring system combines Hadoop cluster to dump data
   from RDB to NoSQL and data backup. By this way, it will not only reduce
   the performance of RDB loading but also keep the service status. Dump
   data to NoSQL need to process without affecting the real-time monitoring
   of air pollution monitoring system. In this part, we focus on without
   interruption web service, and it can be up to 60%, through optimizing it
   with dump method and backup data service, MapReduce can restart the
   service and distribute the database when RDB is impairing. Besides that,
   through three different types of conversion mode, we can get the best
   data conversion in our system. Finally, air pollution monitoring service
   provides a variant of air pollution factor as an essential basis of
   environment detection and analysis to serve people living in a more
   comfortable environment.
OI Yang, Chao-Tung/0000-0002-9579-4426
ZR 0
TC 1
ZB 0
Z8 0
ZS 0
Z9 1
SN 1432-7643
EI 1433-7479
UT WOS:000530547900011
ER

PT J
AU Liu, Xixia
TI Application of cloud-based visual communication design in Internet of
   Things image
SO SOFT COMPUTING
VL 24
IS 11
SI SI
BP 8041
EP 8050
DI 10.1007/s00500-019-04111-2
PD JUN 2020
PY 2020
AB In order to apply cloud computing to study visual communication design,
   high-resolution remote sensing image features and applications were
   analyzed. A high-resolution remote sensing image storage model in the
   cloud computing environment was designed. Afterward, deep analysis and
   comparison were made toward the current mainstream cloud platform. Based
   on the characteristics of high-resolution remote sensing images, the key
   technologies in the design of high-resolution remote sensing image
   storage model in cloud computing environment were discussed. The results
   showed that the integration of cloud platform Hadoop and virtualization
   management cloud platform provided corresponding transparent use of
   distributed computing resources for different remote sensing image
   applications. Therefore, this method provides a new way for other
   industries to apply cloud computing environments.
Z8 0
ZR 0
ZB 0
ZS 0
TC 1
Z9 1
SN 1432-7643
EI 1433-7479
UT WOS:000530547900017
ER

PT J
AU Huang, Mu-Jung
   Sung, Hsiu-Shu
   Hsieh, Tsu-Jen
   Wu, Ming-Cheng
   Chung, Shao-Hsi
TI Applying data-mining techniques for discovering association rules
SO SOFT COMPUTING
VL 24
IS 11
SI SI
BP 8069
EP 8075
DI 10.1007/s00500-019-04163-4
PD JUN 2020
PY 2020
AB Data mining has become a hot research topic, and how to mine valuable
   knowledge from such huge volumes of data remains an open problem.
   Processing huge volumes of data presents a challenge to existing
   computation software and hardware. This study proposes a model using
   association rule mining (ARM) which is a kind of data-mining technique
   for discovering association rules of chronic diseases from the enormous
   data that are collected continuously through health examination and
   medical treatment. This study makes three critical contributions: (1) It
   suggests a systematical model of exploring huge volumes of data using
   ARM, (2) it shows that helpful implicit rules are discovered through
   data-mining techniques, and (3) the results proved that the proposed
   model can act as an expert system for discovering useful knowledge from
   huge volumes of data for the references of doctors and patients to the
   specific chronic diseases prognosis and treatments.
ZS 0
Z8 0
ZR 0
TC 1
ZB 0
Z9 1
SN 1432-7643
EI 1433-7479
UT WOS:000530547900020
ER

PT J
AU Wu, Haotian
   Li, Guangan
TI Visual communication design elements of Internet of Things based on
   cloud computing applied in graffiti art schema
SO SOFT COMPUTING
VL 24
IS 11
SI SI
BP 8077
EP 8086
DI 10.1007/s00500-019-04171-4
PD JUN 2020
PY 2020
AB In order to create more attractive graffiti works, the Internet of
   Things technology is used to collect people's preference information
   data, and then cloud computing and big data analysis are applied to
   calculate and analyze the data, so as to get more design elements in
   line with people's preferences, providing more material for the creators
   of graffiti art and facilitating their further creation of graffiti. In
   recent years, graffiti art, as a kind of postmodern marginal cultural
   art, has great expressiveness and creativity, which makes graffiti art
   widely used. Particularly in visual communication design, graffiti art
   has more characteristics and is deeply loved by the people. With the
   continuous development of science and technology, Internet of Things
   technology and cloud computing have acquired more information for many
   fields, thus assisting the field to complete deeper analysis and
   research. However, there are few applications in the field of graffiti
   art. Therefore, this paper combines cloud computing and Internet of
   Things to obtain more visual communication design elements to provide
   material for the creator, which is conductive for their continuing
   creation.
ZS 0
TC 1
ZR 0
ZB 0
Z8 0
Z9 1
SN 1432-7643
EI 1433-7479
UT WOS:000530547900021
ER

PT J
AU Zhang, Wenjuan
   Huang, Yingping
TI Using big data computing framework and parallelized PSO algorithm to
   construct the reservoir dispatching rule optimization
SO SOFT COMPUTING
VL 24
IS 11
SI SI
BP 8113
EP 8124
DI 10.1007/s00500-019-04188-9
PD JUN 2020
PY 2020
AB The paper aims to study how to realize the rational allocation and
   efficient utilization of water resources among reservoirs and coordinate
   the balanced optimization of benefit among dispatching objectives under
   the premise of ensuring flood control safety. A multi-objective optimal
   dispatching system for reservoirs in Jinsha River basin based on the
   Spark big data computing framework and parallelized particle swarm
   optimization (PSO) is proposed. The characteristics of multiple
   objectives of water resources optimal dispatching system in Jinsha River
   basin are analyzed. The multiple objectives have been transformed into
   single objectives, and the solving model of the problem is obtained.
   Secondly, the parallel algorithm programming model, the PSO algorithm
   and its parallel strategy for solving optimization problems, and the
   parallel method of PSO based on Spark big data computing framework are
   studied. The results show that the research work provides a scientific
   theoretical basis and a feasible optimization method for the management
   and dispatch of cascade hydropower stations. Therefore, this study plays
   a decisive role in promoting the efficient operation of water resources
   optimal dispatching system and has good reference value for the
   development and application of big data parallel programming based on
   Spark platform.
ZR 0
ZS 0
ZB 0
TC 1
Z8 0
Z9 1
SN 1432-7643
EI 1433-7479
UT WOS:000530547900024
ER

PT J
AU Gao, Suwei
   Zhou, Changchun
TI Differential privacy data publishing in the big data platform of precise
   poverty alleviation
SO SOFT COMPUTING
VL 24
IS 11
SI SI
BP 8139
EP 8147
DI 10.1007/s00500-019-04352-1
PD JUN 2020
PY 2020
AB In order to study the application of differential privacy data release
   for the data platform of precise poverty alleviation (PPA), in this
   study, the data was protected by using differential privacy protection
   algorithm, and combined with artificial neural network to construct the
   algorithm model. And then based on MATLAB simulation experiment, the
   operation effect of the simulation model was verified through multiple
   angles. From the relationship between budget and coefficient, it can be
   concluded that compared with extraction procedure and noprivacy by
   statistical test, the algorithm proposed in this study was found to be
   more practical, and the result was close to the original data, and the
   effect was better; the error rate was also the lowest, not higher than
   0.075. Comparing the accuracy of the algorithm with other algorithms,
   the result showed that other methods made the precision lower, but the
   function mechanism designed in this study did not; from the perspective
   of time, it is found that the time consumption of algorithm designed in
   this study was greatly reduced compared with other methods. Through the
   research in this paper, the model designed by combining artificial
   neural network and differential privacy achieved the expected effect.
   Although there are some shortcomings in the experimental process, in
   general, it can provide direction and guidance for the subsequent PPA
   work, and its social development has important guiding significance.
ZR 0
TC 1
ZB 0
ZS 0
Z8 0
Z9 1
SN 1432-7643
EI 1433-7479
UT WOS:000530547900026
ER

PT J
AU Wang, Weihong
   Lu, Chang
TI Visualization analysis of big data research based on Citespace
SO SOFT COMPUTING
VL 24
IS 11
SI SI
BP 8173
EP 8186
DI 10.1007/s00500-019-04384-7
PD JUN 2020
PY 2020
AB In recent years, with the massive growth of data, the world today has
   entered the era of big data. Big data has brought tremendous value to
   all fields of today's society, and it has also brought enormous
   challenges, which has attracted great attention from all walks of life.
   Analyze and forecast the research hotspots and future development trends
   in the field of big data, and understand the development changes and
   priorities in the field of big data research, which will play a
   significant role in promoting the development of social development and
   scientific research. In the era of big data, how to extract information
   from huge amounts of complex data and present complex information more
   clearly and clearly, the most effective way is to use visualization
   technology. The article uses the information visualization software
   Citespace to study the data related to big data in the Web of Science
   and CNKI database from 2008 to 2017 for 10 years, from macro to micro to
   the representative countries of the literature, keywords and co-cited
   documents. Through visualization analysis, the article clarifies the key
   research directions, key documents and hot spot frontiers in the field
   of big data research, forecasts the future development trends in this
   field, and compares the research situation at home and abroad, in order
   to provide readers and other researchers with certain reference and
   help.
Z8 0
ZR 0
TC 1
ZB 0
ZS 0
Z9 1
SN 1432-7643
EI 1433-7479
UT WOS:000530547900029
ER

PT J
AU Chen, Liang-Chu
   Lee, Chia-Meng
   Chen, Mu-Yen
TI Exploration of social media for sentiment analysis using deep learning
SO SOFT COMPUTING
VL 24
IS 11
SI SI
BP 8187
EP 8197
DI 10.1007/s00500-019-04402-8
PD JUN 2020
PY 2020
AB With the rapid growth of web content from social media, such studies as
   online opinion mining or sentiment analysis of text have started
   receiving attention from government, industry, and academic sectors. In
   recent years, sentiment analysis has not only emerged under knowledge
   fusion in the big data era, but has also become a popular research topic
   in the area of artificial intelligence and machine learning. This study
   used the Militarylife PTT board of Taiwan's largest online forum as the
   source of its experimental data. The purpose of this study was to
   construct a sentiment analysis framework and processes for social media
   in order to propose a self-developed military sentiment dictionary for
   improving sentiment classification and analyze the performance of
   different deep learning models with various parameter calibration
   combinations. The experimental results show that the accuracy and
   F1-measure of the model that combines existing sentiment dictionaries
   and the self-developed military sentiment dictionary are better than the
   results from using existing sentiment dictionaries only. Furthermore,
   the prediction model trained using the activation function, Tanh, and
   when the number of Bi-LSTM network layers is two, the accuracy and
   F1-measure have an even better performance for sentiment classification.
TC 2
Z8 0
ZR 0
ZS 0
ZB 0
Z9 2
SN 1432-7643
EI 1433-7479
UT WOS:000530547900030
ER

PT J
AU Chen, Yue
   Yang, Jianqiang
TI Historic Neighborhood Design Based on Facility Heatmap and Pedestrian
   Simulation: Case Study in China
SO JOURNAL OF URBAN PLANNING AND DEVELOPMENT
VL 146
IS 2
AR 04020001
DI 10.1061/(ASCE)UP.1943-5444.0000554
PD JUN 1 2020
PY 2020
AB With the rapid growth of tourism in China, the spatial conflict between
   tourists and the host community has become a major issue in historic
   neighborhood design. This study employed big data and pedestrian
   simulation technologies in the improvement design of Pingjiang Historic
   Quarter. Multisource big data including the cell phone signal data of
   WeChat (social media application), point of interest (POI) data, and
   field survey statistics have been processed in geographic information
   systems (GIS), statistical product and service solutions (SPSS), and the
   simulation software AnyLogic to diagnose the current facility shortage
   and traffic problems in the study area, and to calculate and test the
   key parameters for the simulation modeling of alternative schemes with
   emphasis on facility location and pedestrian traffic. Results showed
   that a more centralized layout of new tourist attractions on the
   northwestern portion of the vacant land to be developed could reduce the
   through traffic of tourists in residential zones, and the joint
   development of urban mass transit and the new Visitor Center in the
   southeastern portion could alleviate current traffic congestion.
ZR 0
Z8 0
TC 0
ZS 0
ZB 0
Z9 0
SN 0733-9488
EI 1943-5444
UT WOS:000530381600014
ER

PT J
AU Lai, Jianbo
   Pan, Jinghu
TI China's City Network Structural Characteristics Based on Population Flow
   during Spring Festival Travel Rush: Empirical Analysis of "Tencent
   Migration" Big Data
SO JOURNAL OF URBAN PLANNING AND DEVELOPMENT
VL 146
IS 2
AR 04020018
DI 10.1061/(ASCE)UP.1943-5444.0000581
PD JUN 1 2020
PY 2020
AB With the advent of the Internet era, network data have become an
   important carrier characterizing residents' geography behavior. Tencent
   Migration big data can fully, dynamically, immediately, and visually
   record a population migration trajectory with location-based service
   (LBS) technology. Through the Tencent Migration data platform, data on
   daily population floating among 346 cities in China during the 2018
   Spring Festival travel rush (SFTR) are obtained. The characteristics and
   spatial pattern of population flow among cities are analyzed from the
   perspectives of the population flow distribution level, hierarchical
   aggregation of the distributed network system, population flow spatial
   patterns, and network characteristics. Three-hundred forty-six cities
   were divided into nine communities. The results are as follows: the net
   inflow routes of the population in the three periods all show a
   diamond-shaped skeleton supported by a cross-shaped one. The population
   distribution centers are mainly concentrated in the four major urban
   agglomerations. The clear hierarchical structure and level distinction
   of population distribution centers can be identified, and there is a
   positive correlation between the level of city administrative and the
   influence of population floating. Population flows of most cities are in
   a relatively balanced state. The degree of urban network nodes is the
   power-law distribution, so the network is scale free, and the network
   has small-world characteristic. It provides a new perspective for the
   study of population mobility and urban network.
ZB 0
Z8 0
ZR 0
TC 0
ZS 0
Z9 0
SN 0733-9488
EI 1943-5444
UT WOS:000530381600020
ER

PT J
AU Niu, Haifeng
   Silva, Elisabete A.
TI Crowdsourced Data Mining for Urban Activity: Review of Data Sources,
   Applications, and Methods
SO JOURNAL OF URBAN PLANNING AND DEVELOPMENT
VL 146
IS 2
AR 04020007
DI 10.1061/(ASCE)UP.1943-5444.0000566
PD JUN 1 2020
PY 2020
AB The penetration of devices integrated with location-based services and
   internet services has generated massive data about the everyday life of
   citizens and tracked their activities happening in cities. Crowdsourced
   data, such as social media data, points of interest (POIs) data, and
   collaborative websites, generated by the crowd, have become fine-grained
   proxy data of urban activity and widely used in research in urban
   studies. However, due to the heterogeneity of data types of crowdsourced
   data and the limitation of previous studies mainly focusing on a
   specific application, a systematic review of crowdsourced data mining
   for urban activity is still lacking. In order to fill the gap, this
   paper conducts a literature search in the Web of Science database,
   selecting 226 highly related papers published between 2013 and 2019.
   Based on these papers, the review first conducts a bibliometric analysis
   identifying underpinning domains, pivot scholars, and papers around this
   topic. The review also synthesizes previous research into three parts:
   main applications of different data sources and data fusion; application
   of spatial analysis in mobility patterns, functional areas, and event
   detection; and application of sociodemographic and perception analysis
   in city attractiveness, demographic characteristics, and sentiment
   analysis. The challenges of this type of data are also discussed in the
   end. This study provides a systematic and current review for both
   researchers and practitioners interested in the applications of
   crowdsourced data mining for urban activity.
ZR 0
TC 0
Z8 0
ZB 0
ZS 0
Z9 0
SN 0733-9488
EI 1943-5444
UT WOS:000530381600001
ER

PT J
AU Poplin, Alenka
TI Big Data and Occupants' Behavior in Built Environments: Introducing a
   Game-Based Data Collection Method
SO JOURNAL OF URBAN PLANNING AND DEVELOPMENT
VL 146
IS 2
AR 04020003
DI 10.1061/(ASCE)UP.1943-5444.0000552
PD JUN 1 2020
PY 2020
AB Energy-related human behavior in buildings is difficult to define and
   quantify, yet critical to our understanding of total building energy
   consumption. It substantially influences energy consumption and saving.
   In the United States, residential and commercial buildings account for
   more than 70% of the total electrical energy consumed in the country.
   This paper explores the implementation of an online energy game,
   e-footprints, which aims to collect data about occupants' energy
   consumption and saving, and summarizes the feedback related to the first
   prototype of the user interface. The game was tested with 110
   international students. The study focuses on the visualization,
   aesthetics, and usability of the e-footprints energy game, as these are
   the important elements of a player's interaction with the user interface
   and greatly influence the game play and the data that can be gathered.
   The paper concludes with a summary of the findings and general
   recommendations that may be useful for others using serious online urban
   planning games.
Z8 0
TC 0
ZS 0
ZB 0
ZR 0
Z9 0
SN 0733-9488
EI 1943-5444
UT WOS:000530381600011
ER

PT J
AU Kong, Weichang
   Qiao, Fei
   Wu, Qidi
TI Real-manufacturing-oriented big data analysis and data value evaluation
   with domain knowledge
SO COMPUTATIONAL STATISTICS
VL 35
IS 2
SI SI
BP 515
EP 538
DI 10.1007/s00180-019-00919-6
PD JUN 2020
PY 2020
AB As one of the most popular topics currently, big data has played an
   important role in both academic research and practical applications.
   However, in the manufacturing industry, it is difficult to make full use
   of the research results for production optimization and/or management
   due to the low quality of real workshop data. Typical quality problems
   of real workshop data include the information match degree, missing
   recessive data, and false error identification. The conventional data
   analysis methods cannot handle most such issues because these methods
   fail to consider professional insights into and domain knowledge about
   the data. The main motivation of this paper is to explore methods for
   analyzing and evaluating big data with domain knowledge. For this
   purpose, real production data from a semiconductor manufacturing
   workshop are adopted as the data object. First, a series of data
   analysis techniques with domain knowledge are developed for diagnosing
   the imperfections. Then, corresponding data processing techniques with
   domain knowledge are proposed for solving those data quality problems
   according to specific flaws in the data. Furthermore, this paper
   proposes quantitative calculation methods of data value density to
   determine the extent to which data quality can be improved by the
   proposed data processing techniques. Case studies are conducted to
   demonstrate that data analysis and processing techniques with domain
   knowledge can effectively handle data quality problems of real workshop
   data in terms of the information match degree, missing recessive data,
   and false error identification. The work in this paper has the potential
   to be further extended and applied to other big data applications beyond
   the manufacturing industry.
ZR 0
ZB 0
TC 1
ZS 0
Z8 0
Z9 1
SN 0943-4062
EI 1613-9658
UT WOS:000529695200005
ER

PT J
AU Smallman, Luke
   Underwood, William
   Artemiou, Andreas
TI Simple Poisson PCA: an algorithm for (sparse) feature extraction with
   simultaneous dimension determination
SO COMPUTATIONAL STATISTICS
VL 35
IS 2
SI SI
BP 559
EP 577
DI 10.1007/s00180-019-00903-0
PD JUN 2020
PY 2020
AB Dimension reduction tools offer a popular approach to analysis of
   high-dimensional big data. In this paper, we propose an algorithm for
   sparse Principal Component Analysis for non-Gaussian data. Since our
   interest for the algorithm stems from applications in text data analysis
   we focus on the Poisson distribution which has been used extensively in
   analysing text data. In addition to sparsity our algorithm is able to
   effectively determine the desired number of principal components in the
   model (order determination). The good performance of our proposal is
   demonstrated with both synthetic and real data examples.
OI Underwood, William/0000-0003-4604-1548
ZR 0
Z8 0
ZS 0
TC 0
ZB 0
Z9 0
SN 0943-4062
EI 1613-9658
UT WOS:000529695200007
ER

PT J
AU Faisal Munir, Rana
   Abello, Alberto
   Romero, Oscar
   Thiele, Maik
   Lehner, Wolfgang
TI A cost-based storage format selector for materialized results in big
   data frameworks
SO DISTRIBUTED AND PARALLEL DATABASES
VL 38
IS 2
BP 335
EP 364
DI 10.1007/s10619-019-07271-0
PD JUN 2020
PY 2020
AB Modern big data frameworks (such as Hadoop and Spark) allow multiple
   users to do large-scale analysis simultaneously, by deploying
   data-intensive workflows (DIWs). These DIWs of different users share
   many common tasks (i.e, 50-80%), which can be materialized and reused in
   future executions. Materializing the output of such common tasks
   improves the overall processing time of DIWs and also saves
   computational resources. Current solutions for materialization store
   data on Distributed File Systems by using a fixed storage format.
   However, a fixed choice is not the optimal one for every situation.
   Specifically, different layouts (i.e., horizontal, vertical or hybrid)
   have a huge impact on execution, according to the access patterns of the
   subsequent operations. In this paper, we present a cost-based approach
   that helps deciding the most appropriate storage format in every
   situation. A generic cost-based framework that selects the best format
   by considering the three main layouts is presented. Then, we use our
   framework to instantiate cost models for specific Hadoop storage formats
   (namely SequenceFile, Avro and Parquet), and test it with two standard
   benchmark suits. Our solution gives on average 1.33x speedup over fixed
   SequenceFile, 1.11x speedup over fixed Avro, 1.32x speedup over fixed
   Parquet, and overall, it provides 1.25x speedup.
Z8 0
ZR 0
ZS 0
TC 0
ZB 0
Z9 0
SN 0926-8782
EI 1573-7578
UT WOS:000528587100003
ER

PT J
AU Nidzwetzki, Jan Kristof
   Gueting, Ralf Hartmut
TI BBoxDB: a distributed and highly available key-bounding-box-value store
SO DISTRIBUTED AND PARALLEL DATABASES
VL 38
IS 2
BP 439
EP 493
DI 10.1007/s10619-019-07275-w
PD JUN 2020
PY 2020
AB BBoxDB is a distributed and highly available key-bounding-box-value
   store, which is designed to handle multi-dimensional big data. To handle
   large amounts of data, the software splits the stored data into
   multi-dimensional shards and spreads them across a cluster of nodes.
   Unlike existing key-value stores, BBoxDB stores each value together with
   an n-dimensional, axis parallel bounding box. The bounding box describes
   the spatial location of the value in an n-dimensional space.
   Multi-dimensional data can be retrieved by using range queries, which
   are efficiently supported by indices. A space partitioner (e.g., a K-D
   Tree, a Quad-Tree or a Grid) is used to split the n-dimensional space
   into disjoint regions (distribution regions). Distribution regions are
   created dynamically, based on the stored data. BBoxDB can handle growing
   and shrinking datasets. The data redistribution is performed in the
   background and does not affect the availability of the system; read and
   write access is still possible at any time. BBoxDB works with
   distribution groups, the data of all tables in a distribution group are
   distributed in the same way (co-partitioned). Spatial joins on
   co-partitioned tables can be executed efficiently without data shuffling
   between nodes. BBoxDB supports spatial joins out-of-the-box using the
   bounding boxes of the stored data. The joins are supported by a spatial
   index and executed in a distributed and parallel manner on the nodes of
   the cluster.
ZR 0
TC 0
Z8 0
ZB 0
ZS 0
Z9 0
SN 0926-8782
EI 1573-7578
UT WOS:000528587100006
ER

PT J
AU El-Kenawy, El-Sayed
   Eid, Marwa
TI HYBRID GRAY WOLF AND PARTICLE SWARM OPTIMIZATION FOR FEATURE SELECTION
SO INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL
VL 16
IS 3
BP 831
EP 844
DI 10.24507/ijicic.16.03.831
PD JUN 2020
PY 2020
AB The big data comprises a relatively developing area of study which is
   due to numerous facts gathered daily and the wishes to be helpful
   information for use in our day by day life. One of the most crucial
   pre-processing of data is the feature selection. This paper proposes a
   hybrid technique that combines two algorithms namely Gray Wolf
   Optimization (GWO) and Particle Swarm Optimization (PSO), the manner
   that lets in the critical functions to be recognized and lets the
   insignificant ones and the complexity to be erased. This enables the
   obligations of the gadget learning classification while making use of
   training to the classifier with the data set. A hybrid approach is
   primarily based on metaheuristics swarm intelligence algorithms, which
   simulate the gray wolf's management and hunting manner in nature and PSO
   which people are moving impacted by their local best positions and by
   the global best position. This hybridization is to acquire the balance
   between exploitation and exploration. We used seventeen datasets from
   UCI machine gaining knowledge of repository within the experiments and
   comparisons results to assess the effectiveness and quality of the
   GWOPSO.
ZS 0
TC 0
ZB 0
Z8 0
ZR 0
Z9 0
SN 1349-4198
EI 1349-418X
UT WOS:000530038000004
ER

PT J
AU Yuan, Wei
   Liu, Yao
   Huang, Yi
   Xie, Ruoyun
TI MAIN TECHNIQUES OF POLICY EVALUATION AND DECISION-MAKING ANALYSIS
   PLATFORM
SO INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL
VL 16
IS 3
BP 1101
EP 1108
DI 10.24507/ijicic.16.03.1101
PD JUN 2020
PY 2020
AB The policy text refers to documents produced in policy activities, and
   has always been important tools or carriers for policy evaluation. The
   traditional way to analyze policy texts mainly relies on people to read
   and compile valuable information. This method is of low
   informationization, efficiency and timeliness, and it is impossible to
   track valuable information in real time. In this article, network
   embedding, PMI-Entropy and other technologies are used to modify the
   performance of a Policy Evaluation and Decision-Making Analysis
   Platform; thus decisions can be evaluated and made more conveniently and
   precisely in the big data environment.
ZB 0
TC 0
ZR 0
ZS 0
Z8 0
Z9 0
SN 1349-4198
EI 1349-418X
UT WOS:000530038000021
ER

PT J
AU Lee, Ha Na
   Song, B. K.
TI The cost of presidential impeachment to politically connected firms
SO JAPANESE JOURNAL OF POLITICAL SCIENCE
VL 21
IS 2
BP 109
EP 121
AR PII S1468109919000173
DI 10.1017/S1468109919000173
PD JUN 2020
PY 2020
AB This study examines the ways political events can affect the stock
   prices of politically connected firms by studying one of the biggest
   corruption scandals in modern South Korean history, which led to the
   first-ever impeachment of a sitting president. We analyzed the stock
   returns of firms that donated money to foundations allegedly controlled
   by the president's confidante. We found that the abnormal stock returns
   of politically connected firms decreased when the president was removed
   from office. Using tick-by-tick stock price data, we were able to
   pinpoint the exact moments when the stock prices of firms that donated
   money fluctuated, as the president's fate was determined by the justices
   of the Constitutional Court.
TC 0
ZR 0
Z8 0
ZB 0
ZS 0
Z9 0
SN 1468-1099
EI 1474-0060
UT WOS:000529544300004
ER

PT J
AU Rudert, Selma C.
   Keller, Matthias D.
   Hales, Andrew H.
   Walker, Mirella
   Greifeneder, Rainer
TI Who Gets Ostracized? A Personality Perspective on Risk and Protective
   Factors of Ostracism
SO JOURNAL OF PERSONALITY AND SOCIAL PSYCHOLOGY
VL 118
IS 6
BP 1247
EP 1268
DI 10.1037/pspp0000271
PD JUN 2020
PY 2020
AB Ostracism, excluding and ignoring others, results from a variety of
   factors. Here, we investigate the effect of personality on the
   likelihood of becoming a target of ostracism. Theorizing that
   individuals low in conscientiousness or agreeableness are at risk of
   getting ostracized, we tested our hypotheses within 5 preregistered
   studies: Four experiments investigating participants' willingness to
   ostracize targets characterized by different personality traits and a
   reverse correlation face modeling study where we determined and
   subsequently validated the stereotypical face of an ostracized person. A
   survey study within a representative German data panel further
   corroborated our findings. In line with our hypotheses, persons low in
   conscientiousness or agreeableness provoke more ostracism intentions
   (Studies 1, 2, and 4), are more likely to be actually ostracized by
   others (Study 3), represent the stereotype of an "ostracizable" person
   (Study 5), and report experiencing more ostracism (Study 6). Effects
   remained stable even after controlling for likability of the target
   (Study 2 and 4). Moreover, being described as negative on 1 personality
   dimension could not be compensated by being described as positive on the
   other (Study 4). In exploratory analyses, we further investigated the
   effects of openness to experience, neuroticism, and extraversion. In
   sum, we find evidence that personality affects the likelihood of
   becoming a target of ostracism, and that especially low agreeableness
   and conscientiousness represent risk factors.
RI Rudert, Selma/L-2209-2016
OI Rudert, Selma/0000-0001-5986-2447
ZB 0
TC 0
Z8 0
ZS 0
ZR 0
Z9 0
SN 0022-3514
EI 1939-1315
UT WOS:000529372000008
PM 31599628
ER

PT J
AU Chen, Si
   Shan, Liran Christine
   Tao, Wanting
   Lu, Ting
   Regan, Aine
   Han, Hongwei
   Guo, Lixia
   Deng, Taotao
   Wall, Patrick
TI A survey of Chinese consumers' knowledge, beliefs and behavioural
   intentions regarding salt intake and salt reduction
SO PUBLIC HEALTH NUTRITION
VL 23
IS 8
BP 1450
EP 1459
AR PII S1368980019003689
DI 10.1017/S1368980019003689
PD JUN 2020
PY 2020
AB Objective: Globally, China is among the 'saltiest' nations. In order to
   support current nationwide salt reduction initiatives, we investigated
   Chinese consumers' knowledge, beliefs and behaviours related to salt
   intake and salt reduction. Design: A cross-sectional face-to-face survey
   was carried out, focusing on salt knowledge, beliefs and behaviours
   related to salt intake and salt reduction, perceptions of salt reduction
   responsibility and support for different national strategies. Setting:
   The survey was carried out in China mainland. Participants: Consumers (n
   2444) from six of seven major geographical regions in China participated
   in the survey. After data cleaning, a sample of 2430 was included in the
   final analysis. Results: A majority of Chinese consumers believed that
   salt added during home cooking was the biggest contributor to their salt
   intake. Knowledge gaps existed in the awareness of salt hidden in
   certain foods and flavouring products. Chinese consumers in general were
   interested in lowering their salt intake. They were aware of salt
   reduction tools, but the adoption level was low. Consumers expressed
   strong support for promotion of salt-restriction spoons and public
   education, but not fiscal policies (e.g. salt-related tax or subsidies).
   In terms of individual differences, education status demonstrated a
   substantial impact on salt reduction knowledge and behaviour.
   Conclusions: There is still big room to 'shake' Chinese consumers' salt
   habit. The present study provides important evidence and consumer
   insights to support China's efforts to meet its salt reduction targets.
ZB 0
Z8 0
ZR 0
TC 0
ZS 0
Z9 0
SN 1368-9800
EI 1475-2727
UT WOS:000529702400016
PM 31928552
ER

PT J
AU Mahajan, Varun
   Nauriyal, D. K.
   Singh, S. P.
TI Domestic market competitiveness of Indian drug and pharmaceutical
   industry
SO REVIEW OF MANAGERIAL SCIENCE
VL 14
IS 3
BP 519
EP 559
DI 10.1007/s11846-018-0299-7
PD JUN 2020
PY 2020
AB This paper attempts to analyse the competitiveness of Indian drug and
   pharmaceutical industry in the domestic market where multinational
   pharma companies are entering and expanding in a big way, especially
   after enforcement of product patent regime in 2005. The study applied
   data envelopment analysis model to estimate relative efficiency and
   productivity changes in 141 Indian pharmaceutical firms during 2000-2001
   to 2012-2013 which encompass pre- and post-product patent regimes. The
   present study found negative impact of Product Patent Act on the
   efficiency scores. The technological change factor is found to have
   played positive role in the growth of productivity, whereas technical
   efficiency change depicts the judicious utilization of input resources
   for improving performance. A sensitivity analysis with the inclusion of
   R&D expenditure in input variables, confirmed the validity of our
   selected variables. It found marginal bearing of new patent regime on
   the efficiency of R&D active firms, though it was found to have
   significantly impacted efficiency scores of large firms, R&D intensive
   firms, and group-owned firms. The study reported that large size, R&D
   intensive, private-foreign owned and those engaged in drug formulations
   exhibit better performance. Further, it is found that ownership, capital
   imports intensity and size have a positive and significant relationship
   with efficiency scores, whereas the age, time dummy and size square
   variables are inversely related. The results suggest that Indian firms
   need substantive improvements in efficiency by adopting best managerial
   practices, ensuring optimum utilization of resources, and investing
   significantly in the technology and products innovation.
Z8 0
ZB 0
ZS 0
TC 1
ZR 0
Z9 1
SN 1863-6683
EI 1863-6691
UT WOS:000529687100003
ER

PT J
AU Ball, Kirstie
   Canhoto, Ana
   Daniel, Elizabeth
   Dibb, Sally
   Meadows, Maureen
   Spiller, Keith
TI Organizational tensions arising from mandatory data exchange between the
   private and public sector: The case of financial services
SO TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE
VL 155
AR UNSP 119996
DI 10.1016/j.techfore.2020.119996
PD JUN 2020
PY 2020
AB This paper examines the organizational tensions arising from mandatory
   data exchange initiatives between private and public organizations. The
   focus is the UK financial services sector, which is required to monitor
   and report on customer identities and transactions under the country's
   Anti-Money Laundering/Counter-Terrorist Finance (AML/CTF) regulations.
   The transferred data are generated from existing organizational
   activities, systems, processes and working patterns; we examine how
   government demands for such data affect commercial priorities, customer
   relationships and working patterns in the sector. We adopt an
   exploratory approach to investigate this phenomenon, consisting of 16
   in-depth interviews, analysis of documents and two case studies. Three
   contributions are made. First, we use remediation theory to show that
   existing organizational arrangements are reconfigured at multiple
   analytical levels, creating tensions between the organizations'
   commercial and compliance roles. Second, we establish the information
   flow as an appropriate unit of analysis in the study of data exchange
   mechanisms and reveal the flows that characterise AML/CTF compliance for
   financial services organizations. Finally, we adopt a 'set theoretic'
   perspective on multi-level organizational research, to argue that the
   multi-level effects of this regulation can be examined in parallel.
OI Meadows, Maureen/0000-0001-7777-7756
Z8 0
ZR 0
TC 0
ZB 0
ZS 0
Z9 0
SN 0040-1625
EI 1873-5509
UT WOS:000528313800039
ER

PT J
AU Elia, Gianluca
   Petruzzelli, Antonio Messeni
   Urbinati, Andrea
TI Implementing open innovation through virtual brand communities: A case
   study analysis in the semiconductor industry
SO TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE
VL 155
AR UNSP 119994
DI 10.1016/j.techfore.2020.119994
PD JUN 2020
PY 2020
AB The paper focuses on virtual brand community (VBC) as new management
   tool for open innovation. Existing research on the intersection between
   brand communities and innovation management shows how the knowledge of
   the brand communities' members and their engagement in product-related
   discussions represent a relevant source of innovation for the companies.
   However, how do companies implement open innovation through the VBC and
   how do they implement purposeful practices represent an unexplored
   research area. By adopting a value-oriented perspective of open
   innovation, this study interprets the VBC as a co-creation space where
   undertaking opportunity identification and resource mobilization for
   value creation and value capture. The paper presents a single case study
   of a multinational company operating in the semiconductor industry that
   has recently implemented a VBC as a tool for peer-to-peer support and
   knowledge sharing. Results show the features of this VBC and the set of
   practices designed to realize the open innovation strategies. By
   adopting an open innovation perspective, the article presents a model of
   VBC as a collaborative space for innovation. For practitioners, the
   article provides evidences and insights about the use of VBC to support
   the implementation of open innovation strategies.
ZS 0
TC 0
ZR 0
ZB 0
Z8 0
Z9 0
SN 0040-1625
EI 1873-5509
UT WOS:000528313800033
ER

PT J
AU Geissinger, Andrea
   Laurell, Christofer
   Sandstrom, Christian
TI Digital Disruption beyond Uber and Airbnb-Tracking the long tail of the
   sharing economy
SO TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE
VL 155
AR UNSP 119323
DI 10.1016/j.techfore.2018.06.012
PD JUN 2020
PY 2020
AB The sharing economy can be regarded as a discontinuous innovation that
   creates increased abundance throughout society. Extant literature on the
   sharing economy has been predominantly concerned with Uber and Airbnb.
   As little is known about where the sharing economy is gaining momentum
   beyond transportation and accommodation, the purpose of this paper is to
   map in what sectors of the economy it is perceived to gain traction.
   Drawing on data from social and traditional media in Sweden, we identify
   a long tail of 17 sectors and 47 subsectors in which a total of 165
   unique sharing-economy actors operate, including sectors such as
   ondemand services, fashion and clothing, and food delivery. Our findings
   therefore point at the expanding scope of the sharing economy and
   relatedly, we derive a set of implications for firms.
TC 9
Z8 0
ZS 0
ZR 0
ZB 0
Z9 9
SN 0040-1625
EI 1873-5509
UT WOS:000528313800002
ER

PT J
AU Maresch, Daniela
   Gartner, Johannes
TI Make disruptive technological change happen - The case of additive
   manufacturing
SO TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE
VL 155
AR UNSP 119216
DI 10.1016/j.techfore.2018.02.009
PD JUN 2020
PY 2020
AB Disruptive technological change can contribute to a more abundant world.
   However, potentially disruptive technologies often struggle to
   significantly influence practice. One prominent example is additive
   manufacturing (AM). Although AM is often regarded as the next great
   technological revolution in waiting, it has not yet established itself
   on a large scale in many fields of application. We investigate the
   reasons behind those challenges by looking at the various fields in
   which AM is applied and relating them to the specific challenges AM
   faces, as well as the opportunities it offers in those fields. Our
   findings rely on a multi-perspective technology foresight process that
   is based on a discourse analytic approach and that comprises data
   tomography covering the biggest German-language online magazine on AM
   and qualitative interview data collected from a range of AM
   stake-holders. The findings provide an empirically well-founded
   evaluation and explanation of the link between the challenges and
   opportunities offered by AM and the extent to which this disruptive
   technology is leveraged in specific fields. The findings prompt
   recommendations on how new potentially disruptive technologies can
   foster abundance in traditional, well established market economies based
   on the example of the well-developed but traditional market economy of
   Austria.
OI Maresch, Daniela/0000-0002-1443-2520
ZR 0
TC 3
ZS 0
ZB 0
Z8 0
Z9 3
SN 0040-1625
EI 1873-5509
UT WOS:000528313800004
ER

PT J
AU Fareri, S.
   Fantoni, G.
   Chiarello, F.
   Coli, E.
   Binda, A.
TI Estimating Industry 4.0 impact on job profiles and skills using text
   mining
SO COMPUTERS IN INDUSTRY
VL 118
AR UNSP 103222
DI 10.1016/j.compind.2020.103222
PD JUN 2020
PY 2020
AB Industry 4.0 is introducing rapid and epochal changes and challenges.
   Among these, the issue of skills and job profiles is assuming a critical
   role. In fact, the literature highlights not only the necessary
   integration of existing skills in professional profiles, but also the
   inevitable creation of new ones to properly manage the digitalisation
   trends. Although, the state of the art mostly focuses on building models
   to assess the digital maturity of companies, considering instead the
   impact on the labor market as a hazy issue. Moreover, the literature
   tends to offer qualitative approaches to the topic, making the results
   uncertain; on the other side, quantitative ones tend to be mainly
   applied on structured databases, while the supply and demand of
   competences (findable in CVs, vacancies or firm's job profiles) are less
   treated. The goal of the present research is developing a measure for
   quantifying the readiness of employees belonging to a big firm with
   respect to the Industry 4.0 paradigm. To reach the goal, a data-driven
   approach based on text mining techniques is applied to a case study. In
   particular the present methodology makes use of a previously developed
   enriched dictionary of technologies and methods 4.0 (Chiarello et al.,
   2018). The source is used to analyze job profiles' descriptions
   belonging to Whirlpool, a multinational company with a structured
   database of jobs and skills. The process allows the identification of
   technologies, techniques and related skills contained in job
   descriptions. Starting from these, the Industry 4.0 impact on each job
   profile is measured. Finally, the metadata of the job profiles are
   analyzed to evaluate to which extent the skills of profiles 4.0-ready
   and non-4.0-ready differ. In the end, the work provides a framework for
   estimating the Industry 4.0 readiness of enterprises' human capital
   which demonstrates to be fast, adaptable and reusable. (C) 2020 Elsevier
   B.V. All rights reserved.
ZB 0
Z8 0
ZR 0
ZS 0
TC 0
Z9 0
SN 0166-3615
EI 1872-6194
UT WOS:000528007600002
ER

PT J
AU Gorges, Matthias
   Ansermino, J Mark
TI Augmented intelligence in pediatric anesthesia and pediatric critical
   care.
SO Current opinion in anaesthesiology
VL 33
IS 3
BP 404
EP 410
DI 10.1097/ACO.0000000000000845
PD 2020-Jun
PY 2020
AB PURPOSE OF REVIEW: Acute care technologies, including novel monitoring
   devices, big data, increased computing capabilities, machine-learning
   algorithms and automation, are converging. This enables the application
   of augmented intelligence for improved outcome predictions, clinical
   decision-making, and offers unprecedented opportunities to improve
   patient outcomes, reduce costs, and improve clinician workflow. This
   article briefly explores recent work in the areas of automation,
   artificial intelligence and outcome prediction models in pediatric
   anesthesia and pediatric critical care.
   RECENT FINDINGS: Recent years have yielded little published research
   into pediatric physiological closed loop control (a type of automation)
   beyond studies focused on glycemic control for type 1 diabetes. However,
   there has been a greater range of research in augmented decision-making,
   leveraging artificial intelligence and machine-learning techniques, in
   particular, for pediatric ICU outcome prediction.
   SUMMARY: Most studies focusing on artificial intelligence demonstrate
   good performance on prediction or classification, whether they use
   traditional statistical tools or novel machine-learning approaches. Yet
   the challenges of implementation, user acceptance, ethics and regulation
   cannot be underestimated. Areas in which there is easy access to
   routinely labeled data and robust outcomes, such as those collected
   through national networks and quality improvement programs, are likely
   to be at the forefront of the adoption of these advances.
OI Ansermino, J Mark/0000-0001-8427-2035; Gorges,
   Matthias/0000-0003-2193-178X
ZS 0
ZB 0
TC 0
Z8 0
ZR 0
Z9 0
EI 1473-6500
UT MEDLINE:32324658
PM 32324658
ER

PT J
AU Gregory, Anne
   Halff, Gregor
TI The damage done by big data-driven public relations
SO PUBLIC RELATIONS REVIEW
VL 46
IS 2
AR UNSP 101902
DI 10.1016/j.pubrev.2020.101902
PD JUN 2020
PY 2020
AB Over the last two decades it has been argued that public relations
   contributes to hegemony by corporate organizations over stakeholder
   groups who have less power and resources. In its original formulation,
   the concept of hegemony had two defining features: firstly, it was
   conceived of as a society-wide, macroscopic formation and second as
   self-reinforcing i.e. self-replicating. This article argues that the
   rise of big-data in public relations is a hegemonic development that
   further re-enforces the current institutional logics and power in the
   three main spheres of society: corporate, governance and civic. Using
   the economic notion of externalities, the authors argue that loss of
   agency over personal data is the unpriced, unrecognized externality that
   drives the big-data market. This externality is dependent on those who
   are the losers of agency not having the requisite information, power or
   resources to negotiate alternatives that might re-dress the balance. As
   users and proponents of the use of big data, the public relations
   profession has a number of key questions to answer if it is not to
   re-inforce arguments that it is a hegemonizing force in organizations
   and society. Normal economic remedies to address externalities are not
   adequate to a case that is both ethical as well as economic in nature.
   The article therefore concludes with five arguments that the public
   relations profession should debate to provide leadership within
   organisations and society.
ZB 0
Z8 0
ZS 0
TC 0
ZR 0
Z9 0
SN 0363-8111
EI 1873-4537
UT WOS:000528266000017
ER

PT J
AU Huber, Brigitte
   Gil de Zuniga, Homero
   Liu, James
TI Assessing political second screening behavior and personality traits:
   The roles of economic development, freedom of expression and
   monochromatic vs. polychromatic cultures
SO TELEMATICS AND INFORMATICS
VL 49
AR 101365
DI 10.1016/j.tele.2020.101365
PD JUN 2020
PY 2020
AB This study focuses on an emerging media multitasking phenomenon called
   second screening or dual screening. Employing two-wave panel-data from
   19 countries, we test whether the Big Five personality traits help
   explain the use of an additional screen or device while watching
   political content on TV to discuss the program with others or to look up
   for additional information. Results show that extraversion positively
   predicts political second screening. In contrast, agreeableness and
   openness to new experience are negatively related to political second
   screening. Moreover, multilevel analysis is performed to test whether
   the between-country variation is related to economic, political and
   cultural indicators.
ZS 0
TC 1
ZB 0
ZR 0
Z8 0
Z9 1
SN 0736-5853
UT WOS:000525319900006
ER

PT J
AU Ellingson, Sally R.
   Davis, Brian
   Allen, Jonathan
TI Machine learning and ligand binding predictions: A review of data,
   methods, and obstacles
SO BIOCHIMICA ET BIOPHYSICA ACTA-GENERAL SUBJECTS
VL 1864
IS 6
AR 129545
DI 10.1016/j.bbagen.2020.129545
PD JUN 2020
PY 2020
AB Computational predictions of ligand binding is a difficult problem, with
   more accurate methods being extremely computationally expensive. The use
   of machine learning for drug binding predictions could possibly leverage
   the use of biomedical big data in exchange for time-intensive
   simulations. This paper reviews current trends in the use of machine
   learning for drug binding predictions, data sources to develop machine
   learning algorithms, and potential problems that may lead to overfitting
   and ungeneralizable models. A few popular datasets that can be used to
   develop virtual high-throughput screening models are characterized using
   spatial statistics to quantify potential biases. We can see from
   evaluating some common benchmarks that good performance correlates with
   models with high-predicted bias scores and models with low bias scores
   do not have much predictive power. A better understanding of the limits
   of available data sources and how to fix them will lead to more
   generalizable models that will lead to novel drug discovery.
TC 0
ZR 0
Z8 0
ZS 0
ZB 0
Z9 0
SN 0304-4165
EI 1872-8006
UT WOS:000525322300004
PM 32057823
ER

PT J
AU Matthews, Paul M
   Block, Valerie J
   Leocani, Letizia
TI E-health and multiple sclerosis.
SO Current opinion in neurology
VL 33
IS 3
BP 271
EP 276
DI 10.1097/WCO.0000000000000823
PD 2020-Jun
PY 2020
AB PURPOSE OF REVIEW: To outline recent applications of e-health data and
   digital tools for improving the care and management of healthcare for
   people with multiple sclerosis.
   RECENT FINDINGS: The digitization of most clinical data, along with
   developments in communication technologies, miniaturization of sensors
   and computational advances are enabling aggregation and clinically
   meaningful analyses of real-world data from patient registries, digital
   patient-reported outcomes and electronic health records (EHR). These
   data are allowing more confident descriptions of prognoses for multiple
   sclerosis patients and the long-term relative benefits and safety of
   disease-modifying treatments (DMT). Registries allow detailed, multiple
   sclerosis-specific data to be shared between clinicians more easily,
   provide data needed to improve the impact of DMT and, with EHR,
   characterize clinically relevant interactions between multiple sclerosis
   and other diseases. Wearable sensors provide continuous, long-term
   measures of performance dynamics in relevant ecological settings. In
   conjunction with telemedicine and online apps, they promise a major
   expansion of the scope for patients to manage aspects of their own care.
   Advances in disease understanding, decision support and self-management
   using these Big Data are being accelerated by machine learning and
   artificial intelligence.
   SUMMARY: Both health professionals and patients can employ e-health
   approaches and tools for development of a more patient-centred learning
   health system.
ZR 0
TC 0
Z8 0
ZS 0
ZB 0
Z9 0
EI 1473-6551
UT MEDLINE:32324706
PM 32324706
ER

PT J
AU Damasio, Ludmila M. A.
   Peninno, Maria Grazia
   Lopes, Priscila F. M.
TI Small changes, big impacts: Geographic expansion in small-scale
   fisheries
SO FISHERIES RESEARCH
VL 226
AR 105533
DI 10.1016/j.fishres.2020.105533
PD JUN 2020
PY 2020
AB Small-scale fisheries are an important, yet neglected, millenarian
   activity that has been undergoing significant changes that threaten its
   future. Understanding how this activity is spatially distributed and the
   factors that drive its use of the marine space over time can shed some
   light on how fishing efforts and their impacts have moved over different
   parts of coastal marine ecosystems. This study investigated changes to
   the spatial distribution of small-scale fisheries along the Brazilian
   equatorial region between 1994 and 2014 and the factors, from ecological
   to socioeconomic, that influenced this shift. Bayesian hierarchical
   spatial models were used together with environmental variables, and
   species and fisheries data to identify fisheries spatial variations.
   Fisheries spatial transitions were also assessed to determine whether
   they occurred as a result of significant changes to target species and
   their abundance, fisheries technology and efforts, and/or economic
   revenues. A relevant shift in the fisheries spatial distribution was
   detected and demonstrated that fishing has been mostly moving from
   shallow to deeper waters. Although the target species remained the same
   in 1994 and 2014, abundance of these species decreased significantly
   over time, which has consequently affected fisher revenues. It is
   possible that, when new and further areas were exploited, initial
   catches were either better or similar to previous catch levels in older
   and closer grounds, which may have masked earlier signs of overfishing.
   Even small changes, such as shifting fishing grounds to a few kilometers
   offshore, could be a proxy for negative socioeconomic and ecological
   changes in fishing communities that is brought about by resource decline
   in areas closer to the coast. An important step toward detecting signs
   of ecological collapse with social consequences is to identify
   additional fisheries changes not commonly reported in landing data, such
   as ground shifts.
RI pennino, maria grazia/; Lopes, Priscila/H-2028-2012
OI pennino, maria grazia/0000-0002-7577-2617; Lopes,
   Priscila/0000-0002-6774-5117
Z8 0
ZB 0
ZS 0
TC 0
ZR 0
Z9 0
SN 0165-7836
EI 1872-6763
UT WOS:000525305200017
ER

PT J
AU Fahim, Muhammad
   Fraz, Khadija
   Sillitti, Alberto
TI TSI: Time series to imaging based model for detecting anomalous energy
   consumption in smart buildings
SO INFORMATION SCIENCES
VL 523
BP 1
EP 13
DI 10.1016/j.ins.2020.02.069
PD JUN 2020
PY 2020
AB In smart buildings, efficient energy consumption is one of the biggest
   challenges to solve, which can contribute to reduce the global warming
   of our planet, due to its relevance. In this paper, a time series to
   image (TSI) based model is introduced to identify anomalous energy
   consumption in residential buildings. It has a novel encoding scheme to
   transform univariate time series data into images for extracting the
   useful information and one-class support vector machine (OCSVM) for the
   classification task. The TSI extracts descriptive and representative
   feature spaces from the data and encode them into images using Markov
   Transition Function (MTF). We empirically evaluate the proposed model
   over publicly available real world dataset and compared the results with
   the state-of-the-art method. The obtained results are competitive and
   confirm the applicability of TSI model in real-world scenarios. (C) 2020
   Elsevier Inc. All rights reserved.
ZR 0
ZB 0
ZS 0
TC 0
Z8 0
Z9 0
SN 0020-0255
EI 1872-6291
UT WOS:000527016100001
ER

PT J
AU Nasrollahi, M.
   Ramezani, J.
TI A Model to Evaluate the Organizational Readiness for Big Data Adoption
SO INTERNATIONAL JOURNAL OF COMPUTERS COMMUNICATIONS & CONTROL
VL 15
IS 3
AR UNSP 3874
DI 10.15837/ijccc.2020.3.3874
PD JUN 2020
PY 2020
AB Evaluating organizational readiness for adopting new technologies always
   was an important issue for managers. This issue for complicated subjects
   such as Big Data is undeniable. Managers tend to adopt Big Data, with
   the best readiness. But this is not possible unless they can assess
   their readiness. In the present paper, we propose a model to evaluate
   the organizational readiness for Big Data adoption. To accomplish this
   objective, firstly, we identified the criteria that impact
   organizational readiness based on a comprehensive literature review. In
   the next step using Principal Component Analysis (PCA) for criterion
   reduction and integration, twelve main criteria were identified. Then
   the hierarchical structure of criteria was developed. Further, Fuzzy
   Best-Worst Method (FBWM) has been used to identify the weight of the
   criteria. The finding enables decision-makers to appropriately choose
   the more important criteria and drop unimportant criteria in
   strengthening organizational readiness for Big Data adoption.
   Statistics-based hierarchical model and MCDM based criteria weighting
   have been proposed, which is a new effort in evaluating organizational
   readiness for Big Data adoption.
RI Ramezani, Javaneh/I-6374-2018
OI Ramezani, Javaneh/0000-0003-1414-186X
ZR 0
ZB 0
ZS 0
TC 0
Z8 0
Z9 0
SN 1841-9836
EI 1841-9844
UT WOS:000528258600009
ER

PT J
AU Lydia, E. Laxmi
   Kumar, P. Krishna
   Shankar, K.
   Lakshmanaprabu, S. K.
   Vidhyavathi, R. M.
   Maseleno, Andino
TI Charismatic Document Clustering Through Novel K-Means Non-negative
   Matrix Factorization (KNMF) Algorithm Using Key Phrase Extraction
SO INTERNATIONAL JOURNAL OF PARALLEL PROGRAMMING
VL 48
IS 3
BP 496
EP 514
DI 10.1007/s10766-018-0591-9
PD JUN 2020
PY 2020
AB The tedious challenging of Big Data is to store and retrieve of required
   data from the search engines. Problem Defined There is an obligation for
   the quick and efficient retrieval of useful information for the many
   organizations. The elementary idea is to arrange these computing files
   of organization into individual folders in an hierarchical order of
   folders. Manually, to order these files into folders, there is an ardent
   need to know about the file contents and name of the files to give
   impression of files, so that it provides an alignment of certain set of
   files as a bunch. Problem Statement Manual grouping of files has its own
   complications, for example when these files are in numerous amounts and
   also their contents cannot be illustrious by their labels. Therefore,
   it's an intense requirement for Document clustering with data processing
   machines for enthusiastic results. Existing System A couple of analyzers
   are impending with dynamic algorithms and comprehensive analogy of
   extant algorithms, but, yet, these have been restricted to organizations
   and colleges. After recent updated rules of NMF their raised a self
   interest in document clustering. These rules gave trust in its
   performances with better results when compared to Latent Semantic
   Indexing with Singular Value Decomposition. Proposed System A new
   working miniature called Novel K-means Non-Negative Matrix Factorization
   (KNMF) is implemented using renovated guidelines of NMF which has been
   diagnosed for clustering documents consequently. A new data set called
   Newsgroup20 is considered for the exploratory purpose. Removal of common
   clutter/stop words using keywords from Key Phrase Extraction Algorithm
   and a new proposed Iterated Lovin stemming will be utilized in
   preprocessing step inassisting to KNMF. Compared to the Porter stemmer
   and Lovins stemmer algorithms, Iterative Lovins algorithm is providing
   5% more reduction. 60% of the document terms are been minimized to root
   as remaining terms are already root words. Eventually, an appeal to
   these processes named "Progressive Text mining radical" is developed
   inlateral exertion of K-Means algorithm from the defined Apache Mahout
   Project which is used to analyze the performance of the MapReduce
   framework in Hadoop.
RI Shankar, Dr. K./Y-9178-2018
OI Shankar, Dr. K./0000-0002-2803-3846
Z8 0
ZS 0
ZB 0
TC 1
ZR 0
Z9 1
SN 0885-7458
EI 1573-7640
UT WOS:000528215000006
ER

PT J
AU Devi, R. Ramya
   Chamundeeswari, V. Vijaya
TI Triple DES: Privacy Preserving in Big Data Healthcare
SO INTERNATIONAL JOURNAL OF PARALLEL PROGRAMMING
VL 48
IS 3
BP 515
EP 533
DI 10.1007/s10766-018-0592-8
PD JUN 2020
PY 2020
AB Big data stand as a technique to retrieve, collect, manage and also
   analyze a vast quantity of structured and also unstructured data which
   are tough to process utilizing the traditional database that involves
   new technologies to examine them. With the expanding success of the big
   data usage, loads of challenges emerged. Timeless, scalability and
   privacy are the chief problems that researchers endeavor to work out.
   Privacy-preserving is at present a highly active domain of research. To
   guarantee a safe and trustworthy big data atmosphere, it is imperative
   to pinpoint the drawbacks of the existing solutions furthermore conceive
   directions for future study. In the given paper, the security and also
   the privacy-preserving on big data is proposed concerning the healthcare
   industry and to beat security issues in existing approach. Mainly
   anonymizations along with Triple DES techniques aimed at security
   purpose are incorporated. Triple DES offers a fairly simple technique of
   increasing the key size of DES to shield against such attacks, devoid of
   necessitates to design an entirely new block cipher algorithm. Data
   anonymization work as an information sanitizer whose target is to defend
   the data privacy. It encrypts or takes away the personally recognizable
   data as of the data sets in order that the persons about whom the data
   designate remain anonymous. In this work, a combination of anonymization
   and Triple DES are utilized that are shortly called as the A3DES
   algorithm. Experimental outcome reveals that the approach performed well
   when contrasted with all other related approaches.
ZR 0
ZB 0
ZS 0
Z8 0
TC 1
Z9 1
SN 0885-7458
EI 1573-7640
UT WOS:000528215000007
ER

PT J
AU Qu, Xueqi
   Wang, Xi
   Huang, Xiaona
   Ashish, K C
   Yang, Yuning
   Huang, Yue
   Chen, Chunyi
   Gao, Yaqing
   Wang, Yinping
   Zhou, Hong
TI Socio-emotional challenges and development of children left behind by
   migrant mothers.
SO Journal of global health
VL 10
IS 1
BP 010806
EP 010806
DI 10.7189/jogh.10.010806
PD 2020-Jun
PY 2020
AB Background: With great economic development and rapid urbanization in
   China, left-behind children whose parents migrate to big cities for job
   has become a large special population which requires more attention. The
   present study aims to explore the specific influence of migrant mothers
   on early child development, especially on social-emotional problems.
   Methods: The data of this study was obtained from a cross-sectional
   study in 8 counties of central and western rural China. Development
   status of 1880 children aged <60 months were assessed by Ages & Stages
   Questionnaire-Chinese Edition (ASQ) and the Ages and Stages
   Questionnaire: Social Emotional-Chinese Edition (ASQ: SE). Multivariate
   logistic regressions were used to analyze the association between being
   left behand by migrant mothers and developmental problems in various
   domains, while adjusting socio-demographic, socio-economic and perinatal
   co-variates, and effect modification analysis were conducted to explore
   the effect of age, gender and birth order.
   Results: Children left behind by migrant mothers were more likely to
   have overall suspected developmental delay (odds ratio (OR)=1.24, 95%
   confidence interval (CI)=1.13-1.35), developmental delay in personal
   social domain (OR=1.55, 95% CI=1.17-2.04) and socio-emotional delay
   compared with those living with their own mothers (OR=1.49, 95%
   CI=1.11-2.00) after adjusting for potential confounders. Additionally,
   girls increased the odds of social-emotional problems among children
   being left behind by migrating mother (P for interaction=0.037).
   Conclusions: The study concluded that children left behind by migrant
   mothers were more likely to have suspected developmental delay compared
   with their peers living with mothers, especially on social emotional
   development. Future intervention is needed for this special population
   and should pay more attention to girls.
ZR 0
Z8 0
TC 0
ZB 0
ZS 0
Z9 0
EI 2047-2986
UT MEDLINE:32373338
PM 32373338
ER

PT J
AU Devereaux, Abigail
   Peng, Linan
TI Give us a little social credit: to design or to discover personal
   ratings in the era of Big Data
SO JOURNAL OF INSTITUTIONAL ECONOMICS
VL 16
IS 3
BP 369
EP 387
AR PII S1744137419000754
DI 10.1017/S1744137419000754
PD JUN 2020
PY 2020
AB In 2014, the State Council of the Chinese Communist Party announced the
   institution of a social credit system by 2020, a follow-up to a similar
   statement on the creation of a social credit system issued by the State
   Council in 2007. Social credit ratings of the type being developed by
   the State Council in partnership with Chinese companies go beyond
   existing financial credit ratings in an attempt to project less-tangible
   personal characteristics like trustworthiness, criminal tendencies, and
   group loyalty onto a single scale. The emergence of personal credit
   ratings is enabled by Big Data, automated decision-making processes,
   machine learning, and facial recognition technology. It is quite likely
   that various kinds of personal and social credit ratings shall become
   reality in the near future. We explore China's version of its social
   credit system so far, compare the welfare and epistemological qualities
   of an ecology of personal ratings emanating from polycentric sources
   versus a social credit rating, and discuss whether a social credit
   system in an ideologically driven state is less a tool to maximize
   social welfare through trustworthiness provision and more a method of
   preventing and punishing deviance from a set of party-held ideological
   values.
ZR 0
Z8 0
ZS 0
TC 0
ZB 0
Z9 0
SN 1744-1374
EI 1744-1382
UT WOS:000528230800008
ER

PT J
AU Bhandari, Ritu
   Kirilina, Evgeniya
   Caan, Matthan
   Suttrup, Judith
   De Sanctis, Teresa
   De Angelis, Lorenzo
   Keysers, Christian
   Gazzola, Valeria
TI Does higher sampling rate (multiband plus SENSE) improve group
   statistics - An example from social neuroscience block design at 3T
SO NEUROIMAGE
VL 213
AR 116731
DI 10.1016/j.neuroimage.2020.116731
PD JUN 2020
PY 2020
AB Multiband (MB) or Simultaneous multi-slice (SMS) acquisition schemes
   allow the acquisition of MRI signals from more than one spatial
   coordinate at a time. Commercial availability has brought this technique
   within the reach of many neuroscientists and psychologists. Most early
   evaluation of the performance of MB acquisition employed resting state
   fMRI or the most basic tasks. In this study, we tested whether the
   advantages of using MB acquisition schemes generalize to group analyses
   using a cognitive task more representative of typical cognitive
   neuroscience applications. Twenty-three subjects were scanned on a
   Philips 3 T scanner using five sequences, up to eight-fold acceleration
   with MB-factors 1 to 4, SENSE factors up to 2 and corresponding TRs of
   2.45s down to 0.63s, while they viewed (i) movie blocks showing complex
   actions with hand object interactions and (ii) control movie blocks
   without hand object interaction. Data were processed using a widely used
   analysis pipeline implemented in SPM12 including the unified
   segmentation and canonical HRF modelling. Using random effects
   group-level, voxel-wise analysis we found that all sequences were able
   to detect the basic action observation network known to be recruited by
   our task. The highest t-values were found for sequences with MB4
   acceleration. For the MB1 sequence, a 50% bigger voxel volume was needed
   to reach comparable t-statistics. The group-level t-values for resting
   state networks (RSNs) were also highest for MB4 sequences. Here the MB1
   sequence with larger voxel size did not perform comparable to the MB4
   sequence. Altogether, we can thus recommend the use of MB4 (and SENSE
   1.5 or 2) on a Philips scanner when aiming to perform group-level
   analyses using cognitive block design fMRI tasks and voxel sizes in the
   range of cortical thickness (e.g. 2.7 mm isotropic). While results will
   not be dramatically changed by the use of multiband, our results suggest
   that MB will bring a moderate but significant benefit.
Z8 0
TC 0
ZS 0
ZR 0
ZB 0
Z9 0
SN 1053-8119
EI 1095-9572
UT WOS:000525321000010
PM 32173409
ER

PT J
AU Owen, V. Elizabeth
   Baker, Ryan S.
TI Fueling Prediction of Player Decisions: Foundations of Feature
   Engineering for Optimized Behavior Modeling in Serious Games
SO TECHNOLOGY KNOWLEDGE AND LEARNING
VL 25
IS 2
BP 225
EP 250
DI 10.1007/s10758-018-9393-9
PD JUN 2020
PY 2020
AB As a digital learning medium, serious games can be powerful, immersive
   educational vehicles and provide large data streams for understanding
   player behavior. Educational data mining and learning analytics can
   effectively leverage big data in this context to heighten insight into
   student trajectories and behavior profiles. In application of these
   methods, distilling event-stream data down to a set of salient features
   for analysis (i.e. feature engineering) is a vital element of robust
   modeling. This paper presents a process for systematic game-based
   feature engineering to optimize insight into player behavior: the IDEFA
   framework (Integrated Design of Event-stream Features for Analysis).
   IDEFA aligns game design and data collection for high-resolution feature
   engineering, honed through critical, iterative interplay with analysis.
   Building on recent research in game-based data mining, we empirically
   investigate IDEFA application in serious games. Results show that
   behavioral models which used a full feature set produced more meaningful
   results than those with no feature engineering, with greater insight
   into impactful learning interactions, and play trajectories
   characterizing groups of players. This discovery of emergent player
   behavior is fueled by the data framework, resultant base data stream,
   and rigorous feature creation process put forward in IDEFA-integrating
   iterative design, feature engineering, and analysis for optimal insight
   into serious play.
ZS 0
ZB 0
Z8 0
TC 1
ZR 0
Z9 1
SN 2211-1662
EI 2211-1670
UT WOS:000528577000001
ER

PT J
AU Jia, Susan (Sixue)
TI Motivation and satisfaction of Chinese and US tourists in restaurants: A
   cross-cultural text mining of online reviews
SO TOURISM MANAGEMENT
VL 78
AR 104071
DI 10.1016/j.tourman.2019.104071
PD JUN 2020
PY 2020
AB Tourists with dissimilar cultural backgrounds think and behave
   differently. Precisely capturing and correctly understanding the
   cultural difference will help tourism managers generate greater customer
   satisfaction and increased business revenue. To this end, this paper
   uncovers and compares the motivation and satisfaction of restaurant
   tourist customers coming from China and U.S. by investigating their
   online ratings and reviews. From two major online review communities,
   customer ratings and reviews have been retrieved, quantified,
   text-mined, compared, and interpreted using statistics, latent Dirichlet
   allocation, and frequency analysis. Results suggest that Chinese
   tourists are less inclined to assign lower ratings to restaurants, and
   are more strongly fascinated by the food offered, whereas U.S. tourists
   are more apt to be fun-seeking, and are less uncomfortable with
   crowdedness.
TC 0
Z8 0
ZB 0
ZR 0
ZS 0
Z9 0
SN 0261-5177
EI 1879-3193
UT WOS:000514750800022
ER

PT J
AU Cui Tiejun
   Li Shasha
TI System movement space and system mapping theory for reliability of IoT
SO FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE
VL 107
BP 70
EP 81
DI 10.1016/j.future.2020.01.040
PD JUN 2020
PY 2020
AB The Internet of things (IoT) is ubiquitous, and its system structure is
   becoming increasingly complex. Hence, its reliability has become a
   concern for people. Scientific research on system reliability, fault
   processes and fault big data in industrial engineering, industrial
   informatization and IoT is complex. It must be conducted by combining
   information science, system science, intelligence science and data
   science. In this paper, we propose an analysis method of the reliability
   and fault big data for the study of IoT that is abstracted as a system.
   The paper introduces information ecological methodology into fault big
   data processing to complete fault information transformation. Regarding
   system reliability as an objective, the power, representations and
   measurement of system movement are investigated. The system movement
   space (SMS) and system mapping theory (SMT) are proposed and used for
   the identification of the system structure. Finally, the correspondence
   relationship between the artificial system and the natural system, their
   characteristics and mapping methods, and the system characteristics that
   are consistent with various philosophical views are identified. The
   paper provides a theoretical basis and analytical methods for the study
   of system movement and change processes, especially for the study of the
   system reliability via fault big data analysis. (C) 2020 Elsevier B.V.
   All rights reserved.
Z8 0
ZB 0
ZS 0
TC 0
ZR 0
Z9 0
SN 0167-739X
EI 1872-7115
UT WOS:000527331800005
ER

PT J
AU Sun, Chenghao
TI Research on investment decision-making model from the perspective of
   "Internet of Things plus Big data''
SO FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE
VL 107
BP 286
EP 292
DI 10.1016/j.future.2020.02.003
PD JUN 2020
PY 2020
AB With the continuous improvement of the global securities market, the
   market competition is unprecedented fierce. In the aspect of investment
   decision support system, there is an urgent need to continuously absorb
   new information processing technologies and improve the scientific and
   standardization of decision-making, so as to achieve the goal of
   improving investment decision-making efficiency and stabilizing
   investment returns. Firstly, this paper introduces the defect that the
   database, model base and knowledge base are designed and implemented
   independently in the traditional decision support system. Then,
   constructing a unified and efficient data processing platform for
   Internet of Things based on DMFS technology, which realizes the
   integration of database and model, and innovatively establishes a data
   mining model facing market big data, dynamically analyzes and proposes
   investment decisions. Finally, the operating income data of a listed
   company in recent ten years are selected for simulation, which verifies
   the efficiency of the model system in processing dynamic data and the
   stability of investment income. (C) 2020 Elsevier B.V. All rights
   reserved.
ZB 0
ZS 0
Z8 0
TC 0
ZR 0
Z9 0
SN 0167-739X
EI 1872-7115
UT WOS:000527331800020
ER

PT J
AU Barba-Gonzalez, Cristobal
   Nebro, Antonio J.
   Benitez-Hidalgo, Antonio
   Garcia-Nieto, Jose
   Aldana-Montes, Jose F.
TI On the design of a framework integrating an optimization engine with
   streaming technologies
SO FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE
VL 107
BP 538
EP 550
DI 10.1016/j.future.2020.02.020
PD JUN 2020
PY 2020
AB A number of streaming technologies have appeared in the last years as a
   result of the rising of Big Data applications. Nowadays, deciding which
   technology to adopt is not an easy task due not only to the number of
   available data streaming processing projects, but also because they are
   continuously evolving. In this paper, we focus on how these issues have
   affected jMetalSP, a framework for dynamic multi-objective optimization
   that incorporates streaming features. jMetalSP allows the development of
   three tier optimization workflows where the central component is an
   optimizer that is continuously solving a dynamic multi-objective
   optimization problem. This problem can change as a consequence of the
   analysis of data streams carried out by components that use the Apache
   Spark streaming engine. A third kind of components receive and process
   the Pareto front approximations being yielded by the optimization
   algorithm. However, all jMetalSP elements are tightly coupled and linked
   to Spark, making it difficult to use a different streaming system. To
   overcome this issue, we have redesigned the jMetalSP architecture to
   make it flexible enough to avoid the dependence of any particular
   streaming system. This way, popular Apache projects such as Spark
   Structured Streaming, Kafka Streams, or Flink can be used without
   requiring to change the rest of components of the application.
   Furthermore, Kafka can be used for inter-process communication, what
   enables the execution of components in different nodes of a cluster,
   independently of their implementation languages thanks to the
   serialization of data streams with Apache Avro. We show how the embraced
   solution provides a high degree of flexibility that enhances the
   usability of jMetalSP. To this end, a representative case study based on
   a transport problem is conducted that focuses on data representation and
   performance evaluation of the Spark, Flink, and Kafka systems. (C) 2020
   Elsevier B.V. All rights reserved.
ZR 0
ZB 0
TC 0
ZS 0
Z8 0
Z9 0
SN 0167-739X
EI 1872-7115
UT WOS:000527331800039
ER

PT J
AU Basanta-Val, P.
   Fernandez-Garcia, N.
   Sanchez-Fernandez, L.
TI Predictable remote invocations for distributed stream processing
SO FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE
VL 107
BP 716
EP 729
DI 10.1016/j.future.2017.08.023
PD JUN 2020
PY 2020
AB Typical infrastructure for big-data includes multiple machines with data
   accessed remotely with request-response patterns from different remote
   locations. Currently, most of the state-of-the-art remote invocation
   techniques are focused on models for distributed interactions, which
   have not explored the advantages given by parallel computing, such as
   those offered to run on distributed stream processors. In this context,
   the article is focused on the definition of a predictable remote
   procedure call (RPC) able to take advantage from the distributed stream
   processing technology. Potentially, this type of infrastructure enables
   efficient parallel computations, reducing the effective response-time of
   end-to-end invocations linearly with the number of resources assigned to
   the system, as the data increases. The article describes a predictable
   model which defines maximum response-times for different types of
   applications described in the context of Apache Storm. Evaluation also
   offers clues on the performance one may expect from this type of
   infrastructure. (c) 2017 Elsevier B.V. All rights reserved.
RI Sanchez-Fernandez, Luis/I-3867-2015
OI Sanchez-Fernandez, Luis/0000-0002-9801-4747
Z8 0
ZR 0
ZB 0
ZS 0
TC 2
Z9 2
SN 0167-739X
EI 1872-7115
UT WOS:000527331800052
ER

PT J
AU Rawashdeh, Majdi
   Al Zamil, Mohammed Gh
   Samarah, Samer
   Hossain, M. Shamim
   Muhammad, Ghulam
TI A knowledge-driven approach for activity recognition in smart homes
   based on activity profiling
SO FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE
VL 107
BP 924
EP 941
DI 10.1016/j.future.2017.10.031
PD JUN 2020
PY 2020
AB The Internet of Things (IoT) is a technology for seamlessly connecting a
   large number of small-end devices and enabling the development of many
   smart applications to control different aspects of our life; shifting
   us, ever-closer to living in a smart city. IoT makes it possible to
   convert our homes to smart environments in which sensors are responsible
   for handling inhabitants' behaviours and monitor their daily activities.
   Activity Recognition (AR) is a new service within smart homes. It has
   been introduced as a solution to improve the quality of life of people
   such as elderly and children. AR is concerned with the assignment of an
   activity label to a sequence of sensors' events that are generated from
   the smart infrastructure. To help in effectively recognizing home
   activities, classification algorithms are applied on segmented sequences
   that are extracted automatically. Segments are subject to error due to
   the existence of irrelevant data and difficulties in how segmentation is
   applied. This negatively affects the accuracy on the classification
   task. In addition, the data generated from the network is streamed in
   nature, and big data techniques need to be utilized. In this paper, we
   propose a model to improve Activity Recognition in smart homes. The
   proposed technique is based on defining a profile for each activity from
   training datasets. The profile will be used to induce extra features and
   will help in distinguishing residents' activities (fingerprinting). To
   validate our model, real datasets have been used for the experiments,
   and results show a significant enhancement in accuracy, compared with
   traditional techniques. (c) 2017 Elsevier B.V. All rights reserved.
RI Muhammad, Ghulam/H-5884-2011; Hossain, M. Shamim/
OI Muhammad, Ghulam/0000-0002-9781-3969; Hossain, M.
   Shamim/0000-0001-5906-9422
ZS 0
ZR 0
TC 1
ZB 0
Z8 0
Z9 1
SN 0167-739X
EI 1872-7115
UT WOS:000527331800072
ER

PT J
AU Karim, Ahmad
   Siddiqa, Aisha
   Safdar, Zanab
   Razzaq, Maham
   Gillani, Syeda Anum
   Tahir, Huma
   Kiran, Sana
   Ahmed, Ejaz
   Imran, Muhammad
TI Big data management in participatory sensing: Issues, trends and future
   directions
SO FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE
VL 107
BP 942
EP 955
DI 10.1016/j.future.2017.10.007
PD JUN 2020
PY 2020
AB Participatory sensing has become an emerging technology of this era
   owing to its low cost in big sensor data collection. Prior to
   participatory sensing, large-scale deployment complexities were found in
   wireless sensor networks when collecting data from widespread resources.
   Participatory sensing systems employ handheld devices as sensors to
   collect data from communities and transmit to the cloud, where data are
   further analyzed by expert systems. The processes involved in
   participatory sensing, such as data collection, transmission, analysis,
   and visualization, exhibit certain management issues. This study aims to
   identify big data management issues that must be addressed at the cloud
   side during data processing and storing and at the participant side
   during data collection and visualization. It then proposes a framework
   for big data management in participatory sensing to resolve the
   contemporary big data management issues on the basis of suggested
   principles. Moreover, this work presents case studies to elaborate the
   existence of the highlighted issues. Finally, the limitations,
   recommendations, and future research directions for academia and
   industry in the domain of participatory sensing are discussed. (C) 2017
   Published by Elsevier B.V.
TC 3
ZR 0
ZS 0
ZB 0
Z8 0
Z9 3
SN 0167-739X
EI 1872-7115
UT WOS:000527331800073
ER

PT J
AU Silva, Bhagya Nathali
   Khan, Murad
   Han, Kijun
TI Integration of Big Data analytics embedded smart city architecture with
   RESTful web of things for efficient service provision and energy
   management
SO FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE
VL 107
BP 975
EP 987
DI 10.1016/j.future.2017.06.024
PD JUN 2020
PY 2020
AB Emergence of smart things has revolutionized the conventional internet
   into a connected network of things, maturing the concept of Internet of
   Things (IoT). With the evolution of IoT, many attempts were made to
   realize the notion of smart cities. However, demands for processing
   enormous amount of data and platform incompatibilities of connected
   smart things hindered the actual implementation of smart cities. Keeping
   it in view, we proposed a Big Data analytics embedded smart city
   architecture, which is further integrated with the web via a smart
   gateway. Integration with the web provides a universal communication
   platform to overcome the platform incompatibilities of smart things. We
   introduced Big Data analytics to enhance data processing speed. Further,
   we evaluated authentic datasets to determine the threshold values for
   intelligent decision-making and to present the performance improvement
   gained in data processing. Finally, we presented a representational
   state transfer (RESTful) web of things (WoT) integrated smart building
   architecture (smart home) to reveal the performance improvements of the
   proposed smart city architecture in terms of network performance and
   energy management of smart buildings. (C) 2017 Elsevier B.V. All rights
   reserved.
ZR 0
TC 1
ZS 0
ZB 0
Z8 0
Z9 1
SN 0167-739X
EI 1872-7115
UT WOS:000527331800076
ER

PT J
AU Boje, Calin
   Guerriero, Annie
   Kubicki, Sylvain
   Rezgui, Yacine
TI Towards a semantic Construction Digital Twin: Directions for future
   research
SO AUTOMATION IN CONSTRUCTION
VL 114
AR 103179
DI 10.1016/j.autcon.2020.103179
PD JUN 2020
PY 2020
AB As the Architecture, Engineering and Construction sector is embracing
   the digital age, the processes involved in the design, construction and
   operation of built assets are more and more influenced by technologies
   dealing with value-added monitoring of data from sensor networks,
   management of this data in secure and resilient storage systems
   underpinned by semantic models, as well as the simulation and
   optimisation of engineering systems. Aside from enhancing the efficiency
   of the value chain, such information-intensive models and associated
   technologies play a decisive role in minimising the lifecycle impacts of
   our buildings. While Building Information Modelling provides procedures,
   technologies and data schemas enabling a standardised semantic
   representation of building components and systems, the concept of a
   Digital Twin conveys a more holistic socio-technical and
   process-oriented characterisation of the complex artefacts involved by
   leveraging the synchronicity of the cyber-physical bi-directional data
   flows. Moreover, BIM lacks semantic completeness in areas such as
   control systems, including sensor networks, social systems, and urban
   artefacts beyond the scope of buildings, thus requiring a holistic,
   scalable semantic approach that factors in dynamic data at different
   levels. The paper reviews the multi-faceted applications of BIM during
   the construction stage and highlights limits and requirements, paving
   the way to the concept of a Construction Digital Twin. A definition of
   such a concept is then given, described in terms of underpinning
   research themes, while elaborating on areas for future research.
ZR 0
TC 0
ZB 0
Z8 0
ZS 0
Z9 0
SN 0926-5805
EI 1872-7891
UT WOS:000526785800022
ER

PT J
AU Zhang, Yakun
   Gong, Guofang
   Yang, Huayong
   Li, Wenjing
   Liu, Jian
TI Precision versus intelligence: Autonomous supporting pressure balance
   control for slurry shield tunnel boring machines
SO AUTOMATION IN CONSTRUCTION
VL 114
AR 103173
DI 10.1016/j.autcon.2020.103173
PD JUN 2020
PY 2020
AB This paper presents a method for the autonomous control of supporting
   pressure balance for a slurry shield tunnel boring machine. The
   mechanism of multi-system coupling interactions of the slurry supporting
   process is revealed by establishing the dynamic model of the process.
   Furthermore, the degree of controllability of the manipulated inputs is
   analyzed and verified theoretically using singular value decomposition.
   Based on the analysis of the supporting process dynamics, a
   cyber-physical system (CPS)-based hierarchical autonomous control scheme
   is proposed. The execution level digital optimal controllers are
   designed and auto-tuned. The discrete event-driven control logic is also
   included in the execution level and modeled as a finite state machine.
   For comparison purpose, the coordination level controller is implemented
   using a hybrid switched model predictive controller and a deep neural
   network, respectively. Various artificial neural networks with different
   hyper-parameters are trained and compared using big data. The
   performance of the proposed autonomous control methodology is tested and
   compared with human operators by using randomly extracted construction
   field data. The test results show that the autonomous control system
   with switched model predictive controller outperforms that with the deep
   neural network and human operators. The results validate the feasibility
   and effectiveness of the proposed autonomous control methodology.
TC 0
ZB 0
Z8 0
ZS 0
ZR 0
Z9 0
SN 0926-5805
EI 1872-7891
UT WOS:000526785800017
ER

PT J
AU Dolan, Erin L
   Borrero, Michelle
   Callis-Duehl, Kristine
   Musgrove, Miranda M Chen
   de Lima, Joelyn
   Ero-Tolliver, Isi
   Gerhart, Laci M
   Goodwin, Emma C
   Hamilton, Lindsey R
   Henry, Meredith A
   Herrera, Jose
   Huot, Bethany
   Kiser, Stacey
   Ko, Melissa E
   Kravec, Marcy E
   Lee, Mark
   Limeri, Lisa B
   Peffer, Melanie E
   Pires, Debra
   Lugo, Juan S Ramirez
   Sharp, Starlette M
   Suarez, Nicole A
TI Undergraduate Biology Education Research Gordon Research Conference: A
   Meeting Report.
SO CBE life sciences education
VL 19
IS 2
BP mr1
EP mr1
DI 10.1187/cbe.19-09-0188
PD 2020-Jun
PY 2020
AB The 2019 Undergraduate Biology Education Research Gordon Research
   Conference (UBER GRC), titled "Achieving Widespread Improvement in
   Undergraduate Education," brought together a diverse group of
   researchers and practitioners working to identify, promote, and
   understand widespread adoption of evidence-based teaching, learning, and
   success strategies in undergraduate biology. Graduate students and
   postdocs had the additional opportunity to present and discuss research
   during a Gordon Research Seminar (GRS) that preceded the GRC. This
   report provides a broad overview of the UBER GRC and GRS and highlights
   major themes that cut across invited talks, poster presentations, and
   informal discussions. Such themes include the importance of working in
   teams at multiple levels to achieve instructional improvement, the
   potential to use big data and analytics to inform instructional change,
   the need to customize change initiatives, and the importance of
   psychosocial supports in improving undergraduate student well-being and
   academic success. The report also discusses the future of the UBER GRC
   as an established meeting and describes aspects of the conference that
   make it unique, both in terms of facilitating dissemination of research
   and providing a welcoming environment for conferees.
ZB 0
ZS 0
TC 0
Z8 0
ZR 0
Z9 0
EI 1931-7913
UT MEDLINE:32357093
PM 32357093
ER

PT J
AU Baccarelli, Enzo
   Scardapane, Simone
   Scarpiniti, Michele
   Momenzadeh, Alireza
   Uncini, Aurelio
TI Optimized training and scalable implementation of Conditional Deep
   Neural Networks with early exits for Fog-supported IoT applications
SO INFORMATION SCIENCES
VL 521
BP 107
EP 143
DI 10.1016/j.ins.2020.02.041
PD JUN 2020
PY 2020
AB The incoming IoT big data era requires efficient and
   resource-constrained mining of large sets of distributed data. This
   paper explores a possible approach to this end, combining the two
   emerging paradigms of Conditional Neural Networks with early exits and
   Fog Computing. Apart from describing the general framework, we provide
   four specific contributions. First, after reviewing the basic
   architectures of CDNNs with early exits and characterizing their
   computational capacity, we consider three basic algorithms for their
   supervised training (namely the End-to-End, Layer-Wise and
   Classifier-Wise training algorithms), and, then, formally characterize
   and compare the resulting tradeoffs in a Fog-supported implementation.
   Second, after presenting a reference architecture for the local
   classifiers equipping the considered CDNNs, we develop an optimized
   framework for the parallel and distributed setting of their decision
   thresholds. Third, we propose a greedy algorithm for placing the early
   exits efficiently on the considered CDNNs and prove its linear scaling
   complexity. Fourth, we analytically characterize in closed form and
   analyze the energy performance of the optimal CDNN-onto-Fog mapping.
   Finally, extensive numerical tests are presented, in order to test and
   compare the energy-vs.-implementation complexity-vs.-accuracy
   performance of the resulting optimized CDNN-over-Fog platforms under the
   IoT-oriented SVHN and FER-2013 datasets. (C) 2020 Elsevier Inc. All
   rights reserved.
RI Scardapane, Simone/AAA-2267-2020
OI Scardapane, Simone/0000-0003-0881-8344
Z8 0
ZB 0
ZS 0
ZR 0
TC 0
Z9 0
SN 0020-0255
EI 1872-6291
UT WOS:000527015900008
ER

PT J
AU Zhang, Hewei
   Dong, Shaohua
   Ling, Jiatong
   Zhang, Laibin
   Cheang, Brenda
TI A modified method for the safety factor parameter: The use of big data
   to improve petroleum pipeline reliability assessment
SO RELIABILITY ENGINEERING & SYSTEM SAFETY
VL 198
AR 106892
DI 10.1016/j.ress.2020.106892
PD JUN 2020
PY 2020
AB Due to the potential severity of oil and gas pipeline accidents,
   accurate assessments on the reliability and viability of pipelines in
   the petroleum industry is of paramount importance. Nevertheless, the
   safety factor (SF) parameter in some well-established assessment
   standards are limited in their applications. This paper proposes a
   modified method for the SF parameter to better assess petroleum pipeline
   reliability. The proposed method improves upon current methods in that
   the SF is derived from multiple critical factors based on pipeline big
   data rather than the calculation of only the pressure of the pipeline.
   Data from an in-service pipeline is used as a case study to demonstrate
   how the proposed modified SF parameter is calculated. Comparative
   analysis with the existing method's results provide clear evidence that
   the proposed modification method is more accurate as it shows how the SF
   parameter changes according to different regional levels. This modified
   method, which incorporates Correlation Analysis, Mutual Information
   Principal Component Analysis (MIPCA), and Weighted Aggregated Sum
   Product Assessment (WASPAS), is in accordance with the widely accepted
   American Society of Mechanical Engineers (ASME) Manual for Determining
   the Remaining Strength of Corroded Pipelines (B31G-2012). With that
   said, the effectiveness of our modified method is directly related to
   the factors and case-based values being used. Therefore, although
   generally applicable to any pipeline, any form of SF analytics must be
   on a case-by-case basis.
ZS 0
ZB 0
Z8 0
ZR 0
TC 0
Z9 0
SN 0951-8320
EI 1879-0836
UT WOS:000527843700025
ER

PT J
AU Zhang, Mengchuang
   Yao, Qin
   Sun, Shouyi
   Li, Lei
   Hou, Xu
TI An efficient strategy for reliability-based multidisciplinary design
   optimization of twin-web disk with non-probabilistic model
SO APPLIED MATHEMATICAL MODELLING
VL 82
BP 546
EP 572
DI 10.1016/j.apm.2020.01.066
PD JUN 2020
PY 2020
AB The twin-web disk holds big promise for increasing efficiency of the
   aircraft engine. Its reliability-based multidisciplinary design
   optimization involves several disciplines including fluid mechanics,
   heat transfer, structural strength, and vibration. The solution to this
   optimization problem requires three-loop calculations including loops
   for optimization, reliability, and interdisciplinary consistence often
   making its computational cost unacceptably high. The lack of sufficient
   amount of probabilistic data, especially for this brand-new turbine
   disk, makes matters worse. In this paper, the non-probabilistic
   uncertain variables are described by an evidence theory-based fuzzy set
   method, which we extend to general structure of uncertain data. We also
   propose two modifications of the active learning kriging model: one of
   them for the purpose of optimization with respect to the distance from
   the optimum point and another one for the purpose of assessing
   reliability by introducing the importance concept. Applications of these
   two modifications are demonstrated in this paper. Finally, a
   multi-adaptive learning kriging strategy for non-probabilistic
   reliability-based multidisciplinary design optimization of twin-web disk
   is proposed to improve its power efficiency and reliability in a
   computationally effective way. (C) 2020 Elsevier Inc. All rights
   reserved.
ZB 0
TC 0
ZS 0
ZR 0
Z8 0
Z9 0
SN 0307-904X
EI 1872-8480
UT WOS:000527324800027
ER

PT J
AU Toledo Borges, Mariana
TI Mercado, vigilância e Facebook na era do espetacular integrado, ou
   inside us all there is a code
X1 Mercado, vigilancia y Facebook en la era del espectacular integrado, o
   inside us all there is a code
Y1 Market, Surveillance, and Facebook in the Era of the Integrated
   Spectacle, or Inside Us All There Is a Code
SO Literatura: Teoría, Historia, Crítica
VL 22
IS 1
BP 137
EP 178
DI 10.15446/lthc.v22n1.82295
PD 2020-06
PY 2020
AB ABSTRACT The object of the article is to analyze some contemporary
   cultural phenomena related to the hegemony of the internet as a space
   for socialization and entertainment, in the light of the concept of
   integrated spectacle, formulated by French Situationist Guy Debord in
   1988. It focuses on the operation of Facebook, the world's largest
   social network, and its powerful algorithmic technology that operates
   with vast reserves ofbig data. The main conclusions drawn on the basis
   of the theoretical discussion and observation of the company's
   activities are: 1) the threat to democratic tenets and the rise of a
   State and economic totalitarianism; 2) the end of the right to privacy
   and secrecy as a propaganda weapon; and 3) control and the replacement
   of reality by its representation, which confirms what Debord called the
   society of the spectacle.
X4 RESUMEN El trabajo tiene el propósito de analizar algunos fenómenos
   culturales contemporáneos relacionados a la hegemonía del Internet como
   entorno de socialización y entretenimiento a la luz del concepto de
   espectacular integrado, formulado por el situacionista francés Guy
   Debord en 1988. Se hace énfasis en el funcionamiento de la empresa
   Facebook -lo que se justifica por constituirse como la red social más
   poblada del mundo- y su poderosa tecnología algorítmica que funciona
   desde enormes reservas de big data. Las principales conclusiones
   planteadas, desde la convergencia entre la discusión teórica y la
   observación de las actividades de la empresa, son: 1) la amenaza a los
   postulados democráticos y el ascenso de un totalitarismo
   estatal-económico; 2) el fin del derecho a la privacidad y el sigilo
   como arma de propaganda; y 3) el control y la supresión de la realidad
   por su representación, es decir, la confirmación de lo que Debord
   denominó sociedad del espectáculo.
Y4 RESUMO O objetivo deste trabalho é propor uma análise de alguns
   fenômenos culturais contemporâneos ligados à hegemonia da internet como
   ambiente de socialização e entretenimento à luz do conceito de
   espetacular integrado, formulado pelo situacionista francês Guy Debord
   em 1988. Daremos enfoque ao funcionamento da empresa Facebook -o que se
   justifica por se constituir como a rede social mais populosa do mundo- e
   sua poderosa tecnologia algorítmica movida a enormes reservas de big
   data. As principais conclusões que apresentamos, a partir da
   convergência entre a discussão teórica e a observação das atividades da
   empresa, são as seguintes: 1) a ameaça aos princípios democráticos e a
   ascensão de um totalitarismo estatal-econômico; 2) o fim do direito à
   privacidade e o sigilo como arma de propaganda; e 3) o controle e a
   supressão da realidade por sua representação, ou seja, a confirmação
   daquilo que Debord denominou sociedade do espetáculo.
Z8 0
ZR 0
TC 0
ZB 0
ZS 0
Z9 0
SN 0123-5931
UT SCIELO:S0123-59312020000100137
ER

PT J
AU Takada, Masaaki
   Suzuki, Taiji
   Fujisawa, Hironori
TI Independently Interpretable Lasso for Generalized Linear Models.
SO Neural computation
VL 32
IS 6
BP 1168
EP 1221
DI 10.1162/neco_a_01279
PD 2020-Jun
PY 2020
AB Sparse regularization such as ℓ1 regularization is a quite powerful and
   widely used strategy for high-dimensional learning problems. The
   effectiveness of sparse regularization has been supported practically
   and theoretically by several studies. However, one of the biggest issues
   in sparse regularization is that its performance is quite sensitive to
   correlations between features. Ordinary ℓ1 regularization selects
   variables correlated with each other under weak regularizations, which
   results in deterioration of not only its estimation error but also
   interpretability. In this letter, we propose a new regularization
   method, independently interpretable lasso (IILasso), for generalized
   linear models. Our proposed regularizer suppresses selecting correlated
   variables, so that each active variable affects the response
   independently in the model. Hence, we can interpret regression
   coefficients intuitively, and the performance is also improved by
   avoiding overfitting. We analyze the theoretical property of the IILasso
   and show that the proposed method is advantageous for its sign recovery
   and achieves almost minimax optimal convergence rate. Synthetic and real
   data analyses also indicate the effectiveness of the IILasso.
TC 0
ZB 0
ZR 0
Z8 0
ZS 0
Z9 0
EI 1530-888X
UT MEDLINE:32343648
PM 32343648
ER

PT J
AU Machuca-Martinez, Fiderman
   Amado, Ruben Camargo
   Gutierrez, Oscar
TI Coronaviruses: A patent dataset report for research and development
   (R&D) analysis.
SO Data in brief
VL 30
BP 105551
EP 105551
DI 10.1016/j.dib.2020.105551
PD 2020-Jun
PY 2020
AB This work shows a patent database for Coronaviruses that provides an
   overview of the patenting activity and trends in focused antiviral
   therapy with the use of triazole based compounds, glycoprotein, and
   protease inhibitors as possible treatment. The patent data was obtained
   from Orbit Intelligence Software using a patent family structure to get
   a big database that could be used for built patent landscape report
   (PLR), market analysis, technical and competitive intelligence, and
   monitoring and survey of a new ideas for the treatment of coronavirus
   diseases. The raw data is reported in four databases, which were
   classified according to different items: legal status (alive, dead), 1st
   application year (after 2015, 2011-2015, 2006-2010, 2001-2005), and Top
   5 International Patents Classifications (IPC). The main players, the
   investment trend, markets, geographical distribution, technology
   overview, technologies distribution, and patent citation are showed by
   this analysed data report.
OI Machuca-Martinez, Fiderman/0000-0002-4553-3957
ZB 0
ZR 0
Z8 0
ZS 0
TC 0
Z9 0
EI 2352-3409
UT MEDLINE:32337328
PM 32337328
ER

PT J
AU Rossi, Bruno
   Chren, Stanislav
TI Smart Grids Data Analysis: A Systematic Mapping Study
SO IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS
VL 16
IS 6
BP 3619
EP 3639
DI 10.1109/TII.2019.2954098
PD JUN 2020
PY 2020
AB Data analytics and data science play a significant role in nowadays
   society. In the context of smart grids, the collection of vast amounts
   of data has seen the emergence of a plethora of data analysis
   approaches. In this article, we conduct a systematic mapping study aimed
   at getting insights about different facets of SG data analysis:
   application subdomains (e.g., power load control), aspects covered
   (e.g., forecasting), used techniques (e.g., clustering), tool support,
   research methods (e.g., experiments/simulations), and
   replicability/reproducibility of research. The final goal is to provide
   a view of the current status of research. Overall, we found that each
   subdomain has its peculiarities in terms of techniques, approaches, and
   research methodologies applied. Simulations and experiments play a
   crucial role in many areas. The replicability of studies is limited
   concerning the provided implemented algorithms, and to a lower extent
   due to the usage of private datasets.
OI Rossi, Bruno/0000-0002-8659-1520
TC 0
ZS 0
ZR 0
Z8 0
ZB 0
Z9 0
SN 1551-3203
EI 1941-0050
UT WOS:000526381800001
ER

PT J
AU Zhu, Kunpeng
   Li, Guochao
   Zhang, Yu
TI Big Data Oriented Smart Tool Condition Monitoring System
SO IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS
VL 16
IS 6
BP 4007
EP 4016
DI 10.1109/TII.2019.2957107
PD JUN 2020
PY 2020
AB The computer numerical control (CNC) machining is the technical
   foundation of modern high-end manufacturing. To satisfy the productivity
   and precision requirement, it is required to monitor and adaptively
   control the machining process in real time under varying working
   conditions. The current CNC machining system is limited by the data
   acquisition methods and modeling approaches, and it is difficult to make
   full use of monitoring information to smartly assess and optimize the
   cutting conditions online. This article proposes a new idea and a novel
   model to solve the problem, with a big data analytics framework for
   smart tool condition monitoring (TCM). Driven by the monitored big data,
   this article systematically investigates the key issues for TCM, such as
   machining dynamics, intelligent tool wear monitoring and compensation
   algorithms, heterogeneous big data fusion, and deep learning methods.
   Under this scheme, it develops the smart TCM system that could improve
   the CNC machining precision and productivity significantly.
TC 0
ZB 0
ZR 0
Z8 0
ZS 0
Z9 0
SN 1551-3203
EI 1941-0050
UT WOS:000526381800035
ER

PT J
AU Okawa, Manabu
TI Online signature verification using single-template matching with
   time-series averaging and gradient boosting
SO PATTERN RECOGNITION
VL 102
AR 107227
DI 10.1016/j.patcog.2020.107227
PD JUN 2020
PY 2020
AB In keeping with recent developments in artificial intelligence in the
   era of big data, there is a demand for online signature verification
   systems that operate at high speeds, provide a high level of security,
   and allow high tolerances while achieving sufficient performance. In
   response to these needs, the present study proposes a novel,
   single-template strategy using a mean template set and weighted multiple
   dynamic time warping (DTW) distances for a function-based approach to
   online signature verification. Specifically, to obtain an effective mean
   template for each feature while reflecting intra-user variability
   between all the reference samples, we adopt a novel time-series
   averaging method based on Euclidean barycenterbased DTW barycenter
   averaging. Then, by using the mean template set, we calculate multiple
   DTW distances from multivariate time series based on dependent and
   independent warping. Finally, to boost the discriminative power, we
   apply a weighting scheme using a gradient boosting model to efficiently
   combine the multiple DTW distances. Experimental results using the
   common SVC2004 Task1/Task2 and MCYT-100 signature datasets confirm that
   the proposed method is effective for online signature verification. (C)
   2020 Elsevier Ltd. All rights reserved.
ZS 0
ZR 0
TC 0
ZB 0
Z8 0
Z9 0
SN 0031-3203
EI 1873-5142
UT WOS:000525825100022
ER

PT J
AU Kwon, Hyuk-Yoon
TI Real and synthetic data sets for benchmarking key-value stores focusing
   on various data types and sizes.
SO Data in brief
VL 30
BP 105441
EP 105441
DI 10.1016/j.dib.2020.105441
PD 2020-Jun
PY 2020
AB In this article, we present real and synthetic data sets for
   benchmarking key-values stores. Here, we focus on various data types and
   sizes. Key-value pairs in key-value data sets consist of the key and the
   value. We can construct any kinds of data as key-value data sets by
   assigning an arbitrary type of data as the value and a unique ID as the
   key. Therefore, key-value pairs are quite worthy when we deal with big
   data because the data types in the big data application become more
   various and, even sometimes, they are not known or determined. In this
   article, we crawl four kinds of real data sets by varying the type of
   data sets (i.e., variety) and generate four kinds of synthetic data sets
   by varying the size of data sets (i.e., volume). For real data sets, we
   crawl data sets with various data types from Twitter, i.e., Tweets in
   text, a list of hashtags, geo-location of the tweet, and the number of
   followers. We also present algorithms for crawling real data sets based
   on REST APIs and streaming APIs and for generating synthetic data sets.
   Using those algorithms, we can crawl any key-value pairs of data types
   supported by Twitter and can generate any size of synthetic data sets by
   extending them simply. Last, we show that the crawled and generated data
   sets are actually utilized for the well-known key-value stores such as
   Level DB of Google, RocksDB of Facebook, and Berkeley DB of Oracle.
   Actually, the presented real and synthetic data sets have been used for
   comparing the performance of them. As an example, we present an
   algorithm of the basic operations for the key-value stores of LevelDB.
OI Kwon, Hyuk-Yoon/0000-0002-1125-6533
ZB 0
ZR 0
Z8 0
ZS 0
TC 0
Z9 0
EI 2352-3409
UT MEDLINE:32322613
PM 32322613
ER

PT J
AU Varnavskiy, Kirill
   Chen, QingGuang
   Nepsha, Fedor
TI Structure orderliness assessment of grid development to improve the
   reliability of coal mine external electrical power supply
SO ELECTRIC POWER SYSTEMS RESEARCH
VL 183
AR 106283
DI 10.1016/j.epsr.2020.106283
PD JUN 2020
PY 2020
AB State-of-the-art reliability assessment methods require a large amount
   of initial statistical data, which does not always have the necessary
   degree of accuracy for accurate assessment. Moreover, this data is often
   difficult to obtain, which can ultimately delay the execution of
   calculations and increase error within results. This paper explores an
   alternative assessment method using the "structural orderliness
   indicator" and minimal initial data to calculate the change in
   reliability indicators in connection with reinforcement decisions. This
   paper includes the cost of reconstruction associated with the
   introduction of a new unit cost indicator for increasing the structure
   orderliness index. As a real-world application, the following discussion
   proposes improvements to external electrical power supply reliability
   for coal-mining enterprises within the Russian Federation, such as in
   the Kemerovo region (the biggest coal-producing region of Russia). In
   recent years, the number of production process suspensions and emergency
   shutdowns of life support facilities has increased due to external power
   supply disruptions. The performed calculations made possible
   qualitatively comparison the proposed method and state-of-the-art method
   based on the determination of reliability indices (SAIDI, SAIFI, etc.).
RI Nepsha, Fedor/R-6873-2016
OI Nepsha, Fedor/0000-0002-7468-2548
TC 0
ZR 0
Z8 0
ZB 0
ZS 0
Z9 0
SN 0378-7796
EI 1873-2046
UT WOS:000525764200015
ER

PT J
AU Harvey, John
   Smith, Andrew
   Golightly, David
   Goulding, James
   Gallage, H. P. Samanthika
TI Prosocial exchange systems: Nonreciprocal giving, lending, and
   skill-sharing
SO COMPUTERS IN HUMAN BEHAVIOR
VL 107
AR UNSP 106268
DI 10.1016/j.chb.2020.106268
PD JUN 2020
PY 2020
AB Prosocial exchange systems support cooperation and exchange in support
   of more sustainable forms of consumption. While often assumed that
   exchanges within such systems are reciprocal, it remains unproven as to
   what extent reciprocity occurs. This study uses data from a live service
   - Streetbank.com - to present an analysis of direct and indirect
   reciprocal relationships (for interactions of giving, lending, and
   skillsharing) over 4 and half years. The dataset contains behavioural
   data relating to 5053 acts of offline non-monetary exchange. The
   analysis categorised different forms of exchange that took place -
   giving, lending, and skill sharing. These exchanges were then analysed
   for direct (one-to-one) and indirect reciprocity (chains of three or
   more users). The results show that instances of reciprocity are rare,
   and when present often span more than one type of exchange. The
   conclusion is that reciprocity cannot be assumed to be the norm in
   prosocial exchange systems. Practically, design and deployment should
   not be predicated on reciprocity. Furthermore, any means to encourage
   reciprocity should make patterns of exchange visible, and do so across
   hybrid forms of exchange.
OI Harvey, John/0000-0003-4188-1900
ZR 0
TC 0
ZS 0
ZB 0
Z8 0
Z9 0
SN 0747-5632
EI 1873-7692
UT WOS:000523598100039
ER

PT J
AU Dalvi-Esfahani, Mohammad
   Alaedini, Zohre
   Nilashi, Mehrbakhsh
   Samad, Sarminah
   Asadi, Shahla
   Mohammadi, Majid
TI Students' green information technology behavior: Beliefs and personality
   traits
SO JOURNAL OF CLEANER PRODUCTION
VL 257
AR 120406
DI 10.1016/j.jclepro.2020.120406
PD JUN 1 2020
PY 2020
AB Adoption of green information technology (Green IT) as an initiative of
   pro-environmental behavior is quite sparse among Malaysian students. Due
   to the need to integrate personality traits in environmental behavioral
   studies, the current study deriving from the planned behavior theory
   attempts to investigate the influence of attitudinal factors on
   students' pro-ecological behavioral intention to practice Green IT.
   Extremely few studies explored the moderating role of personality traits
   in the context of Green IT adoption and thus this study attempts to fill
   the current research gap. The personality traits of openness,
   agreeableness and conscientiousness were included in the research model
   as moderating variables. A number of 262 pieces of data were collected
   from students. Based on the partial least squares approach and
   bootstrapping method, the results revealed that except social norms,
   other variables greatly influenced the intention to practice Green IT.
   Moreover, the moderating effects analysis showed that the personality
   trait of conscientiousness was the only trait that significantly
   moderated the relationships in the proposed model. (C) 2020 Elsevier
   Ltd. All rights reserved.
RI Nilashi, Mehrbakhsh/AAM-2215-2020; Asadi, Shahla/
OI Nilashi, Mehrbakhsh/0000-0002-2804-3227; Asadi,
   Shahla/0000-0002-8199-2122
Z8 0
ZB 0
ZR 0
TC 0
ZS 0
Z9 0
SN 0959-6526
EI 1879-1786
UT WOS:000522383500106
ER

PT J
AU Giama, E.
   Papadopoulos, A. M.
TI Benchmarking carbon footprint and circularity in production processes:
   The case of stonewool and extruded polysterene
SO JOURNAL OF CLEANER PRODUCTION
VL 257
AR 120559
DI 10.1016/j.jclepro.2020.120559
PD JUN 1 2020
PY 2020
AB The use of construction and building materials is connected with
   important amounts of raw materials as well as energy inputs.
   Construction contributes to integrated building management an issue that
   has been analysed in several research works and projects. In order to
   quantify the environmental impact of a production process it is
   essential to create the inventory analysis of the raw materials used as
   well as the energy consume within the system studied. There are several
   environmental assessment tools developed to evaluate environmental
   impact in connection to economic effectiveness. The rising economic and
   environmental sustainability challenges which the construction sector
   faces as part of the competitive, globalized economy is the reason for
   evaluating the environmental criteria in the decision making process. In
   that sense, decarbonisation and circular economy support the European
   vision for sustainability and clean energy. The goal of this study is to
   benchmark carbon footprint in relation to the system's boundaries.
   Indicators related to carbon emissions and different approaches based on
   system's boundaries (including cradle to grave, cradle to site, cradle
   to gate) have been defined and introduced. Moreover, carbon footprint
   indicators as well as circularity indicators were calculated for
   insulation materials' production process. . Also, efforts to shift
   towards a circular economy are made under real conditions, comparing the
   closed loops to linear flows for the two production processes. Finally,
   the recycling scenario is compared to the linear flow, demonstrating the
   relevance of carbon indicators. One of the key findings of the research
   is that circular economy can be expand in two directions: (a) on a
   single material or process level, one has to establish the availability
   of reliable data that will enable the study from cradle to grave since
   there is a huge variety of building materials and elements that can be
   found (b) on a bigger scale, one has to consider whole systems. In both
   cases a number of parameters such as energy use, raw materials input,
   and operational cost can be affected and improved. (C) 2020 Elsevier
   Ltd. All rights reserved.
ZB 0
TC 0
ZR 0
ZS 0
Z8 0
Z9 0
SN 0959-6526
EI 1879-1786
UT WOS:000522383500044
ER

PT J
AU Xia, Chuyu
   Xiang, Mingtao
   Fang, Kai
   Li, Yan
   Ye, Yanmei
   Shi, Zhou
   Liu, Jingming
TI Spatial-temporal distribution of carbon emissions by daily travel and
   its response to urban form: A case study of Hangzhou, China
SO JOURNAL OF CLEANER PRODUCTION
VL 257
AR 120797
DI 10.1016/j.jclepro.2020.120797
PD JUN 1 2020
PY 2020
AB There is a growing recognition that optimizing urban form can reduce
   road transport-related carbon emissions, particularly in carbon
   emissions by daily travel. In this study, we proposed an improved
   bottom-up approach combining Vehicle Specific Power (VSP) model and
   Enhanced Two-Step Floating Catchment Area (E2SFCA) method to estimate
   the carbon emissions by daily travel. Then, a geographical weighted
   regression (GWR) model considering the urban residential density (RD)
   and land use mix level (LML) of urban form as independent variables was
   employed to explore the relationship between urban form and carbon
   emissions. A typical working day (June 5th of 2017) of Hangzhou was
   chosen as a case study in this paper. The results showed that (1) per
   hour carbon emission in the morning peak period of 6:30 a.m.-9:30 a.m.
   was higher than that in the evening peak of 22:00-24:00 by 33.34%; and
   distribution of the highest carbon emissions was in the eastern,
   northeastern and northwestern parts of Hangzhou; (2) The RD and LML were
   positively and negatively associated with carbon emissions. and the
   coefficients for Ln (RD) and (LML) ranged from 0.29 to 0.70 and from
   -9.01 to -6.06, respectively. (3) The spatial distribution of
   coefficients demonstrated that the highest effects of RD on carbon
   emissions were observed in the central parts of Hangzhou, and those of
   LML on carbon emissions were observed in southern Hangzhou featured by
   industrial parks. This study may provide insights to mitigate carbon
   emissions from daily travel with multiple public policies including
   mixed land-use policies, urban density control and spatial planning. (C)
   2020 Elsevier Ltd. All rights reserved.
RI shi, Zhou/M-7845-2019
OI shi, Zhou/0000-0003-3914-5402
Z8 0
ZR 0
TC 0
ZS 0
ZB 0
Z9 0
SN 0959-6526
EI 1879-1786
UT WOS:000522383500018
ER

PT J
AU Al-Saud, Mamdooh
   Eltamaly, Ali M.
   Mohamed, Mohamed A.
   Kavousi-Fard, Abdollah
TI An Intelligent Data-Driven Model to Secure Intravehicle Communications
   Based on Machine Learning
SO IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS
VL 67
IS 6
BP 5112
EP 5119
DI 10.1109/TIE.2019.2924870
PD JUN 2020
PY 2020
AB The high relying of electric vehicles on either in-vehicle or
   between-vehicle communications can cause big issues in the system. This
   paper is going to mainly address the cyberattack in electric vehicles
   and propose a secured and reliable intelligent framework to avoid
   hackers from penetration into the vehicles. The proposed model is
   constructed based on an improved support vector machine model for
   anomaly detection based on the controller area network bus protocol. In
   order to improve the capabilities of the model for fast malicious attack
   detection and avoidance, a new optimization algorithm based on social
   spider optimization algorithm is developed, which will reinforce the
   training process offline. Also, a two-stage modification method is
   proposed to increase the search ability of the algorithm and avoid
   premature convergence. Last but not least, the simulation results on the
   real datasets reveal the high performance, reliability, and security of
   the proposed model against denial-of-service hacking in the electric
   vehicles.
RI Mohamed, Mohamed/; Eltamaly, Ali/E-6486-2016
OI Mohamed, Mohamed/0000-0001-8700-0270; Eltamaly, Ali/0000-0002-9831-7182
ZR 0
ZB 0
Z8 0
TC 1
ZS 0
Z9 1
SN 0278-0046
EI 1557-9948
UT WOS:000521959100081
ER

PT J
AU Xu, Xiaoxu
   Zhang, Bo
   Zhang, Haiwen
TI UNIQUENESS IN INVERSE ACOUSTIC AND ELECTROMAGNETIC SCATTERING WITH
   PHASELESS NEAR-FIELD DATA AT A FIXED FREQUENCY
SO INVERSE PROBLEMS AND IMAGING
VL 14
IS 3
BP 489
EP 510
DI 10.3934/ipi.2020023
PD JUN 2020
PY 2020
AB This paper is concerned with uniqueness results in inverse acoustic and
   electromagnetic scattering problems with phaseless total-field data at a
   fixed frequency. We use superpositions of two point sources as the
   incident fields at a fixed frequency and measure the modulus of the
   acoustic total-field (called phaseless acoustic near-field data) on two
   spheres containing the scatterers generated by such incident fields on
   the two spheres. Based on this idea, we prove that the impenetrable
   bounded obstacle or the index of refraction of an inhomogeneous medium
   can be uniquely determined from the phaseless acoustic near-field data
   at a fixed frequency. Moreover, the idea is also applied to the
   electromagnetic case, and it is proved that the impenetrable bounded
   obstacle or the index of refraction of an inhomogeneous medium can be
   uniquely determined by the phaseless electric near-field data at a fixed
   frequency, that is, the modulus of the tangential component with the
   orientations e(phi) and e(theta), respectively, of the electric
   total-field measured on a sphere enclosing the scatters and generated by
   superpositions of two electric dipoles at a fixed frequency located on
   the measurement sphere and another bigger sphere with the polarization
   vectors e(phi) and e(theta), respectively. As far as we know, this is
   the first uniqueness result for three-dimensional inverse
   electromagnetic scattering with phaseless near-field data.
ZS 0
ZR 0
TC 0
ZB 0
Z8 0
Z9 0
SN 1930-8337
EI 1930-8345
UT WOS:000521829300005
ER

PT J
AU Bilal, Muhammad
   Oyedele, Lukumon O.
TI Big Data with deep learning for benchmarking profitability performance
   in project tendering
SO EXPERT SYSTEMS WITH APPLICATIONS
VL 147
AR 113194
DI 10.1016/j.eswa.2020.113194
PD JUN 2020
PY 2020
AB A reliable benchmarking system is crucial for the contractors to
   evaluate the profitability performance of project tenders. Existing
   benchmarks are ineffective in the tender evaluation task for three
   reasons. Firstly, these benchmarks are mostly based on the profit
   margins as the only key performance indicator (KPI) while there are
   other KPIs fit to drive the evaluation process. Secondly, these
   benchmarks don't take project context into account, thereby restricts
   their predictive accuracy. And finally, these benchmarks are obtained
   from small subsets of data, making it hard to generalise. As a result,
   estimators cannot probe into tenders to judge the strengths and
   weaknesses of their bids. This advancement is critical for not only
   choosing more lucrative opportunities but also driving negotiations
   during the tendering process.
   This study aims to develop a benchmarking system for tender evaluation
   using Big Data of 1.2 terabytes, comprising 5.7 million cells. A
   holistic list of seventeen (17) KPIs is identified from the email data
   using Text Mining approaches. Besides, eight (8) key project attributes
   are chosen for ensuring contextaware benchmarking using Focused Group
   Interviews (FG1s). At the crux of this work lies the proposition of a
   deep ensemble learner based on the decomposition-integration
   methodology. In the decomposition stage, the model predicts several
   attribute-specific benchmarks for each KPI using our proposed
   contextaware algorithm. In the integration stage, deep neural
   network-based learners are trained to generate final project-sensitive
   KPI benchmark. The learner is deployed in the Spring tool to support the
   tender evaluation of power infrastructure projects. A tender of 60km
   underground cabling project is evaluated using the proposed learner. The
   system spontaneously identified KPIs in the tender that require further
   attention to achieve greater profitability performance. (C) 2020
   Elsevier Ltd. All rights reserved.
ZS 0
ZB 0
Z8 0
TC 0
ZR 0
Z9 0
SN 0957-4174
EI 1873-6793
UT WOS:000521117700033
ER

PT J
AU He, Xinxin
   Cheng, Yuanping
   Hu, Biao
   Wang, Zhenyang
   Wang, Chenghao
   Yi, Minghao
   Wang, Liang
TI Effects of coal pore structure on methane-coal sorption hysteresis: An
   experimental investigation based on fractal analysis and hysteresis
   evaluation
SO FUEL
VL 269
AR 117438
DI 10.1016/j.fuel.2020.117438
PD JUN 1 2020
PY 2020
AB To investigate the effects of coal pore structure on the methane-coal
   sorption hysteresis, six coal samples were collected. The methane-coal
   sorption measurement was performed at 35 degrees C and pressure up to
   5.5 MPa using a high-pressure volumetric analysis system (HPVAS). With
   the help of N-2 physisorption at 77 K and CO2 physisorption at 273 K,
   basic pore properties including specific surface area (SSA), mode
   diameters and pore size distribution (PSD) were obtained through
   classical thermodynamic methods and the advanced density functional
   theory (DFT). A Frechet distance index (FDI) based on the resemblance of
   two curves was proposed to overcome the difficulty in quantitatively
   evaluating the methane-coal sorption hysteresis. Quantified
   heterogeneity of the coal pore structure by five fractal dimensions
   derived from Frenkel-Halsey-Hill model (D-FHH1 and D-FHH2),
   Neimark-Kiselev model (D-NK), Wang-Li model (D-WL) and Sierpinski model
   (D-SPS) was coupled with the FDI for regression analyses. Results
   indicate that increasing SSA and stronger first-layer adsorption energy
   may exacerbate the methane-coal sorption hysteresis, while no
   satisfactory correlation was observed between the methane-coal sorption
   hysteresis and the pore volume. Wider Dubinin-Astakhov PSD and bigger
   mode diameters were found corresponding to smaller FDIs indicating
   reduced methane-coal sorption hysteresis. Correlation between the FDI
   and the fractal dimensions revealed a possible positive correlation
   between the methane-coal sorption hysteresis and the heterogeneity of
   the coal pore structure, especially for D-FHH2 whose applied pore widths
   were 2.78-385 nm.
ZR 0
TC 0
ZB 0
Z8 0
ZS 0
Z9 0
SN 0016-2361
EI 1873-7153
UT WOS:000520021800069
ER

PT J
AU Mahmud, M.S.
   Huang, J.Z.
   Salloum, S.
   Emara, T.Z.
   Sadatdiynov, K.
TI A survey of data partitioning and sampling methods to support big data
   analysis
SO Big Data Mining and Analytics
VL 3
IS 2
BP 85
EP 101
DI 10.26599/BDMA.2019.9020015
PD June 2020
PY 2020
AB Computer clusters with the shared-nothing architecture are the major
   computing platforms for big data processing and analysis. In cluster
   computing, data partitioning and sampling are two fundamental strategies
   to speed up the computation of big data and increase scalability. In
   this paper, we present a comprehensive survey of the methods and
   techniques of data partitioning and sampling with respect to big data
   processing and analysis. We start with an overview of the mainstream big
   data frameworks on Hadoop clusters. The basic methods of data
   partitioning are then discussed including three classical horizontal
   partitioning schemes: range, hash, and random partitioning. Data
   partitioning on Hadoop clusters is also discussed with a summary of new
   strategies for big data partitioning, including the new Random Sample
   Partition (RSP) distributed model. The classical methods of data
   sampling are then investigated, including simple random sampling,
   stratified sampling, and reservoir sampling. Two common methods of big
   data sampling on computing clusters are also discussed: record-level
   sampling and block-level sampling. Record-level sampling is not as
   efficient as block-level sampling on big distributed data. On the other
   hand, block-level sampling on data blocks generated with the classical
   data partitioning methods does not necessarily produce good
   representative samples for approximate computing of big data. In this
   survey, we also summarize the prevailing strategies and related work on
   sampling-based approximation on Hadoop clusters. We believe that data
   partitioning and sampling should be considered together to build
   approximate cluster computing frameworks that are reliable in both the
   computational and statistical respects.
ZB 0
ZR 0
ZS 0
Z8 0
TC 1
Z9 1
SN 2096-0654
UT INSPEC:19414178
ER

PT J
AU Bigorra, Anna Marti
   Isaksson, Ove
   Karlberg, Magnus
TI Semi-autonomous methodology to validate and update customer needs
   database through text data analytics
SO INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT
VL 52
AR UNSP 102073
DI 10.1016/j.ijinfomgt.2020.102073
PD JUN 2020
PY 2020
AB To develop highly competitive products, companies need to understand
   customer needs (CNs) by effectively gathering and analysing customer
   data. With the advances in Information Technology, customer data comes
   not only from surveys and focus groups but also from social media and
   networking sites. Few studies have focused on developing algorithms that
   are devised exclusively to help to understand customer needs from big
   opinion data. Topic mining, aspect-based sentiment analysis and word
   embedding are some of the techniques adopted to identify CNs from text
   data. However, most of them do not consider the possibility that part of
   the customer data analysed is already known by companies. With the aim
   to continuously enhance company understanding of CNs, this paper
   presents an autonomous methodology for automatically classifying a set
   of text data (customer sentences) as referring to known or unknown CN
   statements by the company. For verification purposes, an example
   regarding a set of customer answers from an open survey questionnaire
   regarding the climate system of a car is illustrated. Results indicate
   that the proposed methodology helps companies to validate and update the
   customer need database with an average of 90 % precision and 60 %
   recall.
ZR 0
ZB 0
ZS 0
Z8 0
TC 0
Z9 0
SN 0268-4012
EI 1873-4707
UT WOS:000519969300025
ER

PT J
AU Liu, Zhiyong
   Li, Zipei
TI A blockchain-based framework of cross-border e-commerce supply chain
SO INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT
VL 52
AR UNSP 102059
DI 10.1016/j.ijinfomgt.2019.102059
PD JUN 2020
PY 2020
AB Blockchain technology provides us a new tool to solve the product
   traceability problem in supply chain management. This research focuses
   on the cross-border e-commerce context, to propose a blockchain-based
   framework, and develop a set of corresponding techniques and methods for
   achieving traceable products and transactions in supply chain
   management. A general blockchain-based product traceability framework is
   introduced. This framework is based on a cross-border e-commerce supply
   chain context, incorporating a series of blockchain-based models,
   including multi-chain structure model, data management model and block
   structure model. Several core methods and algorithms are also developed,
   such as information anchoring method, key distribution method,
   information encryption algorithm and anti-counterfeiting method. The
   framework, models and methods form a complete and comprehensive
   solution, which are evaluated by applying to several typical problems
   and attack cases. The case analysis results show that the framework,
   models and methods can successfully deal with key recover problem, and
   protect against clone attack, counterfeit tag attack and counterfeit
   product attack. The effectiveness, extendibility, security,
   implementation and governance issues of applying these solutions are
   also discussed. This research contributes to the theoretical and
   practical literatures on blockchain technology, cross-border e-commerce
   and supply chain management research fields.
ZB 0
TC 1
ZR 0
Z8 0
ZS 0
Z9 1
SN 0268-4012
EI 1873-4707
UT WOS:000519969300012
ER

PT J
AU Upadhyay, Parijat
   Kumar, Anup
TI The intermediating role of organizational culture and internal
   analytical knowledge between the capability of big data analytics and a
   firm's performance
SO INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT
VL 52
AR UNSP 102100
DI 10.1016/j.ijinfomgt.2020.102100
PD JUN 2020
PY 2020
AB Firms are increasingly relying on business insights obtained by
   deploying data analytics. Analytics-driven business decisions have thus
   taken a strategic imperative role for the competitive advantage of a
   firm to endure. The extent and effectiveness through which business
   firms can actually derive benefits by deploying big data-based practices
   requires deep analysis and calls for extensive research. This study
   extends the big data analytics capability (BDAC) model by examining the
   mediatory effects of organizational culture (CL) between internal
   analytical knowledge (KN) and BDAC, as well as the mediating effects of
   BDAC between CL and firm performance. The findings bring into focus that
   CL plays the role of complementary mediation between BDAC and KN to
   positively impact firm performance (FP); BDAC also plays a similar
   mediatory role between CL and the performance of a firm.
ZB 0
ZS 0
ZR 0
TC 0
Z8 0
Z9 0
SN 0268-4012
EI 1873-4707
UT WOS:000519969300038
ER

PT J
AU Wamba, Samuel Fosso
   Queiroz, Maciel M.
TI Blockchain in the operations and supply chain management: Benefits,
   challenges and future research opportunities
SO INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT
VL 52
AR UNSP 102064
DI 10.1016/j.ijinfomgt.2019.102064
PD JUN 2020
PY 2020
AB Blockchain technologies have captured the imagination of scholars,
   managers, and practitioners around the world. It is widely accepted by
   these actors that blockchain is not a buzzword, but a highly disruptive
   technology that is already remodeling the organizations and their supply
   chain business models. Despite the meaningful advance in the last years,
   blockchain applications regarding the operations and supply chain
   management (OSCM) are still in their infancy. Little is known about the
   role of blockchain in terms of operations traceability, as well in areas
   such as e-commerce, agriculture, public services, etc. Therefore, this
   Special Issue seeks to extend our understanding of blockchain
   applications in OSCM and how firms create and capture business value
   with blockchain. To this effect, this Special Issue will provide a
   well-articulated and in-depth discussion of the role of blockchain in
   creating value in the domain of OSCM. Specifically, it is expected that
   more light is shed on how blockchain integrates with and impacts new
   business models, transforms relationships, and improves performance and
   competitive advantage in OSCM. Also, the evolution of blockchain was
   reviewed in order to provide a strong background to the readers. The
   literature review was performed taking into account a bibliometric
   perspective of blockchain-related publications. The review supports the
   importance of this Special Issue by highlighting the urgent needs of
   this topic in this reputable journal. Finally, we provide future
   research directions and a guide for the papers presented in this Special
   Issue.
RI Queiroz, Maciel M./F-1274-2014
OI Queiroz, Maciel M./0000-0002-6025-9191
Z8 0
TC 1
ZB 0
ZR 0
ZS 0
Z9 1
SN 0268-4012
EI 1873-4707
UT WOS:000519969300017
ER

PT J
AU Wong, Lai-Wan
   Leong, Lai-Ying
   Hew, Jun-Jie
   Tan, Garry Wei-Han
   Ooi, Keng-Boon
TI Time to seize the digital evolution: Adoption of blockchain in
   operations and supply chain management among Malaysian SMEs
SO INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT
VL 52
AR UNSP 101997
DI 10.1016/j.ijinfomgt.2019.08.005
PD JUN 2020
PY 2020
AB This study aims to investigate the effects of relative advantage,
   complexity, upper management support, cost, market dynamics, competitive
   pressure and regulatory support on blockchain adoption for operations
   and supply chain management among Small-Medium Enterprises (SMEs) in
   Malaysia. Unlike existing studies that employed linear models with
   Technology Acceptance Model or United Theory of Acceptance and Use of
   Technology that ignores the organisational and environmental factors, we
   adopted the Technology, Organisation and Environment Framework that
   covers the technological dimensions of relative advantage and
   complexity, organisational dimensions of upper management support and
   cost and environmental dimensions of market dynamics, competitive
   pressure and regulatory support. Empirical data from 194 SMEs were
   investigated and ranked using a nonlinear non-compensatory PLS-ANN
   approach. Competitive pressure, complexity, cost and relative have
   significant effects on behavioural intention. Market dynamics,
   regulatory support and upper management support were insignificant
   predictors. SMEs often lack resources for technological investments but
   faces same requirements for streamlining business processes to optimise
   returns and blockchain presents a viable option for SMEs' sustainability
   due to its features of immutability, transparency and security that have
   the potential to revolutionise businesses. This study contributes new
   knowledge to the literature on factors that affect blockchain adoption
   and justifications were discussed accordingly.
RI Hew, Jun-Jie/I-4883-2019; OOI, Keng-Boon/I-4143-2019; Han, Garry Tan Wei/C-6565-2011; Wong, Lai-Wan/
OI Hew, Jun-Jie/0000-0003-4957-1050; OOI, Keng-Boon/0000-0002-3384-1207;
   Han, Garry Tan Wei/0000-0003-2974-2270; Wong,
   Lai-Wan/0000-0003-1961-8452
ZB 0
TC 6
ZR 0
ZS 0
Z8 0
Z9 6
SN 0268-4012
EI 1873-4707
UT WOS:000519969300007
ER

PT J
AU Yong, Binbin
   Shen, Jun
   Liu, Xin
   Li, Fucun
   Chen, Huaming
   Zhou, Qingguo
TI An intelligent blockchain-based system for safe vaccine supply and
   supervision
SO INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT
VL 52
AR UNSP 102024
DI 10.1016/j.ijinfomgt.2019.10.009
PD JUN 2020
PY 2020
AB Immunization is an indispensable mechanism for preventing infectious
   diseases in modern society, and vaccine safety is closely related to
   public health and national security. However, issues such as vaccine
   expiration and vaccine record fraud are still widespread in vaccine
   supply chains. Therefore, an effective management system for the
   supervision of vaccine supply chains is urgently required. As the next
   generation of core technology after the Internet, blockchain is designed
   to build trust mechanisms that can change current information management
   methods. Meanwhile, the development of machine learning technologies
   provides additional ways to analyze the data in information management
   systems. The main objective of this study is to develop a "vaccine
   blockchain" system based on blockchain and machine learning
   technologies. This vaccine blockchain system is designed to support
   vaccine traceability and smart contract functions, and can be used to
   address the problems of vaccine expiration and vaccine record fraud.
   Additionally, the use of machine learning models can provide valuable
   recommendations to immunization practitioners and recipients, allowing
   them to choose better immunization methods and vaccines.
OI Shen, Jun/0000-0002-9403-7140
Z8 0
ZR 0
ZB 0
TC 3
ZS 0
Z9 3
SN 0268-4012
EI 1873-4707
UT WOS:000519969300011
ER

PT J
AU Li Xiangming
   Liu, Meihua
   Zhang, Chengping
TI Technological impact on language anxiety dynamic
SO COMPUTERS & EDUCATION
VL 150
AR 103839
DI 10.1016/j.compedu.2020.103839
PD JUN 2020
PY 2020
AB Insufficient information was generated from the existing literature of
   cross-sectional studies about the changes of language learning anxiety,
   especially in technology-assisted language settings. This paper filled
   the gap by designing a longitudinal study of 10 weeks in which the
   mobile learning apps of Rain Classroom was administered to 158
   postgraduate students in language class. Quantitative results were
   generated, using paired samples T-test and one-way repeated measures
   ANOVA, from the 5-point Likert scale of English Language Class Anxiety
   Scale, 7-point scale recall of anxiety changes across 4 weeks, pre- and
   post-test language performance, combined with the qualitative interview
   transcripts administered before and after the learning process. In
   consistency with prior findings, the study results produced a
   significant decrease in anxiety in general, corroborating the interview
   and the self-recalling measure results. Further, the self-recalled scale
   revealed a more complex pattern of anxiety with the general decreasing
   tendency mixed with the increasing trend between the last two weeks.
   This study implied that the binary approach of anxiety reduction was not
   sufficient for the big picture of fluctuations and variations of
   language anxiety. The combination of language outcome data reinforced
   the explanatory forces than a single-dimensional dataset.
ZB 0
ZS 0
Z8 0
ZR 0
TC 0
Z9 0
SN 0360-1315
EI 1873-782X
UT WOS:000518405100014
ER

PT J
AU Wang, Shouxiang
   Chen, Haiwen
   Wu, Lei
   Wang, Jianfeng
TI A novel smart meter data compression method via stacked convolutional
   sparse auto-encoder
SO INTERNATIONAL JOURNAL OF ELECTRICAL POWER & ENERGY SYSTEMS
VL 118
AR 105761
DI 10.1016/j.ijepes.2019.105761
PD JUN 2020
PY 2020
AB With the wide deployment of smart meters in distribution systems, a new
   challenge emerges for the storage and transmission of huge volume of
   power consumption data collected by smart meters. In this paper, a
   deep-learning-based compression method for smart meter data is proposed
   via stacked convolutional sparse auto-encoder (SCSAE). An efficient and
   lightweight auto-encoder structure is first designed by leveraging the
   unique characteristics of smart meter readings. Specifically, the
   encoder is designed based on 2D separable convolution layers and the
   decoder is based on transposed convolution layers. Compared with the
   existing auto-encoder method and traditional methods, the proposed
   structure is redesigned, and the parameters and reconstruction errors
   are efficiently reduced. In addition, cluster-based indexes are used to
   represent the regularity of power consumption behavior and the
   relationship between electricity consumption behavior and compression
   effect is studied. Case studies illustrate that the proposed method can
   attain significant enhancement in model size, computational efficiency,
   and reconstruction error reduction while maintaining the most abundant
   details. And grouping compression considering users' electricity
   consumption rules can further improve the compression effect.
ZR 0
TC 1
ZS 0
ZB 0
Z8 0
Z9 1
SN 0142-0615
EI 1879-3517
UT WOS:000518691600017
ER

PT J
AU Barredo Arrieta, Alejandro
   Diaz-Rodriguez, Natalia
   Del Ser, Javier
   Bennetot, Adrien
   Tabik, Siham
   Barbado, Alberto
   Garcia, Salvador
   Gil-Lopez, Sergio
   Molina, Daniel
   Benjamins, Richard
   Chatila, Raja
   Herrera, Francisco
TI Explainable Artificial Intelligence (XAI): Concepts, taxonomies,
   opportunities and challenges toward responsible AI
SO INFORMATION FUSION
VL 58
BP 82
EP 115
DI 10.1016/j.inffus.2019.12.012
PD JUN 2020
PY 2020
AB In the last few years, Artificial Intelligence (AI) has achieved a
   notable momentum that, if harnessed appropriately, may deliver the best
   of expectations over many application sectors across the field. For this
   to occur shortly in Machine Learning, the entire community stands in
   front of the barrier of explainability, an inherent problem of the
   latest techniques brought by sub-symbolism (e.g. ensembles or Deep
   Neural Networks) that were not present in the last hype of AI (namely,
   expert systems and rule based models). Paradigms underlying this problem
   fall within the so-called eXplainable AI (XAI) field, which is widely
   acknowledged as a crucial feature for the practical deployment of AI
   models. The overview presented in this article examines the existing
   literature and contributions already done in the field of XAI, including
   a prospect toward what is yet to be reached. For this purpose we
   summarize previous efforts made to define explainability in Machine
   Learning, establishing a novel definition of explainable Machine
   Learning that covers such prior conceptual propositions with a major
   focus on the audience for which the explainability is sought. Departing
   from this definition, we propose and discuss about a taxonomy of recent
   contributions related to the explainability of different Machine
   Learning models, including those aimed at explaining Deep Learning
   methods for which a second dedicated taxonomy is built and examined in
   detail. This critical literature analysis serves as the motivating
   background for a series of challenges faced by XAI, such as the
   interesting crossroads of data fusion and explainability. Our prospects
   lead toward the concept of Responsible Artificial Intelligence, namely,
   a methodology for the large-scale implementation of AI methods in real
   organizations with fairness, model explainability and accountability at
   its core. Our ultimate goal is to provide newcomers to the field of XAI
   with a thorough taxonomy that can serve as reference material in order
   to stimulate future research advances, but also to encourage experts and
   professionals from other disciplines to embrace the benefits of AI in
   their activity sectors, without any prior bias for its lack of
   interpretability.
RI Molina Cabrera, Daniel/F-3230-2010
OI Molina Cabrera, Daniel/0000-0002-4175-2204
Z8 0
TC 4
ZB 0
ZS 0
ZR 0
Z9 4
SN 1566-2535
EI 1872-6305
UT WOS:000516799200007
ER

PT J
AU Venkatesh, V. G.
   Kang, Kai
   Wang, Bill
   Zhong, Ray Y.
   Zhang, Abraham
TI System architecture for blockchain based transparency of supply chain
   social sustainability
SO ROBOTICS AND COMPUTER-INTEGRATED MANUFACTURING
VL 63
AR 101896
DI 10.1016/j.rcim.2019.101896
PD JUN 2020
PY 2020
AB Social sustainability is a major concern in global supply chains for
   protecting workers from exploitation and for providing a safe working
   environment. Although there are stipulated standards to govern supply
   chain social sustainability, it is not uncommon to hear of businesses
   being reported for noncompliance issues. Even reputable firms such as
   Unilever have been criticized for production labor exploitation.
   Consumers now increasingly expect sellers to disclose information on
   social sustainability, but sellers are confronted with the challenge of
   traceability in their multi-tier global supply chains. Blockchain offers
   a promising future to achieve instant traceability in supply chain
   social sustainability. This study develops a system architecture that
   integrates the use of blockchain, internet-of-things (IoT) and big data
   analytics to allow sellers to monitor their supply chain social
   sustainability efficiently and effectively. System implementation cost
   and potential challenges are analyzed before the research is concluded.
OI Kang, Kai/0000-0002-3142-5883; Wang, Bin/0000-0002-3504-8683
ZB 0
TC 1
ZS 0
Z8 0
ZR 0
Z9 1
SN 0736-5845
EI 1879-2537
UT WOS:000514013700005
ER

PT J
AU Dickson, Cameron
   Hypponen, Elina
TI Precision health: a primer for physiotherapists.
SO Physiotherapy
VL 107
BP 66
EP 70
DI 10.1016/j.physio.2019.08.004
PD 2020-Jun
PY 2020
AB Health care provision is changing, and so is the information we use to
   guide decisions related to patient care. Increasingly, health
   practitioners will need to deal with genetics and 'big data' in the
   context of clinical practice. Indeed, commercial packages for consumer
   genetic testing are already widely available, and devices enabling
   self-monitoring of health are in daily use by many of our patients.
   "Precision health" (distinct from "precision medicine") provides a
   model, which allows us to bring our genome together with our external
   environment (lifestyles, societal influences etc.) and eventually, our
   transient internal environment (reflected by 'omics'), to optimise
   disease prevention and care. Such advancements have given rise to a need
   for primary health care clinicians to understand basic genetic and
   precision health concepts. This editorial meets this need, serving as a
   primer by providing the following: an introduction to current primary
   health challenges; description of the key elements of the precision
   health model; an overview of basic genetic, and associated research
   concepts; a snapshot of some clinically pertinent research in the
   context of precision health; and a brief discussion of challenges and
   future directions.
RI Hypponen, Elina/B-2596-2014
OI Hypponen, Elina/0000-0003-3670-9399
ZR 0
ZB 0
Z8 0
ZS 0
TC 0
Z9 0
EI 1873-1465
UT MEDLINE:32026837
PM 32026837
ER

PT J
AU Kooijman, Margit K
   Buining, Elisah M
   Swinkels, Ilse C S
   Koes, Bart W
   Veenhof, Cindy
TI Do therapist effects determine outcome in patients with shoulder pain in
   a primary care physiotherapy setting?
SO Physiotherapy
VL 107
BP 111
EP 117
DI 10.1016/j.physio.2019.08.009
PD 2020-Jun
PY 2020
AB OBJECTIVES: To explore whether a therapist effect exists in
   physiotherapists treating patients with shoulder pain and to identify if
   personality traits of the physiotherapist influences patients outcome.
   DESIGN: Observational cohort study.
   SETTING: Primary care physiotherapy practices.
   PARTICIPANTS: Data on patients with shoulder complaints that started and
   finished treatment between 2009 and 2012 were derived from the NIVEL
   Primary Care Database. Personality traits of the physiotherapist were
   identified using the Big Five Inventory. Data of 2814 patients and 56
   physiotherapists were analysed using multi level linear regression.
   MAIN OUTCOME MEASURE: Severity of complaint was measured on a 10-point
   Likert scale at the start and end of treatment. Change score is used as
   outcome.
   RESULTS: A therapist effect exists in the rehabilitation of patients
   with shoulder complaints in a physiotherapy setting; the physiotherapist
   explained 12% of variance and the personality trait extraversion showed
   a significant association (P=0.03) with change in treatment outcome.
   CONCLUSION: Current explorative study suggests that patients who were
   treated by therapists that tend to be more outgoing and energetic
   achieved better treatment results. Additional studies are needed to
   unravel the interplay between personality traits and other variables of
   importance, like patients' personality traits or psychological factors,
   in treating patients with shoulder complaints.
OI Buining, Elisah/0000-0003-4370-9370
ZB 0
Z8 0
TC 0
ZS 0
ZR 0
Z9 0
EI 1873-1465
UT MEDLINE:32026811
PM 32026811
ER

PT J
AU Taylor, Stephanie
   Bishop, Annette
TI Patient and public beliefs about the role of imaging in the management
   of non-specific low back pain: a scoping review.
SO Physiotherapy
VL 107
BP 224
EP 233
DI 10.1016/j.physio.2019.08.014
PD 2020-Jun
PY 2020
AB BACKGROUND OR CONTEXT: Routine imaging for non-specific low back pain is
   advised against in guidelines yet imaging continues to occur. Patient
   and public beliefs regarding imaging may be a driving factor
   contributing to this.
   OBJECTIVES: To review the current evidence in relation to patient and
   public beliefs regarding imaging for low back pain.
   DATA SOURCES: A systematic scoping review was conducted in databases
   Medline, Embase, Cinahl, Psyc info (inception - Jan 2018).
   STUDY SELECTION: Any method of study including beliefs of adults about
   imaging for non-specific low back pain.
   DATA EXTRACTION AND DATA SYNTHESIS: Descriptive data was extracted and
   patient and public beliefs about imaging for low back pain was analysed
   using conventional qualitative content analysis.
   RESULTS: 12 studies from an initial search finding of 1135 were
   analysed. 3 main themes emerged; (1) The Desire for imaging; (2)
   Influences on patient desire for imaging including (a) clinical
   presentation, (b) past experience and (c)relationships with care
   professionals and (3) Negative consequences of imaging.
   LIMITATIONS: Few qualitative studies were found, all studies were in
   English language, the majority of studies were older than 2003.
   CONCLUSION AND IMPLICATIONS OF KEY FINDINGS: There is little available
   evidence on patient and public beliefs about imaging but what evidence
   there is suggests that imaging is seen as positive in the management of
   low back pain and patient desire for a diagnosis is a big driver of
   this. There is also a suggestion that these beliefs may still be being
   influenced by health care professionals.
OI Taylor, Stephanie/0000-0003-4804-542X; Bishop,
   Annette/0000-0002-9810-7994
TC 0
Z8 0
ZR 0
ZB 0
ZS 0
Z9 0
EI 1873-1465
UT MEDLINE:32026824
PM 32026824
ER

PT J
AU Wang, Ruili
   Weng, Jian
   Zhu, Xiaofeng
TI Deep understanding of big multimedia data
SO NEUROCOMPUTING
VL 391
BP 189
EP 190
DI 10.1016/j.neucom.2019.03.072
PD MAY 28 2020
PY 2020
ZS 0
ZR 0
Z8 0
TC 0
ZB 0
Z9 0
SN 0925-2312
EI 1872-8286
UT WOS:000531729800016
ER

PT J
AU Liu, Pingkuo
   Chu, Penghao
TI Renewables finance and investment: how to improve industry with private
   capital in China
SO JOURNAL OF MODERN POWER SYSTEMS AND CLEAN ENERGY
VL 7
IS 6
BP 1385
EP 1398
DI 10.1007/s40565-018-0465-6
PD NOV 2019
PY 2019
AB One purpose of stimulating financing and investment through private
   capital is to absorb a higher proportion of renewables and promote
   renewable industry development. This paper first reviews the current
   overall situation of renewables financing and investment, and further
   analyzes the policy environment with respect to the development plan,
   regulation and special funds. Based on the analysis of the status quo,
   the paper then discusses the internalities and the externalities that
   have driven the changes of private capital investment in renewable
   energy projects, illustrated by a strengths weaknesses opportunities
   threats (SWOT) analysis. An ideal financing model, public-private
   partnership and distributed energy resources pattern are analyzed to
   identify key arrangements and design proper development schemes for both
   private investors and the government. If China can overcome the defects
   and obstacles in a reasonable and orderly fashion, the financing and
   investment problem of China's renewables industry will be solved in many
   ways. Private capital in the Chinese renewable energy market will bring
   great incentive if the entire industry can select some promising
   sub-industries in the renewables sector and choose some appropriate
   operation modes.
OI Liu, Po-Yu/0000-0001-8006-4917; Yang, Qin/0000-0002-9926-1723; Yang,
   Chao-Tung/0000-0002-9579-4426
ZB 0
Z8 0
ZR 0
ZS 0
TC 5
Z9 5
SN 2196-5625
EI 2196-5420
UT WOS:000504342900002
PM 30395737
ER

PT J
AU Pasupa, Kitsuchart
   Rathasamuth, Wanthanee
   Tongsima, Sissades
TI Discovery of significant porcine SNPs for swine breed identification by
   a hybrid of information gain, genetic algorithm, and frequency feature
   selection technique.
SO BMC bioinformatics
VL 21
IS 1
BP 216
EP 216
DI 10.1186/s12859-020-3471-4
PD 2020 May 26
PY 2020
AB BACKGROUND: The number of porcine Single Nucleotide Polymorphisms (SNPs)
   used in genetic association studies is very large, suitable for
   statistical testing. However, in breed classification problem, one needs
   to have a much smaller porcine-classifying SNPs (PCSNPs) set that could
   accurately classify pigs into different breeds. This study attempted to
   find such PCSNPs by using several combinations of feature selection and
   classification methods. We experimented with different combinations of
   feature selection methods including information gain, conventional as
   well as modified genetic algorithms, and our developed frequency feature
   selection method in combination with a common classification method,
   Support Vector Machine, to evaluate the method's performance.
   Experiments were conducted on a comprehensive data set containing SNPs
   from native pigs from America, Europe, Africa, and Asia including
   Chinese breeds, Vietnamese breeds, and hybrid breeds from Thailand.
   RESULTS: The best combination of feature selection methods-information
   gain, modified genetic algorithm, and frequency feature selection
   hybrid-was able to reduce the number of possible PCSNPs to only 1.62%
   (164 PCSNPs) of the total number of SNPs (10,210 SNPs) while maintaining
   a high classification accuracy (95.12%). Moreover, the near-identical
   performance of this PCSNPs set to those of bigger data sets as well as
   even the entire data set. Moreover, most PCSNPs were well-matched to a
   set of 94 genes in the PANTHER pathway, conforming to a suggestion by
   the Porcine Genomic Sequencing Initiative.
   CONCLUSIONS: The best hybrid method truly provided a sufficiently small
   number of porcine SNPs that accurately classified swine breeds.
ZR 0
TC 0
ZB 0
ZS 0
Z8 0
Z9 0
EI 1471-2105
UT MEDLINE:32456608
PM 32456608
ER

PT J
AU Sung, Joseph J Y
   Poon, Nicholas C H
TI Artificial intelligence in gastroenterology: where are we heading?
SO Frontiers of medicine
DI 10.1007/s11684-020-0742-4
PD 2020-May-26
PY 2020
AB Artificial intelligence (AI) is coming to medicine in a big wave. From
   making diagnosis in various medical conditions, following the latest
   advancements in scientific literature, suggesting appropriate therapies,
   to predicting prognosis and outcome of diseases and conditions, AI is
   offering unprecedented possibilities to improve care for patients.
   Gastroenterology is a field that AI can make a significant impact. This
   is partly because the diagnosis of gastrointestinal conditions relies a
   lot on image-based investigations and procedures (endoscopy and
   radiology). AI-assisted image analysis can make accurate assessment and
   provide more information than conventional analysis. AI integration of
   genomic, epigenetic, and metagenomic data may offer new classifications
   of gastrointestinal cancers and suggest optimal personalized treatments.
   In managing relapsing and remitting diseases such as inflammatory bowel
   disease, irritable bowel syndrome, and peptic ulcer bleeding, convoluted
   neural network may formulate models to predict disease outcome,
   enhancing treatment efficacy. AI and surgical robots can also assist
   surgeons in conducting gastrointestinal operations. While the
   advancement and new opportunities are exciting, the responsibility and
   liability issues of AI-assisted diagnosis and management need much
   deliberations.
ZR 0
TC 0
ZS 0
Z8 0
ZB 0
Z9 0
EI 2095-0225
UT MEDLINE:32458189
PM 32458189
ER

PT J
AU Katapally, Tarun R
TI A Global Digital Citizen Science Policy to Tackle Pandemics Like
   COVID-19.
SO Journal of medical Internet research
VL 22
IS 5
BP e19357
EP e19357
DI 10.2196/19357
PD 2020 May 26
PY 2020
AB The coronavirus disease (COVID-19) pandemic is an extremely complex
   existential threat that requires cohesive societal effort to address
   health system inefficiencies. When our society has faced existential
   crises in the past, we have banded together by using the technology at
   hand to overcome them. The COVID-19 pandemic is one such threat that
   requires not only a cohesive effort, but also enormous trust to follow
   public health guidelines, maintain social distance, and share
   necessities. However, are democratic societies with civil liberties
   capable of doing this? Mobile technology has immense potential for
   addressing pandemics like COVID-19, as it gives us access to big data in
   terms of volume, velocity, veracity, and variety. These data are
   particularly relevant to understand and mitigate the spread of pandemics
   such as COVID-19. In order for such intensive and potentially intrusive
   data collection measures to succeed, we need a cohesive societal effort
   with full buy-in from citizens and their representatives. This article
   outlines an evidence-based global digital citizen science policy that
   provides the theoretical and methodological foundation for ethically
   sourcing big data from citizens to tackle pandemics such as COVID-19.
Z8 0
ZS 0
ZR 0
ZB 0
TC 0
Z9 0
EI 1438-8871
UT MEDLINE:32408267
PM 32408267
ER

PT J
AU Stepanovic, Srboljub
   Georgakarakos, Georgios
   Holmbacka, Simon
   Lilius, Johan
TI An efficient model for quantifying the interaction between structural
   properties of software and hardware in the ARM big.LITTLE architecture
SO CONCURRENCY AND COMPUTATION-PRACTICE & EXPERIENCE
VL 32
IS 10
SI SI
AR e5230
DI 10.1002/cpe.5230
PD MAY 25 2020
PY 2020
AB Heterogeneous architectures offer the opportunity to achieve high
   performance and energy efficiency by selecting appropriate cores for the
   execution of ever-changing software applications. Appropriate core
   selection depends on the interaction between the structural properties
   of the software and the hardware that influences the performance of the
   software. We propose a model for efficient core selection when executing
   software on ARM's big.LITTLE heterogeneous architecture. It features a
   metric based on the correlation between the performance and the number
   of last-level data cache (LLC) misses on a big and a LITTLE core.
   Additionally, our model defines a soft threshold in terms of the number
   of LLC misses, which determines efficient core selection. We verify the
   model using stress and variable workload benchmarks as well as two
   popular high-throughput applications for mutlicore targets, namely, HEVC
   and LDPC decoders, profiled with X-Mem, Linux perf, and PMCTrack dynamic
   tools. Results show that our model can be used for efficient core
   selection with a relatively small error probability.
TC 0
ZB 0
ZR 0
ZS 0
Z8 0
Z9 0
SN 1532-0626
EI 1532-0634
UT WOS:000528553500006
ER

PT J
AU Hernigou, Jacques
   Morel, Xavier
   Callewier, Antoine
   Bath, Olivier
   Hernigou, Philippe
TI Staying home during "COVID-19" decreased fractures, but trauma did not
   quarantine in one hundred and twelve adults and twenty eight children
   and the "tsunami of recommendations" could not lockdown twelve elective
   operations.
SO International orthopaedics
DI 10.1007/s00264-020-04619-5
PD 2020-May-25
PY 2020
AB PURPOSE: The current pandemic caused by COVID-19 is the biggest
   challenge for national health systems for a century. While most medical
   resources are allocated to treat COVID-19 patients, fractures still need
   to be treated, as some patients with non-deferrable pathologies. The aim
   of this paper is to report the early experience of an integrated team of
   orthopaedic surgeons during this period.
   MATERIAL AND METHODS: This is a mono-geographic, observational,
   retrospective, descriptive study. We collected data from the beginning
   of the epidemic (1 March 2020), during the pandemic lockdown period
   (declared in the country on March 16, 2020) until the end of our study
   period on April 15, 2020. All the 140 patients presented to the
   Emergency Department of the hospital during this period with a diagnosis
   of fracture, or trauma (sprains, dislocations, wounds) were included in
   the cohort. In addition, 12 patients needing hospitalization for
   planning a non-deferrable elective surgical treatment were included. A
   group of patients from the two same hospitals and treated during the
   same period (1st March 2018 to April 15, 2018) but previously was used
   as control.
   RESULTS: Of these 152 patients (mean age 45.5 years; range 1 to 103),
   100 underwent a surgical procedure and 52 were managed non-operatively.
   Twenty-eight were children and 124 were adults. The COVID-19 diagnosis
   was confirmed for four patients. The frequency of patients with
   confirmed COVID-19 diagnosis among this population treated in emergency
   was ten fold higher (2.6%; 4 among 152) than in the general population
   (0.30%) of the country. The mortality rate for patients with surgery was
   2% (2 of 100 patients) and 50% (2 of 4) for those older than 60 years
   with COVID-19; it was null for patients who were managed
   non-operatively. As compared to the year 2018, the number of patients
   seen with trauma had decreased of 32% during the epidemic.
   CONCLUSION: Staying home during the COVID-19 pandemic decreased trauma
   frequency of 32%. The structural organization in our hospital allowed us
   to reduce the time to surgery and ultimately hospital stay, thereby
   maximizing the already stretched medical resources available to treat
   all the patients who needed orthopedic care during this period.
OI Hernigou, Jacques/0000-0001-9402-6401
Z8 0
ZB 0
TC 0
ZS 0
ZR 0
Z9 0
EI 1432-5195
UT MEDLINE:32451655
PM 32451655
ER

PT J
AU Gattellari, Melina
   Goumas, Chris
   Jalaludin, Bin
   Worthington, John M
TI Population-based stroke surveillance using big data: state-wide
   epidemiological trends in admissions and mortality in New South Wales,
   Australia.
SO Neurological research
BP 1
EP 10
DI 10.1080/01616412.2020.1766860
PD 2020-May-25
PY 2020
AB OBJECTIVES: Epidemiological trends for major causes of death and
   disability, such as stroke, may be monitored using administrative data
   to guide public health initiatives and service delivery.
   METHODS: We calculated admissions rates for ischaemic stroke,
   intracerebral haemorrhage and subarachnoid haemorrhage between 1 January
   2005 and December 31st, 2013 and rates of 30-day mortality and 365-day
   mortality in 30-day survivors to 31 December 2014 for patients aged
   15years or older from New South Wales, Australia. Annual Average
   Percentage Change in rates was estimated using negative binomial
   regression.
   RESULTS: Of 81,703 eligible admissions, 64,047 (78.4%) were ischaemic
   strokes and 13,302 (16.3%) and 4,778 (5.8%) were intracerebral and
   subarachnoid haemorrhages, respectively. Intracerebral haemorrhage
   admissions significantly declined by an average of 2.2% annually (95%
   Confidence Interval=-3.5% to -0.9%) (p<0.001). Thirty-day mortality
   rates significantly declined for ischaemic stroke (Average Percentage
   Change -2.9%, 95% Confidence Interval=-5.2% to -1.0%) (p=0.004) and
   subarachnoid haemorrhage (Average Percentage Change=-2.6%, 95%
   Confidence Interval=-4.8% to -0.2%) (p=0.04). Mortality at 365-days
   amongst 30-day survivors of ischaemic stroke and intracerebral
   haemorrhage was stable over time and increased in subarachnoid
   haemorrhage (Annual Percentage Change 6.2%, 95% Confidence
   Interval=-0.1% to 12.8%), although not significantly (p=0.05).
   DISCUSSION: Improved prevention may have underpinned declining
   intracerebral haemorrhage rates while survival gains suggest that
   innovations in care are being successfully translated. Mortality in
   patients surviving the acute period is unchanged and may be increasing
   for subarachnoid haemorrhage warranting investment in post-discharge
   care and secondary prevention.
ZS 0
ZR 0
Z8 0
TC 0
ZB 0
Z9 0
EI 1743-1328
UT MEDLINE:32449879
PM 32449879
ER

PT J
AU David, Fabrice P A
   Litovchenko, Maria
   Deplancke, Bart
   Gardeux, Vincent
TI ASAP 2020 update: an open, scalable and interactive web-based portal for
   (single-cell) omics analyses.
SO Nucleic acids research
DI 10.1093/nar/gkaa412
PD 2020-May-25
PY 2020
AB Single-cell omics enables researchers to dissect biological systems at a
   resolution that was unthinkable just 10 years ago. However, this
   analytical revolution also triggered new demands in 'big data'
   management, forcing researchers to stay up to speed with increasingly
   complex analytical processes and rapidly evolving methods. To render
   these processes and approaches more accessible, we developed the
   web-based, collaborative portal ASAP (Automated Single-cell Analysis
   Portal). Our primary goal is thereby to democratize single-cell omics
   data analyses (scRNA-seq and more recently scATAC-seq). By taking
   advantage of a Docker system to enhance reproducibility, and novel
   bioinformatics approaches that were recently developed for improving
   scalability, ASAP meets challenging requirements set by recent cell
   atlasing efforts such as the Human (HCA) and Fly (FCA) Cell Atlas
   Projects. Specifically, ASAP can now handle datasets containing millions
   of cells, integrating intuitive tools that allow researchers to
   collaborate on the same project synchronously. ASAP tools are versioned,
   and researchers can create unique access IDs for storing complete
   analyses that can be reproduced or completed by others. Finally, ASAP
   does not require any installation and provides a full and modular
   single-cell RNA-seq analysis pipeline. ASAP is freely available at
   https://asap.epfl.ch.
ZS 0
Z8 0
ZR 0
ZB 0
TC 0
Z9 0
EI 1362-4962
UT MEDLINE:32449934
PM 32449934
ER

PT J
AU Santi, Daniele
   Spaggiari, Giorgia
   Casonati, Andrea
   Casarini, Livio
   Grassi, Roberto
   Vecchi, Barbara
   Roli, Laura
   De Santis, Maria Cristina
   Orlando, Giovanna
   Gravotta, Enrica
   Baraldi, Enrica
   Setti, Monica
   Trenti, Tommaso
   Simoni, Manuela
TI Multilevel approach to male fertility by machine learning highlights a
   hidden link between haematological and spermatogenetic cells.
SO Andrology
DI 10.1111/andr.12826
PD 2020-May-25
PY 2020
AB BACKGROUND: Male infertility represents a complex clinical condition
   requiring an accurate multilevel assessment, in which machine learning
   (ML) technology, combining large data series in nonlinear and highly
   interactive ways, could be innovatively applied.
   METHODS: A longitudinal, observational, retrospective, big data study
   was carried out, applying for the first time the ML in the context of
   male infertility. A large database including all semen samples collected
   between 2010 and 2016 was generated, together with blood biochemical
   examinations, environmental temperature and air pollutants exposure.
   First, the database was analysed with principal component analysis (PCA)
   and multivariable linear regression analyses. Second, classification
   analyses were performed, in which patients were a priori classified
   according to semen parameters. Third, ML algorithms were applied in a
   training phase (80% of the entire database) and in a tuning phase (20%
   of the dataset). Finally, conventional statistical analyses were applied
   considering semen parameters and those other variables extracted during
   ML.
   RESULTS: The final database included 4,239 patients, aggregating semen
   analyses, blood and environmental parameters. Classification analyses
   were able to recognize oligozoospermic, teratozoospermic,
   asthenozoospermic and patients with altered semen parameters (0.58
   accuracy, 0.58 sensitivity and 0.57 specificity). ML algorithms detected
   three haematological variables, i.e. lymphocytes number, erythrocyte
   distribution and mean globular volume, significantly related to semen
   parameters (0.69 accuracy, 0.78 sensitivity and 0.41 specificity).
   CONCLUSION: This is the first ML application to male fertility,
   detecting potential mathematical algorithms able to describe patients'
   semen characteristics changes. In this setting, a possible hidden link
   between testicular and haematopoietic tissues was suggested, according
   to their similar proliferative properties.
RI Santi, Daniele/J-7005-2018
OI Santi, Daniele/0000-0001-6607-7105
Z8 0
TC 0
ZR 0
ZB 0
ZS 0
Z9 0
EI 2047-2927
UT MEDLINE:32449608
PM 32449608
ER

PT J
AU Camarillo, Henry
   Munoz, Martha M
TI Weak relationships between swimming morphology and water depth in
   wrasses and parrotfish belie multiple selective demands on form-function
   evolution.
SO Integrative and comparative biology
DI 10.1093/icb/icaa041
PD 2020-May-25
PY 2020
AB Mechanical tradeoffs in performance are predicted to sculpt
   macroevolutionary patterns of morphological diversity across
   environmental gradients. Water depth shapes the amount of wave energy
   organisms experience, which should result in evolutionary tradeoffs
   between speed and maneuverability in fish swimming morphology. Here, we
   tested whether morphological evolution would reflect functional
   tradeoffs in swimming performance in 131 species of wrasses and
   parrotfish (Family: Labridae) across a water depth gradient. We found
   that maximum water depth predicts variation in pectoral fin aspect ratio
   (AR) in wrasses, but not in parrotfish. Shallow-water wrasses exhibit
   wing-like pectoral fins that help with 'flapping', which allows more
   efficient swimming at faster speeds. Deeper water species, in contrast,
   exhibit more paddle-like pectoral fins associated with enhanced
   maneuverability at slower speeds. Functional morphology responds to a
   number of different, potentially contrasting selective pressures.
   Furthermore, many-to-one mapping may release some traits from selection
   on performance at the expense of others. As such, deciphering the
   signatures of mechanical tradeoffs on phenotypic evolution will require
   integrating multiple aspects of ecological and morphological variation.
   As the field of evolutionary biomechanics moves into the era of big
   data, we will be uniquely poised to disentangle the intrinsic and
   extrinsic predictors of functional diversity.
TC 0
Z8 0
ZB 0
ZS 0
ZR 0
Z9 0
EI 1557-7023
UT MEDLINE:32449771
PM 32449771
ER

PT J
AU Ganse, Bergita
   Drey, Michael
   Hildebrand, Frank
   Knobe, Matthias
   Degens, Hans
TI Performance declines are accelerated in the oldest-old track and field
   athletes 80 to 94 years of age.
SO Rejuvenation research
DI 10.1089/rej.2020.2337
PD 2020-May-25
PY 2020
AB Physical performance declines with age, even in exercising, healthy
   individuals without major illnesses or orthopaedic issues. The rate of
   performance decline is often reported to accelerate after the age of 70
   years, but almost no data are available on performance in the fittest
   oldest-old. To assess their rate of decline in performance, the biggest
   dataset of track and field athletes ≥80 years (1567 results) ever
   published was generated for different disciplines from German athletics
   Federations including 1997-2019. Performance at age 80 of athletes still
   participating at age 85 was compared to those who discontinued. Only one
   out of every 22 athletes competing at age 80 still competed at age 90.
   The performance decline was more than three times as steep in athletes
   ≥80 (on average 1.62%/year, men: 100m R=0.31, p<0.001; 200m R=0.17,
   p=0.037; long jump R=-0,37, p<0.001; shot put R=-0.32, p<0.001; discus
   R=-0.34, p<0.001; javelin R=-0.43, p<0.001; women: shot put R=-0.24,
   p=0.017; discus R=-0.33, p=0.010) compared to athletes 30-69 years
   (0.46%/year), and accelerated at an average of 67 years. This
   accelerated decline was most pronounced in the sprint disciplines and
   lowest in the throws. Performance at age 80 was similar in athletes
   still participating at age 85 to those who discontinued, and the
   variability in results was decreased after age 90. In conclusion,
   physical performance declines more than three times as fast after around
   the age of 67 years compared to before. This was particularly the case
   for sprinting, but was not a result of dropout of poorer performing
   athletes.
TC 0
ZB 0
Z8 0
ZS 0
ZR 0
Z9 0
EI 1557-8577
UT MEDLINE:32449641
PM 32449641
ER

PT J
AU Wyatt, David
   Lampon, Scott
   McKevitt, Christopher
TI Delivering healthcare's 'triple aim': electronic health records and the
   health research participant in the UK National Health Service.
SO Sociology of health & illness
DI 10.1111/1467-9566.13101
PD 2020-May-25
PY 2020
AB The UK National Health Service (NHS) is changing. Consecutive UK
   industrial strategies have supported the shift from an NHS that provides
   free-at-point-of-delivery healthcare to one that also facilitates
   research. Said to promote healthcare's triple aim of 'better health,
   better healthcare, and lower cost' (Wachter, 2016, 3), the digitisation
   of patient records is a core part in opening routine aspects of the
   health system to potential research. In this paper, we thematically
   analyse 11 policy documents and ask, how does the NHS discuss its
   decision to digitise patient records and what are the implications of
   such practices on the citizen? We document how (1) digitisation is
   presented as a collective endeavour for patients and NHS professionals,
   offering new possibilities for patients to participate in their own
   health and that of the population through research and, (2) digitisation
   contributes to the building of an efficient health system. Through this
   analysis we reflect on how discussions of digitisation present
   uncritically the potential of Electronic Health Records and big data
   analytics to improve care and generate wealth through research, and
   reconfigure patienthood, by placing research participation as a routine
   part of accessing NHS healthcare.
ZR 0
Z8 0
TC 0
ZB 0
ZS 0
Z9 0
EI 1467-9566
UT MEDLINE:32449794
PM 32449794
ER

PT J
AU Matos, Manuel J. B.
   Pina, Ana S.
   Roque, A. C. A.
TI Rational design of affinity ligands for bioseparation
SO JOURNAL OF CHROMATOGRAPHY A
VL 1619
AR 460871
DI 10.1016/j.chroma.2020.460871
PD MAY 24 2020
PY 2020
AB Affinity adsorbents have been the cornerstone in protein purification.
   The selective nature of the molecular recognition interactions
   established between an affinity ligands and its target provide the basis
   for efficient capture and isolation of proteins. The plethora of
   affinity adsorbents available in the market reflects the importance of
   affinity chromatography in the bioseparation industry. Ligand discovery
   relies on the implementation of rational design techniques, which
   provides the foundation for the engineering of novel affinity ligands.
   The main goal for the design of affinity ligands is to discover or
   improve functionality, such as increased stability or selectivity.
   However, the methodologies must adapt to the current needs, namely to
   the number and diversity of biologicals being developed, and the
   availability of new tools for big data analysis and artificial
   intelligence. In this review, we offer an overview on the development of
   affinity ligands for bioseparation, including the evolution of rational
   design techniques, dating back to the years of early discovery up to the
   current and future trends in the field. (C) 2020 Elsevier B.V. All
   rights reserved.
CT International Symposium of the
   French-Speaking-Association-for-Separation-Sciences (APSEP)
CY MAR, 2019
CL Paris, FRANCE
SP French Speaking Assoc Separat Sci
RI Pina, Ana/H-5876-2013; Matos, Manuel/R-4434-2017; Roque, Ana Cecilia/G-5513-2012
OI Pina, Ana/0000-0001-9729-0371; Matos, Manuel/0000-0001-8711-3101; Roque,
   Ana Cecilia/0000-0002-4586-3024
ZR 0
ZS 0
ZB 0
Z8 0
TC 1
Z9 1
SN 0021-9673
EI 1873-3778
UT WOS:000530685300001
PM 32044126
ER

PT J
AU Phan, Lynn
   Yu, Weijun
   Keralis, Jessica M
   Mukhija, Krishay
   Dwivedi, Pallavi
   Brunisholz, Kimberly D
   Javanmardi, Mehran
   Tasdizen, Tolga
   Nguyen, Quynh C
TI Google Street View Derived Built Environment Indicators and Associations
   with State-Level Obesity, Physical Activity, and Chronic Disease
   Mortality in the United States.
SO International journal of environmental research and public health
VL 17
IS 10
DI 10.3390/ijerph17103659
PD 2020 May 22
PY 2020
AB Previous studies have demonstrated that there is a high possibility that
   the presence of certain built environment characteristics can influence
   health outcomes, especially those related to obesity and physical
   activity. We examined the associations between select neighborhood built
   environment indicators (crosswalks, non-single family home buildings,
   single-lane roads, and visible wires), and health outcomes, including
   obesity, diabetes, cardiovascular disease, and premature mortality, at
   the state level. We utilized 31,247,167 images collected from Google
   Street View to create indicators for neighborhood built environment
   characteristics using deep learning techniques. Adjusted linear
   regression models were used to estimate the associations between
   aggregated built environment indicators and state-level health outcomes.
   Our results indicated that the presence of a crosswalk was associated
   with reductions in obesity and premature mortality. Visible wires were
   associated with increased obesity, decreased physical activity, and
   increases in premature mortality, diabetes mortality, and cardiovascular
   mortality (however, these results were not significant). Non-single
   family homes were associated with decreased diabetes and premature
   mortality, as well as increased physical activity and park and
   recreational access. Single-lane roads were associated with increased
   obesity and decreased park access. The findings of our study
   demonstrated that built environment features may be associated with a
   variety of adverse health outcomes.
ZS 0
ZB 0
Z8 0
TC 0
ZR 0
Z9 0
EI 1660-4601
UT MEDLINE:32456114
PM 32456114
ER

PT J
AU Goyal, Lalit Mohan
   Mittal, Mamta
   Kaushik, Ranjeeta
   Verma, Amit
   Kaur, Iqbaldeep
   Roy, Sudipta
   Kim, Tai-Hoon
TI Improved ECG Watermarking Technique Using Curvelet Transform.
SO Sensors (Basel, Switzerland)
VL 20
IS 10
DI 10.3390/s20102941
PD 2020 May 22
PY 2020
AB Hiding data in electrocardiogram signals are a big challenge due to the
   embedded information that can hamper the accuracy of disease detection.
   On the other hand, hiding data into ECG signals provides more security
   for, and authenticity of, the patient's data. Some recent studies used
   non-blind watermarking techniques to embed patient information and data
   of a patient into ECG signals. However, these techniques are not robust
   against attacks with noise and show a low performance in terms of
   parameters such as peak signal to noise ratio (PSNR), normalized
   correlation (NC), mean square error (MSE), percentage residual
   difference (PRD), bit error rate (BER), structure similarity index
   measure (SSIM). In this study, an improved blind ECG-watermarking
   technique is proposed to embed the information of the patient's data
   into the ECG signals using curvelet transform. The Euclidean distance
   between every two curvelet coefficients was computed to cluster the
   curvelet coefficients and after this, data were embedded into the
   selected clusters. This was an improvement not only in terms of
   extracting a hidden message from the watermarked ECG signals, but also
   robust against image-processing attacks. Performance metrics of SSIM,
   NC, PSNR and BER were used to measure the superiority of presented work.
   KL divergence and PRD were also used to reveal data hiding in curvelet
   coefficients of ECG without disturbing the original signal. The
   simulation results also demonstrated that the clustering method in the
   curvelet domain provided the best performance-even when the hidden
   messages were large size.
TC 0
Z8 0
ZB 0
ZS 0
ZR 0
Z9 0
EI 1424-8220
UT MEDLINE:32455935
PM 32455935
ER

PT J
AU Barquin, Miguel
   Calvo, Virginia
   Garcia-Garcia, Francisco
   Nunez, Beatriz
   Sanchez-Herrero, Estela
   Serna-Blasco, Roberto
   Auglyte, Milda
   Carcereny, Enric
   Rodriguez-Abreu, Delvys
   Lopez Castro, Rafael
   Guirado, Maria
   Camps, Carlos
   Bosch-Barrera, Joaquin
   Massuti, Bartomeu
   Ortega, Ana Laura
   Del Barco, Edel
   Gonzalez-Larriba, Jose Luis
   Aguiar, David
   Garcia-Campelo, Rosario
   Domine, Manuel
   Agraso, Sara
   Sala, M Angeles
   Oramas, Juana
   Bernabe, Reyes
   Blanco, Remei
   Parejo, Consuelo
   Cruz, Alberto
   Menasalvas, Ernestina
   Royuela, Ana
   Romero, Atocha
   Provencio, Mariano
TI Sex is a strong prognostic factor in stage IV non-small-cell lung cancer
   patients and should be considered in survival rate estimation.
SO Cancer epidemiology
VL 67
BP 101737
EP 101737
DI 10.1016/j.canep.2020.101737
PD 2020-May-22
PY 2020
AB BACKGROUND: Biological differences between the sexes have a major impact
   on disease and treatment outcome. In this paper, we evaluate the
   prognostic value of sex in stage IV non-small-cell lung cancer (NSCLC)
   in the context of routine clinical data, and compare this information
   with other external datasets.
   METHODS: Clinical data from stage IV NSCLC patients from Hospital Puerta
   de Hierro (HPH) were retrieved from electronic health records using big
   data analytics (N = 397). In addition, data from the Spanish Lung Cancer
   Group (GECP) Tumor Registry (N = 1382) and from a published study
   available from the cBioPortal (MSK) (N = 601) were analyzed. Survival
   curves were estimated using the Kaplan-Meier method. A Cox proportional
   hazards regression model was used to assess the prognostic value of sex.
   A meta-analysis to compare the outcome for males and females in terms of
   overall survival (OS) and progression free survival (PFS) was performed.
   RESULTS: The median OS time was 12 months for males and 19 months for
   females (overall HR = 0.77; 95% CI: 0.68-0.87; P < 0.001). Similarly,
   females with stage IV NSCLC harboring an EGFR-sensitizing mutation lived
   significantly longer than males (median OS: males, 19 months; females,
   32 months) with a lower risk of death compared with males (overall HR =
   0.75; 95% CI: 0.67-0.84). In addition, female patients benefited more
   from EGFR inhibitors in terms of PFS and OS (overall HR = 0.45; 95% CI:
   0.32-0.64, and HR = 0.62; 95% CI: 0.48-0.80, respectively). Median PFS
   was 21 months in females and 12 months in males (P < 0.001).
   CONCLUSIONS: Using routine clinical data we confirmed the previous
   finding that among stage IV NSCLC patients, females had a significantly
   better prognosis than males. The effect size of the sex was notable,
   highlighting the fact that survival rates are usually estimated and
   patients are generally managed without considering the sexes separately,
   which may lead to suboptimal results.
ZR 0
Z8 0
ZS 0
TC 0
ZB 0
Z9 0
EI 1877-783X
UT MEDLINE:32450544
PM 32450544
ER

PT J
AU Lugo, Alessandra
   Edvall, Niklas K
   Lazar, Andra
   Mehraei, Golbarg
   Lopez-Escamez, Jose-Antonio
   Bulla, Jan
   Uhlen, Inger
   Canlon, Barbara
   Gallus, Silvano
   Cederroth, Christopher R
TI Relationship between headaches and tinnitus in a Swedish study.
SO Scientific reports
VL 10
IS 1
BP 8494
EP 8494
DI 10.1038/s41598-020-65395-1
PD 2020 May 22
PY 2020
AB The heterogeneity of tinnitus is likely accounting for the lack of
   effective treatment approaches. Headaches have been related to tinnitus,
   yet little is known on how headaches impact tinnitus. We use
   cross-sectional data from the Swedish Tinnitus Outreach Project to i)
   evaluate the association between headaches and tinnitus (n=1,984 cases
   and 1,661 controls) and ii) investigate the phenotypic characteristics
   of tinnitus subjects with tinnitus (n=660) or without (n=1,879)
   headaches. In a multivariable logistic regression model, headache was
   significantly associated with any tinnitus (odds ratio, OR=2.61) and
   more so with tinnitus as a big problem (as measured by the tinnitus
   functional index, TFI≥48; OR=5.63) or severe tinnitus (using the
   tinnitus handicap inventory, THI≥58; OR=4.99). When focusing on subjects
   with tinnitus, the prevalence of headaches was 26% and reached 40% in
   subjects with severe tinnitus. A large number of socioeconomic,
   phenotypic and psychological characteristics differed between headache
   and non-headache subjects with any tinnitus. With increasing tinnitus
   severity, fewer differences were found, the major ones being vertigo,
   neck pain and other pain syndromes, as well as stress and anxiety. Our
   study suggests that headaches could contribute to tinnitus distress and
   potentially its severity.
ZB 0
Z8 0
TC 0
ZR 0
ZS 0
Z9 0
EI 2045-2322
UT MEDLINE:32444677
PM 32444677
ER

PT J
AU Huang, Mingfeng
   Liu, Anfeng
   Xiong, Neal N.
   Wang, Tian
   Vasilakos, Athanasios V.
TI An effective service-oriented networking management architecture for
   5G-enabled internet of things
SO COMPUTER NETWORKS
VL 173
AR 107208
DI 10.1016/j.comnet.2020.107208
PD MAY 22 2020
PY 2020
AB The development of a 5G-enabled Internet of Things has led to a dramatic
   increase in network traffic load, which has presented tremendous
   challenges to network management. In this paper, a service-oriented
   network architecture is proposed to support the effective management of
   5G-enabled IoT systems. This architecture effectively reduces the
   traffic load and simplifies network management by introducing a service
   aggregation and caching (SAaC) scheme. Specifically, SAaC first breaks
   through the data-centric network architecture by converting data into
   services. Then, SAaC significantly reduces traffic load and energy
   consumption by service aggregation. Finally, SAaC introduces service
   caching, and each content router caches new services locally after
   aggregating received services so that user requests are handled at the
   network layer. Experimental results demonstrate that compared with
   traditional solutions, the SAaC scheme improves the request response
   time by 20.52%-56.09%, reduces the traffic load by 10.85%-37.67%, and
   reduces energy consumption by more than 50%.
Z8 0
TC 0
ZS 0
ZB 0
ZR 0
Z9 0
SN 1389-1286
EI 1872-7069
UT WOS:000530027500006
ER

PT J
AU Tu, Shanshan
   Waqas, Muhammad
   Lin, Qiangqiang
   Rehman, Sadaqat Ur
   Hanif, Muhammad
   Xiao, Chuangbai
   Butt, M. Majid
   Chang, Chin-Chen
TI Tracking area list allocation scheme based on overlapping community
   algorithm
SO COMPUTER NETWORKS
VL 173
AR 107182
DI 10.1016/j.comnet.2020.107182
PD MAY 22 2020
PY 2020
AB Reducing the singling overhead for tracking and mobile paging devices is
   a challenging issue in the study of location management of cellular
   networks. Cellular networks have become massive generators of data, and
   in the forthcoming years, this data is expected to increase drastically.
   Big data-based intelligence and analytics can improve network
   operational efficiency and user service quality. This work proposes to
   exploit massive handover and paging data from cellular networks to
   minimize singling due to user mobility. In this paper, we offer a new
   holistic tracking area lists (TAL) management methodology, considering
   group user mobility behavior and paging characteristics. Firstly, a
   series of graphs showing the evolution of user mobility and traffic is
   built from handover and paging statistics in the network management
   system (NMS). Then, the TAL allocation problem is formulated as a
   classical graph partitioning problem, which is then solved by detecting
   overlapping communities algorithm based on game theory. Results show
   that the proposed method can effectively reduce the location management
   singling overhead and improve the TAL configuration efficiency.
OI Waqas, Muhammad/0000-0003-0814-7544
TC 0
ZS 0
ZR 0
ZB 0
Z8 0
Z9 0
SN 1389-1286
EI 1872-7069
UT WOS:000530027500003
ER

PT J
AU Andrighetti, Tahila
   Bohar, Balazs
   Lemke, Ney
   Sudhakar, Padhmanand
   Korcsmaros, Tamas
TI MicrobioLink: An Integrated Computational Pipeline to Infer Functional
   Effects of Microbiome-Host Interactions.
SO Cells
VL 9
IS 5
DI 10.3390/cells9051278
PD 2020 May 21
PY 2020
AB Microbiome-host interactions play significant roles in health and in
   various diseases including autoimmune disorders. Uncovering these
   inter-kingdom cross-talks propels our understanding of disease
   pathogenesis and provides useful leads on potential therapeutic targets.
   Despite the biological significance of microbe-host interactions, there
   is a big gap in understanding the downstream effects of these
   interactions on host processes. Computational methods are expected to
   fill this gap by generating, integrating, and prioritizing
   predictions-as experimental detection remains challenging due to
   feasibility issues. Here, we present MicrobioLink, a computational
   pipeline to integrate predicted interactions between microbial and host
   proteins together with host molecular networks. Using the concept of
   network diffusion, MicrobioLink can analyse how microbial proteins in a
   certain context are influencing cellular processes by modulating gene or
   protein expression. We demonstrated the applicability of the pipeline
   using a case study. We used gut metaproteomic data from Crohn's disease
   patients and healthy controls to uncover the mechanisms by which the
   microbial proteins can modulate host genes which belong to biological
   processes implicated in disease pathogenesis. MicrobioLink, which is
   agnostic of the microbial protein sources (bacterial, viral, etc.), is
   freely available on GitHub.
ZB 0
ZS 0
Z8 0
TC 0
ZR 0
Z9 0
EI 2073-4409
UT MEDLINE:32455748
PM 32455748
ER

PT J
AU Eichstaedt, Johannes C.
   Weidman, Aaron C.
TI Tracking Fluctuations in Psychological States Using Social Media
   Language: A Case Study of Weekly Emotion
SO EUROPEAN JOURNAL OF PERSONALITY
DI 10.1002/per.2261
EA MAY 2020
PY 2020
AB Personality psychologists are increasingly documenting dynamic,
   within-person processes. Big data methodologies can augment this
   endeavour by allowing for the collection of naturalistic and
   personality-relevant digital traces from online environments. Whereas
   big data methods have primarily been used to catalogue static
   personality dimensions, here we present a case study in how they can be
   used to track dynamic fluctuations in psychological states. We apply a
   text-based, machine learning prediction model to Facebook status updates
   to compute weekly trajectories of emotional valence and arousal. We
   train this model on 2895 human-annotated Facebook statuses and apply the
   resulting model to 303 575 Facebook statuses posted by 640 US Facebook
   users who had previously self-reported their Big Five traits, yielding
   an average of 28 weekly estimates per user. We examine the correlations
   between model-predicted emotion and self-reported personality, providing
   a test of the robustness of these links when using weekly aggregated
   data, rather than momentary data as in prior work. We further present
   dynamic visualizations of weekly valence and arousal for every user,
   while making the final data set of 17 937 weeks openly available. We
   discuss the strengths and drawbacks of this method in the context of
   personality psychology's evolution into a dynamic science. (c) 2020
   European Association of Personality Psychology
TC 0
ZR 0
ZS 0
ZB 0
Z8 0
Z9 0
SN 0890-2070
EI 1099-0984
UT WOS:000534349400001
ER

PT J
AU Barros, Alex
   Resque, Paulo
   Almeida, Joao
   Mota, Renato
   Oliveira, Helder
   Rosario, Denis
   Cerqueira, Eduardo
TI Data Improvement Model Based on ECG Biometric for User Authentication
   and Identification.
SO Sensors (Basel, Switzerland)
VL 20
IS 10
DI 10.3390/s20102920
PD 2020 May 21
PY 2020
AB The rapid spread of wearable technologies has motivated the collection
   of a variety of signals, such as pulse rate, electrocardiogram (ECG),
   electroencephalogram (EEG), and others. As those devices are used to do
   so many tasks and store a significant amount of personal data, the
   concern of how our data can be exposed starts to gain attention as the
   wearable devices can become an attack vector or a security breach. In
   this context, biometric also has expanded its use to meet new security
   requirements of authentication demanded by online applications, and it
   has been used in identification systems by a large number of people.
   Existing works on ECG for user authentication do not consider a
   population size close to a real application. Finding real data that has
   a big number of people ECG's data is a challenge. This work investigates
   a set of steps that can improve the results when working with a higher
   number of target classes in a biometric identification scenario. These
   steps, such as increasing the number of examples, removing outliers, and
   including a few additional features, are proven to increase the
   performance in a large data set. We propose a data improvement model for
   ECG biometric identification (user identification based on
   electrocardiogram-DETECT), which improves the performance of the
   biometric system considering a greater number of subjects, which is
   closer to a security system in the real world. The DETECT model
   increases precision from 78% to 92% within 1500 subjects, and from 90%
   to 95% within 100 subjects. Moreover, good False Rejection Rate (i.e.,
   0.064003) and False Acceptance Rate (i.e., 0.000033) were demonstrated.
   We designed our proposed method over PhysioNet Computing in Cardiology
   2018 database.
TC 0
ZB 0
ZR 0
Z8 0
ZS 0
Z9 0
EI 1424-8220
UT MEDLINE:32455686
PM 32455686
ER

PT J
AU Shang, Ronghua
   Zhang, Weitong
   Jiao, Licheng
   Zhang, Xiangrong
   Stolkin, Rustam
TI Dynamic Immunization Node Model for Complex Networks Based on Community
   Structure and Threshold.
SO IEEE transactions on cybernetics
VL PP
DI 10.1109/TCYB.2020.2989427
PD 2020-May-21
PY 2020
AB In the information age of big data, and increasingly large and complex
   networks, there is a growing challenge of understanding how best to
   restrain the spread of harmful information, for example, a computer
   virus. Establishing models of propagation and node immunity are
   important parts of this problem. In this article, a dynamic node immune
   model, based on the community structure and threshold (NICT), is
   proposed. First, a network model is established, which regards nodes
   carrying harmful information as new nodes in the network. The method of
   establishing the edge between the new node and the original node can be
   changed according to the needs of different networks. The propagation
   probability between nodes is determined by using community structure
   information and a similarity function between nodes. Second, an improved
   immune gain, based on the propagation probability of the community
   structure and node similarity, is proposed. The improved immune gain
   value is calculated for neighbors of the infected node at each time
   step, and the node is immunized according to the hand-coded parameter:
   immune threshold. This can effectively prevent invalid or insufficient
   immunization at each time step. Finally, an evaluation index,
   considering both the number of immune nodes and the number of infected
   nodes at each time step, is proposed. The immune effect of nodes can be
   evaluated more effectively. The results of network immunization
   experiments, on eight real networks, suggest that the proposed method
   can deliver better network immunization than several other well-known
   methods from the literature.
ZS 0
TC 0
Z8 0
ZB 0
ZR 0
Z9 0
EI 2168-2275
UT MEDLINE:32452780
PM 32452780
ER

PT J
AU Wang, Lei
   Lin, Nanping
   Lin, Kongying
   Xiao, Chunhong
   Wang, Ren
   Chen, Jingbo
   Zhou, Weiping
   Liu, Jingfeng
TI The Clinical Value of Postoperative Transarterial Chemoembolization for
   Resectable Patients with Intermediate Hepatocellular Carcinoma After
   Radical Hepatectomy: a Propensity Score-Matching Study.
SO Journal of gastrointestinal surgery : official journal of the Society
   for Surgery of the Alimentary Tract
DI 10.1007/s11605-020-04588-5
PD 2020-May-21
PY 2020
AB BACKGROUND AND AIMS: Surgical resection for patients with intermediate
   hepatocellular carcinoma (HCC) is preferred in China, but the prognosis
   remains far from satisfactory. Postoperative transarterial
   chemoembolization (p-TACE) has been conducted prevalently to prevent
   recurrence, but its efficacy remains controversial. Hence, we collected
   the data from primary liver cancer big data (PLCBD) to investigate the
   clinical value of p-TACE for patients with intermediate HCC and identify
   the potential beneficiaries.
   METHODS: Patients who were diagnosed with intermediate HCC between
   December 2012 and December 2015 were identified through the PLCBD.
   Disease-free survival (DFS) of patients who received p-TACE or not
   following radical resection was evaluated using Kaplan-Meier survival
   curves before and after 1:1 propensity scoring match (PSM). Subgroup
   analysis was conducted stratified by risk factors associated with
   recurrence.
   RESULTS: A total of 325 intermediate HCC patients receiving radical
   resection were eligible in this study, including 123 patients in the
   p-TACE group and 202 in the non-TACE group. Median DFS in the p-TACE
   group was significantly longer than in the non-TACE group (23.3months
   vs. 18.0months, P=0.016) in the whole cohort with no severe complicates,
   which was confirmed in a well-matched cohort (17.4months vs. 23.3months,
   P=0.012). In addition, p-TACE was identified as an independent risk
   factors of DFS by multivariate Cox regression analysis before and after
   PSM (both P<0.05). After adjusting for other prognostic variables,
   patients were found to significantly benefit from p-TACE in DFS if they
   were male, or had hepatitis, diabetes, cirrhosis, AFP ≤400ng/ml,
   anatomic hepatectomy, no severe surgical complication, no intraoperative
   transfusion, tumor number=2, differentiation grading III, capsule, or
   had no transfusion (all P<0.05).
   CONCLUSION: With the current data, we concluded that p-TACE was safe and
   efficient for the patients with intermediate HCC following radical
   resection, and male patients with hepatitis, diabetes, cirrhosis, AFP
   ≤400ng/ml, anatomic hepatectomy, no severe surgical complication, no
   intraoperative transfusion, tumor number=2, differentiation grading III,
   and capsule would benefit more from p-TACE.
Z8 0
ZR 0
ZB 0
ZS 0
TC 0
Z9 0
EI 1873-4626
UT MEDLINE:32440804
PM 32440804
ER

PT J
AU Lin, Leesa
   Hou, Zhiyuan
TI Combat COVID-19 with artificial intelligence and big data.
SO Journal of travel medicine
DI 10.1093/jtm/taaa080
PD 2020-May-21
PY 2020
Z8 0
TC 0
ZB 0
ZR 0
ZS 0
Z9 0
EI 1708-8305
UT MEDLINE:32437541
PM 32437541
ER

PT J
AU Pei, Lishan
   Shen, Xia
   Qu, Kai
   Tan, Conge
   Zou, Junbo
   Wang, Yanxia
   Ping, Fan
TI The Study On Two-Way Adjustment Mechanism of Rhei Radix et Rhizoma for
   Cardiovascular Diseases.
SO Combinatorial chemistry & high throughput screening
DI 10.2174/1386207323666200521120308
PD 2020-May-21
PY 2020
AB AIM AND OBJECTIVE: Myocardial infarction, cerebral infarction and other
   diseases caused by vascular obstruction have always jeopardized human
   life and health. More and more reports indicate that Rhei Radix et
   Rhizoma has a good clinical effect in the prevention and treatment of
   cardiovascular disease. Owing to the complexity of herbal medicine, the
   pharmacodynamic mechanism of Rhei Radix et Rhizoma is still not clear.
   The objective of this study was to explore the two-way adjustment
   mechanism of Rhei Radix et Rhizoma and provided a new solution for the
   prevention and treatment of cardiovascular disease.
   MATERIALS AND METHODS: Based on the systems pharmacology method and big
   data analysis technology, this study used data mining, reverse
   pharmacophore matching, network construction, GO and KEGG Analysis, and
   molecular docking to investigate the two-way adjustment mechanism of
   Rhei Radix et Rhizoma.
   RESULTS: The results suggest that Rhei Radix et Rhizoma plays a two-way
   adjustment of activating blood circulation as well as blood coagulation
   in the prevention and treatment of cardiovascular diseases. The
   components involved in activating blood circulation were mainly
   Anthraquinones components. The corresponding targets were NOS2, NOS3,
   CALM1, and the corresponding pathways were Calcium signaling pathway,
   VEGF signaling pathway, Platelet activation, PI3K-Akt signaling pathway.
   For blood coagulation, the components were mainly Tannins components,
   the corresponding targets were F2, F10, ELANE, and the corresponding
   pathways were Neuroactive ligand-receptor interaction, Complement and
   coagulation cascades.
   CONCLUSION: Through this study, it was indicated that Rhei Radix et
   Rhizoma exerts the two-way adjustment of activating blood circulation
   and blood coagulation in the prevention and treatment of cardiovascular
   diseases. And it can make up for the existing blood circulation drugs
   for cardiovascular disease, only blood circulation is used, and the side
   effects of uncontrollable large-area bleeding because of the long-term
   use of the drugs. This study provides a material basis for the
   development of new blood-activating drugs based on natural medicines.
Z8 0
ZR 0
ZB 0
ZS 0
TC 0
Z9 0
EI 1875-5402
UT MEDLINE:32436824
PM 32436824
ER

PT J
AU Lin, Jing
   Pan, Weike
   Li, Lin
   Chen, Zixiang
   Ming, Zhong
TI Matrix factorization with heterogeneous multiclass preference context
SO NEUROCOMPUTING
VL 390
BP 148
EP 157
DI 10.1016/j.neucom.2020.01.060
PD MAY 21 2020
PY 2020
AB The spreading use of the Internet and big data technology has spawned
   the need for recommendation systems. However, to alleviate public
   anxiety about privacy, this paper advocates making recommendation with
   internal context, which refers to the implicit context hidden beneath
   the rating matrix only. Inspired by a recent work that embeds
   neighborhood information among users (as represented by multi-class
   preference context, MPC) into a factorization-based method, we extend it
   to both user-oriented and item-oriented, and put forward both
   user-oriented MPC and item-oriented MPC into a generic factorization
   framework called matrix factorization with heterogeneous MPC (MF-HMPC).
   In particular, we derive two specific recommendation methods from
   MF-HMPC with different structures, including MF with dual MPC (MF-DMPC)
   and MF with pipelined MPC (MF-PMPC), which are corresponding to
   concurrent structure and sequential structure, respectively. Extensive
   empirical studies on four public datasets show that our two forms of
   MF-HMPC outperform the referenced state-of-the-art MF methods as well as
   two representative deep learning methods. Moreover, we also discover
   some interesting facts about how these two kinds of internal contextual
   information complement each other. The main advantage of our methods is
   that they manage to strike a good balance between user-oriented
   neighborhood information and item-oriented neighborhood information. (C)
   2020 Elsevier B.V. All rights reserved.
ZB 0
Z8 0
ZR 0
ZS 0
TC 0
Z9 0
SN 0925-2312
EI 1872-8286
UT WOS:000531729000014
ER

PT J
AU de Jesus Rubio, Jose
   Pan, Yongping
   Lughofer, Edwin
   Chen, Mu-Yen
   Qiu, Jianbin
TI Fast learning of neural networks with application to big data processes
SO NEUROCOMPUTING
VL 390
BP 294
EP 296
DI 10.1016/j.neucom.2019.10.057
PD MAY 21 2020
PY 2020
RI Rubio, Jose de Jesus/H-1337-2013
OI Rubio, Jose de Jesus/0000-0002-2005-5979
ZS 0
ZR 0
TC 1
ZB 0
Z8 0
Z9 1
SN 0925-2312
EI 1872-8286
UT WOS:000531728800009
ER

PT J
AU Hernandez, Gerardo
   Zamora, Erik
   Sossa, Humberto
   Tellez, German
   Furlan, Federico
TI Hybrid neural networks for big data classification
SO NEUROCOMPUTING
VL 390
BP 327
EP 340
DI 10.1016/j.neucom.2019.08.095
PD MAY 21 2020
PY 2020
AB Two new hybrid neural architectures combining morphological neurons and
   perceptrons are introduced in this paper. The first architecture, called
   Morphological - Linear Neural Network (MLNN) consists of a hidden layer
   of morphological neurons and an output layer of classical perceptrons
   has the capability of extracting features. The second architecture,
   called Linear-Morphological Neural Network (LMNN) is composed of one or
   several perceptron layers as a feature extractor, it is then followed by
   an output layer of morphological neurons for non-linear classification.
   Both architectures are trained by stochastic gradient descent. One of
   the main contributions of this paper is to show that the morphological
   layer offers a greater capacity to extract features than the perceptron
   layer. This claim is supported both theoretically and experimentally. We
   prove that the morphological layer possesses a greater capacity per
   computation unit to segment the 2D input space than the perceptron
   layer. In other words, adding more hyper-boxes produces more response
   regions than adding hyperplanes. From an empirical point of view, we
   test the two new models on 25 standard datasets at low dimensionality
   and one big data dataset. The result is that MLNN requires a lesser
   number of learning parameters than the other tested architectures while
   achieving better accuracies. (C) 2019 Elsevier B.V. All rights reserved.
ZS 0
TC 1
Z8 0
ZB 0
ZR 0
Z9 1
SN 0925-2312
EI 1872-8286
UT WOS:000531728800012
ER

PT J
AU Mohamad, Saad
   Bouchachia, Abdelhamid
TI Deep online hierarchical dynamic unsupervised learning for pattern
   mining from utility usage data
SO NEUROCOMPUTING
VL 390
BP 359
EP 373
DI 10.1016/j.neucom.2019.08.093
PD MAY 21 2020
PY 2020
AB While most non-intrusive load monitoring (NILM) work has focused on
   supervised algorithms, unsupervised approaches can be more interesting
   and practical. Specifically, they do not require labelled training data
   to be acquired from the individual appliances and can be deployed to
   operate on the measured aggregate data directly. We propose a fully
   unsupervised novel NILM framework based on Dynamic Bayesian hierarchical
   mixture model and Deep Belief network (DBN). The deep network learns, in
   unsupervised fashion, low-level generic appliance-specific features from
   the raw signals of the house utilities usage, then the hierarchical
   Bayesian model learns high-level features representing the consumption
   patterns of the residents captured by the correlations among the
   low-level features. The temporal ordering of the high-level features is
   captured by the Dynamic Bayesian Model. Using this architecture, we
   overcome the computational complexity that would occur if temporal
   modelling was directly applied to the raw data or even to the
   constructed features. The computational efficiency is crucial as our
   application involves massive data from different utilities usage.
   Moreover, we develop a novel online inference algorithm to cope with
   this big data. Finally, we propose different evaluation methods to
   analyse the results which show that our algorithm finds useful patterns.
   (C) 2019 Elsevier B.V. All rights reserved.
ZS 0
ZR 0
Z8 0
TC 0
ZB 0
Z9 0
SN 0925-2312
EI 1872-8286
UT WOS:000531728800014
ER

PT J
AU Jamil, Waqas
   Bouchachia, Abdelhamid
TI Competitive regularised regression
SO NEUROCOMPUTING
VL 390
BP 374
EP 383
DI 10.1016/j.neucom.2019.08.094
PD MAY 21 2020
PY 2020
AB Regularised regression uses sparsity and variance to reduce the
   complexity and over-fitting of a regression model. The present paper
   introduces two novel regularised linear regression algorithms:
   Competitive Iterative Ridge Regression (CIRR) and Online Shrinkage via
   Limit of Gibbs Sampler (OSLOG) for fast and reliable prediction on "Big
   Data" without making distributional assumption on the data. We use the
   technique of competitive analysis to design them and show their strong
   theoretical guarantee. Furthermore, we compare their performance against
   some neoteric regularised regression methods such as Online Ridge
   Regression (ORR) and the Aggregating Algorithm for Regression (AAR). The
   comparison of the algorithms is done theoretically, focusing on the
   guarantee on the performance on cumulative loss, and empirically to show
   the advantages of CIRR and OSLOG. (C) 2019 Published by Elsevier B.V.
ZS 0
TC 0
Z8 0
ZB 0
ZR 0
Z9 0
SN 0925-2312
EI 1872-8286
UT WOS:000531728800015
ER

PT J
AU Kunz, Meik
   Jeromin, Julian
   Fuchs, Maximilian
   Christoph, Jan
   Veronesi, Giulia
   Flentje, Michael
   Nietzer, Sarah
   Dandekar, Gudrun
   Dandekar, Thomas
TI In silico signaling modeling to understand cancer pathways and treatment
   responses.
SO Briefings in bioinformatics
VL 21
IS 3
BP 1115
EP 1117
DI 10.1093/bib/bbz033
PD 2020-May-21
PY 2020
AB Precision medicine has changed thinking in cancer therapy, highlighting
   a better understanding of the individual clinical interventions. But
   what role do the drivers and pathways identified from pan-cancer genome
   analysis play in the tumor? In this letter, we will highlight the
   importance of in silico modeling in precision medicine. In the current
   era of big data, tumor engines and pathways derived from pan-cancer
   analysis should be integrated into in silico models to understand the
   mutational tumor status and individual molecular pathway mechanism at a
   deeper level. This allows to pre-evaluate the potential therapy response
   and develop optimal patient-tailored treatment strategies which pave the
   way to support precision medicine in the clinic of the future.
TC 0
ZB 0
ZS 0
Z8 0
ZR 0
Z9 0
EI 1477-4054
UT MEDLINE:31117120
PM 31117120
ER

PT J
AU Zeeshan, Saman
   Xiong, Ruoyun
   Liang, Bruce T
   Ahmed, Zeeshan
TI 100 Years of evolving gene-disease complexities and scientific
   debutants.
SO Briefings in bioinformatics
VL 21
IS 3
BP 885
EP 905
DI 10.1093/bib/bbz038
PD 2020-May-21
PY 2020
AB It's been over 100 years since the word `gene' is around and
   progressively evolving in several scientific directions. Time-to-time
   technological advancements have heavily revolutionized the field of
   genomics, especially when it's about, e.g. triple code development, gene
   number proposition, genetic mapping, data banks, gene-disease maps,
   catalogs of human genes and genetic disorders, CRISPR/Cas9, big data and
   next generation sequencing, etc. In this manuscript, we present the
   progress of genomics from pea plant genetics to the human genome project
   and highlight the molecular, technical and computational developments.
   Studying genome and epigenome led to the fundamentals of development and
   progression of human diseases, which includes chromosomal, monogenic,
   multifactorial and mitochondrial diseases. World Health Organization has
   classified, standardized and maintained all human diseases, when many
   academic and commercial online systems are sharing information about
   genes and linking to associated diseases. To efficiently fathom the
   wealth of this biological data, there is a crucial need to generate
   appropriate gene annotation repositories and resources. Our focus has
   been how many gene-disease databases are available worldwide and which
   sources are authentic, timely updated and recommended for research and
   clinical purposes. In this manuscript, we have discussed and compared 43
   such databases and bioinformatics applications, which enable users to
   connect, explore and, if possible, download gene-disease data.
OI Ahmed, Zeeshan/0000-0002-7065-1699
TC 1
ZB 0
ZS 0
Z8 0
ZR 0
Z9 1
EI 1477-4054
UT MEDLINE:30972412
PM 30972412
ER

PT J
AU Oliveri Conti, Gea
   Ferrante, Margherita
   Banni, Mohamed
   Favara, Claudia
   Nicolosi, Ilenia
   Cristaldi, Antonio
   Fiore, Maria
   Zuccarello, Pietro
TI Micro- and nano-plastics in edible fruit and vegetables. The first diet
   risks assessment for the general population.
SO Environmental research
VL 187
BP 109677
EP 109677
DI 10.1016/j.envres.2020.109677
PD 2020-May-20
PY 2020
AB Microplastics (MPs) represent a current public health concern since
   toxicity has not yet fully investigated. They were found in several
   foods, but to the best of our knowledge, at this time no data was
   reported for the edible vegetables and fruits. We focused on diet
   exposure aiming to evaluate the number and the size (<10mum) of MPs in
   the most commonly consumed vegetables and fruits, in relation to their
   recommended daily intake too. MPs extraction and analysis were carried
   out using an innovative Italian methodology and SEM-EDX, respectively.
   Finally, we calculated the Estimated Daily Intakes (EDIs) for adults and
   children for each type of vegetal and fruit. The higher median (IQR)
   level of MPs in fruit and vegetable samples was 223,000 (52,600-307,750)
   and 97,800 (72,175-130,500), respectively. In particular, apples were
   the most contaminated fruit samples, while carrot was the most
   contaminated vegetable. Conversely, the lower median (IQR) level was
   observed in lettuce samples 52,050 (26,375-75,425). Both vegetable and
   fruit samples MPs levels were characterized by wide variability. The
   smallest size of MPs was found in the carrot samples (1.51mum), while
   the biggest ones were found in the lettuce (2.52mum). Both vegetable and
   fruit samples had size of the MPs characterized by low variability. We
   found the highest median level of MPs in samples purchased from the
   "fruiter 3" (124,900 p/g) and the lowest in those purchased in
   "supermarket" (87,600 p/g). The median size of the MPs had overlapping
   dimensions in all the purchase sites, with the exception of the samples
   purchased at the "shop at km zero 2 which had slightly smaller size
   (1.81mum). The highest adults' (4.62E+05) and children's (1.41E+06) EDIs
   are due the ingestion of apples, instead the lowest are due to the
   ingestion of carrots (adults: 2.96E+04; children: 1.15E+05). We
   hypothesized that the mechanism of uptake and translocation of MPs can
   be the same described and reported for carbon-nanomaterials. This may be
   a possible translocation route of MPs by environment to vegetables
   permitting, so, the translocation or uptake inside of their biological
   systems. Based on the results obtained it is urgent important to perform
   toxicological and epidemiological studies to investigate for the
   possible effects of MPs on human health.
ZR 0
TC 0
ZB 0
Z8 0
ZS 0
Z9 0
EI 1096-0953
UT MEDLINE:32454310
PM 32454310
ER

PT J
AU Shen, Yun
   Zhou, Jian
   Hu, Gang
TI Practical use of electronic health records among patients with diabetes
   in scientific research.
SO Chinese medical journal
VL 133
IS 10
BP 1224
EP 1230
DI 10.1097/CM9.0000000000000784
PD 2020-May-20
PY 2020
AB Electronic health (medical) records, which are also considered as
   patients' information that are routinely collected, provide a great
   chance for researchers to develop an epidemiological understanding of
   disease. Electronic health records systems cannot develop without the
   advance of computer industries. While conducting clinical trials that
   are always costly, feasible and reasonable analysis of routine patients'
   information is more cost-effective and reflective of clinical practice,
   which is also called real world study. Real world studies can be well
   supported by big data in healthcare industry. Real world studies become
   more and more focused and important with the development of
   evidence-based medicine. These big data will definitely help in making
   decisions, making policies and guidelines, monitoring of effectiveness
   and safety on new drugs or technologies. Extracting, cleaning, and
   analyzing such big data will be a great challenge for clinical
   researchers. Successful applications and developments of electronic
   health record in western countries (eg, disease registries, health
   insurance claims, etc) have provided a clear direction for Chinese
   researchers. However, it is still at primary stages in China. This
   review tries to provide a full perspective on how to translate the
   electronic health records into scientific achievements, for example,
   among patients with diabetes. As a summary in the end, resource sharing
   and collaborations are highly recommended among hospitals and healthcare
   groups.
Z8 0
TC 0
ZS 0
ZB 0
ZR 0
Z9 0
EI 2542-5641
UT MEDLINE:32433055
PM 32433055
ER

PT J
AU Lecky, Donna M
   Granier, Steve
   Allison, Rosalie
   Verlander, Neville Q
   Collin, Simon M
   McNulty, Cliodna A M
TI Infectious Disease and Primary Care Research-What English General
   Practitioners Say They Need.
SO Antibiotics (Basel, Switzerland)
VL 9
IS 5
DI 10.3390/antibiotics9050265
PD 2020 May 20
PY 2020
AB BACKGROUND: Infections are one of the most common reasons for patients
   attending primary care. Antimicrobial resistance (AMR) is perhaps one of
   the biggest threats to modern medicine; data show that 81% of
   antibiotics in the UK are prescribed in primary care.
   AIM: To identify where the perceived gaps in knowledge, skills, guidance
   and research around infections and antibiotic use lie from the general
   practitioner (GP) viewpoint.
   DESIGN AND SETTING: An online questionnaire survey.
   METHOD: The survey, based on questions asked of Royal College of General
   Practitioners (RCGP) members in 1999, and covering letter were
   electronically sent to GPs between May and August 2017 via various
   primary care dissemination routes.
   RESULTS: Four hundred and twenty-eight GPs responded. Suspected
   Infection in the elderly, recurrent urinary tract infection (UTI),
   surveillance of AMR in the community, leg ulcers, persistent cough and
   cellulitis all fell into the top six conditions ranked in order of
   importance that require further research, evidence and guidance. Acute
   sore throat, otitis media and sinusitis were of lower importance than in
   1999.
   CONCLUSION: This survey will help the NHS, the UK National Institute for
   Health and Care Excellence (NICE) and researchers to prioritise for the
   development of guidance and research for chronic conditions highlighted
   for which there is little evidence base for diagnostic and management
   guidelines in primary care. In contrast, 20 years of investment into
   research, guidance and resources for acute respiratory infections have
   successfully reduced these as priority areas for GPs.
RI McNulty, Cliodna Ann Miriam/; Lecky, Donna/AAB-6849-2019; Allison, Rosalie/
OI McNulty, Cliodna Ann Miriam/0000-0003-4969-5360; Lecky,
   Donna/0000-0002-1223-9356; Allison, Rosalie/0000-0003-1266-2549
TC 0
ZB 0
Z8 0
ZR 0
ZS 0
Z9 0
SN 2079-6382
UT MEDLINE:32443700
PM 32443700
ER

PT J
AU Yan, Xiliang
   Sedykh, Alexander
   Wang, Wenyi
   Yan, Bing
   Zhu, Hao
TI Construction of a web-based nanomaterial database by big data curation
   and modeling friendly nanostructure annotations.
SO Nature communications
VL 11
IS 1
BP 2519
EP 2519
DI 10.1038/s41467-020-16413-3
PD 2020 May 20
PY 2020
AB Modern nanotechnology research has generated numerous experimental data
   for various nanomaterials. However, the few nanomaterial databases
   available are not suitable for modeling studies due to the way they are
   curated. Here, we report the construction of a large nanomaterial
   database containing annotated nanostructures suited for modeling
   research. The database, which is publicly available through
   http://www.pubvinas.com/, contains 705 unique nanomaterials covering 11
   material types. Each nanomaterial has up to six physicochemical
   properties and/or bioactivities, resulting in more than ten endpoints in
   the database. All the nanostructures are annotated and transformed into
   protein data bank files, which are downloadable by researchers
   worldwide. Furthermore, the nanostructure annotation procedure generates
   2142 nanodescriptors for all nanomaterials for machine learning
   purposes, which are also available through the portal. This database
   provides a public resource for data-driven nanoinformatics modeling
   research aimed at rational nanomaterial design and other areas of modern
   computational nanotechnology.
OI Zhu, Hao/0000-0002-3559-6129
ZS 0
ZR 0
Z8 0
TC 0
ZB 0
Z9 0
EI 2041-1723
UT MEDLINE:32433469
PM 32433469
ER

PT J
AU Eberhart-Phillips, Luke J
   Cruz-Lopez, Medardo
   Lozano-Angulo, Lydia
   Del Angel, Salvador Gomez
   Rojas-Abreu, Wendoly
   Bucio-Pacheco, Marcos
   Kupper, Clemens
TI CeutaOPEN, individual-based field observations of breeding snowy plovers
   Charadrius nivosus.
SO Scientific data
VL 7
IS 1
BP 149
EP 149
DI 10.1038/s41597-020-0490-y
PD 2020 May 20
PY 2020
AB Shorebirds (part of the order Charadriiformes) have a global
   distribution and exhibit remarkable variation in ecological and
   behavioural traits that are pertinent to many core questions in the
   fields of evolutionary ecology and conservation biology. Shorebirds are
   also relatively convenient to study in the wild as they are ground
   nesting and often occupy open habitats that are tractable to monitor.
   Here we present a database documenting the reproductive ecology of 1,647
   individually marked snowy plovers (Charadrius nivosus) monitored between
   2006 and 2016 at Bahia de Ceuta (23°54N, 106°57W) - an important
   breeding site in north-western Mexico. The database encompasses various
   morphological, behavioural, and fitness-related traits of males and
   females along with spatial and temporal population dynamics. This open
   resource will serve as an important data repository for addressing
   overarching questions in avian ecology and wetland conservation during
   an era of big data and global collaborative science.
ZB 0
ZS 0
TC 0
Z8 0
ZR 0
Z9 0
EI 2052-4463
UT MEDLINE:32433461
PM 32433461
ER

PT J
AU Zhao, Jing
   Li, Hang
   Kung, David
   Fisher, Marc
   Shen, Ying
   Liu, Renyu
TI Impact of the COVID-19 Epidemic on Stroke Care and Potential Solutions.
SO Stroke
BP STROKEAHA120030225
EP STROKEAHA120030225
DI 10.1161/STROKEAHA.120.030225
PD 2020-May-20
PY 2020
AB Background and Purpose- When the coronavirus disease 2019 (COVID-19)
   outbreak became paramount, medical care for other devastating diseases
   was negatively impacted. In this study, we investigated the impact of
   the COVID-19 outbreak on stroke care across China. Methods- Data from
   the Big Data Observatory Platform for Stroke of China consisting of 280
   hospitals across China demonstrated a significant drop in the number of
   cases of thrombolysis and thrombectomy. We designed a survey to
   investigate the major changes during the COVID-19 outbreak and potential
   causes of these changes. The survey was distributed to the leaders of
   stroke centers in these 280 hospitals. Results- From the data of Big
   Data Observatory Platform for Stroke of China, the total number of
   thrombolysis and thrombectomy cases dropped 26.7% (P<0.0001) and 25.3%
   (P<0.0001), respectively, in February 2020 as compared with February
   2019. We retrieved 227 valid complete datasets from the 280 stroke
   centers. Nearly 50% of these hospitals were designated hospitals for
   COVID-19. The capacity for stroke care was reduced in the majority of
   the hospitals. Most of the stroke centers stopped or reduced their
   efforts in stroke education for the public. Hospital admissions related
   to stroke dropped 40%; thrombolysis and thrombectomy cases dropped 25%,
   which is similar to the results from the Big Data Observatory Platform
   for Stroke of China as compared with the same period in 2019. Many
   factors contributed to the reduced admissions and prehospital delays;
   lack of stroke knowledge and proper transportation were significant
   limiting factors. Patients not coming to the hospital for fear of virus
   infection was also a likely key factor. Conclusions- The COVID-19
   outbreak impacted stroke care significantly in China, including
   prehospital and in-hospital care, resulting in a significant drop in
   admissions, thrombolysis, and thrombectomy. Although many factors
   contributed, patients not coming to the hospital was probably the major
   limiting factor. Recommendations based on the data are provided.
TC 0
ZB 0
ZR 0
Z8 0
ZS 0
Z9 0
EI 1524-4628
UT MEDLINE:32432997
PM 32432997
ER

PT J
AU Divaris, Kimon
   Moss, Kevin
   Beck, James D
TI Biologically informed stratification of periodontal disease holds the
   key to achieving precision oral health.
SO Journal of periodontology
DI 10.1002/JPER.20-0096
PD 2020-May-20
PY 2020
AB Medicine and dentistry need to treat the individual not the "average
   patient." This personalized or precision approach to health care
   involves correctly diagnosing and properly classifying people to
   effectively customize prevention, diagnosis, and treatment. This is not
   a trivial undertaking. Achieving precision health requires making sense
   of big data, both at the population level and at the molecular level.
   The latter can include genetic, epigenetic, transcriptomic, proteomic,
   metabolomic data, and microbiome data. This biological information can
   augment established clinical measurements and supplement data on
   socioeconomic status, lifestyle, behaviors, and environmental
   conditions. Here, the central thesis is that, with sufficient data and
   appropriate methods, it is possible to segregate symptom-based and
   phenotypically based categories of patients into clinically and
   biologically similar groups. These groups are likely to have different
   clinical trajectories and benefit from different treatments.
   Additionally, such groups are optimal for investigations seeking to
   unveil the genomic basis of periodontal disease susceptibility. Analysis
   of these complex data to produce actionable and replicable health and
   disease categories requires appropriately sophisticated bioinformatics
   approaches and thorough validation in diverse patient samples and
   populations. Successful research programs will need to consider both
   population-level and well-controlled deep phenotyping approaches.
   Biologically informed stratification of periodontal disease is both
   feasible and desirable. Ultimately, this approach can accelerate the
   development of precision health through improvements in research and
   clinical applications. This article is protected by copyright. All
   rights reserved.
RI Divaris, Kimon/E-4706-2011
OI Divaris, Kimon/0000-0003-1290-7251
TC 0
ZR 0
Z8 0
ZS 0
ZB 0
Z9 0
EI 1943-3670
UT MEDLINE:32432812
PM 32432812
ER

PT J
AU Gajewska, Magdalena
   Skrzypiec, Katarzyna
   Jozwiakowski, Krzysztof
   Mucha, Zbigniew
   Wojcik, Wlodzimierz
   Karczmarczyk, Agnieszka
   Bugajski, Piotr
TI Kinetics of pollutants removal in vertical and horizontal flow
   constructed wetlands in temperate climate
SO SCIENCE OF THE TOTAL ENVIRONMENT
VL 718
AR 137371
DI 10.1016/j.scitotenv.2020.137371
PD MAY 20 2020
PY 2020
AB This paper reports a comparative study on kinetics of organic matter
   expressed as BODs and nitrogen removal in constructed wetlands operated
   in Poland. Analyzed data were collected at eight wetland systems,
   composed of subsurface flow beds: horizontal flow (HF) and vertical flow
   (VF), in different number and sequences. The analysis involved
   particularly mass removal rates (MRR) and first-order removal rate
   coefficients of BODs and total nitrogen (k(A) and k(v) for VF and HF
   filters, respectively, and k(20) as a parameter averaged for a
   temperature of 20 degrees C). It was found that the higher the load of
   pollutants applied to the beds, the higher MRR values were obtained. The
   average k-rates in analyzed systems were mostly lower than those
   reported in the literature, espedaily in the case of total nitrogen. Its
   removal obtained in horizontal flow beds was k(v) = 0.002-0.042 d while
   in vertical flow systems k(A) varied from 0.007 m d to 0.0037 m d(-1).
   According to data given by previous studies, first-order reaction rates
   for nitrogen removal varied in range from k(v) = 0.048 d(-1) to k(v) =
   0.19 d(-1) and k(A) from 0.007 to 0.1 m d(-1) in HF and VF beds,
   respectively. Regarding BOD s shown in literature, removal rate k(v) for
   HF beds varied from 0.071 to 6.11 d(-1), and k(A) for VF beds varied
   from 0.019 to 1.0 m d(-1) while in this study lower k-rates were
   obtained: k(v) = 0.005-0.085 d(-1) and k(A) = 0.015-0.130 m d(-1).
   Relatively long monitoring period, for some of constructed wetland up to
   16 years, resulted in good data set and enables creation of the graphs,
   which could be helpful in evaluation and designing of constructed
   wetlands for PE bigger than 50, in moderate climate conditions. (C) 2020
   The Author(s). Published by Elsevier B.V.
RI Skrzypiec, Katarzyna/S-2501-2018
OI Skrzypiec, Katarzyna/0000-0003-0810-4181
ZR 0
Z8 0
ZS 0
TC 1
ZB 1
Z9 1
SN 0048-9697
EI 1879-1026
UT WOS:000526029000078
PM 32092523
ER

PT J
AU Li, Yunwei
   Wu, Haitao
   Shen, Keyuan
   Hao, Yu
   Zhang, Pengfei
TI Is environmental pressure distributed equally in China? Empirical
   evidence from provincial and industrial panel data analysis
SO SCIENCE OF THE TOTAL ENVIRONMENT
VL 718
AR 137363
DI 10.1016/j.scitotenv.2020.137363
PD MAY 20 2020
PY 2020
AB China's rapid economic development has resulted in increasingly serious
   environmental pollution that is negatively affecting the health of
   Chinese citizens. Notably, the unfair distribution of resources may
   cause the uneven distribution of the environmental burden. In this
   study, panel data of 30 Chinese provinces and 32 industries for the
   period 2004 to 2017 is used to investigate how the environmental burden
   is distributed across different regions and industries. To manage
   potential endogeneity and allow for dynamics, the generalized method of
   moments and panel vector autoregression models are employed. The
   estimation results indicate that, on the whole, urban residents endure
   the most serious environmental pollution. Notably, a big gap is observed
   between urban and rural residents' share of environmental pressure, and
   a similar gap is also observed between developed and underdeveloped
   areas in China. Moreover, the government is responsible for less
   environmental pressure than companies for urban residents and rural
   residents. The subindustry regression results indicate that the
   "polluting department" bears the most environmental pressure, and the
   "green department" also bore some negative environmental pressure. (C)
   2020 Elsevier B.V. All rights reserved.
ZR 0
ZB 0
Z8 0
TC 0
ZS 0
Z9 0
SN 0048-9697
EI 1879-1026
UT WOS:000526029000077
PM 32325619
ER

PT J
AU Judge, Melinda
   Parker, Erica
   Naniche, Denise
   Le Souef, Peter
TI Gene Expression: the Key to Understanding HIV-1 Infection?
SO Microbiology and molecular biology reviews : MMBR
VL 84
IS 2
DI 10.1128/MMBR.00080-19
PD 2020 May 13
PY 2020
AB SUMMARYGene expression profiling of the host response to HIV infection
   has promised to fill the gaps in our knowledge and provide new insights
   toward vaccine and cure. However, despite 20years of research, the
   biggest questions remained unanswered. A literature review identified 62
   studies examining gene expression dysregulation in samples from
   individuals living with HIV. Changes in gene expression were dependent
   on cell/tissue type, stage of infection, viremia, and treatment status.
   Some cell types, notably CD4+ T cells, exhibit upregulation of cell
   cycle, interferon-related, and apoptosis genes consistent with
   depletion. Others, including CD8+ T cells and natural killer cells,
   exhibit perturbed function in the absence of direct infection with HIV.
   Dysregulation is greatest during acute infection. Differences in study
   design and data reporting limit comparability of existing research and
   do not as yet provide a coherent overview of gene expression in HIV.
   This review outlines the extraordinarily complex host response to HIV
   and offers recommendations to realize the full potential of HIV host
   transcriptomics.
ZS 0
TC 0
ZB 0
ZR 0
Z8 0
Z9 0
EI 1098-5557
UT MEDLINE:32404327
PM 32404327
ER

PT J
AU Chi, Bin
   Lu, Weisheng
   Ye, Meng
   Bao, Zhikang
   Zhang, Xiaoling
TI Construction waste minimization in green building: A comparative
   analysis of LEED-NC 2009 certified projects in the US and China
SO JOURNAL OF CLEANER PRODUCTION
VL 256
AR 120749
DI 10.1016/j.jclepro.2020.120749
PD MAY 20 2020
PY 2020
AB Construction waste minimization is a key sustainability goal in green
   building rating systems. Although these rating systems traverse
   countries boundaries, no research so far has compared construction waste
   minimization performance in such systems across countries. This research
   aims to investigate and compare the construction waste minimization
   performance of green building projects in the US and China by focusing
   on the widely adopted LEED (Leadership in Energy and Environmental
   Design) certification system. Data on 599 and 297 LEED-New Construction
   (NC) 2009 certified projects in the US and China, respectively, were
   sourced from the US Green Building Council project directory. Their
   construction waste minimization-related points were compared using the
   Mann-Whitney U and effect size test, and semi-structured interviews were
   conducted to identify the possible causes behind statistical analysis
   results. We found no significant difference in construction waste
   minimization performance of LEED platinum-level projects in the US and
   China, but the magnitude of the difference between two countries
   increased as the certification level went lower. The enforcement on
   regulations, recycling market development, public consciousness and
   advanced technologies lead to the differences while the influence of the
   political, economic, social, and technological context increased when
   the projects were certified with lower LEED levels. An amenable context
   should be fostered to achieve a better construction waste minimization
   performance in green building and a sustainable development goal. (C)
   2020 Elsevier Ltd. All rights reserved.
ZS 0
ZR 0
TC 2
ZB 0
Z8 0
Z9 2
SN 0959-6526
EI 1879-1786
UT WOS:000524981300046
ER

PT J
AU Aggarwal, Suruchi
   Kumar, Ajay
   Jamwal, Shilpa
   Midha, Mukul Kumar
   Talukdar, Narayan Chandra
   Yadav, Amit Kumar
TI HyperQuant-A Computational Pipeline for Higher Order Multiplexed
   Quantitative Proteomics.
SO ACS omega
VL 5
IS 19
BP 10857
EP 10867
DI 10.1021/acsomega.0c00515
PD 2020-May-19
PY 2020
AB Quantitative proteomics has evolved considerably over the last decade
   with the advent of higher order multiplexing (HOM) techniques. With the
   development of methods such as-multitagging, cPILOT, hyperplexing,
   BONPlex, and MITNCAT, the HOM technique is rapidly taking the center
   stage in multiplexed quantitative proteomics. These studies combined MS1
   and MS2 labels in a single experiment enabling higher sample throughput.
   While HOM is highly promising, the computational analysis is still a big
   challenge, as the available tools cannot harness its power completely.
   We have developed a new quantitative pipeline, HyperQuant to aid in
   accurately quantitating complex HOM data. The pipeline uses
   identification results from either MaxQuant or any other search engine
   and quantitation results from QuantWizIQ. The Mapper and Combiner
   modules of HyperQuant allow facile integration of the labeled data,
   along with peptide spectrum match (PSM) intensity/ratio integration for
   proteins, respectively, for each PSM label combination. This also
   includes appropriate combination of replicates/fractions before
   summarizing the protein intensity/ratio, leading to robust quantitation.
   To the best of our knowledge, this is the first tool for the
   quantitation of HOM data with flexibility for any combination of MS1 and
   MS2 labels. We demonstrate its utility in analyzing two 18-plex data
   sets from the hyperplexing and the BONplex studies. The tool is open
   source and freely available for noncommercial use. HyperQuant is a
   highly valuable tool that will help in advancing the field of
   multiplexed quantitative proteomics.
ZS 0
ZB 0
Z8 0
ZR 0
TC 0
Z9 0
EI 2470-1343
UT MEDLINE:32455206
PM 32455206
ER

PT J
AU Yamashita, Norio
   Morita, Masahiko
   Yokota, Hideo
   Mimori-Kiyosue, Yuko
TI Digital Spindle: A New Way to Explore Mitotic Functions by Whole Cell
   Data Collection and a Computational Approach.
SO Cells
VL 9
IS 5
DI 10.3390/cells9051255
PD 2020 May 19
PY 2020
AB From cells to organisms, every living system is three-dimensional (3D),
   but the performance of fluorescence microscopy has been largely limited
   when attempting to obtain an overview of systems' dynamic processes in
   three dimensions. Recently, advanced light-sheet illumination
   technologies, allowing drastic improvement in spatial discrimination,
   volumetric imaging times, and phototoxicity/photobleaching, have been
   making live imaging to collect precise and reliable 3D information
   increasingly feasible. In particular, lattice light-sheet microscopy
   (LLSM), using an ultrathin light-sheet, enables whole-cell 3D live
   imaging of cellular processes, including mitosis, at unprecedented
   spatiotemporal resolution for extended periods of time. This technology
   produces immense and complex data, including a significant amount of
   information, raising new challenges for big image data analysis and new
   possibilities for data utilization. Once the data are digitally archived
   in a computer, the data can be reused for various purposes by anyone at
   any time. Such an information science approach has the potential to
   revolutionize the use of bioimage data, and provides an alternative
   method for cell biology research in a data-driven manner. In this
   article, we introduce examples of analyzing digital mitotic spindles and
   discuss future perspectives in cell biology.
ZS 0
Z8 0
ZR 0
ZB 0
TC 0
Z9 0
EI 2073-4409
UT MEDLINE:32438637
PM 32438637
ER

PT J
AU Harker, Nadine
   Londani, Mukhethwa
   Morojele, Neo
   Petersen Williams, Petal
   Parry, Charles Dh
TI Characteristics and Predictors of Heavy Episodic Drinking (HED) among
   Young People Aged 16-25: The International Alcohol Control Study (IAC),
   Tshwane, South Africa.
SO International journal of environmental research and public health
VL 17
IS 10
DI 10.3390/ijerph17103537
PD 2020 May 19
PY 2020
AB In South Africa, little is known about alcohol consumption patterns,
   such as drinks consumed, container size, salience of alcohol price,
   affordability and availability, and perceptions of alcohol policies as
   potential predictors of heavy episodic alcohol (HED) use among young
   people. This paper examines predictors of HED among young people with
   specific consideration given to these alcohol consumption patterns. This
   study conducted in the Tshwane Metropole in 2014 employed multi-stage
   stratified cluster random sampling. Participants were between the ages
   16-25 years. A structured questionnaire was used to collect data. Of the
   287 (n = 678) participants who had used alcohol in the past six months
   and for whom we had complete consumption data, almost half were
   identified as heavy episodic drinkers (HEDs) and were significantly more
   likely to consume alcohol on a daily basis (p = 0.001). Having nightclub
   as the primary drinking location (p = 0.023) and drinking from a
   container size bigger than one standard drink (p = 0.014) were
   significant predictors for HED. HEDs were also more likely to have a
   perception that most people consume alcohol (p = 0.047). The results
   point to HED of alcohol among young people who drink in South Africa,
   highlighting the need for multicomponent interventions.
RI Parry, Charles/A-2906-2009; Petersen Williams, Petal/
OI Parry, Charles/0000-0001-9787-2785; Petersen Williams,
   Petal/0000-0001-5535-2458
ZB 0
ZR 0
Z8 0
ZS 0
TC 0
Z9 0
EI 1660-4601
UT MEDLINE:32438540
PM 32438540
ER

PT J
AU Rasteau, S
   Sigaux, N
   Louvrier, A
   Bouletreau, P
TI Three-dimensional acquisition technologies for facial soft tissues -
   Applications and prospects in orthognathic surgery.
SO Journal of stomatology, oral and maxillofacial surgery
DI 10.1016/j.jormas.2020.05.013
PD 2020-May-19
PY 2020
AB The management of patients with dento-maxillofacial deformities is based
   on assessments of the dental occlusion - facial skeleton - soft tissues
   triad. As societal demands and surgical practices have evolved, facial
   soft tissues have moved to the forefront of considerations in
   orthognathic surgery. Techniques are therefore required to analyze
   facial soft tissues objectively and reproducibly, for diagnosis,
   preoperative planning, and follow-up. Several technologies are currently
   capable of providing three-dimensional (3D) models of the face, either
   by 3D reconstruction of traditional computed tomography or cone beam
   computed tomography data, or directly by stereophotogrammetry, laser
   scanning or structured light scanning. Multimodal image registration
   techniques allow bone base, dental occlusion and facial soft tissue
   information to be combined in a 3D virtual patient. Three-dimensional
   cephalometric analysis of the facial skeleton and skin is now perfectly
   integrated in virtual planning and is gradually gaining in automation
   and accuracy. Photorealistic 3D simulations allow optimal soft tissue
   planning and facilitate physician-patient communication. Finally, these
   facial modeling techniques facilitate post-operative studies of soft
   tissues, which generally involve comparisons of volumetric data. There
   are many research avenues to pursue and technical improvements are to be
   expected, particularly through the development of big data and
   artificial intelligence approaches.
ZS 0
TC 0
ZB 0
ZR 0
Z8 0
Z9 0
EI 2468-7855
UT MEDLINE:32442635
PM 32442635
ER

PT J
AU Bellamkonda Sathyanarayanan, Vidhyasagar
   Jeevarathinam, Raja Paul Perinbam
   Marudhamuthu, Krishnamurthy
TI A Novel Oppositional Chaotic Flower Pollination Optimization Algorithm
   for Automatic Tuning of Hadoop Configuration Parameters.
SO Big data
DI 10.1089/big.2019.0111
PD 2020-May-19
PY 2020
AB At present, due to the introduction of the big data era, numerous
   numbers of data are generated consistently. Many applications utilize
   big data platforms, namely Spark, Hadoop, Amazon web services, and so
   on, since these platforms use several parameters for tuning that further
   enhance the operating performances. It requires a long duration of time
   to tune the parameters because of the complex relationship and large
   quantity of parameters. As a result, the building of such parameters and
   performance optimization at a particular duration of time becomes a
   challenging task. Several auto-tuning approaches are developed to
   achieve an optimal design. However, these approaches increase the
   computation time and minimize the efficiency of the cluster. It is
   necessary to tune the parameters automatically with low computational
   and processing time as well as to improve the performance of the system.
   In this proposed approach, a novel automatic parameter tuning system
   named as Opt. Tuner is proposed to select the Hadoop configuration
   parameters with less computational time. The optimization of the
   proposed approach is achieved by the Flower Pollination Algorithm. Here,
   a chaotic mapping along with Opposition-Based Learning is introduced for
   population initialization to form a novel Oppositional Chaotic Flower
   Pollination Algorithm. The main motive of this initialization phase
   involves in generating better individuals and to guide the search agent
   more quickly. In this novel approach, 15 configuration parameters are
   considered for auto-tuning. Finally, the performance of the proposed
   approach utilizes the wordcount and sort application to investigate the
   exhibition and proficiency of diverse databases.
RI BS, VIDHYASAGAR/K-7570-2017
OI BS, VIDHYASAGAR/0000-0001-6645-8426
TC 0
ZR 0
ZB 0
Z8 0
ZS 0
Z9 0
EI 2167-647X
UT MEDLINE:32429741
PM 32429741
ER

PT J
AU Ravuri, Vasavi
   Vasundra, S
TI Moth-Flame Optimization-Bat Optimization: Map-Reduce Framework for Big
   Data Clustering Using the Moth-Flame Bat Optimization and Sparse Fuzzy
   C-Means.
SO Big data
DI 10.1089/big.2019.0125
PD 2020-May-19
PY 2020
AB The technical advancements in big data have become popular and most
   desirable among users for storing, processing, and handling huge data
   sets. However, clustering using these big data sets has become a major
   challenge in big data analysis. The conventional clustering algorithms
   used scalable solutions for managing huge data sets. Thus, this study
   proposes a technique for big data clustering using the spark
   architecture. The proposed technique undergoes two steps for clustering
   the big data, involving feature selection and clustering, performed in
   the initial cluster nodes of spark architecture. At first, the initial
   cluster nodes read the big data from various distributed systems, and
   the optimal features are selected and placed in the feature vector based
   on the proposed moth-flame optimization-based bat (MFO-Bat) algorithm,
   which is designed by integrating MFO and Bat algorithms. Then, the
   selected features are fed to the final cluster nodes of spark, which
   uses the sparse-fuzzy C-means method for performing optimal clustering.
   The performance of proposed MFO-Bat outperformed other existing methods
   with a maximal classification accuracy of 95.806%, Dice coefficient of
   99.181%, and Jaccard coefficient of 98.376%, respectively.
TC 0
Z8 0
ZR 0
ZS 0
ZB 0
Z9 0
EI 2167-647X
UT MEDLINE:32429686
PM 32429686
ER

PT J
AU Mayes, Robert
   Long, Tammy
   Huffling, Lacey
   Reedy, Aaron
   Williamson, Brad
TI Undergraduate Quantitative Biology Impact on Biology Preservice
   Teachers.
SO Bulletin of mathematical biology
VL 82
IS 6
BP 63
EP 63
DI 10.1007/s11538-020-00740-z
PD 2020 May 19
PY 2020
AB Quantitative biology is a rapidly advancing field in the biological
   sciences, particularly given the rise of large datasets and computer
   processing capabilities that have continually expanded over the past
   50years. Thus, the question arises, How should K-12 biology teachers
   incorporate quantitative biology skills into their biology curriculum?
   The teaching of quantitative biology has not been readily integrated
   into undergraduate biology curricula that impact preservice teachers.
   This has potential to cascade effects downward into the quality of
   learning about quantitative biology that can be expected in K-12
   contexts. In this paper, we present the perspectives of a mathematics
   educator, a science educator, and two biologists, and discuss how we
   have personally incorporated aspects of quantitative reasoning into our
   courses. We identify some common challenges relevant to expanding
   implementation of quantitative reasoning in undergraduate biology
   courses in order to serve the needs of preservice teachers-both in their
   disciplinary courses and methods courses. For example, time constraints,
   math pedagogical content knowledge, and personal views about the
   relevance of quantitative principles in biology teaching and learning
   can impact how and to what extent they become implemented in curricula.
   In addition, although national standards at the K-12 level do address
   quantitative reasoning, the emphasis and guidance provided are sparser
   than for other content standards. We predict that both K-12 standards
   and guidelines for undergraduate education will only increase in their
   emphasis on quantitative skills as computation, "big data," and
   statistical modeling are increasingly becoming requisite skills for
   biologists.
TC 0
ZS 0
Z8 0
ZB 0
ZR 0
Z9 0
EI 1522-9602
UT MEDLINE:32430563
PM 32430563
ER

PT J
AU Ovchinnikova, Svetlana
   Anders, Simon
TI Exploring dimension-reduced embeddings with Sleepwalk.
SO Genome research
DI 10.1101/gr.251447.119
PD 2020-May-19
PY 2020
AB Dimension-reduction methods, such as t-SNE or UMAP, are widely used when
   exploring high-dimensional data describing many entities, for example,
   RNA-seq data for many single cells. However, dimension reduction is
   commonly prone to introducing artifacts, and we hence need means to see
   where a dimension-reduced embedding is a faithful representation of the
   local neighborhood and where it is not. We present Sleepwalk, a simple
   but powerful tool that allows the user to interactively explore an
   embedding, using color to depict original or any other distances from
   all points to the cell under the mouse cursor. We show how this approach
   not only highlights distortions but also reveals otherwise hidden
   characteristics of the data, and how Sleepwalk's comparative modes help
   integrate multisample data and understand differences between embedding
   and preprocessing methods. Sleepwalk is a versatile and intuitive tool
   that unlocks the full power of dimension reduction and will be of value
   not only in single-cell RNA-seq but also in any other area with
   matrix-shaped big data.
RI Anders, Simon/D-4087-2011
OI Anders, Simon/0000-0003-4868-1805
ZB 0
ZR 0
Z8 0
ZS 0
TC 0
Z9 0
EI 1549-5469
UT MEDLINE:32430339
PM 32430339
ER

PT J
AU Kim, Kwanho
   Gibson, Laura A
   Williams, Sharon
   Kim, Yoonsang
   Binns, Steven
   Emery, Sherry L
   Hornik, Robert C
TI Valence of Media Coverage about Electronic Cigarettes and Other Tobacco
   Products from 2014-2017: Evidence from Automated Content Analysis.
SO Nicotine & tobacco research : official journal of the Society for
   Research on Nicotine and Tobacco
DI 10.1093/ntr/ntaa090
PD 2020-May-19
PY 2020
AB INTRODUCTION: As media exposure can influence people's opinions and
   perceptions about vaping and smoking, analyzing the valence of media
   content about tobacco products (i.e., overall attitude toward tobacco,
   cigars, electronic cigarettes, etc.) is an important issue. This study
   advances the field by analyzing a large amount of media content about
   multiple tobacco products across six different media sources.
   METHODS: From May 2014 to December 2017, we collected all
   English-language media items about tobacco products that U.S. young
   people might see from mass media and websites (long-form), and social
   media (Twitter and YouTube). We used supervised machine-learning to
   develop validated algorithms to label the valence of these media items.
   Using the labeled results, we examined the impact of product type
   (e-cigarettes vs. other tobacco products), source (long-form vs. social
   media), and time (by month) on the valence of coverage.
   RESULTS: We obtained 152,886 long-form media texts (20% with more than a
   passing mention), nearly 86 million tweets, and 12,262 YouTube videos
   about tobacco products. Most long-form media content opposed, while most
   social media coverage supported, the use of e-cigarettes and other
   tobacco products. Over time, within source valence proportions were
   stable, though in aggregate, the amount of media coverage against the
   use of tobacco products decreased.
   CONCLUSIONS: This study describes the U.S. public communication
   environment about vaping and smoking for young people and offers a novel
   big data approach to analyzing media content. Results suggest that
   content has gradually become less negative toward the use of
   e-cigarettes and other tobacco products.
ZR 0
ZB 0
Z8 0
TC 0
ZS 0
Z9 0
EI 1469-994X
UT MEDLINE:32428214
PM 32428214
ER

PT J
AU Neely, Christopher J
   Graham, Elaina D
   Tully, Benjamin J
TI MetaSanity: An integrated microbial genome evaluation and annotation
   pipeline.
SO Bioinformatics (Oxford, England)
DI 10.1093/bioinformatics/btaa512
PD 2020-May-19
PY 2020
AB SUMMARY: As the importance of microbiome research continues to become
   more prevalent and essential to understanding a wide variety of
   ecosystems (e.g., marine, built, host-associated, etc.), there is a need
   for researchers to be able to perform highly reproducible and quality
   analysis of microbial genomes. MetaSanity incorporates analyses from
   eleven existing and widely used genome evaluation and annotation suites
   into a single, distributable workflow, thereby decreasing the workload
   of microbiologists by allowing for a flexible, expansive data analysis
   pipeline. MetaSanity has been designed to provide separate, reproducible
   workflows, that (1) can determine the overall quality of a microbial
   genome, while providing a putative phylogenetic assignment, and (2) can
   assign structural and functional gene annotations with varying degrees
   of specificity to suit the needs of the researcher. The software suite
   combines the results from several tools to provide broad insights into
   overall metabolic function. Importantly, this software provides built-in
   optimization for "big data" analysis by storing all relevant outputs in
   an SQL database, allowing users to query all the results for the
   elements that will most impact their research.
   AVAILABILITY: MetaSanity is provided under the GNU General Public
   License v.3.0 and is available for download at
   https://github.com/cjneely10/MetaSanity. This application is distributed
   as a Docker image. MetaSanity is implemented in Python3/Cython and C++.
   Instructions for its installation and use are available within the
   GitHub wiki page at https://github.com/cjneely10/MetaSanity/wiki, and
   additional instructions are available at
   https://cjneely10.github.io/year-archive/. MetaSanity is optimized for
   users with limited programming experience.
   SUPPLEMENTARY INFORMATION: Supplementary data are available at
   Bioinformatics online.
ZS 0
ZB 0
TC 0
ZR 0
Z8 0
Z9 0
EI 1367-4811
UT MEDLINE:32426808
PM 32426808
ER

PT J
AU Horvath, Dragos
   Marcou, Gilles
   Varnek, Alexandre
TI "Big Data" Fast Chemoinformatics Model to Predict Generalized Born
   Radius and Solvent Accessibility as a Function of Geometry.
SO Journal of chemical information and modeling
DI 10.1021/acs.jcim.9b01172
PD 2020-May-19
PY 2020
AB The Generalized Born (GB) solvent model is offering the best
   accuracy/computing effort ratio yet requires drastic simplifications to
   estimate of the Effective Born Radii (EBR) in bypassing a too expensive
   volume integration step. EBRs are a measure of the degree of burial of
   an atom and not very sensitive to small changes of geometry: in
   molecular dynamics, the costly EBR update procedure is not mandatory at
   every step. This work however aims at implementing a GB model into the
   Sampler for Multiple Protein-Ligand Entities (S4MPLE) evolutionary
   algorithm with mandatory EBR updates at each step triggering arbitrarily
   large geometric changes. Therefore, a quantitative structure-property
   relationship has been developed in order to express the EBRs as a linear
   function of both the topological neighborhood and geometric occupancy of
   the space around atoms. A training set of 810 molecular systems,
   starting from fragment-like to drug-like compounds, proteins, host-guest
   systems, and ligand-protein complexes, has been compiled. For each
   species, S4MPLE generated several hundreds of random conformers. For
   each atom in each geometry of each species, its "standard" EBR was
   calculated by numeric integration and associated to topological and
   geometric descriptors of the atom neighborhood. This training set (EBR,
   atom descriptors) involving >5 M entries was subjected to a
   boot-strapping multilinear regression process with descriptor selection.
   In parallel, the strategy was repurposed to also learn atomic
   solvent-accessible areas (SA) based on the same descriptors. Resulting
   linear equations were challenged to predict EBR and SA values for a
   similarly compiled external set of >2000 new molecular systems.
   Solvation energies calculated with estimated EBR and SA match "standard"
   energies within the typical error of a force-field-based approach (a few
   kilocalories per mole). Given the extreme diversity of molecular systems
   covered by the model, this simple EBR/SA estimator covers a vast
   applicability domain.
ZS 0
ZB 0
ZR 0
TC 0
Z8 0
Z9 0
EI 1549-960X
UT MEDLINE:32374171
PM 32374171
ER

PT J
AU Cheng, Fei
   Li, Huizhen
   Brooks, Bryan W
   You, Jing
TI Retrospective Risk Assessment of Chemical Mixtures in the Big Data Era:
   An Alternative Classification Strategy to Integrate Chemical and
   Toxicological Data.
SO Environmental science & technology
VL 54
IS 10
BP 5925
EP 5927
DI 10.1021/acs.est.0c01062
PD 2020-May-19
PY 2020
RI Brooks, Bryan/B-2612-2010
OI Brooks, Bryan/0000-0002-6277-9852
ZR 0
ZB 0
ZS 0
Z8 0
TC 0
Z9 0
EI 1520-5851
UT MEDLINE:32356979
PM 32356979
ER

PT J
AU Yang, Yun
   Duan, Zongtao
TI An effective co-evolutionary algorithm based on artificial bee colony
   and differential evolution for time series predicting optimization
SO COMPLEX & INTELLIGENT SYSTEMS
DI 10.1007/s40747-020-00149-0
EA MAY 2020
PY 2020
AB Non-linear model optimization for predicting time series is a challenge
   problem. In Intelligent Transportation Systems (ITS) application, the
   indispensable short-term traffic flow prediction with big data makes the
   problem worst. To improve the prediction accuracy and ensure real-time
   performance in the big data environment, we propose a novel
   co-evolutionary artificial bee colony (ABC) improved by differential
   evolution (DE) optimization algorithm combined with a traffic flow
   predicting model trained by extreme learning machine (ELM) neural
   network. The proposed model can inherit the better generalization
   performance and the less training time consumption of the standard ELM,
   and can achieve a more balanced search strategy with the optimized
   weights and biases to overcome the random initialization deficiency of
   the typical ELM, and successfully obtain higher prediction accuracy
   compared with state-of-the-art methods. To verify the efficiency of the
   proposed model, we apply it to Lozi and Tent chaotic time series
   simulations and measured traffic flow time series experiments.
   Simulation and experimental results demonstrate that the proposed model
   has superior performance and competitive computational efficiency.
Z8 0
TC 0
ZS 0
ZB 0
ZR 0
Z9 0
SN 2199-4536
EI 2198-6053
UT WOS:000533802600001
ER

PT J
AU Christensen, Alexander P.
   Golino, Hudson
   Silvia, Paul J.
TI A Psychometric Network Perspective on the Validity and Validation of
   Personality Trait Questionnaires
SO EUROPEAN JOURNAL OF PERSONALITY
DI 10.1002/per.2265
EA MAY 2020
PY 2020
AB This article reviews the causal implications of latent variable and
   psychometric network models for the validation of personality trait
   questionnaires. These models imply different data generating mechanisms
   that have important consequences for the validity and validation of
   questionnaires. From this review, we formalize a framework for assessing
   the evidence for the validity of questionnaires from the psychometric
   network perspective. We focus specifically on the structural phase of
   validation, where items are assessed for redundancy, dimensionality, and
   internal structure. In this discussion, we underline the importance of
   identifying unique personality components (i.e. an item or set of items
   that share a unique common cause) and representing the breadth of each
   trait's domain in personality networks. After, we argue that
   psychometric network models have measures that are statistically
   equivalent to factor models but we suggest that their substantive
   interpretations differ. Finally, we provide a novel measure of
   structural consistency, which provides complementary information to
   internal consistency measures. We close with future directions for how
   external validation can be executed using psychometric network models.
   (c) 2020 European Association of Personality Psychology
Z8 0
ZB 0
ZR 0
TC 0
ZS 0
Z9 0
SN 0890-2070
EI 1099-0984
UT WOS:000533543800001
ER

PT J
AU Fiorentino, Raffaele
   Grimaldi, Francesco
   Lamboglia, Rita
   Merendino, Alessandro
TI How smart technologies can support sustainable business models: insights
   from an air navigation service provider
SO MANAGEMENT DECISION
DI 10.1108/MD-09-2019-1327
EA MAY 2020
PY 2020
AB Purpose Although research on smart technologies explains their critical
   importance in sustainable business models (SBMs) (Mikalef et al., 2017),
   it remains unclear how organisations can embrace smart technologies to
   create and/or improve their sustainable business models. The purpose of
   this paper is to unravel and address the challenges of smart
   technologies to build and maintain a sustainable business model for
   organisations. Design/methodology/approach The research develops an
   empirical analysis through a case study approach. We have investigated
   the case of ENAV - an Italian air navigation service provider - and how
   this firm uses smart technologies in the creation of its successful SBM.
   After constructing a basic theory, the authors moved to evidence
   collection. The data analysis has adopted a qualitative approach based
   on a thematic analysis of the transcripts and related documents.
   Findings The findings from the case study support the idea that the
   business value and the strategic relevance of smart technologies still
   remain largely underestimated in SBM adoption (Mikalef et al., 2017).
   Case study findings suggest that until today smart technologies have
   played a minimal role in SBM adoption. However, the smart technologies
   show the potential to inform the SBM adoption process by contributing to
   corporate communication for external stakeholders and to the main
   dimensions of SBMs such as safety and security or the respect for social
   and environmental criteria in the supply chain. Practical implications
   This study seeks to support organisations and their directors to build
   and improve sustainable business models through smart technologies to
   maintain their competitive advantages. Specifically, our findings
   suggest that smart technologies can help organisations bridge the
   design-implementation gap of sustainable business models.
   Originality/value This research advances our understanding of the role
   of smart technologies by explaining how they can enhance sustainable
   business model adoption. Indeed, we offer a comprehensive view of the
   integration of insights from three different but related literature
   streams such as sustainability strategies, smart technologies and change
   management studies.
ZB 0
Z8 0
ZS 0
ZR 0
TC 0
Z9 0
SN 0025-1747
EI 1758-6070
UT WOS:000533582500001
ER

PT J
AU Marques, Ana, I
   Garcia, Vicente
   Salvador Sanchez, J.
TI Ranking-based MCDM models in financial management applications: analysis
   and emerging challenges
SO PROGRESS IN ARTIFICIAL INTELLIGENCE
DI 10.1007/s13748-020-00207-1
EA MAY 2020
PY 2020
AB Over the last decades, the academic and professional communities have
   paid much attention toward the use of multi-criteria decision-making
   methods in a range of business and financial problems due to the variety
   and complexity of their decisions. Within this branch of operations
   research, the value-based and outranking relations approaches stand as
   two of the most powerful methodologies for decision-makers and analysts
   to produce accurate predictions and consistent evaluations in financial
   decision-making problems. This paper aims to provide an in-depth
   presentation of the contributions of multi-attribute value-based and
   outranking relations methods to a group of relevant financial
   applications in the period 2000-2018, putting the emphasis on the
   state-of-the-art developments and identifying open questions and
   critical challenges that deserve further research efforts.
ZS 0
ZR 0
Z8 0
ZB 0
TC 0
Z9 0
SN 2192-6352
EI 2192-6360
UT WOS:000533823300001
ER

PT J
AU Garg, Bharat
   Patel, Sujit Kumar
   Dutt, Sunil
TI LoBA: A Leading One Bit Based Imprecise Multiplier for Efficient Image
   Processing
SO JOURNAL OF ELECTRONIC TESTING-THEORY AND APPLICATIONS
DI 10.1007/s10836-020-05883-4
EA MAY 2020
PY 2020
AB Several applications such as signal processing, multimedia and big data
   analysis exhibit computational error tolerance. This tolerance can be
   exploited to achieve efficient designs by sacrificing accuracy.
   Therefore, approximate computing presents a new design paradigm that
   smashes the traditional belief of error-free computations and provides
   efficient design with quality metrics specific to an application. The
   multiplication operation significantly determines the performance of the
   core due to the compute intensive operation. Therefore, this paper
   proposes a novel leading one bit based approximate (LoBA) multiplier
   architecture that selects k-bits from n-bit inputs (k <= n/4) based on
   leading one bit (LOB) and then computes approximate product based of
   these small input. The accuracy is further improved by selecting next
   k-bits based on LOB position and considering the partial product for
   computing final product. Four imprecise LoBA multipliers are presented
   that provide trade-off between accuracy and performance. Finally, the
   effectiveness of the proposed architectures is shown over the existing
   multipliers as standalone arithmetic unit and in the application by
   implementing Gaussian smoothing filters. The proposed 16-bit LoBA0 and
   LoBA1 designs reduce power consumption by 64.2% and 32.9%, respectively
   over the existing multiplier architecture.
ZS 0
TC 0
ZB 0
ZR 0
Z8 0
Z9 0
SN 0923-8174
EI 1573-0727
UT WOS:000533796700001
ER

PT J
AU Vogelius, Ivan R.
   Petersen, Jens
   Bentzen, Soren M.
TI Harnessing data science to advance radiation oncology
SO MOLECULAR ONCOLOGY
DI 10.1002/1878-0261.12685
EA MAY 2020
PY 2020
AB Radiation oncology, a major treatment modality in the care of patients
   with malignant disease, is a technology- and computer-intensive medical
   specialty. As such, it should lend itself ideally to data science
   methods, where computer science, statistics, and clinical knowledge are
   combined to advance state-of-the-art care. Nevertheless, data science
   methods in radiation oncology research are still in their infancy and
   successful applications leading to improved patient care remain scarce.
   Here, we discuss data interoperability issues within and across
   organizational boundaries that hamper the introduction of big data and
   data science techniques in radiation oncology. At the semantic level,
   creating common underlying models and codification of the data,
   including the use of data elements with standardized definitions, an
   ontology, remains a work in progress. Methodological issues in data
   science and in the use of large population-based health data registries
   are identified. We show that data science methods and big data cannot
   replace randomized clinical trials in comparative effectiveness research
   by reviewing a series of instances where the outcomes of big data
   analyses and randomized trials are at odds. We also discuss the modern
   wave of machine learning and artificial intelligence as represented by
   deep learning and convolutional neural networks. Finally, we identify
   promising research avenues and remain optimistic that the data sources
   in radiation oncology can be linked to yield important insights in the
   near future. We argue that data science will be a valuable complement
   to, but not a replacement of, the traditional hypothesis-driven
   translational research chain and the randomized clinical trials that
   form the backbone of evidence-based medicine.
OI Vogelius, Ivan Richter/0000-0002-8877-1218
Z8 0
ZS 0
ZB 0
ZR 0
TC 0
Z9 0
SN 1574-7891
EI 1878-0261
UT WOS:000533273400001
PM 32255249
ER

PT J
AU De Grove, Frederik
   Boghe, Kristof
   De Marez, Lieven
TI (What) Can Journalism Studies Learn from Supervised Machine Learning?
SO JOURNALISM STUDIES
VL 21
IS 7
SI SI
BP 912
EP 927
DI 10.1080/1461670X.2020.1743737
PD MAY 18 2020
PY 2020
AB In recent years, scholars have explored the applicability of supervised
   machine learning (SML) within journalism studies. While such
   computational methods could be of added value to the field, the
   rationale for employing these supervised models harbors some assumptions
   that deserve further inspection. This paper seeks to specify under which
   conditions SML could be useful for journalism scholars and where the
   field stands in exploiting its potential benefits. We start with an
   introduction to SML and give an overview of its applications within
   journalism studies. Next, we identify challenges for the field in its
   adoption of such techniques. These include overstating the time and
   financial savings caused by automatic coding, neglecting proper sampling
   methods, the danger of algorithmic determinism and the limited
   generalizability of predictive modeling across different domains,
   contexts and time periods. At the same time, we distinguish several
   opportunities. These include sharing classifiers, standardizing coding
   schemes and adopting general purpose techniques. Most importantly, in
   order for SML to contribute to the epistemological advancements in the
   field, SML could be used to explain how long-standing theories in
   journalism are changing. In turn, this might help us to disentangle the
   inner workings of our contemporary complex news ecosystem.
Z8 0
ZR 0
ZS 0
TC 0
ZB 0
Z9 0
SN 1461-670X
EI 1469-9699
UT WOS:000532580700005
ER

PT J
AU Boyko, Alexey
   Melnikov, Mikhail
TI Prevalence and Incidence of Multiple Sclerosis in Russian Federation: 30
   Years of Studies.
SO Brain sciences
VL 10
IS 5
DI 10.3390/brainsci10050305
PD 2020 May 18
PY 2020
AB In the Russian Federation, multiple sclerosis prevalence rates vary from
   10 to 80 cases per 100,000, depending on region and the nationality of
   the population. The main characteristics of multiple sclerosis
   epidemiology in the XX century in this big territory are: (1) steady
   increase in multiple sclerosis prevalence and incidence rates, maybe
   because of better diagnosis and treatment, but also changes in
   environmental/epigenetic risk profile and/or lifestyle factors; (2)
   increase of the female to male ratio, increase in multiple sclerosis
   incidence mainly in females; (3) appearance and increasing frequency of
   multiple sclerosis in ethnic groups, previously free of multiple
   sclerosis (Northern Tribes, Yakuts and others). The latest data show
   that in European Russia, the multiple sclerosis prevalence varies from
   30 to 80 cases, in Siberia-from 20 to 70 cases, with steady increases,
   especially in women.
ZS 0
ZB 0
Z8 0
ZR 0
TC 0
Z9 0
SN 2076-3425
UT MEDLINE:32443404
PM 32443404
ER

PT J
AU Deng, Zile
   Cao, Yuanlong
   Zhou, Xinyu
   Yi, Yugen
   Jiang, Yirui
   You, Ilsun
TI Toward Efficient Image Recognition in Sensor-Based IoT: A Weight
   Initialization Optimizing Method for CNN Based on RGB Influence
   Proportion.
SO Sensors (Basel, Switzerland)
VL 20
IS 10
DI 10.3390/s20102866
PD 2020 May 18
PY 2020
AB As the Internet of Things (IoT) is predicted to deal with different
   problems based on big data, its applications have become increasingly
   dependent on visual data and deep learning technology, and it is a big
   challenge to find a suitable method for IoT systems to analyze image
   data. Traditional deep learning methods have never explicitly taken the
   color differences of data into account, but from the experience of human
   vision, colors play differently significant roles in recognizing things.
   This paper proposes a weight initialization method for deep learning in
   image recognition problems based on RGB influence proportion, aiming to
   improve the training process of the learning algorithms. In this paper,
   we try to extract the RGB proportion and utilize it in the weight
   initialization process. We conduct several experiments on different
   datasets to evaluate the effectiveness of our proposal, and it is proven
   to be effective on small datasets. In addition, as for the access to the
   RGB influence proportion, we also provide an expedient approach to get
   the early proportion for the following usage. We assume that the
   proposed method can be used for IoT sensors to securely analyze complex
   data in the future.
OI Cao, Yuanlong/0000-0002-6557-6559; You, Ilsun/0000-0002-0604-3445
Z8 0
ZS 0
TC 0
ZB 0
ZR 0
Z9 0
EI 1424-8220
UT MEDLINE:32443591
PM 32443591
ER

PT J
AU Davy, Christina M
   Squires, Kelly
   Zimmerling, J Ryan
TI Estimation of spatiotemporal trends in bat abundance from mortality data
   collected at wind turbines.
SO Conservation biology : the journal of the Society for Conservation
   Biology
DI 10.1111/cobi.13554
PD 2020-May-18
PY 2020
AB Renewable energy sources such as wind energy are an essential tool for
   reducing the causes of climate change, but wind turbines can pose a
   collision risk for bats. To date, the population-level effects of
   wind-related mortality have only been estimated for a single bat
   species. To estimate temporal trends in bat abundance, we considered
   wind turbines as opportunistic sampling tools for flying bats (analogous
   to fishing nets), where catch per unit effort (carcass abundance per
   monitored turbine) is a proxy for aerial abundance of bats, after
   accounting for seasonal variation in activity. We leveraged a large
   dataset of standardized bat carcass searches from 594 turbines in
   southern Ontario, Canada, correcting for surveyor efficiency and
   scavenger removal. We used Bayesian hierarchical models to estimate
   temporal trends in aerial abundance of bats and explore the effect of
   spatial factors (including landscape features associated with bat
   habitat, such as wetlands, croplands and forested lands) on the number
   of mortalities for each species.We found strong evidence of rapid
   declines in the abundance of four species in our study areas, with
   declines in "capture" of carcasses over seven years ranging from 65%
   (big brown bat) to 91% (silver-haired bat). Estimated declines were
   independent of the effects of mitigation (increasing turbine cut-in
   speed from 3.5 to 5.5 m/s), which significantly reduced but did not
   eliminate bat mortality. Late-summer mortality of hoary, eastern red,
   and silver-haired bats was predicted by woodlot cover, while mortality
   of big brown bats decreased with increasing elevation.These landscape
   predictors of bat mortality can inform the siting of future wind energy
   operations. Nevertheless, our most important result is the apparent
   decline in abundance of four "common" species of bat in the airspace,
   which requires further investigation. Article impact statement: Data
   from 594 wind turbines suggest rapid declines in abundance for four
   "common" species of bat, and identify spatial predictors of bat
   mortality at turbines. This article is protected by copyright. All
   rights reserved.
ZR 0
ZB 0
TC 0
ZS 0
Z8 0
Z9 0
EI 1523-1739
UT MEDLINE:32424911
PM 32424911
ER

PT J
AU Beaney, Thomas
   Schutte, Aletta E
   Stergiou, George S
   Borghi, Claudio
   Burger, Dylan
   Charchar, Fadi J
   Cro, Suzie
   Diaz, Alejandro Bimbo
   Damasceno, Albertino
   Espeche, Walter G
   Jose, Arun Pulikkottil
   Khan, Nadia A
   Kokubo, Yoshihiro
   Maheshwari, Anuj
   Marin, Marcos J
   More, Arun
   Neupane, Dinesh
   Nilsson, Peter M
   Patil, Mansi
   Prabhakaran, Dorairaj
   Ramirez, Agustin Jose
   Rodriguez, Pablo D
   Schlaich, Markus P
   Steckelings, Ulrike Muscha
   Tomaszewski, Maciej
   Unger, Thomas
   Wainford, Richard D
   Wang, Ji-Guang
   Williams, Bryan
   Poulter, Neil R
TI May Measurement Month 2019: The Global Blood Pressure Screening Campaign
   of the International Society of Hypertension.
SO Hypertension (Dallas, Tex. : 1979)
DI 10.1161/HYPERTENSIONAHA.120.14874
PD 2020-May-18
PY 2020
AB Elevated blood pressure remains the single biggest risk factor
   contributing to the global burden of disease and mortality. May
   Measurement Month is an annual global screening campaign aiming to
   improve awareness of blood pressure at the individual and population
   level. Adults ({greater than or equal to}18 years) recruited through
   opportunistic sampling were screened at sites in 92 countries during May
   2019. Ideally three blood pressure readings were measured for each
   participant, and data on lifestyle factors and co-morbidities were
   collected. Hypertension was defined as a systolic BP {greater than or
   equal to} 140 mmHg, and/or a diastolic BP {greater than or equal to} 90
   mmHg (mean of the second and third readings) or taking antihypertensive
   medication. When necessary, multiple imputation was used to estimate
   participants' mean blood pressure. Mixed-effects models were used to
   evaluate associations between blood pressure and participant
   characteristics. Of 1,508,130 screenees 482,273 (32.0%) had never had a
   blood pressure measurement before and 513,337 (34.0%) had hypertension,
   of whom 58.7% were aware and 54.7% were on antihypertensive medication.
   Of those on medication, 57.8% were controlled to <140/90 mmHg, and 28.9%
   to <130/80mmHg. Of all those with hypertension, 31.7% were controlled to
   <140/90mmHg and 350,825 (23.3%) participants had untreated, or
   inadequately treated hypertension. Of those taking antihypertensive
   medication, half were taking only a single drug and 25% reported using
   aspirin inappropriately. This survey is the largest ever synchronised
   and standardised contemporary compilation of global blood pressure data.
   This campaign is needed as a temporary substitute for systematic blood
   pressure screening in many countries worldwide.
RI Beaney, Thomas/; Schutte, Aletta/E-5126-2018; Steckelings, Ulrike Muscha/
OI Beaney, Thomas/0000-0001-9709-7264; Schutte, Aletta/0000-0001-9217-4937;
   Steckelings, Ulrike Muscha/0000-0002-5430-4275
TC 0
ZS 0
Z8 0
ZB 0
ZR 0
Z9 0
EI 1524-4563
UT MEDLINE:32419505
PM 32419505
ER

PT J
AU Prinsloo, Paul
TI Data frontiers and frontiers of power in (higher) education: a view
   of/from the Global South
SO TEACHING IN HIGHER EDUCATION
VL 25
IS 4
SI SI
BP 366
EP 383
DI 10.1080/13562517.2020.1723537
PD MAY 18 2020
PY 2020
AB 'Data as technology' has always been, and continues to be an essential
   part of the structuring of South African society and education, during
   and post-colonialism and post-apartheid. In the reconfiguration of South
   African education post-apartheid, student data constitutes a data
   frontier as un-mapped, under-utilised and ready for the picking. This
   article maps the data frontier in the nexus of higher education in the
   global/colonial present and the data imaginary that provides a
   particular vision in service of a neoliberal discursive position and
   ideological orientation. As such, the data frontier acts as 'generative
   matrix' for educational policy attempting to address the legacies of
   colonialism and apartheid. The value contribution of this article lies
   in its positioning of the data imaginary in the context of a neoliberal
   approach to education in the context of the Global South.
Z8 0
ZR 0
TC 1
ZB 0
ZS 0
Z9 1
SN 1356-2517
EI 1470-1294
UT WOS:000531004000002
ER

PT J
AU Marachi, Roxana
   Quill, Lawrence
TI The case of Canvas: Longitudinal datafication through learning
   management systems
SO TEACHING IN HIGHER EDUCATION
VL 25
IS 4
SI SI
BP 418
EP 434
DI 10.1080/13562517.2020.1739641
PD MAY 18 2020
PY 2020
AB The Canvas Learning Management System (LMS) is used in thousands of
   universities across the United States and internationally, with a strong
   and growing presence in K-12 and higher education markets. Analyzing the
   development of the Canvas LMS, we examine 1) 'frictionless' data
   transitions that bridge K12, higher education, and workforce data 2)
   integration of third party applications and interoperability or
   data-sharing across platforms 3) privacy and security vulnerabilities,
   and 4) predictive analytics and dataveillance. We conclude that
   institutions of higher education are currently ill-equipped to protect
   students and faculty required to use the Canvas Instructure LMS from
   data harvesting or exploitation. We challenge inevitability narratives
   and call for greater public awareness concerning the use of predictive
   analytics, impacts of algorithmic bias, need for algorithmic
   transparency, and enactment of ethical and legal protections for users
   who are required to use such software platforms.
OI Marachi, Roxana/0000-0002-3483-4121
ZB 0
Z8 0
ZR 0
ZS 0
TC 1
Z9 1
SN 1356-2517
EI 1470-1294
UT WOS:000531004000005
ER

PT J
AU Kwet, Michael
   Prinsloo, Paul
TI The 'smart' classroom: a new frontier in the age of the smart university
SO TEACHING IN HIGHER EDUCATION
VL 25
IS 4
SI SI
BP 510
EP 526
DI 10.1080/13562517.2020.1734922
PD MAY 18 2020
PY 2020
AB This article examines developments in the 'smart classroom' as a new
   frontier for the university. It provides a conceptual map of the scope
   and limitations of smart classrooms, contextualized to smart university
   initiatives. First, it introduces the notion of 'smart' technology in
   cities, campuses, and classrooms. Next, it examines how the smart
   classroom is conceptualized, its present applications, and how it may be
   utilized with or without integration into the smart campus. Finally, it
   explores the ethical implications of the smart classroom. It concludes
   by recommending new regulations for smart classrooms and provides
   examples of classroom technologies constructive to the pedagogical
   process.
ZR 0
Z8 0
TC 1
ZB 0
ZS 0
Z9 1
SN 1356-2517
EI 1470-1294
UT WOS:000531004000010
ER

PT J
AU He, Yihai
   Cui, Jiaming
   Liu, Fengdi
   Zhu, Chunling
TI Risk-based quality accident ranking approach using failure mechanism and
   Axiomatic domain mapping
SO TOTAL QUALITY MANAGEMENT & BUSINESS EXCELLENCE
VL 31
IS 7-8
BP 847
EP 868
DI 10.1080/14783363.2018.1453300
PD MAY 18 2020
PY 2020
AB Manufacturers face numerous product quality accidents and thus require
   an effective and general approach to rank the occurred quality
   accidents. Therefore, a universal risk-based quality accident ranking
   method emphasising the importance of the accident formation mechanism is
   proposed in this paper to rank, analyse, and prevent occurred quality
   accidents comprehensively. First, the risk formation mechanism of
   quality accident is proposed emphatically using two typical failure
   mechanisms and Axiomatic domain mapping, and the structure of big
   quality accident data is presented on the basis of big product lifecycle
   data in order to provide data support for the subsequent risk analysis.
   Second, the accident failure cost, probability, and detectivity are
   adopted as the critical risk factors, which are computed using the
   failure cost model, extended fault tree and Axiomatic relevance tree
   respectively. Third, a modified risk importance index considering the
   relative weight of risk factors is presented to measure and rank the
   risk priority of quality accidents. Finally, a case study on a computer
   control panel accident risk analysis is conducted to verify the
   effectiveness of the proposed approach. Results show that the proposed
   method can objectively reflect the accident risk degree and provide
   necessary reference for accident risk mitigation.
ZS 0
ZB 0
ZR 0
TC 4
Z8 0
Z9 4
SN 1478-3363
EI 1478-3371
UT WOS:000530945100009
ER

PT J
AU Cai, Ming Bo
   Shvartsman, Michael
   Wu, Anqi
   Zhang, Hejia
   Zhu, Xia
TI Incorporating structured assumptions with probabilistic graphical models
   in fMRI data analysis.
SO Neuropsychologia
BP 107500
EP 107500
DI 10.1016/j.neuropsychologia.2020.107500
PD 2020-May-17
PY 2020
AB With the wide adoption of functional magnetic resonance imaging (fMRI)
   by cognitive neuroscience researchers, large volumes of brain imaging
   data have been accumulated in recent years. Aggregating these data to
   derive scientific insights often faces the challenge that fMRI data are
   high-dimensional, heterogeneous across people, and noisy. These
   challenges demand the development of computational tools that are
   tailored both for the neuroscience questions and for the properties of
   the data. We review a few recently developed algorithms in various
   domains of fMRI research: fMRI in naturalistic tasks, analyzing
   full-brain functional connectivity, pattern classification, inferring
   representational similarity and modeling structured residuals. These
   algorithms all tackle the challenges in fMRI similarly: they start by
   making clear statements of assumptions about neural data and existing
   domain knowledge, incorporating those assumptions and domain knowledge
   into probabilistic graphical models, and using those models to estimate
   properties of interest or latent structures in the data. Such approaches
   can avoid erroneous findings, reduce the impact of noise, better utilize
   known properties of the data, and better aggregate data across groups of
   subjects. With these successful cases, we advocate wider adoption of
   explicit model construction in cognitive neuroscience. Although we focus
   on fMRI, the principle illustrated here is generally applicable to brain
   data of other modalities.
OI Cai, Ming Bo/0000-0003-0768-7215
ZB 0
TC 0
ZS 0
ZR 0
Z8 0
Z9 0
EI 1873-3514
UT MEDLINE:32433952
PM 32433952
ER

PT J
AU Belhadi, Asma
   Djenouri, Youcef
   Djenouri, Djamel
   Lin, Jerry Chun-Wei
TI A recurrent neural network for urban long-term traffic flow forecasting
SO APPLIED INTELLIGENCE
DI 10.1007/s10489-020-01716-1
EA MAY 2020
PY 2020
AB This paper investigates the use of recurrent neural network to predict
   urban long-term traffic flows. A representation of the long-term flows
   with related weather and contextual information is first introduced. A
   recurrent neural network approach, named RNN-LF, is then proposed to
   predict the long-term of flows from multiple data sources. Moreover, a
   parallel implementation on GPU of the proposed solution is developed
   (GRNN-LF), which allows to boost the performance of RNN-LF. Several
   experiments have been carried out on real traffic flow including a small
   city (Odense, Denmark) and a very big city (Beijing). The results reveal
   that the sequential version (RNN-LF) is capable of dealing effectively
   with traffic of small cities. They also confirm the scalability of
   GRNN-LF compared to the most competitive GPU-based software tools when
   dealing with big traffic flow such as Beijing urban data.
TC 0
Z8 0
ZB 0
ZS 0
ZR 0
Z9 0
SN 0924-669X
EI 1573-7497
UT WOS:000533171900001
ER

PT J
AU Timms, L.
   Hume, C.
   Wilson, V
   McClean, L.
   Marshman, Z.
   Zaitoun, H.
TI A service evaluation of an intervention to increase application of
   topical fluoride varnish in general dental practice in South Yorkshire
SO EUROPEAN ARCHIVES OF PAEDIATRIC DENTISTRY
DI 10.1007/s40368-020-00539-5
EA MAY 2020
PY 2020
AB Purpose Dental caries is still common in children in the UK despite many
   available preventative interventions. Application of topical fluoride
   varnish can reduce caries experience. National and international
   guidance recommends at least twice-yearly application of topical
   fluoride varnish, however guidance is not always followed. This project
   aimed to first identify the proportion of patients receiving fluoride
   varnish by their primary care dental practitioner prior to their
   referral to a secondary care service and subsequently increase this rate
   by introducing an intervention. Methods The intervention required the
   referring practitioner to document the date of which topical fluoride
   was applied prior to referral. Referrals without this information were
   rejected. Data were collected pre and post this change in policy to
   ascertain fluoride application rates. Parents and children were
   questioned about the frequency of application, and referral forms were
   reviewed for practitioner-reported application. Results Topical fluoride
   application rates improved by 19% points for patient-reported
   application, and 31% points for practitioner-reported application. The
   biggest increase in application rate was in the cohort of patients
   receiving 6-monthly fluoride application. Conclusion This study
   demonstrated that a simple intervention, mandating that primary care
   dental practitioners record the most recent application of topical
   fluoride before referring a patient to secondary care, can improve the
   rates of topical fluoride varnish application in the UK.
ZS 0
ZR 0
Z8 0
ZB 0
TC 0
Z9 0
SN 1818-6300
EI 1996-9805
UT WOS:000533175300002
PM 32418054
ER

PT J
AU Yan, Xue
   Weihan, Wang
   Chang, Miao
TI Research on financial assets transaction prediction model based on LSTM
   neural network
SO NEURAL COMPUTING & APPLICATIONS
DI 10.1007/s00521-020-04992-7
EA MAY 2020
PY 2020
AB In recent years, with the breakthrough of big data and deep learning
   technology in various fields, many scholars have begun to study the
   stock market time series by using deep learning technology. In the
   process of model training, the selection of training samples, model
   structure and optimization methods are often subjective. Therefore,
   studying these influencing factors is beneficial to provide scientific
   suggestions for the training of recurrent neural networks and is
   beneficial to improve the prediction accuracy of the model. In this
   paper, the LSTM deep neural network is used to model and predict the
   financial transaction data of Shanghai, and the three types of factors
   affecting the prediction accuracy of the model are systematically
   studied. Finally, a high-precision short-term prediction model of
   financial market time series based on LSTM deep neural network is
   constructed. In addition, this paper compares BP neural network,
   traditional RNN and RNN improved LSTM deep neural network. It proves
   that the LSTM deep neural network has higher prediction accuracy and can
   effectively predict the stock market time series.
ZR 0
Z8 0
ZS 0
TC 0
ZB 0
Z9 0
SN 0941-0643
EI 1433-3058
UT WOS:000533185900004
ER

PT J
AU Segun, Oguntade Emmanuel
   Shohaimi, Shamarina
   Nallapan, Meenakshii
   Lamidi-Sarumoh, Alaba Ajibola
   Salari, Nader
TI Statistical Modelling of the Effects of Weather Factors on Malaria
   Occurrence in Abuja, Nigeria.
SO International journal of environmental research and public health
VL 17
IS 10
DI 10.3390/ijerph17103474
PD 2020 May 16
PY 2020
AB Background: despite the increase in malaria control and elimination
   efforts, weather patterns and ecological factors continue to serve as
   important drivers of malaria transmission dynamics. This study examined
   the statistical relationship between weather variables and malaria
   incidence in Abuja, Nigeria. Methodology/Principal Findings: monthly
   data on malaria incidence and weather variables were collected in Abuja
   from the year 2000 to 2013. The analysis of count outcomes was based on
   generalized linear models, while Pearson correlation analysis was
   undertaken at the bivariate level. The results showed more malaria
   incidence in the months with the highest rainfall recorded
   (June-August). Based on the negative binomial model, every unit increase
   in humidity corresponds to about 1.010 (95% confidence interval (CI),
   1.005-1.015) times increase in malaria cases while the odds of having
   malaria decreases by 5.8% for every extra unit increase in temperature:
   0.942 (95% CI, 0.928-0.956). At lag 1 month, there was a significant
   positive effect of rainfall on malaria incidence while at lag 4,
   temperature and humidity had significant influences. Conclusions:
   malaria remains a widespread infectious disease among the local subjects
   in the study area. Relative humidity was identified as one of the
   factors that influence a malaria epidemic at lag 0 while the biggest
   significant influence of temperature was observed at lag 4. Therefore,
   emphasis should be given to vector control activities and to create
   public health awareness on the proper usage of intervention measures
   such as indoor residual sprays to reduce the epidemic especially during
   peak periods with suitable weather conditions.
OI Shohaimi, Shamarina/0000-0003-0591-6627; Lamidi-Sarumoh,
   Alaba/0000-0001-8077-3027
TC 0
Z8 0
ZB 0
ZS 0
ZR 0
Z9 0
EI 1660-4601
UT MEDLINE:32429373
PM 32429373
ER

PT J
AU Abbas, Ghulam
   Wang, Shouyang
TI Does macroeconomic uncertainty really matter in predicting stock market
   behavior? A comparative study on China and USA
SO CHINA FINANCE REVIEW INTERNATIONAL
DI 10.1108/CFRI-06-2019-0077
EA MAY 2020
PY 2020
AB Purpose The study aims to analyze the interaction between macroeconomic
   uncertainty and stock market return and volatility for China and USA and
   tries to draw some invaluable inferences for the investors, portfolio
   managers and policy analysts. Design/methodology/approach Empirically
   the study uses GARCH family models to capture the time-varying
   volatility of stock market and macroeconomic risk factors by using
   monthly data ranging from 1995:M7 to 2018:M6. Then, these volatility
   series are further used in the multivariate VAR model to analyze the
   feedback interaction between stock market and macroeconomic risk factors
   for China and USA. The study also incorporates the impact of Asian
   financial crisis of 1997-1998 and the global financial crisis of
   2007-2008 by using dummy variables in the GARCH model analysis. Findings
   The empirical results of GARCH models indicate volatility persistence in
   the stock markets and the macroeconomic variables of both countries. The
   study finds relatively weak and inconsistent unidirectional causality
   for China mainly running from the stock market to the macroeconomic
   variables; however, the volatility spillover transmission reciprocates
   when the impact of Asian financial crisis and Global financial crisis is
   incorporated. For USA, the contemporaneous relationship between stock
   market and macroeconomic risk factors is quite strong and bidirectional
   both at first and second moment level. Originality/value This study
   investigates the interaction between stock market and macroeconomic
   uncertainty for China and USA. The researchers believe that none of the
   prior studies has made such rigorous comparison of two of the big and
   diverse economies (China and USA) which are quite contrasting in terms
   of political, economic and social background. Therefore, this study also
   tries to test the presumed conception that macroeconomic uncertainty in
   China may have different impact on the stock market return and
   volatility than in USA.
ZB 0
ZS 0
Z8 0
TC 0
ZR 0
Z9 0
SN 2044-1398
EI 2044-1401
UT WOS:000533592000001
ER

PT J
AU Alabsi, Mohammed
   Liao, Yabin
   Nabulsi, Ala-Addin
TI Bearing fault diagnosis using deep learning techniques coupled with
   handcrafted feature extraction: A comparative study
SO JOURNAL OF VIBRATION AND CONTROL
AR UNSP 1077546320929141
DI 10.1177/1077546320929141
EA MAY 2020
PY 2020
AB Deep learning has seen tremendous growth over the past decade. It has
   set new performance limits for a wide range of applications, including
   computer vision, speech recognition, and machinery health monitoring.
   With the abundance of instrumentation data and the availability of high
   computational power, deep learning continues to prove itself as an
   efficient tool for the extraction of micropatterns from machinery big
   data repositories. This study presents a comparative study for feature
   extraction capabilities using stacked autoencoders considering the use
   of expert domain knowledge. Case Western Reserve University bearing
   dataset was used for the study, and a classifier was trained and tested
   to extract and visualize features from 12 different failure classes.
   Based on the raw data preprocessing, four different deep neural network
   structures were studied. Results indicated that integrating domain
   knowledge with deep learning techniques improved feature extraction
   capabilities and reduced the deep neural networks size and computational
   requirements without the need for exhaustive deep neural networks
   architecture tuning and modification.
TC 0
ZS 0
ZR 0
Z8 0
ZB 0
Z9 0
SN 1077-5463
EI 1741-2986
UT WOS:000534031400001
ER

PT J
AU Kadhim, Kadhim Takleef
   Alsahlany, Ali M.
   Wadi, Salim Muhsin
   Kadhum, Hussein T.
TI An Overview of Patient's Health Status Monitoring System Based on
   Internet of Things (IoT)
SO WIRELESS PERSONAL COMMUNICATIONS
DI 10.1007/s11277-020-07474-0
EA MAY 2020
PY 2020
AB The Internet of Things (IoT) is a newly emerging term for the new
   generation of the Internet which allows understanding between
   interconnected devices. IoT acts as an assistant in healthcare and plays
   an extremely important role in wide scopes of medicinal services
   observing applications. Through determining the pattern of parameters
   that are observed, the character of the disease can be expected. Health
   specialists and technicians have developed a great system with low-cost
   healthcare monitoring for people suffering from many diseases using
   common techniques such as wearable devices, wireless channels, and other
   remote devices. Network-related sensors, either worn on the body or in
   living environments, collect rich information to assess the physical and
   mental state of the patient. This work focuses on scanning the existing
   e-health (electronic healthcare) monitoring system using integrated
   systems. The main goal of the e-health monitoring system is to offer the
   patient a prescription automatically according to his or her condition.
   The doctor can check patient health continuously without physical
   interaction. The study aims to explore the uses of IoT applications in
   the medical sector, and its role in raising the level of medical care
   services in health institutions. Also, the study will address the
   applications of IoT in the medical field and the extent of its use to
   enrich traditional methods in various health fields and to determine the
   extent of the ability of IoT to improve the quality of health services
   provided. The study relies on a descriptive research approach through an
   analysis of the literature published in this field. The results of the
   study refer to the application of IoT in the health institutions, it
   will help to obtain accurate diagnoses for patients, which will reflect
   on the quality of service provided to the patient. It will also reduce
   periodic patient reviews to the hospital by relying on IoT applications
   for remote diagnosis. Also, an application in health institutions will
   contribute to providing data correct for the diseases that patients
   suffer from, and hence employing them in preparing scientific research
   to obtain more accurate results. This paper introduces the review of the
   Internet-based healthcare monitoring system (HCMS) and the general
   outlines on opportunities and challenges of the patient's Internet-based
   patient health monitoring system.
ZS 0
Z8 0
TC 0
ZR 0
ZB 0
Z9 0
SN 0929-6212
EI 1572-834X
UT WOS:000533138000001
ER

PT J
AU Pawar, Shrikant
   Liew, Tuck Onn
   Stanam, Aditya
   Lahiri, Chandrajit
TI Common cancer biomarkers of breast and ovarian types identified through
   artificial intelligence
SO CHEMICAL BIOLOGY & DRUG DESIGN
DI 10.1111/cbdd.13672
EA MAY 2020
PY 2020
AB Biomarkers can offer great promise for improving prevention and
   treatment of complex diseases such as cancer, cardiovascular diseases,
   and diabetes. These can be used as either diagnostic or predictive or as
   prognostic biomarkers. The revolution brought about in biological big
   data analytics by artificial intelligence (AI) has the potential to
   identify a broader range of genetic differences and support the
   generation of more robust biomarkers in medicine. AI is invigorating
   biomarker research on various fronts, right from the cataloguing of key
   mutations driving the complex diseases like cancer to the elucidation of
   molecular networks underlying diseases. In this study, we have explored
   the potential of AI through machine learning approaches to propose that
   these methods can act as recommendation systems to sort and prioritize
   important genes and finally predict the presence of specific biomarkers.
   Essentially, we have utilized microarray datasets from open-source
   databases, like GEO, for breast, lung, colon, and ovarian cancer. In
   this context, different clustering analyses like hierarchical and
   k-means along with random forest algorithm have been utilized to
   classify important genes from a pool of several thousand genes. To this
   end, network centrality and pathway analysis have been implemented to
   identify the most potential target as CREB1.
OI Liew, Tuck Onn/0000-0001-7715-7629; Lahiri,
   Chandrajit/0000-0002-9783-7741; , shrikant/0000-0002-6157-2462
ZR 0
TC 0
ZB 0
Z8 0
ZS 0
Z9 0
SN 1747-0277
EI 1747-0285
UT WOS:000532696000001
PM 32410355
ER

PT J
AU Lengauer, Thomas
TI Statistical Data Analysis in the Era of Big Data
SO CHEMIE INGENIEUR TECHNIK
DI 10.1002/cite.202000024
EA MAY 2020
PY 2020
AB Big data is on everyone's lips and often raises emotions. On the one
   hand, the notion is a basis for much technological optimism, mostly
   directed towards new business models, or simplifications and
   optimizations in professional and private life. On the other hand, it is
   a basis for dystopic perspectives, which are targeted, e.g., at
   profiling of the individual and their privacy space, overarching
   optimization in daily life and intransparency of decision making. In
   this article, after a short historical prolog, it is discussed what
   distinguishes big data from traditional data analysis. The underlying
   mathematical methods are introduced and scientific successes are
   reported. Additionally, the risks and limits - especially regarding the
   derivation of causal relationships - of data analysis are discussed.
ZR 0
Z8 0
TC 1
ZS 0
ZB 0
Z9 1
SN 0009-286X
EI 1522-2640
UT WOS:000532830500001
ER

PT J
AU Adane, Mesafint Molla
   Alene, Getu Degu
   Mereta, Seid Tiku
   Wanyonyi, Kristina Lutomya
TI Facilitators and barriers to improved cookstove adoption: a
   community-based cross-sectional study in Northwest Ethiopia
SO ENVIRONMENTAL HEALTH AND PREVENTIVE MEDICINE
VL 25
IS 1
AR 14
DI 10.1186/s12199-020-00851-y
PD MAY 15 2020
PY 2020
AB Background Among the environmental risk factors, household air pollution
   exposure from traditional cooking practices is one of the biggest
   killers globally, which mainly impacts developing countries where many
   families rely on traditional cooking practices. Although improved
   cookstove adoption is central to tackle this public health issue, the
   efforts to disseminate cookstove technologies have faced challenges, and
   the adoption rates are reported to be very low in many developing
   countries including Ethiopia. Therefore, this study aimed to determine
   the magnitude and identify potential factors that may act as
   facilitators or barriers to adoption from users' point of view. Methods
   As part of the wider stove trial project, a cross-sectional study was
   conducted among a total of 5830 households under randomly selected
   clusters. The required data were collected through face-to-face
   interviews, and a backward stepwise logistic regression analysis
   technique was applied to evaluate the effect of potential predictor
   variables on adoption using adjusted odds ratio (AOR) as measures of
   effect. Results The prevalence of adoption was found to be 12.3% (95% CI
   11.5-13.2), and households headed by females (AOR 1.96; 95% CI
   1.24-3.10), private house ownership (AOR 4.58; 95% CI 3.89-6.19),
   separate cooking location (AOR 1.84; 95% CI 1.49-2.78), fuel purchasing
   (AOR 2.13; 95% CI 1.64-2.76), health benefit (AOR 1.76; 95% CI
   1.15-2.70), optimistic social interaction (AOR 1.81; 95% CI 1.46-2.26),
   traditional suitability (AOR 1.58; 95% CI 1.28-1.95), stove use
   demonstration experience (AOR 2.47; 95% CI 1.98-3.07), cheap price (AOR
   2.48; 95% CI 1.91-3.21), availability (AOR 1.81; 95% CI 1.5-1, 2.17),
   fuel-saving benefit (AOR 1.63; 95% CI 1.18-2.24), and more durable stove
   (AOR 1.71; 95% CI 1.30-2.26) of cookstove played a significant role as
   facilitators to adoption. In addition, lower educational level of head
   (AOR 0.31; 95% CI 0.23-0.42) and fuel processing requirement (AOR 0.55;
   95% CI 0.44-0.70) of cookstove were found to be barriers for adoption.
   Conclusions Extremely lower improved cookstove adoption was observed due
   to household- and setting-related, cookstove technology-related, user
   knowledge- and perception-related, and financial- and market
   development-related factors. Therefore, to gain successful adoption,
   implementers and policymakers should consider those important factors in
   the implementation of clean cooking solutions to the community.
OI Wanyonyi, Kristina/0000-0003-2320-6805
Z8 0
ZB 0
TC 0
ZR 0
ZS 0
Z9 0
SN 1342-078X
EI 1347-4715
UT WOS:000533076000001
PM 32414323
ER

PT J
AU Ardagna, D.
   Barbierato, E.
   Gianniti, E.
   Gribaudo, M.
   Pinto, T. B. M.
   da Silva, A. P. C.
   Almeida, J. M.
TI Predicting the performance of big data applications on the cloud
SO JOURNAL OF SUPERCOMPUTING
DI 10.1007/s11227-020-03307-w
EA MAY 2020
PY 2020
AB Data science applications have become widespread as a means to extract
   knowledge from large datasets. Such applications are often characterized
   by highly heterogeneous and irregular data access patterns, thus often
   being referred to as big data applications. Such characteristics make
   the application execution quite challenging for existing software and
   hardware infrastructures to meet their resource demands. The cloud
   computing paradigm, in turn, offers a natural hosting solution to such
   applications since its on-demand pricing model allows allocating
   effectively computing resources according to application's needs.
   However, these properties impose extra challenge to the accurate
   performance prediction of cloud-based applications, which is a key step
   to adequate capacity planning and managing of the hosting
   infrastructure. In this article, we tackle this challenge by exploring
   three modeling approaches for predicting the performance of big data
   applications running on the cloud. We evaluate two queuing-based
   analytical models and dagSim, a fast ad-hoc simulator, in various
   scenarios based on different applications and infrastructure setups. The
   considered approaches are compared in terms of prediction accuracy and
   execution time. Our results indicate that our two best approaches, one
   analytical model and dagSim, can predict average application execution
   times with only up to a 7% relative error, on average. Moreover, a
   comparison with the widely used event-based simulator available with the
   Java Modeling Tool (JMT) suite demonstrates that both the analytical
   model and dagSim run very fast, requiring at least two orders of
   magnitude lower execution time than JMT while providing slightly better
   accuracy, being thus practical for online prediction.
Z8 0
ZR 0
TC 0
ZS 0
ZB 0
Z9 0
SN 0920-8542
EI 1573-0484
UT WOS:000533046500001
ER

PT J
AU Sagers, Luke
   Melas-Kyriazi, Luke
   Patel, Chirag J.
   Manrai, Arjun K.
TI Prediction of chronological and biological age from laboratory data
SO AGING-US
VL 12
IS 9
BP 7626
EP 7638
DI 10.18632/aging.102900
PD MAY 15 2020
PY 2020
AB Aging has pronounced effects on blood laboratory biomarkers used in the
   clinic. Prior studies have largely investigated one biomarker or
   population at a time, limiting a comprehensive view of biomarker
   variation and aging across different populations. Here we develop a
   supervised machine learning approach to study aging using 356 blood
   biomarkers measured in 67,563 individuals across diverse populations.
   Our model predicts age with a mean absolute error (MAE), or average
   magnitude of prediction errors, in held-out data of 4.76 years and an
   R-2 value of 0.92. Age prediction was highly accurate for the pediatric
   cohort (MAE = 0.87, R-2 = 0.94) but inaccurate for ages 65+ (MAE = 4.30,
   R-2 = 0.25). Variability was observed in which biomarkers carry
   predictive power across age groups, genders, and race/ethnicity groups,
   and novel candidate biomarkers of aging were identified for specific age
   ranges (e.g. Vitamin E, ages 18-44). We show that predictors for one age
   group may fail to generalize to other groups and investigate
   non-linearity in biomarkers near adulthood. As populations worldwide
   undergo major demographic changes, it is increasingly important to
   catalogue biomarker variation across age groups and discover new
   biomarkers to distinguish chronological and biological aging.
ZB 0
TC 0
Z8 0
ZR 0
ZS 0
Z9 0
SN 1945-4589
UT WOS:000533150800003
PM 32391803
ER

PT J
AU Kirchner, Allison
   Dachet, Fabien
   Loeb, Jeffrey A.
TI Identifying targets for preventing epilepsy using systems biology of the
   human brain
SO NEUROPHARMACOLOGY
VL 168
AR 107757
DI 10.1016/j.neuropharm.2019.107757
PD MAY 15 2020
PY 2020
AB Approximately one third of all epilepsy patients are resistant to
   current therapeutic treatments. Some patients with focal forms of
   epilepsy benefit from invasive surgical approaches that can lead to
   large surgical resections of human epileptic neocortex. We have
   developed a systems biology approach to take full advantage of these
   resections and the brain tissues they generate as a means to understand
   underlying mechanisms of neocortical epilepsy and to identify novel
   biomarkers and therapeutic targets. In this review, we will describe our
   unique approach that has led to the development of a 'NeuroRepository'
   of electrically-mapped epileptic tissues and associated data. This 'Big
   Data' approach links quantitative measures of ictal and interictal
   activities corresponding to a specific intracranial electrode to
   clinical, imaging, histological, genomic, proteomic, and metabolomic
   measures. This highly characterized data and tissue bank has given us an
   extraordinary opportunity to explore the underlying electrical,
   cellular, and molecular mechanisms of the human epileptic brain. We
   describe specific examples of how an experimental design that compares
   multiple cortical regions with different electrical activities has led
   to discoveries of layer-specific pathways and how these can be 'reverse
   translated' from animal models back to humans in the form of new
   biomarkers and therapeutic targets.
   This article is part of the special issue entitled 'New Epilepsy
   Therapies for the 21st Century - From Antiseizure Drugs to Prevention,
   Modification and Cure of Epilepsy'.
TC 0
ZR 0
ZS 0
Z8 0
ZB 0
Z9 0
SN 0028-3908
EI 1873-7064
UT WOS:000528256100015
PM 31493467
ER

PT J
AU Kallio, Johanna
   Vildjiounaite, Elena
   Koivusaari, Jani
   Rasanen, Pauli
   Simila, Heidi
   Kyllonen, Vesa
   Muuraiskangas, Salla
   Ronkainen, Jussi
   Rehu, Jari
   Vehmas, Kaisa
TI Assessment of perceived indoor environmental quality, stress and
   productivity based on environmental sensor data and personality
   categorization
SO BUILDING AND ENVIRONMENT
VL 175
AR 106787
DI 10.1016/j.buildenv.2020.106787
PD MAY 15 2020
PY 2020
AB Indoor environmental quality (IEQ) has an influence on peoples' health,
   cognitive performance and productivity in school and office
   environments. This study used environmental temperature, humidity, air
   pressure, and CO2 sensor data collected during 3.5-7 months in an office
   and a school facility to classify occupants' perceptions of IEQ, stress
   and productivity in two classes, "negative" and "positive".
   Self-reported data from 15 office workers and four teachers were used to
   train person-specific SVM classifier models. Relatively high accuracies
   were achieved in classifying IEQ (84%), stress (88%) and productivity
   (92%) using different combinations of environmental sensor data.
   Furthermore, the associations between the Big Five personality trait
   variables (neuroticism, extraversion, openness, agreeableness and
   conscientiousness) and negative experiences regarding stress,
   productivity and IEQ were investigated. Positive correlation was found
   between extroversion and co-occurring stress and IEQ problems, which
   suggest that more extroverted people more likely to be stressed by
   insufficient environmental quality or to be more sensitive to
   environmental factors when under stress. Overall, the results indicate
   that it is possible to measure and classify perceived IEQ, stress and
   productivity sufficiently accurately using inexpensive environmental
   sensors.
ZB 0
ZS 0
TC 0
Z8 0
ZR 0
Z9 0
SN 0360-1323
EI 1873-684X
UT WOS:000530724800012
ER

PT J
AU Hassanien, Sherif H
   Bassman, Jonathon R
   Perrien Naccarato, Carmelita M
   Twarozynski, Jack J
   Traynor, John R
   Iula, Donna M
   Anand, Jessica P
TI In vitro Pharmacology of Fentanyl Analogs at the Human Mu Opioid
   Receptor and Their Spectroscopic Analysis.
SO Drug testing and analysis
DI 10.1002/dta.2822
PD 2020-May-15
PY 2020
AB Opioids are widely misused and account for almost half of overdose
   deaths in the United States. The cost in terms of lives, health care,
   and lost productivity is significant and has been declared a national
   crisis. Fentanyl is a highly potent mu opioid receptor (MOR) agonist and
   plays a significant role in the current opioid epidemic; Fentanyl and
   its analogs (fentalogs) are increasingly becoming one of the biggest
   dangers in the opioid crisis. The presence of fentalogs in the illicit
   market is thought to play a significant role in the recent increase in
   opioid-related deaths. Although there is both rodent homolog in vivo and
   in vitro data for some fentalogs, prior to this publication very little
   was known about the pharmacology of many of these illicit compounds at
   the human MOR (hMOR). Using GC-MS, NMR spectroscopy, and in vitro
   assays, this study describes the spectral and pharmacological properties
   of 34 fentalogs. The reported spectra and chemical data will allow for
   easy identification of novel fentalogs in unknown or mixed samples.
   Taken together these data are useful for law enforcement and clinical
   workers as they will aid in identification of fentalogs in unknown
   samples and can potentially be used to predict physiological effects
   after exposure.
OI Hassanien, Sherif/0000-0001-6507-1166
ZR 0
Z8 0
ZS 0
ZB 0
TC 0
Z9 0
EI 1942-7611
UT MEDLINE:32415719
PM 32415719
ER

PT J
AU Lymperopoulos, Georgios
   Ioannou, Petros
TI Building temperature regulation in a multi-zone HVAC system using
   distributed adaptive control
SO ENERGY AND BUILDINGS
VL 215
AR UNSP 109825
DI 10.1016/j.enbuild.2020.109825
PD MAY 15 2020
PY 2020
AB During recent years there have been considerable research efforts on
   improving energy efficiency of buildings. Since Heating, Ventilation and
   Air-Conditioning (HVAC) systems are responsible for a big part of energy
   consumption, developing efficient HVAC control systems is crucial. In
   most of the developed approaches, precise knowledge of system parameters
   and/or adequate historical data is required. However, these approaches
   may not perform as well in the presence of dynamic parameter changes due
   to human activity, material degradation, and wear and tear, or
   disturbances and other operational uncertainties due to occupancy, solar
   gains, electrical equipment, and weather conditions. In this paper, we
   consider buildings with several climate zones and propose a distributed
   adaptive control scheme for a multi-zone HVAC system which can
   effectively regulate zone temperature by applying on-line learning and
   assuming exchange of information between neighboring zones. The
   controller of each zone achieves the local objective of controlling zone
   temperature by compensating for the effects of neighboring zones as well
   as for possible changes in the parameters of the system. Despite the
   exchange of information, each local controller does not know how the
   control actions and temperature of a neighboring zone affect the
   temperature of its own zone. For this reason, each local controller is
   estimating the parameters of the interconnections in real time and uses
   them together with the exchanged information to provide a more accurate
   local zone temperature control. The proposed method is illustrated using
   an example of temperature control in a six-zone building as well as a
   large school building, which are implemented in a Building Controls
   Virtual Test Bed (BCVTB) environment using EnergyPlus and
   MATLAB/Simulink. (C) 2020 Published by Elsevier B.V.
ZB 0
TC 0
Z8 0
ZS 0
ZR 0
Z9 0
SN 0378-7788
EI 1872-6178
UT WOS:000530655600006
ER

PT J
AU Mourby, Miranda
TI Anonymity in eu Health Law: Not An Alternative to Information
   Governance.
SO Medical law review
DI 10.1093/medlaw/fwaa010
PD 2020-May-15
PY 2020
AB Data sharing has long been a cornerstone of healthcare and research and
   is only due to become more important with the rise of Big Data analytics
   and advanced therapies. Cell therapies, for example, rely not only on
   donated cells but also essentially on donated information to make them
   traceable. Despite the associated importance of concepts such as 'donor
   anonymity', the concept of anonymisation remains contentious. The
   Article 29 Working Party's 2014 guidance on 'Anonymisation Techniques'
   has perhaps helped encourage a perception that anonymity is the result
   of data modification 'techniques', rather than a broader process
   involving management of information and context. In light of this
   enduring ambiguity, this article advocates a 'relative' understanding of
   anonymity and supports this interpretation with reference not only to
   the General Data Protection Regulation but also to European Union
   health-related legislation, which also alludes to the concept.
   Anonymity, I suggest, should be understood not as a 'technique' which
   removes the need for information governance but rather as a legal
   standard of reasonable risk-management, which can only be satisfied by
   effective data protection. As such, anonymity can be not so much an
   alternative to data protection as its mirror, requiring similar
   safeguards to maintain privacy and confidentiality.
ZS 0
ZR 0
TC 0
ZB 0
Z8 0
Z9 0
EI 1464-3790
UT MEDLINE:32413130
PM 32413130
ER

PT J
AU Wang, Likun
   Li, Yang
   Wan, Zheng
   Yang, Zaili
   Wang, Tong
   Guan, Keping
   Fu, Lei
TI Use of AIS data for performance evaluation of ship traffic with speed
   control
SO OCEAN ENGINEERING
VL 204
AR 107259
DI 10.1016/j.oceaneng.2020.107259
PD MAY 15 2020
PY 2020
AB Speed control in inland water systems needs to achieve effective balance
   between ship operational efficiency and transport safety. However, speed
   limit regulations are largely formulated through expert judgment rather
   than objective evidence-based evaluation, which sometimes leads to
   inefficiency due to subjective bias. In this study, a new method is
   proposed to evaluate the performance of shipping traffic under current
   speed limits by using the automatic identification system (AIS) big data
   of 4923 ships in the Shanghai section of the Yangtze River in China. The
   key elements of this method include data acquisition, error elimination,
   combination of ship AIS and waterway geocoded data to model traffic flow
   characteristics, and estimation of the correlation between ship speed
   and congestion level. Shipping traffic performance in different segments
   is analyzed. Results reveal that the overall compliance to the speed
   limit is high, and only a few over-speeding cases are noted in certain
   segments. Furthermore, we use a normal distribution to model the
   correlation between ship speed and traffic volume. The findings indicate
   that the current speed limit in the Shanghai section of Yangtze River is
   rational. This work provides useful insights into testing the
   rationality of speed limits in other waterways or shipping channels.
ZS 0
ZR 0
TC 0
Z8 0
ZB 0
Z9 0
SN 0029-8018
UT WOS:000530233700017
ER

PT J
AU Peyton, Benjamin G
   Briggs, Connor
   D'Cunha, Ruhee
   Margraf, Johannes T
   Crawford, T Daniel
TI Machine-Learning Coupled Cluster Properties through a Density Tensor
   Representation.
SO The journal of physical chemistry. A
DI 10.1021/acs.jpca.0c02804
PD 2020-May-15
PY 2020
AB The introduction of machine-learning (ML) algorithms to quantum
   mechanics enables rapid evaluation of otherwise intractable expressions
   at the cost of prior training on appropriate benchmarks. Many
   computational bottlenecks in the evaluation of accurate electronic
   structure theory could potentially benefit from the application of such
   models, from reducing the complexity of the underlying wave function
   parameter space to circumventing the complications of solving the
   electronic Schrodinger equation entirely. Applications of ML to
   electronic structure have thus far been focused on learning molecular
   properties (mainly the energy) from geometric representations. While
   this line of study has been quite successful, highly accurate models
   typically require a "big data" approach with thousands of training data
   points. Herein, we propose a general, systematically improvable scheme
   for wave function-based ML of arbitrary molecular properties, inspired
   by the underlying equations that govern the canonical approach to
   computing the properties. To this end, we combine the established ML
   machinery of the t-amplitude tensor representation with a new reduced
   density matrix representation. The resulting model provides quantitative
   accuracy in both the electronic energy and dipoles of small molecules
   using only a few dozen training points per system.
ZR 0
Z8 0
ZB 0
ZS 0
TC 0
Z9 0
EI 1520-5215
UT MEDLINE:32412756
PM 32412756
ER

PT J
AU Zhang, Wei
   Qiao, Tiezhu
   Pang, Yusong
   Yang, Yi
   Chen, Hong
   Hao, Guirong
TI A Novel Defect Diagnosis Method for Kyropoulos Process-Based Sapphire
   Growth
SO IEEE SENSORS JOURNAL
VL 20
IS 10
BP 5435
EP 5441
DI 10.1109/JSEN.2020.2969963
PD MAY 15 2020
PY 2020
AB When sapphire crystal is prepared with Kyropoulos method, the
   necking-down growth process is a key stage. Sapphire growth defect is a
   big problem in this stage. However, diagnosing growth defects is subject
   to the interference of workers subjectivity and accuracy always goes
   down. To address the problem, a novel defect diagnosis method is
   proposed for necking-down growth process in this paper. Industrial CCD
   sensors replace eyes of skilled workers to observe in this method. A new
   Defect-Diagnosing Siamese network (DDSN) is used in this method. We use
   Siamese architecture to learn similarity through pairs of images. We use
   the deep separable convolution (DSC) into the DDSN to optimize running
   speed and model size. In experiment, dataset is acquired by industrial
   CCD sensors in the necking-down growth process. The accuracy of defect
   diagnosis can reach up to 94.5%. The method significantly improves the
   traditional way.
Z8 0
ZB 0
ZR 0
TC 0
ZS 0
Z9 0
SN 1530-437X
EI 1558-1748
UT WOS:000528845200039
ER

PT J
AU Li, Yanlong
   Qiu, Hongbing
   Chen, Xiao
   Fu, Jielin
TI A novel PAPR reduction algorithm for DCO-OFDM/OQAM system in underwater
   VLC
SO OPTICS COMMUNICATIONS
VL 463
AR 125449
DI 10.1016/j.optcom.2020.125449
PD MAY 15 2020
PY 2020
AB In the underwater visible light communication (VLC), the photon
   propagation scattering effect is obvious and the multipath effect is
   enhanced as the link distance increases. This paper uses orthogonal
   frequency division multiplexing/offset quadrature amplitude modulation
   (OFDM/OQAM) of filter bank multicarrier technology (FBMC), which is
   based on time frequency localization (TFL) filter, to overcome inter
   symbol interference (ISI) and inter carrier interference (ICI). Since
   light-emitting diode (LED) modulation needs positive modulation signal,
   we use the direct current (DC) bias to add on OFDM/OQAM signal so that
   the signal is positive. But, as the OFDM/OQAM is also multicarrier
   modulation system, the instantaneous fluctuation of OFDM/OQAM signal is
   bigger than single carrier modulation system and the nonlinear
   distortion is very serious. Therefore, this paper puts forward the
   modified overlapped selective mapping (M-OSLM) suppression algorithm to
   restrain the peak to average power ratio (PAPR), and optimizes the range
   of data symbol which affects on current data symbol by taking the
   characteristic of filter bank into consideration so that decrease PAPR.
   Thus, the instantaneous volatility of OFDM/OQAM signals is reduced in
   order to select the appropriate DC bias and reduce the clipping
   distortion. The simulation results show that compared with DC-biased
   cyclic prefix optical OFDM (DCO-CP-OFDM), DC-biased optical OFDM/OQAM
   (DCO-OFDM/OQAM) has a better overcoming ability on ISI of underwater
   wireless optical scattered channel. Meanwhile, the performance of PAPR
   reduction is greatly improved by M-OSLM algorithm. The signal-to-noise
   ratio (SNR) is improved by 3 dB averagely compared to DCO-CP-OFDM at the
   same bit error rate (BER).
ZB 0
Z8 0
ZS 0
TC 0
ZR 0
Z9 0
SN 0030-4018
EI 1873-0310
UT WOS:000520479100003
ER

PT J
AU Darbandi, Masoud
   Fatin, Ali
   Bordbar, Hadi
TI Numerical study on NOx reduction in a large-scale heavy fuel oil-fired
   boiler using suitable burner adjustments
SO ENERGY
VL 199
AR 117371
DI 10.1016/j.energy.2020.117371
PD MAY 15 2020
PY 2020
AB A numerical framework was carefully developed to simulate the combustion
   of heavy-fuel-oil (HFO) in a large-scale boiler. The present numerical
   solutions were compared with the measured data of a laboratory benchmark
   test and on-site operational data of the chosen HFO-fired boiler. Next,
   the developed framework was used to perform sensitivity analyses aiming
   to reduce the NO emission from the HFO-fired boiler without any adverse
   effect on its combustion performance. Practically, this study focused on
   re-adjustments of 24 working burners, which could control combustion in
   the HFO-fired boiler. The early outcome showed that the boiler NO
   emission and its combustion performance could be controlled via proper
   adjustments of air distributions within the three burners' stages and
   the swirl intensity. Although bigger mean droplet sizes and higher
   injection velocities reduced the NO emission considerably, it adversely
   led to much lower boiler's combustion efficiency. The present study
   eventually arrived at an optimal adjustment for the burners by
   reconsideration of the air distributions within the three burners'
   stages, the flame swirl intensity magnitude, and the fuel injection
   quality. The achieved optimal adjustment reduced the amount of NO
   emission by 30%, while the combustion efficiency would remain
   unaffected. (C) 2020 Elsevier Ltd. All rights reserved.
ZR 0
TC 0
ZS 0
ZB 0
Z8 0
Z9 0
SN 0360-5442
EI 1873-6785
UT WOS:000527571300029
ER

PT J
AU Beltrami, Monica
   Lindbeck da Silva, Arinei Carlos
TI A grid-quadtree model selection method for support vector machines
SO EXPERT SYSTEMS WITH APPLICATIONS
VL 146
AR 113172
DI 10.1016/j.eswa.2019.113172
PD MAY 15 2020
PY 2020
AB In this paper, a new model selection approach for Support Vector Machine
   (SVM), which integrates the quadtree technique with the grid search,
   denominated grid-quadtree (GQ) is proposed. The developed method is the
   first in the literature to apply the quadtree for the SVM parameters
   optimization. The SVM is a machine-learning technique for pattern
   recognition whose performance relies on its parameters determination.
   Thus, the model selection problem for SVM is an important field of study
   and requires expert and intelligent systems to solve it. Real
   classification data sets involve a huge number of instances and
   features, and the greater is the training data set dimension, the larger
   is the cost of a recognition system. The grid search (GS) is the most
   popular and the simplest method to select parameters for SVM. However,
   it is time-consuming, which limits its application for big-sized
   problems. With this in mind, the main idea of this research is to apply
   the quadtree technique to the GS to make it faster. Hence, this may
   lower computational time cost for solving problems such as
   bio-identification, bank credit risk and cancer detection. Based on the
   asymptotic behaviors of the SVM, it was noticeably observed that the
   quadtree is able to avoid the GS full search space evaluation. As a
   consequence, the GQ carries out fewer parameters analysis, solving the
   same problem with much more efficiency. To assess the GQ performance,
   ten classification benchmark data set were used. The obtained results
   were compared with the ones of the traditional GS. The outcomes showed
   that the GQ is able to find parameters that are as good as the GS ones,
   executing 78.8124% to 85.8415% fewer operations. This research points
   out that the adoption of quadtree expressively reduces the computational
   time of the original GS, making it much more efficient to deal with high
   dimensional and large data sets. (C) 2019 Elsevier Ltd. All rights
   reserved.
ZB 0
Z8 0
ZS 0
ZR 0
TC 0
Z9 0
SN 0957-4174
EI 1873-6793
UT WOS:000519653400016
ER

PT J
AU Mosquera-Lopez, Clara
   Dodier, Robert
   Tyler, Nichole S.
   Wilson, Leah M.
   El Youssef, Joseph
   Castle, Jessica R.
   Jacobs, Peter G.
TI Predicting and Preventing Nocturnal Hypoglycemia in Type 1 Diabetes
   Using Big Data Analytics and Decision Theoretic Analysis
SO DIABETES TECHNOLOGY & THERAPEUTICS
DI 10.1089/dia.2019.0458
EA MAY 2020
PY 2020
AB Background: Despite new glucose sensing technologies, nocturnal
   hypoglycemia is still a problem for people with type 1 diabetes (T1D) as
   symptoms and sensor alarms may not be detected while sleeping.
   Accurately predicting nocturnal hypoglycemia before sleep may help
   minimize nighttime hypoglycemia.
   Methods: A support vector regression (SVR) model was trained to predict,
   before bedtime, the overnight minimum glucose and overnight nocturnal
   hypoglycemia for people with T1D. The algorithm was trained on
   continuous glucose measurements and insulin data collected from 124
   people (22,804 valid nights of data) with T1D. The minimum glucose
   threshold for announcing nocturnal hypoglycemia risk was derived by
   applying a decision theoretic criterion to maximize expected net
   benefit. Accuracy was evaluated on a validation set from 10 people with
   T1D during a 4-week trial under free-living sensor-augmented
   insulin-pump therapy. The primary outcome measures were sensitivity and
   specificity of prediction, the correlation between predicted and actual
   minimum nocturnal glucose, and root-mean-square error. The impact of
   using the algorithm to prevent nocturnal hypoglycemia is shown
   in-silico.
   Results: The algorithm predicted 94.1% of nocturnal hypoglycemia events
   (<3.9 mmol/L, 95% confidence interval [CI], 71.3-99.9) with an area
   under the receiver operating characteristic curve of 0.86 (95% CI,
   0.75-0.98). Correlation between actual and predicted minimum glucose was
   high (R = 0.71, P < 0.001). In-silico simulations showed that the
   algorithm could reduce nocturnal hypoglycemia by 77.0% (P = 0.006)
   without impacting time in target range (3.9-10 mmol/L).
   Conclusion: An SVR model trained on a big data set and optimized using
   decision theoretic criterion can accurately predict at bedtime if
   overnight nocturnal hypoglycemia will occur and may help reduce
   nocturnal hypoglycemia.
OI Mosquera-Lopez, Clara/0000-0003-1586-2490
ZR 0
ZS 0
Z8 0
ZB 0
TC 0
Z9 0
SN 1520-9156
EI 1557-8593
UT WOS:000533291800001
PM 32297795
ER

PT P
AU PARK K
   KIM J
TI Light emitting diode device for improving the skin condition by using a
   sensor, comprises an outer housing forming an outer surface
   corresponding to the users face, an inner housing forming an inner
   surface close to the users face
PN WO2020096115-A1
AE WIBE CO LTD; PARK K
AB 
   NOVELTY - The light emitting diode device comprises an outer housing
   forming an outer surface corresponding to the users face. An inner
   housing forming an inner surface close to the users face. The light
   emitting diode (LED) light emitting unit for irradiating light to the
   users face. A sensor installed in the inner housing to measure a state
   of a users face. A controller that controls the LED light emitting unit
   and the sensor. The outer housing is formed in a concave to cover the
   entire face of the user with an opaque material. The longitudinal groove
   is dug in the area corresponding to the users mouth LED skin environment
   improvement device using sensor.
   USE - Light emitting diode device for improving the skin condition by
   using a sensor.
   ADVANTAGE - The light emitting diode device irradiates the skin with
   light emitting diode wavelengths suitable for various skin types through
   big data and artificial intelligence analysis, and effectively
   discharging skin waste and improving the skin environment.
   DESCRIPTION Of DRAWING(S) - The drawing shows a graphical representation
   of the light emitting diode skin environment. (Drawing includes
   non-English language text).
Z9 0
UT DIIDW:202040541M
ER

PT P
AU TRAN B
   TRAN H
TI Internet of Things (IoT) device for stress or tension detection, has
   smart bolt with head and threaded portions, sensor coupled to threaded
   portion, vibrator, processor, and wireless transceiver
PN US2020149576-A1
AE TRAN B; TRAN H
AB 
   NOVELTY - The IoT device has a smart bolt (100) having a head portion
   (104) and a threaded portion (110), a sensor coupled to the threaded
   portion, a vibrator in the threaded portion that vibrates at one or more
   patterns, a processor coupled to the sensor and the vibrator, and a
   wireless transceiver coupled to the processor.
   USE - IoT device for stress or tension detection. Used in big data
   system (claimed) for predicting stress experienced by a structural unit
   such as a bridge, a building, or a plane.
   ADVANTAGE - The smart bolt can detect tension and communicate to a
   computer for storage and analysis and provides an automatic electronic
   process that eliminates the need for a manual inspection process. The
   use of electronic detection of stress, eliminates subjective human
   judgments and produces greater uniformity in maintenance, inspection,
   and emergency detection procedures.
   DESCRIPTION Of DRAWING(S) - The drawing shows the side view of a smart
   bolt and probe.Smart bolt (100)Electronics (102)Head portion
   (104)Threaded portion (110)Washer (120)
Z9 0
UT DIIDW:202039823A
ER

PT P
AU WALKER B W
   VESTAL G S
   PORADISH F J
TI Method for producing a three-dimensional or multi-viewer image, involves
   preparing a series of alternating bit segments to an image that has a
   multiple of pairs of bit segments where each pair of bit segments
   consists of a first bit segment
PN US2020150447-A1
AE BRASS ROOTS TECHNOLOGIES LLC
AB 
   NOVELTY - The method involves preparing a series of alternating bit
   segments to an image (111) that has a multiple of pairs of bit segments
   where each pair of bit segments consists of a first bit segment that has
   a first set of image data. A second bit segment has a second set of
   image data. The first set of image data and the second set of image data
   differ with regard to a distinguishing and projecting the series of
   alternating bit segments to produce the three-dimensional (3D) or
   multi-viewer image for at least one viewer. The viewer utilizes a
   viewing device that allows the first set of image data to be perceived
   separately from the second set of image data as a distinguished result.
   USE - Method for producing a three-dimensional or multi-viewer image can
   also for used in multiple image projection.
   ADVANTAGE - The methods has the use of passive filtered glasses that
   take advantage of different light polarization and spectrum or active
   glasses that utilize switchable shutters to view different images at
   different time points for either each eye or each viewer. The method
   switches back and forth between left and right eye data at single bit
   segment or multiple bit segment rates in a single projected image to
   create high quality 3D stereo or multi-viewer imaging with no motion
   artifacts. This approach will create equivalents of two different images
   to be formed by alternating bit segments simultaneously which eliminates
   almost all temporal skew between the images. Bigger bits are split into
   smaller segments which avoids the artifacts created by larger pulses of
   lights in large bit weights. More bit segments generally provide better
   image quality so the projector should be able to support more bit
   segments than normal two dimensional (2D) or single viewer operation.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for an apparatus
   for use in multiple image projection utilizing different color
   spectrums.
   DESCRIPTION Of DRAWING(S) - The drawing shows a schematic view for a
   apparatus for multiple image projection.Video data (106)Display device
   (107)Projection lens (110)Image (111)Target (112)
Z9 0
UT DIIDW:202039872L
ER

PT J
AU Friele, Minou
   Broeckerhoff, Peter
   Froehlich, Wiebke
   Doehmann, Indra Spiecker Genannt
   Woopen, Christiane
TI Digital data for more efficient prevention: ethical and legal
   considerations regarding potentials and risks
SO BUNDESGESUNDHEITSBLATT-GESUNDHEITSFORSCHUNG-GESUNDHEITSSCHUTZ
DI 10.1007/s00103-020-03147-2
EA MAY 2020
PY 2020
AB Digitization offers considerable potential for strengthening prevention
   in the healthcare system. Data from various clinical and nonclinical
   sources can be collected in a structured way and systematically
   processed using algorithms. Prevention needs can thus be identified more
   quickly and precisely, and interventions can be planned, implemented,
   and evaluated for specific target groups. At the same time, however, it
   is necessary that data processing not only meets high technical but also
   ethical standards and legal data protection regulations in order to
   avoid or minimize risks. This discussion article examines the potentials
   and risks of digital prevention first from a "data perspective," which
   deals with the use of health-related data for the purpose of prevention,
   and second from an "algorithm perspective," which focuses on the use of
   algorithmic systems, including artificial intelligence, for the
   assessment of needs and evaluation of preventive measures, from an
   ethical and legal point of view. Finally, recommendations are formulated
   for framework conditions that should be created to strengthen the
   further development of prevention in the healthcare system.
ZB 0
ZS 0
ZR 0
Z8 0
TC 0
Z9 0
SN 1436-9990
EI 1437-1588
UT WOS:000532891200002
PM 32410053
ER

PT J
AU Akhtar, Usman
   Sant'Anna, Anita
   Jihn, Chang-Ho
   Razzaq, Muhammad Asif
   Bang, Jaehun
   Lee, Sungyoung
TI A cache-based method to improve query performance of linked Open Data
   cloud
SO COMPUTING
DI 10.1007/s00607-020-00814-9
EA MAY 2020
PY 2020
AB The proliferation of semantic big data has resulted in a large amount of
   content published over the Linked Open Data (LOD) cloud. Semantic Web
   applications consume these data by issuing SPARQL queries. One of the
   main challenges faced by querying the LOD web cloud on account of the
   inherent distributed nature of LOD is its high search latency and lack
   of tools to connect the SPARQL endpoints. In this paper, we propose an
   Adaptive Cache Replacement strategy (ACR) that aims to accelerate the
   overall query processing of the LOD cloud. ACR alleviates the burden on
   SPARQL endpoints by identifying subsequent queries learned from clients
   historical query patterns and caching the result of these queries. For
   cache replacement, we propose an exponential smoothing forecasting
   method to replace the less valuable cache content. In the experimental
   study, we evaluate the performance of the proposed approach in terms of
   hit rates, query time and overhead. The proposed approach is found to
   outperform existing state-of-the-art approaches, increase hit rates by
   5.46%, and reduce the query times by 6.34%.
OI Akhtar, Usman/0000-0003-4553-0550
Z8 0
ZR 0
TC 0
ZB 0
ZS 0
Z9 0
SN 0010-485X
EI 1436-5057
UT WOS:000532866000001
ER

PT J
AU Ahmed, Shamshad
   Rasheed, Tariq
TI Relationship between personality traits and digital literacy skills: a
   study of university librarians
SO DIGITAL LIBRARY PERSPECTIVES
DI 10.1108/DLP-02-2020-0005
EA MAY 2020
PY 2020
AB Purpose
   This study aims to examine the relationship between personality traits
   and digital literacy skills among university librarians of Punjab,
   Pakistan.
   Design/methodology/approach
   Five research hypotheses were established to achieve the study
   objectives. Two instruments; namely, "big five inventory (BFI)" scale of
   personality traits and a structured questionnaire of digital literacy
   skills (library literacy, computer literacy, tool literacy, information
   retrieval literacy and research support literacy) were used to collect
   the data. Pearson correlation test and correlation research design were
   used to examine the relationship between digital literacy skills and
   personality traits of university librarians.
   Findings
   The findings of the study revealed significant relationships between
   personality traits and all digital literacy skills. The study concluded
   that librarians having the extraversion trait are more inclined toward
   digital literacy skills and they can perform well in the libraries as
   compared to professionals with other traits.
   Research limitations/implications
   This study measures the digital literacy skills among the librarians of
   "higher education commission" recognized universities of Punjab,
   Pakistan. The study conclusions and findings are limited in scope to
   only the librarians of these universities. Such topic has no previous
   research.
   Practical implications
   This study has practical implication for university libraries, library
   associations, librarians and library professionals. The results of the
   study are also useful for librarians to acquire digital literacy skills,
   which are necessary in the current digital environment to manage the
   libraries.
   Social implications
   Library professionals can get digital literacy skills to face the
   challenges of digital age.
   Originality/value
   Some researchers examined the relationship of personality traits with
   the social networking sites, internet addiction, knowledge sharing
   behavior, information seeking behavior and academic performance. This
   study in particular identified the relationship of personality traits
   with the digital literacy skills, which are essential for managing the
   libraries. It helps libraries to find suitable library professionals and
   also help managers in assigning the duties based on these personality
   traits and digital literacy skills.
TC 0
Z8 0
ZR 0
ZS 0
ZB 0
Z9 0
SN 2059-5816
EI 2054-1694
UT WOS:000532861600001
ER

PT J
AU Chepkwony, Sarah Cherono
   Dumarcay, Stephane
   Chapuis, Hubert
   Kiprop, Ambrose
   Gerardin, Philippe
   Gerardin-Charbonnier, Christine
TI Geographic and intraspecific variability of mesquitol amounts in
   Prosopis juliflora trees from Kenya
SO EUROPEAN JOURNAL OF WOOD AND WOOD PRODUCTS
DI 10.1007/s00107-020-01535-8
EA MAY 2020
PY 2020
AB Several studies have shown that the heartwood of Prosopis juliflora
   contains high amounts of a naturally rare flavan-3-ol compound
   identified as 2-(3,4-dihydroxyphenyl)chromane-3,7,8-triol otherwise
   known as (-)-mesquitol (1). It is known to possess strong antioxidant
   properties, which may be of valuable interest for further valorization.
   However, no data exists so far showing the variations of its abundance
   depending on the different geographic habitats of the tree, the age and
   the different parts of the tree stem. The variability of flavan-3-ols
   depending on the geographical area and intra-specific variability within
   P. juliflora trees from Kenya was addressed in this substantive study.
   The study was done using wood extracts from three different counties in
   Kenya (Baringo, Garissa and Turkana Counties). Wood samples were
   separated into two categories of ages; small trees, aged less than 4
   years and the big trees, aged more than 8 years. Each sample was divided
   into five different parts, which included the bark, sapwood, knot wood,
   heartwood and the pith. Serial extractions were done by the Dionex
   accelerated solvent extractor using four solvents in increasing polarity
   (dichloromethane, acetone, toluene: ethanol (2:1 v/v) and finally
   water). Gas chromatographic analysis coupled to mass spectrometry was
   employed to identify the different compounds present in the extracts.
   LC-MS/MS method was thereafter developed and used to confirm the
   identity and quantify the amounts of mesquitol present. Two other
   flavan-3-ols identified and quantified included catechin (2) and 4
   '-O-methylgallocatechin (3). A systematic study on the mass spectra and
   the observed fragmentations of the flavonoids showed that mesquitol
   compound is the most abundant compound in P. juliflora with high amounts
   being found in the heartwood and pith of the acetonic extract (47-72%).
   Mesquitol abundance was also found to vary depending on the age of the
   tree and on the geographical areas.
ZB 0
ZS 0
Z8 0
TC 0
ZR 0
Z9 0
SN 0018-3768
EI 1436-736X
UT WOS:000532875600001
ER

PT J
AU Sutzko, D. C.
   Mani, K.
   Behrendt, C. -A.
   Wanhainen, A.
   Beck, A. W.
TI Big data in vascular surgery: registries, international collaboration
   and future directions
SO JOURNAL OF INTERNAL MEDICINE
DI 10.1111/joim.13077
EA MAY 2020
PY 2020
AB Given the increasing availability of large data set, small
   single-institutional series raise decreasing attention. Rapid expansion
   of technology from electronic medical records to easily accessible
   internet access, and widespread use and acceptance of registries in the
   medical world has allowed for research and quality improvement efforts
   using 'big data'. Big data, although technically not defined, typically
   refers to large databases that can be used to investigate common or rare
   disease processes or outcomes, describe variation in clinical practices
   across and between different specialties at various practice location,
   whilst allowing important information about trends over time. Big data
   have allowed investigators to quickly assimilate cohorts of patients
   and/or procedures to answer current questions, with more complete
   population representation and improved generalizability whilst
   decreasing the likelihood of power problems and type II errors. On the
   other hand, pitfalls still exist with the growing problem of hypothesis
   fishing, lack of granularity and the fear by many clinicians that
   registry transparency may have already gone too far, where surgery
   groups or individual surgeon outcomes are readily available to patients
   and referring providers. Within vascular surgery specifically, big data
   have expanded over the last decade and now includes regional, national
   and global registries that have major benefits of gathering specific
   clinical and procedural information within vascular surgery. In this
   review, we highlight the main vascular surgery registries and recap a
   few success stories of how the registries have been leveraged to benefit
   discovery, quality improvement and ultimately patient care.
   Additionally, we outline future directions that will be imperative for
   continued expansion, acceptance and adoption of 'big data' utilization
   inpatients with vascular disease.
RI Behrendt, Christian-Alexander/M-2952-2017
OI Behrendt, Christian-Alexander/0000-0003-0406-3319
ZS 0
TC 0
ZR 0
ZB 0
Z8 0
Z9 0
SN 0954-6820
EI 1365-2796
UT WOS:000532557900001
PM 32303118
ER

PT J
AU Chaudhry, Smita
TI Partner opportunism and willingness to engage in project relationships
SO JOURNAL OF STRATEGY AND MANAGEMENT
DI 10.1108/JSMA-11-2019-0200
EA MAY 2020
PY 2020
AB Purpose The paper seeks to understand the implications of partner
   opportunism for project relationships. Design/methodology/approach Based
   on the theoretical literature, the paper presents a conceptual model
   considering the perspective of the organization impacted by partner
   opportunism. Findings The model proposes that partner opportunism lowers
   willingness to engage by creating perception of loss. The undesirable
   impact of opportunism on perceived loss is less if the partner has made
   high relation-specific investments. Also, the negative impact of
   perceived loss on willingness to engage is less if the partner is
   difficult to substitute. Research limitations/implications The model can
   be tested in the context of information technology (IT) relationships
   because of scope for opportunism in IT project relationships. Data can
   be collected through experimental vignettes. Originality/value The model
   contributes by investigating novel aspects of governance, behavioral
   consequences of opportunism and relation-specific investments in project
   relationships. The paper suggests that organizations can protect
   themselves against the ill effects of partner opportunism by enabling
   their stakeholders to invest substantial time and effort in the
   relationship and fortify relational quality and bonding.
Z8 0
TC 0
ZB 0
ZR 0
ZS 0
Z9 0
SN 1755-425X
UT WOS:000532709900001
ER

PT J
AU Yan, Chuanxu
   Zhou, Shuigeng
TI Effective and scalable causal partitioning based on low-order
   conditional independent tests
SO NEUROCOMPUTING
VL 389
BP 146
EP 154
DI 10.1016/j.neucom.2020.01.021
PD MAY 14 2020
PY 2020
AB Recovering causal relationships from observed data is crucial to a
   variety of applications. Due to the curse of dimensionality, general
   causal discovery methods such as constraint-based methods and functional
   model based methods are not quite effective and efficient for large and
   high-dimensional data sets. Thus, some causal partitioning methods have
   been proposed to handle this problem. However, existing causal
   partitioning methods rely on high-order conditional independent (CI)
   tests, which makes them inefficient in handling dense causal graphs.
   Therefore, high-dimensionality is still a big challenge to these
   methods. In this work, we propose a new split-and-merge strategy to
   enable effective and scalable causality discovery. Different from the
   existing methods, our method uses only low-order CI tests, can get more
   accurate results and is applicable to various scenarios. We provide both
   theoretic analysis and empirical evaluation on the proposed method.
   Experiments on various real-world causal graphs show that the proposed
   method outperforms the stat-of-the-art method in terms of accuracy,
   efficiency and scalability. For high-dimensional cases, our method is
   much faster than the counterpart by one to three orders of magnitudes.
   (C) 2020 The Authors. Published by Elsevier B.V.
ZB 0
ZS 0
ZR 0
Z8 0
TC 0
Z9 0
SN 0925-2312
EI 1872-8286
UT WOS:000531809000012
ER

PT J
AU Bharill, Neha
   Tiwari, Aruna
   Malviya, Aayushi
   Patel, Om Prakash
   Gupta, Akahansh
   Puthal, Deepak
   Saxena, Amit
   Prasad, Mukesh
TI Fuzzy knowledge based performance analysis on big data
SO NEUROCOMPUTING
VL 389
BP 218
EP 228
DI 10.1016/j.neucom.2018.10.088
PD MAY 14 2020
PY 2020
AB Due to the various emerging technologies, an enormous amount of data,
   termed as Big Data, gets collected every day and can be of great use in
   various domains. Clustering algorithms that store the entire data into
   memory for analysis become unfeasible when the dataset is too large.
   Many clustering algorithms present in the literature deal with the
   analysis of huge amount of data. The paper discusses a new clustering
   approach called an Incremental Random Sampling with Iterative
   Optimization Fuzzy c-Means (IRSIO-FCM) algorithm. It is implemented on
   Apache Spark, a framework for Big Data processing. Sparks works really
   well for iterative algorithms by supporting in-memory computations,
   scalability, etc. IRSIO-FCM not only facilitates effective clustering of
   Big Data but also performs storage space optimization during clustering.
   To establish a fair comparison of IRSIO-FCM, we propose an incremental
   version of the Literal Fuzzy c-Means (LFCM) called ILFCM implemented in
   Apache Spark framework. The experimental results are analyzed in terms
   of time and space complexity, NMI, ARI, speedup, sizeup, and scaleup
   measures. The reported results show that IRSIO-FCM achieves a
   significant reduction in run-time in comparison with ILFCM. (C) 2019
   Elsevier B.V. All rights reserved.
Z8 0
ZB 0
TC 0
ZR 0
ZS 0
Z9 0
SN 0925-2312
EI 1872-8286
UT WOS:000531809000019
ER

PT P
AU KATSUYUKI M
TI Image display system such as video wall system, has screen display
   control unit which outputs environmental correction data for adjusting
   color shift between display screen corresponding to color adjustment
   unit
PN WO2020095404-A1
AE NEC DISPLAY SOLUTIONS LTD
AB 
   NOVELTY - The image display system has multiple of display devices
   (111-114) which include a color adjustment unit (14) for adjusting the
   color for each corner region in each display screen. A screen display
   control unit (121) outputs environmental correction data for adjusting
   the color shift between the display screens corresponding to the color
   adjustment unit, to each of the color adjustment units. A control screen
   display unit (122) displays the control image which shows the
   arrangement structure of the display screen of the display device.
   USE - Image display system such as video wall system used for displaying
   image on screen of large area.
   ADVANTAGE - The image display system is provided with a composite
   display screen of big screen comprised from the display screen of
   multiple display apparatus, which reduces the color shift between the
   display screens easily.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for a method for
   displaying image.
   DESCRIPTION Of DRAWING(S) - The drawing shows a structural diagram of
   the image display system. (Drawing includes non-English language
   text)Color adjustment unit (14)Display devices (111-114)Screen display
   control unit (121)Control screen display unit (122)Information
   communication line (400)
Z9 0
UT DIIDW:202042064J
ER

PT J
AU Kim, Ji-Myung
   Bae, Yun Jung
TI Mineral Intake Status of Community-Dwelling Elderly from Urban and Rural
   Areas of South Korea: A Cross-Sectional Study Based on Korean National
   Health and Nutrition Examination Survey, 2013~2016.
SO International journal of environmental research and public health
VL 17
IS 10
DI 10.3390/ijerph17103415
PD 2020 May 14
PY 2020
AB We aimed to evaluate the intake of minerals (calcium, phosphorous,
   sodium, and potassium) in the urban and rural elderly and explore the
   adequacy of intake and food sources for each mineral using nationwide
   big data. The study used data from the Korea National Health and
   Nutrition Examination Survey (KNHANES) between 2013 and 2016. We
   analyzed 5292 elderly individuals that were aged 65 years and older
   (2271 men, 3021 women). Daily calcium, phosphorous, sodium, and
   potassium intake, and they were analyzed using the 24-h dietary recall
   method. Additionally, the adequacy of intake and food sources for each
   mineral was analyzed. Blood triglyceride level was significantly higher
   in rural elderly than in urban elderly. The intake of calcium and
   potassium per 1000 kcal of energy intake was significantly lower in the
   rural elderly, and the proportion of participants with calcium intake
   below the Estimated Average Requirement was significantly higher in the
   rural elderly than in the urban elderly. The intake of calcium,
   phosphorous, and potassium in the rural elderly was lower than that in
   the urban elderly. These results can be used as basic data when making
   social and environmental policies for the health of the elderly and when
   providing targeted dietary education for the management of chronic
   diseases for the elderly.
OI Kim, Ji-Myung/0000-0002-5965-9681
ZR 0
Z8 0
ZS 0
ZB 0
TC 0
Z9 0
EI 1660-4601
UT MEDLINE:32422923
PM 32422923
ER

PT J
AU Zhang, Rong
   Drummond, Alexei
TI Improving the performance of Bayesian phylogenetic inference under
   relaxed clock models.
SO BMC evolutionary biology
VL 20
IS 1
BP 54
EP 54
DI 10.1186/s12862-020-01609-4
PD 2020 May 14
PY 2020
AB BACKGROUND: Bayesian MCMC has become a common approach for phylogenetic
   inference. But the growing size of molecular sequence data sets has
   created a pressing need to improve the computational efficiency of
   Bayesian phylogenetic inference algorithms.
   RESULTS: This paper develops a new algorithm to improve the efficiency
   of Bayesian phylogenetic inference for models that include a per-branch
   rate parameter. In a Markov chain Monte Carlo algorithm, the presented
   proposal kernel changes evolutionary rates and divergence times at the
   same time, under the constraint that the implied genetic distances
   remain constant. Specifically, the proposal operates on the divergence
   time of an internal node and the three adjacent branch rates. For the
   root of a phylogenetic tree, there are three strategies discussed, named
   Simple Distance, Small Pulley and Big Pulley. Note that Big Pulley is
   able to change the tree topology, which enables the operator to sample
   all the possible rooted trees consistent with the implied unrooted tree.
   To validate its effectiveness, a series of experiments have been
   performed by implementing the proposed operator in the BEAST2 software.
   CONCLUSIONS: The results demonstrate that the proposed operator is able
   to improve the performance by giving better estimates for a given chain
   length and by using less running time for a given level of accuracy.
   Measured by effective samples per hour, use of the proposed operator
   results in overall mixing more efficient than the current operators in
   BEAST2. Especially for large data sets, the improvement is up to half an
   order of magnitude.
ZR 0
TC 0
ZS 0
Z8 0
ZB 0
Z9 0
EI 1471-2148
UT MEDLINE:32410614
PM 32410614
ER

PT J
AU Bos, Simon
   Laukens, Debby
TI Metabolic modulation during intestinal fibrosis.
SO Journal of digestive diseases
DI 10.1111/1751-2980.12882
PD 2020-May-14
PY 2020
AB Intestinal fibrosis is one of the biggest blind spots in the therapeutic
   management of inflammatory bowel diseases (IBD). Especially patients
   with Crohn's disease suffer from fibrotic complications, which are
   manifested by clinical stenosis of the bowel. Although fibrosis is
   caused by recurrent episodes of inflammation and wound healing, the
   currently used therapies for IBD do not seem to reduce the incidence of
   stenosis, suggesting that also inflammation-independent mechanisms
   contribute to intestinal fibrogenesis. The lack of anti-fibrotic
   therapies for IBD and the huge burden for the patient has prompted us to
   redirect inflammation research toward understanding mechanisms that
   drive gut fibrosis. Based on data from other fibroproliferative
   diseases, metabolic modifications are increasingly recognized as
   pathogenic processes that may generate new therapeutic opportunities.
   These metabolic alterations result from a switch in cellular metabolism
   of activated fibroblasts, which are the key mediator cells of fibrosis.
   Here, we review the metabolic changes associated with fibrotic disease,
   and summarize the evidence of a metabolic shift during intestinal
   fibrosis. This article is protected by copyright. All rights reserved.
ZS 0
ZB 0
TC 0
ZR 0
Z8 0
Z9 0
EI 1751-2980
UT MEDLINE:32406133
PM 32406133
ER

PT J
AU Andrejevic, Tina P
   Milivojevic, Dusan
   Glisic, Biljana D
   Kljun, Jakob
   Stevanovic, Nevena Lj
   Vojnovic, Sandra
   Medic, Strahinja
   Nikodinovic-Runic, Jasmina
   Turel, Iztok
   Djuran, Milos I
TI Silver(i) complexes with different pyridine-4,5-dicarboxylate ligands as
   efficient agents for the control of cow mastitis associated pathogens.
SO Dalton transactions (Cambridge, England : 2003)
VL 49
IS 18
BP 6084
EP 6096
DI 10.1039/d0dt00518e
PD 2020-May-14
PY 2020
AB Infections of the cow udder leading to mastitis and lower milk quality
   are one of the biggest problems in the dairy industry worldwide.
   Unfortunately, therapeutic options for the treatment of cow mastitis are
   limited as a consequence of the development of pathogens that are
   resistant to conventionally used antibiotics. In the search for agents
   that will be active against cow mastitis associated pathogens, in the
   present study, five new silver(i) complexes with different chelating
   pyridine-4,5-dicarboxylate types of ligands, [Ag(NO3)(py-2py)]n (1),
   [Ag(NO3)(py-2metz)]n (2), [Ag(CH3CN)(py-2py)]BF4 (3), [Ag(py-2tz)2]BF4
   (4) and [Ag(py-2metz)2]BF4 (5), py-2py is dimethyl
   2,2'-bipyridine-4,5-dicarboxylate, py-2metz is dimethyl
   2-(4-methylthiazol-2-yl)pyridine-4,5-dicarboxylate and py-2tz is
   dimethyl 2-(thiazol-2-yl)pyridine-4,5-dicarboxylate, were synthesized,
   structurally characterized and assessed for in vitro antimicrobial
   activity using both standard bioassay and clinical isolates from a
   contaminated milk sample obtained from a cow with mastitis. These
   complexes showed remarkable activity against the standard panel of
   microorganisms and a selection of clinical isolates from the milk of the
   cow diagnosed with mastitis. With the aim of determining the therapeutic
   potential of silver(i) complexes, their toxicity in vivo against the
   model organism, Caenorhabditis elegans (C. elegans), was investigated.
   The complexes that had the best therapeutic profile, 2 and 5, induced
   bacterial membrane depolarization and the production of reactive oxygen
   species (ROS) in Candida albicans cells and inhibited the hyphae as well
   as the biofilm formation. Taken together, the presented data suggest
   that the silver(i) complexes with pyridine ligands could be considered
   for the treatment of microbial pathogens, which are causative agents of
   cow mastitis.
RI Turel, Iztok/A-1516-2008
OI Turel, Iztok/0000-0001-6776-4062
ZR 0
ZB 0
ZS 0
Z8 0
TC 0
Z9 0
EI 1477-9234
UT MEDLINE:32319493
PM 32319493
ER

PT P
AU GONG M
   MOURET R
TI Method for performing abnormality detection based on unsupervised
   learning, involves determining parameter of mask function by
   sequentially performing gaussian random projection and percentile
   thresholding operations on training data
PN KR2110480-B1
AE IGLOO SECURITY INC
AB 
   NOVELTY - The method involves generating service detection data. The
   service detection data is input into a second abnormality detection
   model. Feedback data is received for anomaly detection data from a user.
   A first abnormality detection model is retrained based on the feedback
   data. The second abnormality detection model is replaced with the
   retrained first abnormality detection model. Training data is determined
   as data with abnormality of 5% or less. A mask generation operation of
   the training data is performed. A parameter of mask function is
   determined by sequentially performing centering and scaling operations,
   a gaussian random projection operation and a percentile thresholding
   operation on the training data.
   USE - Method for performing abnormality detection based on unsupervised
   learning in big data and internet-of-things.
   ADVANTAGE - The method enables realizing training abnormality detection
   model efficiently to satisfy user intention by user feedback data
   without stopping an anomaly detection service, and achieving re-learning
   in short time by the anomaly detection model to enhance re-learned with
   feedback data of the user, and increasing accuracy and consistency of a
   machine learning model for the user to correct and predicted re-learn
   results and avoiding storing learning data for initial model learning to
   ensure high re-learning.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for an
   unsupervised learning based abnormality detection performing apparatus.
   DESCRIPTION Of DRAWING(S) - The drawing shows a flow diagram
   illustrating the method for performing abnormality detection based on
   unsupervised learning. (Drawing includes non-English language text).
Z9 0
UT DIIDW:202042310E
ER

PT P
AU LEEWONKYU
TI System for providing discount marketing service using big data-based
   influencer advertisement, has server for storing raw data including
   purchase information of terminal, and construction unit for visualizing
   and outputting analyzed data
PN KR2110495-B1
AE STORYN MEDIA INC
AB 
   NOVELTY - The system (1) has a notification unit for transmitting
   feedback to an advertiser terminal (400). A discount marketing service
   providing server (300) collects purchase information and personal
   information of an influencer terminal (100). A marketing unit analyzes
   data and provides marketing solution to the advertiser terminal and the
   discount marketing service providing server when determining that the
   discount coupon is used by the influencer terminal. The discount
   marketing service providing server stores raw data including purchase
   information and personal information of the influencer terminal and
   analyzes pre-processed data including data mining. A construction unit
   visualizes and outputs the analyzed data.
   USE - System for providing discount marketing service using big
   data-based influencer advertisement and providing a platform for
   maximizing sales and viral effects by providing product discounts to an
   influencer.
   ADVANTAGE - The system increases truthfulness and draw positive
   reactions from consumers and analyzes the data of the influencer to
   advertisers and provide marketing solutions to increase sales by
   removing doubts about recommended actions.
   DESCRIPTION Of DRAWING(S) - The drawing shows a schematic view of a
   system for providing discount marketing service using big data-based
   influencer advertisement.System for providing discount marketing service
   (1)Influencer terminal (100)Network (200)Discount marketing service
   providing server (300)Advertiser terminal (400)Store terminal (500)
Z9 0
UT DIIDW:202043220K
ER

PT J
AU Cuomo, Raphael E.
   Cai, Mingxiang
   Shah, Neal
   Li, Jiawei
   Chen, Wen-Hao
   Obradovich, Nick
   Mackey, Tim K.
TI Characterising communities impacted by the 2015 Indiana HIV outbreak: A
   big data analysis of social media messages associated with HIV and
   substance abuse
SO DRUG AND ALCOHOL REVIEW
DI 10.1111/dar.13091
EA MAY 2020
PY 2020
AB Introduction and Aims Infoveillance approaches (i.e. surveillance
   methods using online content) that leverage big data can provide new
   insights about infectious disease outbreaks and substance use disorder
   topics. We assessed social media messages about HIV, opioid use and
   injection drug use in order to understand how unstructured data can
   prepare public health practitioners for response to future outbreaks.
   Design and Methods We conducted an retrospective analysis of Twitter
   messages during the 2015 HIV Indiana outbreak using machine learning,
   statistical and geospatial analysis to examine the transition between
   opioid prescription drug abuse to heroin injection use and finally HIV
   transmission risk, and to test possible associations with disease burden
   and demographic variables in Indiana and Marion County. Tweets from
   October 2014 to June 2015 were compared to disease burden at the county
   level for Indiana, and classification of census blocks by presence of
   relevant messages was done at the census block level for Marion County.
   Marion County was used as it exhibited the highest total count of
   Tweets.
   Results 257 messages about substance abuse and HIV were significantly
   related to HIV rates (P < 0.001) and opioid-related hospitalisations (P
   = 0.037). Using 157 characteristics from the American Community Survey,
   a linear classifier was computed with an appreciable correlation (r =
   0.49) to risk-related social media messages from Marion County.
   Discussion and Conclusions Communities appear to communicate online in
   response to disease burden. Classification produced an accurate equation
   to model census block risk based on census data, allowing for
   high-dimensional estimation of risk for blocks with sparse populations.
RI Mackey, Tim/H-9156-2013
OI Mackey, Tim/0000-0002-2191-7833
Z8 0
TC 0
ZR 0
ZB 0
ZS 0
Z9 0
SN 0959-5236
EI 1465-3362
UT WOS:000532521100001
PM 32406155
ER

PT J
AU Greco, Luca
   Ritrovato, Pierluigi
   Vento, Mario
TI On the use of semantic technologies for video analytics
SO JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING
DI 10.1007/s12652-020-02021-y
EA MAY 2020
PY 2020
AB The rapid proliferation of smart devices, surveillance cameras,
   infrastructures and buildings enhanced with the Internet of Things (IoT)
   technologies has led to a huge explosion of contents, especially in the
   video domain, determining an ever increasing interest towards the
   development of methods and tools for automatic analysis and
   interpretation of video sequences. Through the years, the availability
   of contextual knowledge has proven to improve video analysis
   performances in several ways, although the formal representation of
   semantic content in a shareable and fusion oriented manner is still an
   open problem, also considering the wide diffusion of Fog and Edge
   computing architectures for video analytics lately. In this context, an
   interesting answer has come from Semantic Web (SW) technologies, that
   opened a new perspective for the so-called Knowledge Based Computer
   Vision (KBCV), adding novel analytics opportunities, improving accuracy,
   and facilitating data exchange between video analysis systems in an open
   extensible manner. In this work, we propose a survey of the papers from
   the last eighteen years, back when first applications of semantic
   technologies to video analytics have appeared. The papers, analyzed
   under different perspectives to give a comprehensive overview of the
   technologies involved, reveal an interesting trend towards the adoption
   of SW technologies for video analytics scopes. As a result of our work,
   some insights about future challenges are also provided.
ZB 0
Z8 0
ZR 0
ZS 0
TC 0
Z9 0
SN 1868-5137
EI 1868-5145
UT WOS:000532649300005
ER

PT J
AU Mostafaeipour, Ali
   Rafsanjani, Amir Jahangard
   Ahmadi, Mohammad
   Dhanraj, Joshuva Arockia
TI Investigating the performance of Hadoop and Spark platforms on machine
   learning algorithms
SO JOURNAL OF SUPERCOMPUTING
DI 10.1007/s11227-020-03328-5
EA MAY 2020
PY 2020
AB One of the most challenging issues in the big data research area is the
   inability to process a large volume of information in a reasonable time.
   Hadoop and Spark are two frameworks for distributed data processing.
   Hadoop is a very popular and general platform for big data processing.
   Because of the in-memory programming model, Spark as an open-source
   framework is suitable for processing iterative algorithms. In this
   paper, Hadoop and Spark frameworks, the big data processing platforms,
   are evaluated and compared in terms of runtime, memory and network
   usage, and central processor efficiency. Hence, the K-nearest neighbor
   (KNN) algorithm is implemented on datasets with different sizes within
   both Hadoop and Spark frameworks. The results show that the runtime of
   the KNN algorithm implemented on Spark is 4 to 4.5 times faster than
   Hadoop. Evaluations show that Hadoop uses more sources, including
   central processor and network. It is concluded that the CPU in Spark is
   more effective than Hadoop. On the other hand, the memory usage in
   Hadoop is less than Spark.
ZR 0
ZS 0
ZB 0
TC 0
Z8 0
Z9 0
SN 0920-8542
EI 1573-0484
UT WOS:000532628500001
ER

PT J
AU Madhusudhan, K. N.
   Sakthivel, P.
TI A secure medical image transmission algorithm based on binary bits and
   Arnold map
SO JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING
DI 10.1007/s12652-020-02028-5
EA MAY 2020
PY 2020
AB The responsibility of maintaining patient's records is with medical
   personnel. The medical personnel are supposed not to disclose any kind
   of medical information related to the patient. This is also applicable
   for the medical information discovered by medical personnel in
   connection with the treatment of the patient. With the advent of
   technology and its penetration into the medical field in the form of
   telemedicine and e-health, the challenge of maintaining confidentiality
   is becoming complex. The confidentiality needs to be protected from
   storage of medical image or transmission of image from a medical
   database center to other. Nowadays, the information of patient is
   printed in the corner of the medical image. This can be accessed by
   anybody or even the machine can access and store the information. During
   an electronic transmission, the patient information may be intercepted
   by a third party. This may lead to big lawsuit. Apart from these
   security issues, for scenarios such as medical research, the image
   should be used but patient information should be hidden. Also for
   diagnostic purposes, the information of the patient should be readily
   accessible to the medical personnel. These constraints lead to the
   necessity of suitable security techniques for medical image storage and
   transmission. If suitable security techniques are not applied, privacy
   of patients will be stake. Hence, numerous methods are being implemented
   by individuals, governments and businesses for secured transmission of
   patient's data. For patient's privacy protection, secured transmission
   requires techniques like cryptography and watermarking. These techniques
   achieve confidentiality and integrity. In this work, a new approach has
   been developed for secured transmission of medical images.
TC 0
ZB 0
ZS 0
ZR 0
Z8 0
Z9 0
SN 1868-5137
EI 1868-5145
UT WOS:000532111100002
ER

PT J
AU Khalighifar, Ali
   Jimenez, Laura
   Nunez-Penichet, Claudia
   Freeman, Benedictus
   Ingenloff, Kate
   Jimenez-Garcia, Daniel
   Peterson, Town
TI Inventory statistics meet big data: complications for estimating numbers
   of species
SO PEERJ
VL 8
AR e8872
DI 10.7717/peerj.8872
PD MAY 13 2020
PY 2020
AB We point out complications inherent in biodiversity inventory metrics
   when applied to large-scale datasets. The number of units of inventory
   effort (e.g., days of inventory effort) in which a species is detected
   saturates, such that crucial numbers of detections of rare species
   approach zero. Any rare errors can then come to dominate species
   richness estimates, creating upward biases in estimates of species
   numbers. We document the problem via simulations of sampling from
   virtual biotas, illustrate its potential using a large empirical dataset
   (bird records from Cape May, NJ, USA), and outline the circumstances
   under which these problems may be expected to emerge.
ZS 0
ZR 0
TC 0
ZB 0
Z8 0
Z9 0
SN 2167-8359
UT WOS:000532063300001
PM 32440370
ER

PT P
AU HAN K
TI Brand value creation service providing system, has manager terminal for
   transmitting analysis data to product analysis module, and value
   creation service providing system for outputting value information
PN KR2110558-B1
AE HAN K
AB 
   NOVELTY - The system has a corporate terminal for transmitting request
   for establishing a brand. The corporate terminal transmits branding
   data, where the branding data includes corporate value information,
   customer information, identity information, storytelling information and
   product information. A big data module classifies element in the
   branding data and performs text mining process corresponding to big
   data. A customer analysis module derives consumer awareness strategy
   from customer information. A manager terminal transmits analysis data to
   a product analysis module. A value creation service providing system
   outputs value information.
                       USE - Brand value creation service providing system.
   ADVANTAGE - The system has uniqueness and high sustainability, and
   eventually improves brand value or image according to needs.
   DESCRIPTION Of DRAWING(S) - The drawing shows a schematic view of a
   brand value creation service providing system. (Drawing includes
   non-English language text).
Z9 0
UT DIIDW:202042315U
ER

PT J
AU Sawada, Ryohto
   Iwasaki, Yuma
   Ishida, Masahiko
TI Model-Free Cluster Analysis of Physical Property Data using Information
   Maximizing Self-Argument Training.
SO Scientific reports
VL 10
IS 1
BP 7903
EP 7903
DI 10.1038/s41598-020-64281-0
PD 2020 May 13
PY 2020
AB We present semi-supervised information maximizing self-argument training
   (IMSAT), a neural network-based classification method that works without
   the preparation of labeled data. Semi-supervised IMSAT can amplify
   specific differences and avoid undesirable misclassification in
   accordance with the purpose. We demonstrate that semi-supervised IMSAT
   has a comparable performance with existing methods for semi-supervised
   learning of image classification and can also classify real experimental
   data (X-ray diffraction patterns and thermoelectric hysteresis curves)
   in the same way even though their shape and dimensions are different.
   Our algorithm will contribute to the automation of big data processing
   and artificial intelligence-driven material development.
ZR 0
Z8 0
ZB 0
ZS 0
TC 0
Z9 0
EI 2045-2322
UT MEDLINE:32404915
PM 32404915
ER

PT J
AU Yanez, Aina M
   Bennasar-Veny, Miquel
   Leiva, Alfonso
   Garcia-Toro, Mauro
TI Implications of personality and parental education on healthy lifestyles
   among adolescents.
SO Scientific reports
VL 10
IS 1
BP 7911
EP 7911
DI 10.1038/s41598-020-64850-3
PD 2020 May 13
PY 2020
AB Several studies have shown an association between personality and health
   status. The aim of this study was to evaluate the association between
   personality traits, parental education and health-related lifestyles in
   a cohort of Spanish adolescents. This is a longitudinal study with a
   source population of 1,123 third-year students (aged 14-15) in secondary
   schools in Spain. At the baseline evaluation sociodemographic variables,
   parental education and personality (Big Five Questionnaire for Children)
   were collected. At 18 months of follow-up health related lifestyles,
   including adherence to a healthy diet (KidMed index), tobacco and
   alcohol consumption, physical exercise, sleep problems and recreative
   screen and social network time were collected. A total of 824
   adolescents (73.4%) completed the 18 months assessment and 695 (84.3%)
   presented valid data. Higher conscientiousness was associated to a lower
   risk for non-adherence to Mediterranean diet (OR=0.7, 95% CIs=0.5-0.9),
   tobacco (OR=0.5, 95% CIs=0.3-0.7) and alcohol consumption (OR=0.6, 95%
   CIs=0.5-0.8), excessive use of screens (OR=0.7, 95% CIs=0.5-0.9) and
   social network sites (OR=0.7, 95% CIs=0.5-0.8). Higher levels of
   extraversion was significantly related to a lower risk of physical
   inactivity (OR=0.7, 95% CIs=0.6-0.9), but they are at a higher risk of
   low adherence to Mediterranean diet (OR=1.3, 95% CIs=1.0-1.7), tobacco
   (OR=2.7, 95% CIs=1.7-4.3) and alcohol consumption (OR=1.9, 95%
   CIs=1.5-2.4) and excessive use of social network sites (OR=1.6, 95%
   CIs=1.3-1.9). High levels of emotional instability were associated with
   tobacco consumption (OR=1.5, 95% CIs=1.0-2.2) and sleep problems
   (OR=2.0, 95% CIs=1.5-2.7). Finally, we found an association with lower
   parental education and adolescents' low adherence to Mediterranean diet
   (OR=1.6, 95% CIs=1.0-2.4) and sleep problems (OR=1.8, 95% CIs=1.0-3.0).
   Cluster analysis of health-related behaviours indicated the presence of
   two different clusters (unhealthy and healthy adolescents) that were
   associated with personality traits. Conscientiousness, extraversion,
   emotional instability and parental education are independent factors
   associated with the acquisition of adolescent healthy lifestyles.
ZR 0
ZS 0
TC 0
ZB 0
Z8 0
Z9 0
EI 2045-2322
UT MEDLINE:32404935
PM 32404935
ER

PT J
AU Weissman, Myrna M
TI Big Data Begin in Psychiatry.
SO JAMA psychiatry
DI 10.1001/jamapsychiatry.2020.0954
PD 2020-May-13
PY 2020
AB The last 40 years of JAMA Psychiatry are reviewed as a celebration of
   its achievements. The focus of this article is on the evolution of big
   data as reflected in key journal articles. The review begins in 1984
   with the introduction of the Epidemiology Catchment Area (ECA) study and
   Freedman's editorial "Psychiatric Epidemiology Counts." The ECA study
   (N=17 000), for the first time in a survey, used clinical diagnosis in 5
   urban communities, thus linking research and care to population rates of
   psychiatric diagnosis. The review then traces the subsequent evolution
   of big data to 5 overlapping phases, other population surveys in the US
   and globally, cohort studies, administrative claims, large genetic data
   sets, and electronic health records. Each of these topics are
   illustrated in articles in JAMA Psychiatry. The many caveats to these
   choices, the historical roots before 1984, as well as the controversy
   around the choice of topics and the term big data are acknowledged. The
   foundation for big data in psychiatry was built on the development of
   defined and reliable diagnosis, assessment tools that could be used in
   large samples, the computational evolution for handling large data sets,
   hypothesis generated by smaller studies of humans and animals with
   carefully crafted phenotypes, the welcoming of investigators from all
   over the world with calls for broader diversity, open access and the
   sharing of data, and introduction of electronic health records more
   recently. Future directions as well as the opportunities for the
   complementary roles of big and little data are described. JAMA
   Psychiatry will continue to be a rich resource of these publications.
ZR 0
Z8 0
TC 0
ZB 0
ZS 0
Z9 0
EI 2168-6238
UT MEDLINE:32401285
PM 32401285
ER

PT J
AU Ballarini, Dario
   Gianfrate, Antonio
   Panico, Riccardo
   Opala, Andrzej
   Ghosh, Sanjib
   Dominici, Lorenzo
   Ardizzone, Vincenzo
   De Giorgi, Milena
   Lerario, Giovanni
   Gigli, Giuseppe
   Liew, Timothy C H
   Matuszewski, Michal
   Sanvitto, Daniele
TI Polaritonic Neuromorphic Computing Outperforms Linear Classifiers.
SO Nano letters
VL 20
IS 5
BP 3506
EP 3512
DI 10.1021/acs.nanolett.0c00435
PD 2020-May-13
PY 2020
AB Machine learning software applications are ubiquitous in many fields of
   science and society for their outstanding capability to solve
   computationally vast problems like the recognition of patterns and
   regularities in big data sets. In spite of these impressive
   achievements, such processors are still based on the so-called von
   Neumann architecture, which is a bottleneck for faster and
   power-efficient neuromorphic computation. Therefore, one of the main
   goals of research is to conceive physical realizations of artificial
   neural networks capable of performing fully parallel and ultrafast
   operations. Here we show that lattices of exciton-polariton condensates
   accomplish neuromorphic computing with outstanding accuracy thanks to
   their high optical nonlinearity. We demonstrate that our neural network
   significantly increases the recognition efficiency compared with the
   linear classification algorithms on one of the most widely used
   benchmarks, the MNIST problem, showing a concrete advantage from the
   integration of optical systems in neural network architectures.
RI Liew, Timothy/D-4300-2016
OI Liew, Timothy/0000-0003-2568-7294
ZR 0
ZS 0
TC 0
ZB 0
Z8 0
Z9 0
EI 1530-6992
UT MEDLINE:32251601
PM 32251601
ER

PT J
AU Luebke, Karsten
   Gehrke, Matthias
   Horst, Joerg
   Szepannek, Gero
TI Why We Should Teach Causal Inference: Examples in Linear Regression With
   Simulated Data
SO JOURNAL OF STATISTICS EDUCATION
DI 10.1080/10691898.2020.1752859
EA MAY 2020
PY 2020
AB Basic knowledge of ideas of causal inference can help students to think
   beyond data, that is, to think more clearly about the data generating
   process. Especially for (maybe big) observational data, qualitative
   assumptions are important for the conclusions drawn and interpretation
   of the quantitative results. Concepts of causal inference can also help
   to overcome the mantra "Correlation does not imply Causation." To
   motivate and introduce causal inference in introductory statistics or
   data science courses, we use simulated data and simple linear regression
   to show the effects of confounding and when one should or should not
   adjust for covariables.
ZR 0
TC 0
Z8 0
ZB 0
ZS 0
Z9 0
SN 1069-1898
UT WOS:000533867600001
ER

PT P
AU CAI M
   LIN H
   WANG B
   RAN X
   ZHOU K
   WANG W
TI Method for predicting the sharing ratio of travel modes based on big
   data, involves obtaining sharing ratio data of different travel modes
   among current cells, and internet data and geographic information system
   data to obtain travel data
PN CN111143769-A
AE SHENZHEN MUNICIPAL DESIGN & RES INST CO
AB 
   NOVELTY - The method involves obtaining the sharing ratio data of
   different travel modes among the current cells, and an internet data and
   geographic information system (GIS) data to obtain travel data of
   different travel modes between communities and basic attribute data of
   the community. A probabilistic model of travel mode selection is
   constructed, and current data is used to calibrate model parameters. The
   probability model is used, which calibrates with the parameters and the
   relevant basic data of the planning year to predict the sharing rate of
   different travel modes between the cells in the planning year.
   USE - Method for predicting the sharing ratio of travel modes based on
   big data.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for a travel
   mode share rate prediction device with first analysis unit.
   DESCRIPTION Of DRAWING(S) - The drawing shows a flowchart of method for
   predicting the sharing ratio of travel modes based on big data. (Drawing
   includes non-English language text).
Z9 0
UT DIIDW:2020423417
ER

PT P
AU CHEN L
TI Big data display method based on knowledge graph, involves obtaining big
   data address information, big data paging data content is downloaded for
   hierarchical analysis, visual graphics are designed in appropriate
   presentation mode
PN CN111143547-A
AE UNIV SHANDONG
AB 
   NOVELTY - The big data display method involves obtaining big data
   address information. The big data paging data content is downloaded for
   performing the hierarchical analysis on the content information. The
   visual graphics are designed in an appropriate presentation mode for
   element extraction. The sentence based on the data collection document
   is extracted. The semantic connection is calculated between any two
   elemental terms for forming a semantic description. The distance of the
   semantic description between the elements in the matrix is represented
   by the value of the corresponding position. The beautification operator
   is based on the graph structure. Multiple layers of repeated layers in
   the knowledge graph are removed by the knowledge graph overlap
   elimination algorithm.
                USE - Big data display method based on the knowledge graph.
   ADVANTAGE - The knowledge graph display method effectively solves the
   problem of slow display of knowledge graphs, and achieves the effect of
   displaying knowledge graphs quickly and effectively, and uses knowledge
   graph beautification algorithms to reduce noise in the knowledge graph,
   and evaluate the beautified knowledge graph according to the
   relationship between the edges and the graph hierarchy for ensuring,
   that the display effect of the knowledge graph meets the visual needs.
   DESCRIPTION Of DRAWING(S) - The drawing shows a flow chart of the big
   data display method. (Drawing includes non-English language text).
Z9 0
UT DIIDW:202042346U
ER

PT P
AU CHENG Y
   LIU W
TI Intelligent temperature patch of automatic warning function has output
   terminal of alarm module and cloud server connected to input terminal of
   management mechanism, information recording unit, big data platform and
   WeChat public account
PN CN111141421-A
AE DONGGUAN YUSHUO TAIHE HEALTH TECHNOLOGY
AB 
   NOVELTY - Patch comprises a power supply fixedly connected to the bottom
   inner surface of a connection box (1). A processor is fixedly connected
   to the bottom inner surface of the connection box and between the power
   supply and a A/D converter. An inner cavity of a square slot is fixedly
   connected with a touch display screen (9). A temperature measuring
   sensor is fixedly connected to the bottom of the connection box. The
   output terminal of a cloud server is connected to the input terminals of
   an information recording unit, a big data platform and a WeChat (RTM:
   Mobile text and voice messaging communication service) public account.
   The output terminal of an alarm module is connected to the input
   terminal of a management mechanism. The output terminal of a time
   setting unit is connected to the input terminal of a timing module. A
   second watch belt (20) matching the first watch belt (19) is fixedly
   connected to the bottom of the elastic sleeve (3).
   USE - Used as intelligent temperature patch of automatic warning
   function.
   ADVANTAGE - The patch: ensures that the product can automatically
   monitor the wearer body temperature in real time during the epidemic
   situation by providing an alarm module; is not only can automatically
   monitor the wearer body temperature in real time but also have high
   temperature and abnormal body temperature; passes the information to the
   management organization to ensure the automatic warning function by
   having a cloud server; provides real-time temperature monitoring and
   data management through big data platform and WeChat (RTM: Mobile text
   and voice messaging communication service) public account; lets the
   monitoring and management personnel remotely also efficiently grasp the
   temperature dynamics of the designated population; responds and
   intervene in real time; and greatly improve the efficiency of
   supervision.
   DESCRIPTION Of DRAWING(S) - The drawing shows a front view of the
   intelligent temperature patch of automatic warning function.Connection
   box (1)Elastic sleeve (3)Touch display screen (9)First watch belt
   (19)Second watch belt (20)
Z9 0
UT DIIDW:2020423982
ER

PT P
AU DI Y
   GUAN H
   ZHANG K
   LI Z
   ZHU Y
TI Data acquisition and analysis system for integrated operation and
   management of new media comprises the resource management module, which
   is used for operating system installation and deployment, hardware
   virtualization, and deployment
PN CN111143651-A
AE ANHUI HAITUN NEW MEDIA IND DEV CO LTD
AB 
   NOVELTY - The data acquisition and analysis system comprises the
   resource management module, which is used for operating system
   installation and deployment, hardware virtualization, and automated
   deployment of big data groups. The data storage module is used to store
   collected data and processing result data. The data processing module is
   used for the cleaning and management of collected data, production of
   user data, management of filtering conditions, and calculation,
   analysis, and processing of user data. The data analysis module is used
   for data extraction, conversion, cleaning, and loading processing. The
   acquired data is used for modeling and mining based on various
   algorithms. The application service module is used to apply the data
   analysis results to the decision-making process to solve actual
   problems.
   USE - Data acquisition and analysis system for integrated operation and
   management of new media.
   ADVANTAGE - The system provides to have convenient data retrieval, short
   data processing logic route, and fast data processing speed, and can
   implement multiple task operations in the data processing process.
Z9 0
UT DIIDW:2020423445
ER

PT P
AU FANG J
   CHE L
   LIU Y
   LI D
   ZHANG Q
   XIONG Y
   QI Y
   DENG X
   KAN Z
   YUE D
   XU L
   WANG G
   YANG D
   TIAN X
TI Multi-mode positioning data compatible offshore land transportation
   reporting terminal, has battery module electrically connected with MCU
   module, vibration sensor, Beidou positioning module, internet of things
   communication module and mobile communication module
PN CN210514634-U
AE CENERTECH TIANJIN CHEM RES & DESIGN INST
AB 
   NOVELTY - The utility model claims multi-mode positioning data of
   offshore land transportation reporting terminal, comprising an MCU
   module, a vibration sensor, and the output end of the input end is
   connected with the MCU module, a Beidou positioning module connected
   with the MCU module; Big Dipper antenna, connected with the big dipper
   positioning module, internet of things communication module, which is
   connected with the MCU module by communication internet, internet of
   things connected antenna, connected with the internet of things
   communication module, mobile communication module, which is connected
   with the MCU module by communication interconnection, battery module,
   which are respectively electrically connected with the MCU module, a
   vibration sensor, a Beidou positioning module, internet of things
   communication module and the mobile communication module. The utility
   model claims a multi-mode positioning data of offshore land transport
   reporting terminal has the following beneficial effects: 1, it realizes
   the Beidou satellite navigation and positioning technology and Internet
   of Things combination of communication technology and mobile
   communication technology application, 2, realizing low power consumption
   of the cargo area or the transfer of operation of when the port is
   placed still.
Z9 0
UT DIIDW:2020433519
ER

PT P
AU HUANG P
TI Skin quality detecting system based on big data technology comprises
   cloud server used to determine skin quality result of person to be
   detected according to skin state data and transmit skin quality result
   to display terminal
PN CN111134620-A
AE BEIJING MEILINIANHUA CULTURE CO LTD
AB 
   NOVELTY - Skin quality detecting system based on big data technology
   comprises a handheld terminal, a cloud server, and a display terminal.
   The handheld terminal is used to obtain the skin state data of the
   person to be detected and transmit the skin state data to the cloud
   server. The cloud server is used to determine the skin quality result of
   the person to be detected according to the skin state data and transmit
   the skin quality result to the display terminal. The display terminal is
   used to visually display the skin quality result.
   USE - Used as skin quality detecting system based on big data
   technology.
   ADVANTAGE - The system can enable users to conveniently and accurately
   detect their own skin quality.
   DESCRIPTION Of DRAWING(S) - The drawing shows a schematic representation
   of the skin quality detecting system based on big data technology
   (Drawing includes non-English language text).
Z9 0
UT DIIDW:202042547R
ER

PT P
AU JIANG R
TI Method for copying data to big data platform, involves using computer
   processor to obtain records contained in change data table, and using
   transaction snapshot consistency to reconstruct relationship change
   history records
PN CN111143376-A
AE JIANG R
AB 
   NOVELTY - The method involves using a computer processor to obtain the
   records contained in the change data table, and using transaction
   snapshot consistency to reconstruct relationship change history records
   to generate consistent change records by connecting change data tables
   and work unit tables based on commit sequence identifiers. The
   consistent change records are stored on the big data platform, and the
   consistent change records are used to answer queries on the big data
   platform.
                      USE - Method for copying data to a big data platform.
   ADVANTAGE - The method involves using a computer processor to obtain the
   records contained in the change data table, and using transaction
   snapshot consistency to reconstruct relationship change history records
   to generate consistent change records by connecting change data tables
   and work unit tables based on commit sequence identifiers, and thus
   enables to copy data to a big data platform in an efficient manner.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for a system for
   copying data to a big data platform, which comprises an acquisition
   module that is computer processor to acquire and change records
   contained in the change data table.
   DESCRIPTION Of DRAWING(S) - The drawing shows a flowchart of the method
   for copying data to a big data platform. (Drawing includes non-English
   language text).
Z9 0
UT DIIDW:2020423517
ER

PT P
AU LI J
   ZHANG Y
TI Economic management big data analysis device, has main machine box whose
   outer wall is provided with touch sensitive screen, and cover plate
   whose lower side is formed with screw hole, where right end of screw
   hole is formed with inner groove
PN CN210515124-U
AE LI J
AB 
   NOVELTY - The utility model claims an economic management for big data
   analysis device, comprising a fixing seat and a liquid crystal display;
   the fixing seat is installed on the lower end outer wall of the liquid
   crystal display, lower end outer wall of the fixing seat is provided
   with a chassis, the left side of the fixing seat of the main case is
   provided with a signal receiver, said seat right side of the mainframe
   box is provided with a voice input terminal, front end outer wall of the
   mainframe box is provided with a touch-sensitive screen, the rubber
   leather sheath perimeter is provided with a transversely extending
   forward of the keyboard tray. pushing the keyboard tray to the tray
   fixing plate, then holding the handle, the turning plate is turned to
   the inner of the rubber leather sheath, by turning the card in the inner
   part of the rubber leather sheath, which effectively prevents the
   entering of dust and fixing the keyboard tray, then the rotary knob and
   knob b; the cover plate is put down, so as to effectively prevent dust
   from entering into the interior of the mainframe box, influence the
   working performance of the analyzing device.
Z9 0
UT DIIDW:202043341W
ER

PT P
AU LIAO Y
   CHEN S
   YANG Z
   WU Y
TI Method for monitoring data quality in a big data environment based on
   data server, data receiving terminal and data quality terminal, involves
   defining data quality evaluation rules and the data quality end stores
   final evaluation results
PN CN111143623-A
AE TECH VALLEY XIAMEN INFORMATION TECHNOLOG
AB 
   NOVELTY - The method involves defining data quality evaluation rules.
   The data quality evaluation rules include integrity evaluation rules,
   consistency evaluation rules, and accuracy evaluation. The data
   collection point is used to collect the data by the data quality end,
   when the data server pushes the data or the data receiver requests the
   data. The data collection point is based on the collected data, and the
   data length result is generated by performing data length statistics.
   The data length result and the encoded data is uploaded to the data
   quality end by data collection point. The Flink technology is used by
   data quality end to calculate the data integrity based on the data
   quality evaluation rules. The data quality end stores the final
   evaluation results.
   USE - Method for monitoring data quality in a big data environment,
   which is based on a data server, a data receiving terminal and a data
   quality terminal.
   ADVANTAGE - The data quality side uses Flink technology to calculate the
   data integrity, match the data consistency, check the data accuracy, and
   generate the final evaluation results, and the data quality side stores
   the final evaluation results, and generates a reminder with incorrect
   data.
   DESCRIPTION Of DRAWING(S) - The drawing shows a schematic flowchart of a
   method for monitoring data quality in a big data environment. (Drawing
   includes non-English text).
Z9 0
UT DIIDW:202042344U
ER

PT P
AU QI J
   ZHOU J
   XU J
TI Big data storage system comprises a big data storage module for
   providing data storage, and shared virtual machine is provided for
   supporting storage sharing functions, and application virtual machine is
   connected to shared virtual machine
PN CN111142777-A
AE GUANGZHOU MINGLEAD INFORMATION TECHNOLOGY CO LTD
AB 
   NOVELTY - The big data storage system comprises a big data storage
   module for providing data storage, and a shared virtual machine is
   provided for supporting storage sharing functions. An application
   virtual machine is connected to the shared virtual machine through an
   internal bus for receiving users according to the user's request, and
   the data of the storage disk is read through the shared virtual machine.
   The detection of the standby virtual machine is used to monitor the
   shared virtual machine. The shared virtual machine fails to work
   normally, and the shared virtual machine is replaced to work. The big
   data storage module includes a first storage device for storing
   important resources, and a second storage device is provided for storing
   temporary resources and resources requiring fast storage.
                       USE - Big data storage system.
                ADVANTAGE - Big data storage system has good use stability.
   DESCRIPTION Of DRAWING(S) - The drawing shows a block diagram of big
   data storage system. (Drawing includes non-English language text).
Z9 0
UT DIIDW:202043631F
ER

PT P
AU TANG H
TI Housekeeping service monitoring device, has wide-angle camera connected
   to data transmission with single chip microcomputer by data wire, where
   single chip microcomputer is connected with driving motor and electric
   cylinder through data line
PN CN210518618-U
AE TANG H
AB 
   NOVELTY - The utility model claims a homemaking service for monitoring
   device, wherein a vehicle body is vertically fixedly connected with a
   mounting bracket, the mounting bracket is fixed with an angle adjusting
   mechanism, wherein the mounting base is horizontally fixedly installed
   on the mounting bracket; the rotating disc to opposite turning way
   clamped on the mounting base, the driving electric motor is fixedly
   installed on the mounting base and is dynamically connected with the
   rotating disc, the rotating disc is vertically equipped with an electric
   cylinder and the top end of the piston rod of electric cylinder in
   opposite turning way is installed with a pulley; pulley is clamped in
   the installing sliding rail and the mounting slide rail is fixedly
   installed with a wide-angle camera, mounting the end of the slide rail
   through the top end of the hinge is connected with the support vertical
   rod, the bottom end of the supporting rod is fixed on the rotating disc;
   the single chip microcomputer is connected with the driving motor, an
   electric cylinder, a wide-angle camera signal through the data line. The
   utility model has big angle shooting direction adjustment, beneficial
   effect of real-time tracking the worker for shooting.
Z9 0
UT DIIDW:2020432718
ER

PT P
AU WANG H
TI Parallel processing method for heterogeneous data of industrial big
   data, involves converting data definition model of source database to
   target define model of database data and converting information in
   source database mode
PN CN111143453-A
AE JINING HAOYING TIANCHENG BIG DATA INFORMATION TECHNOLOGY CO
AB 
   NOVELTY - The parallel processing method involves converting the data
   definition model of the source database to the target define the model
   of the database data. The information in the source database mode needs
   to be shared is converted to the destination database. Related
   information. The heterogeneous database system is built with database
   conversion tools to realize the merger and sharing of data information,
   equipment resources and human resources between different databases. The
   distributed database system is used to solve the problem of parallel
   data processing. A multi-database management system is used to maintain
   the database system.
   USE - Parallel processing method for heterogeneous data of industrial
   big data.
   ADVANTAGE - Parallel processing of heterogeneous big data in the
   industrial field ensures the reliability and scalability of data
   processing.
Z9 0
UT DIIDW:202043629B
ER

PT P
AU WU X
   LUO X
   WANG L
   LI C
   LIU X
   WANG K
TI Data acquisition method with adaptively adjustable sampling frequency,
   involves installing and fixing the sensor. The data is collected through
   the sensor, and calculating number of data collection points in the
   third time detection window
PN CN111147079-A
AE UNIV CHANGAN; CHINA RAILWAY FIRST SURVEY & DESIGN INST
AB 
   NOVELTY - The method involves installing and fixing the sensor. The data
   is collected through the sensor. The initial sampling frequency of the
   fixed sensor is designed. The data is collected at the initial sampling
   frequency by the sensor. The second time detection window is calculated
   by formula. The first time detection window is calculated by formula.
   The ratio of the change rate of the data is calculated in the adjacent
   time detection window. The sampling frequency of the sensor and the
   cumulative change ratio obtained under the constraint condition satisfy
   the relationship of formula. The number of data collection points is
   calculated in the third time detection window.
   USE - Data acquisition method with adaptively adjustable sampling
   frequency.
   ADVANTAGE - The sampling frequency is reduced to reduce system power
   consumption while avoiding invalid big data. Realizes the adaptive
   adjustment of the sampling frequency.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for a data
   collection device with adaptively adjustable sampling frequency.
   DESCRIPTION Of DRAWING(S) - The drawing shows a flowchart of a data
   acquisition method. (Drawing includes non-English language text).
Z9 0
UT DIIDW:202042765N
ER

PT P
AU XIAO Z
TI Large data based district security device, has door body fixedly
   connected with frame, wireless transceiver electrically connected with
   big data service cloud module, and storage battery whose output end is
   connected with input end of processor
PN CN210515426-U
AE SHANGHAI GONGFU IND CO LTD
AB 
   NOVELTY - The utility model claims a big data based on district security
   device, comprising a door main body, front face of the guard body from
   top to bottom are respectively fixedly connected audio hole with a
   camera, a display screen, a key and a card reader, the right side of the
   door body is fixedly connected with frame, the right side of the frame
   inner cavity from top to bottom are respectively fixedly connected with
   a processor and wireless transceiver, top of the frame inner cavity is
   fixedly connected with a data memory, the left side of the frame inner
   cavity is fixedly connected with a locating server, the bottom of the
   said frame body inner cavity is put with a storage battery. advantages
   of this utility model has high safety coefficient, solving the problem
   that the current security device access safety factor low and usually
   can be entering by card and input password, vulnerability is large to
   the criminal, cannot be timely security protection for the cell tenement
   can not timely to alarm to the problem of catching, the criminals to
   escape smoothly.
Z9 0
UT DIIDW:202043709B
ER

PT P
AU XIE M
   SHAO Q
   WANG T
   ZHAO Z
   YI Q
   CHEN S
   YE Y
   YU Y
   YU B
   ZHANG J
   WANG H
   WANG D
TI Method for constructing fault data set of power dispatching data network
   based on big data platform, involves identifying fault occurrence range
   based on protection action event when fault occurs, and fault occurrence
   time range established
PN CN111143622-A
AE STATE GRID ANHUI ELECTRIC POWER CO; CYG SUNRI RELAY PROTECTION
   AUTOMATION CO
AB 
   NOVELTY - The constructing method involves identifying a fault
   occurrence range based on a protection action event when a fault occurs.
   A fault occurrence time range established based on a trigger protection
   action time range. A unified data model obtained through the data
   acquisition interface of the big data platform, and used the unique
   object identity to reverse the data type. The demand operation data
   obtained through the model attribute value, and secondary data processed
   to form a fault data set. The protection device that triggered the event
   and the associated primary and secondary devices are selected as the
   fault impact range.
   USE - Method for constructing a fault data set of a power dispatching
   data network based on a big data platform.
   ADVANTAGE - The efficiency of using data is improved and avoided the
   interference with the existence of data, makes the fault analysis more
   accurate and efficient.
   DESCRIPTION Of DRAWING(S) - The drawing shows a flowchart of a
   constructing method. (Drawing includes non-English language text).
Z9 0
UT DIIDW:202042344V
ER

PT P
AU XU J
   YANG Y
   HU Y
   WANG Y
   LI H
TI Mobile phone expansion device, has terminal interface for receiving
   mobile phone sending, file data, streaming media data, audio data and/or
   video data when terminal interface is connected with data interface of
   mobile phone wireless connection
PN CN210518434-U
AE HAIER BEIJING IC DESIGN CO LTD CN
AB 
   NOVELTY - The utility model claims a mobile phone expansion device, the
   mobile phone expansion device comprises a display screen, a speaker, a
   terminal interface for wireless connection, file HDMI interface, USB
   interface, when the terminal interface is connected with the data
   interface of the mobile phone wireless connection, the terminal
   interface sent by the receiving mobile phone, image data, audio data,
   and/or video data. the mobile phone expansion device itself can be the
   CPU itself or not with a processor, but can be combined with the mobile
   phone, using the processor of the mobile phone and saves the hardware,
   it has better commonality, it can adapt to different types of mobile
   phone. The utility model combines the mobile phone portable, operation
   and big size screen display request. on the basis of consumer in the
   original mobile phone, the cost is far lower than the purchase cost of
   tablet computer/notebook computer purchase product of this utility model
   can simultaneously enjoy the convenient to carry, more convenient
   demonstration, storing data and expanded screen mobile phone browsing
   experience consistency between files, and large screen display.
Z9 0
UT DIIDW:2020432750
ER

PT P
AU YE T
   DU L
   WANG S
TI Predicting house based on smart air outlet big data involves receiving
   parameter data measured by sensors, determining relevant data of house
   and displaying relevant data of house or pushing relevant data of house
   to user
PN CN111141240-A
AE TIANJIN HUALAI TECHNOLOGY CO LTD
AB 
   NOVELTY - Predicting house based on smart air outlet big data comprises
   (a) receiving parameter data measured by sensors installed in the smart
   air outlets in the house, and (b) determining the relevant data of the
   house according to the parameter data, and displaying the relevant data
   of the house or pushing the relevant data of the house to the user,
   where the relevant data of the house includes altitude of the house and
   the volume of the house, and the parameter data measured by the sensor
   includes non-static air pressure data without wind state and wind
   pressure data in the wind state.
   USE - The method is useful for predicting house based on smart air
   outlet big data.
   ADVANTAGE - The method can calculate the altitude of the house through
   air pressure, calculates air volume through the wind pressure of the
   smart air outlet to determine the volume of the house, so that the user
   can have a basic understanding of the house where he is located, and
   improves the user experience.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for house
   prediction device based on smart air outlet big data/
   DESCRIPTION Of DRAWING(S) - The drawing shows a flowchart illustrating
   the method for predicting house based on smart air outlet big data
   (Drawing includes non-English language text).
Z9 0
UT DIIDW:2020424024
ER

PT P
AU ZHAO J
   HUANG G
   XU L
   YU J
TI Three-mode fully isolated anti-irradiation circuit comprises an
   intrinsic circuit that has a combinational logic, where the
   combinational logic inputs the data that is connected to the register,
   the register is connected to big data arbiter
PN CN111147063-A
AE SHANGHAI FUDAN MICROELECTRONICS CO LTD
AB 
   NOVELTY - The three-mode fully isolated anti-irradiation circuit
   comprises an intrinsic circuit that has a combinational logic, where one
   end of the combinational logic inputs the data, and the other end is
   connected to the register. The register other end is connected to the
   first end of the big data arbiter, and the other end of the big data
   arbiter outputs the data. The delay path has a first deglitch, where one
   end of the first deglitch is connected to the other end of the
   combinational logic. The other-end of the first deglitch is connected to
   the first end of the second register, and the other end of the second
   register is connected to the end of the big data arbiter.
                  USE - Three-mode fully isolated anti-irradiation circuit.
   ADVANTAGE - The three-mode fully isolated anti-irradiation circuit
   realizes the single-particle flipping, and single-particle multi-bit
   flipping reinforcement with minimum area loss.
   DESCRIPTION Of DRAWING(S) - The drawing shows a circuit diagram of an
   anti-irradiation circuit. (Drawing includes non-English language text).
Z9 0
UT DIIDW:2020427661
ER

PT J
AU Stefanini, Alessandro
   Aloini, Davide
   Gloor, Peter
TI Silence is golden: the role of team coordination in health operations
SO INTERNATIONAL JOURNAL OF OPERATIONS & PRODUCTION MANAGEMENT
DI 10.1108/IJOPM-12-2019-0792
EA MAY 2020
PY 2020
AB Purpose This study investigates the relationships between team dynamics
   and performance in healthcare operations. Specifically, it explores,
   through wearable sensors, how team coordination mechanisms can influence
   the likelihood of surgical glitches during routine surgery.
   Design/methodology/approach Breast surgeries of a large Italian
   university hospital were monitored using Sociometric Badges - wearable
   sensors developed at MIT Media Lab - for collecting objective and
   systematic measures of individual and group behaviors in real time. Data
   retrieved were used to analyze team coordination mechanisms, as it
   evolved in the real settings, and finally to test the research
   hypotheses. Findings Findings highlight that a relevant portion of
   glitches in routine surgery is caused by improper team coordination
   practices. In particular, results show that the likelihood of glitches
   decreases when practitioners adopt implicit coordination mechanisms
   rather than explicit ones. In addition, team cohesion appears to be
   positively related with the surgical performance. Originality/value For
   the first time, direct, objective and real time measurements of team
   behaviors have enabled an in-depth evaluation of the team coordination
   mechanisms in surgery and the impact on surgical glitches. From a
   methodological perspective, this research also represents an early
   attempt to investigate coordination behaviors in dynamic and complex
   operating environments using wearable sensor tools.
OI Stefanini, Alessandro/0000-0003-1774-4236
ZB 0
ZR 0
ZS 0
TC 0
Z8 0
Z9 0
SN 0144-3577
EI 1758-6593
UT WOS:000532704800001
ER

PT J
AU Islam, A. Y. M. Atiquil
   Ahmad, Khurshid
   Rafi, Muhammad
   Ming, Zheng Jian
TI Performance-based evaluation of academic libraries in the big data era
SO JOURNAL OF INFORMATION SCIENCE
AR 0165551520918516
DI 10.1177/0165551520918516
EA MAY 2020
PY 2020
AB The concept of big data has been extensively considered as a
   technological modernisation in organisations and educational institutes.
   Thus, the purpose of this study is to determine whether the modified
   technology acceptance model (MTAM) is viable for evaluating the
   performance of librarians in the use of big data analytics in academic
   libraries. This study used an empirical research method for collecting
   data from 211 librarians working in Pakistan's universities. On the
   basis of the findings of the MTAM analysis by structural equation
   modelling, the performances of the academic libraries were comprehended
   through the process of big data. The main influential components of the
   performance analysis in this study were the big data analytics
   capabilities, perceived ease of access and the usefulness of big data
   practices in academic libraries. Subsequently, the utilisation of big
   data was significantly affected by skills, perceived ease of access and
   the usefulness of academic libraries. The results also suggested that
   the various components of the academic libraries lead to effective
   organisational performance when linked to big data analytics.
RI Islam, A.Y.M. Atiquil/L-2976-2017
OI Islam, A.Y.M. Atiquil/0000-0002-5430-8057
ZS 0
TC 0
ZR 0
Z8 0
ZB 0
Z9 0
SN 0165-5515
EI 1741-6485
UT WOS:000533094400001
ER

PT J
AU Jaidka, Kokil
   Giorgi, Salvatore
   Schwartz, H. Andrew
   Kern, Margaret L.
   Ungar, Lyle H.
   Eichstaedt, Johannes C.
TI Estimating geographic subjective well-being from Twitter: A comparison
   of dictionary and data-driven language methods
SO PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF
   AMERICA
VL 117
IS 19
BP 10165
EP 10171
DI 10.1073/pnas.1906364117
PD MAY 12 2020
PY 2020
AB Researchers and policy makers worldwide are interested in measuring the
   subjective well-being of populations. When users post on social media,
   they leave behind digital traces that reflect their thoughts and
   feelings. Aggregation of such digital traces may make it possible to
   monitor well-being at large scale. However, social media-based methods
   need to be robust to regional effects if they are to produce reliable
   estimates. Using a sample of 1.53 billion geotagged English tweets, we
   provide a systematic evaluation of word-level and data-driven methods
   for text analysis for generating well-being estimates for 1,208 US
   counties. We compared Twitter-based county-level estimates with
   well-being measurements provided by the Gallup-Sharecare Well-Being
   Index survey through 1.73 million phone surveys. We find that word-level
   methods (e.g., Linguistic Inquiry and Word Count [LIWC] 2015 and
   Language Assessment by Mechanical Turk [LabMT]) yielded inconsistent
   county-level wellbeing measurements due to regional, cultural, and
   socioeconomic differences in language use. However, removing as few as
   three of the most frequent words led to notable improvements in
   well-being prediction. Data-driven methods provided robust estimates,
   approximating the Gallup data at up to r = 0.64. We show that the
   findings generalized to county socioeconomic and health outcomes and
   were robust when poststratifying the samples to be more representative
   of the general US population. Regional well-being estimation from social
   media data seems to be robust when supervised data-driven methods are
   used.
OI Jaidka, Kokil/0000-0002-8127-1157
ZR 0
ZB 0
Z8 0
ZS 0
TC 0
Z9 0
SN 0027-8424
UT WOS:000532837500014
PM 32341156
ER

PT J
AU Dou, Yutan
TI A method to remove depositional background data based on the Modified
   Kernel Hebbian Algorithm
SO ACTA GEOPHYSICA
DI 10.1007/s11600-020-00415-2
EA MAY 2020
PY 2020
AB The seismic sedimentology is an emerging inter-discipline originating
   from the seismic stratigraphy and sequence stratigraphy. However,
   implementation of the seismic sedimentological research is found with
   high difficulties, due to influences imposed by structural and
   depositional background data (including strong reflections). In this
   paper, seismic records are regarded as a combination of the reflection
   from the depositional background and lithological data volumes, and
   moreover, the seismogram of the depositional background data is
   characterized by the low frequency and stable phase. Subsequently, the
   Kernel Hebbian Algorithm (KHA) has been modified to remove the influence
   of the depositional background data. The seismic trace data are used as
   the training set, and an innovative attempt has been made to incorporate
   the Ricker wavelet kernel function. Finally, a depositional background
   data volume extraction methodology with respect to input of
   higher-dimension seismic data has been developed, on the basis of the
   Modified KHA (MKHA), so as to obtain the lithological data volume.
   Utilizing the unsupervised online learning capabilities of the MKHA,
   iterative calculation of Kernel PCA can greatly reduce the computational
   complexity and can be adapted to big data problems. This paper
   introduces the Ricker wavelet kernel function to transform the original
   seismic data into the feature space through the inner-product operation,
   extract the non-linear features, and solve the problem that the seismic
   data of the original sample space is linearly inseparable. The seismic
   sedimentological analysis based on the lithological data volume that is
   able to reflect hidden sand bodies can achieve elaborate carving of the
   reservoir. The proposed method has been tested in Working Block A of the
   East-1 district in the Sulige gas field, the Ordos Basin, China. The
   case study demonstrates that the presented method is capable of
   efficiently removing the depositional background data, and making great
   contributions to improving accuracy of the seismic sedimentological
   analysis of the effective reservoir, with the help of higher-dimension
   seismic data.
ZR 0
TC 0
Z8 0
ZS 0
ZB 0
Z9 0
SN 1895-6572
EI 1895-7455
UT WOS:000532102000001
ER

PT J
AU Ayub, Mubbashir
   Ghazanfar, Mustansar Ali
   Khan, Tasawer
   Saleem, Asjad
TI An Effective Model for Jaccard Coefficient to Increase the Performance
   of Collaborative Filtering
SO ARABIAN JOURNAL FOR SCIENCE AND ENGINEERING
DI 10.1007/s13369-020-04568-6
EA MAY 2020
PY 2020
AB Due to the advancement of technology and an increased number of digital
   devices per person, more and more digital data are generated daily.
   Extracting required data from such big data is a challenging task.
   Recommender systems help us in finding data that best match one's taste.
   Collaborative filtering (CF) is the most popular approach used in
   recommender systems. Various similarity measure techniques are used in
   CF to calculate item-to-item and user-to-user similarity. The majority
   of these methods use common ratings to compute similarity. One of the
   similarity measurement methods is Jaccard similarity, which ignores both
   absolute values of ratings and the average rating value of a user. In
   this paper, we propose an improved measure that considers the ratio
   between absolute rating values and number of commonly rated items. We
   further improved the performance of proposed similarity measure by
   putting some thresholds on the average rating value of a user. An
   important aspect of ratings provided by a user is the rating preference
   behavior of a user, which almost all similarity measurement methods
   ignore. We also incorporated this behavior in our proposed method. The
   proposed method is tested over five publicly available datasets:
   Epinions, FilmTrust, Movie Lens-100K, CiaoDVD and MovieTweetings. The
   proposed method is compared with various modern similarity measures, and
   results show improvements in terms of prediction quality and accuracy.
ZS 0
ZB 0
ZR 0
TC 0
Z8 0
Z9 0
SN 2193-567X
EI 2191-4281
UT WOS:000532100100001
ER

PT J
AU Blanken, Tessa F.
   Courbet, Ophelie
   Franc, Nathalie
   Saenz, Ariadna Albajara
   Van Someren, Eus J. W.
   Peigneux, Philippe
   Villemonteix, Thomas
TI Is an irritable ADHD profile traceable using personality dimensions?
   Replicability, stability, and predictive value over time of data-driven
   profiles
SO EUROPEAN CHILD & ADOLESCENT PSYCHIATRY
DI 10.1007/s00787-020-01546-z
EA MAY 2020
PY 2020
AB Pediatric attention deficit/hyperactivity disorder (ADHD) is a
   heterogeneous condition. In particular, children with ADHD display
   varying profiles of dispositional traits, as assessed through
   temperament and personality questionnaires. Previous data-driven
   community detection analyses based on temperament dimensions identified
   an irritable profile of patients with ADHD, uniquely characterized by
   elevated emotional dysregulation symptoms. Belonging to this profile
   increased the risk of developing comorbid disorders. Here, we
   investigated whether we could replicate this profile in a sample of 178
   children with ADHD, using community detection based on personality
   dimensions. Stability of the identified profiles, of individual
   classifications, and clinical prediction were longitudinally assessed
   over a 1-year interval. Three personality profiles were detected: The
   first two profiles had high levels of neuroticism, with the first
   displaying higher ADHD severity and lower openness to experience
   (profile 1; N = 38), and the second lower agreeableness (profile 2; N =
   73). The third profile displayed scores closer to the normative range on
   all five factors (profile 3; N = 67). The identified profiles did only
   partially replicate the temperament-based profiles previously reported,
   as higher levels of neuroticism were found in two of the three detected
   profiles. Nonetheless, despite changes in individual classifications,
   the profiles themselves were highly stable over time and of clinical
   predictive value. Whereas children belonging to profiles 1 and 2
   benefited from starting medication, children in profile 3 did not.
   Hence, belonging to an emotionally dysregulated profile at baseline
   predicted the effect of medication at follow-up over and above initial
   ADHD symptom severity. This finding suggests that personality profiles
   could play a role in predicting treatment response in ADHD.
ZB 0
Z8 0
TC 0
ZR 0
ZS 0
Z9 0
SN 1018-8827
EI 1435-165X
UT WOS:000532125000001
PM 32399809
ER

PT J
AU Liu, M
   Ning, J
   Du, Y
   Cao, J
   Zhang, D
   Wang, J
   Chen, M
TI Modelling the evolution trajectory of COVID-19 in Wuhan, China:
   experience and suggestions.
SO Public health
VL 183
BP 76
EP 80
DI 10.1016/j.puhe.2020.05.001
PD 2020-May-12
PY 2020
AB OBJECTIVES: In December 2019, a novel coronavirus disease (COVID-19)
   emerged in Wuhan city, China, which has subsequently led to a global
   pandemic. At the time of writing, COVID-19 in Wuhan appears to be in the
   final phase and under control. However, many other countries, especially
   the US, Italy and Spain, are still in the early phases and dealing with
   increasing cases every day. Therefore, this article aims to summarise
   and share the experience of controlling the spread of COVID-19 in Wuhan
   and provide effective suggestions to enable other countries to save
   lives.
   STUDY DESIGN: Data from the National Health Commission of China are used
   to investigate the evolution trajectory of COVID-19 in Wuhan and discuss
   the impacts of the intervention strategies.
   METHODS: A four-stage modified Susceptible-Exposed-Infectious-Removed
   (SEIR) model is presented. This model considers many influencing
   factors, including chunyun (the Spring festival), sealing off the city
   and constructing the Fangcang shelter hospitals. In addition, a novel
   method is proposed to address the abnormal data on 12-13 February as a
   result of changing diagnostic criteria. Four different scenarios are
   considered to capture different intervention measures in practice. The
   exposed population in Wuhan who moved out before sealing off the city
   have also been identified, and an analysis on where they had gone was
   performed using the Baidu Migration Index.
   RESULTS: The results demonstrate that the four-stage model was effective
   in forecasting the peak, size and duration of COVID-19. We found that
   the combined intervention measures are the only effective way to control
   the spread and not a single one of them can be omitted. We estimate that
   England will be another epicentre owing to its incorrect response at the
   initial stages of COVID-19. Fortunately, big data technology can help
   provide early warnings to new areas of the pandemic.
   CONCLUSIONS: The four-stage SEIR model was effective in capturing the
   evolution trajectory of COVID-19. Based on the model analysis, several
   effective suggestions are proposed to prevent and control the pandemic
   for countries that are still in the initial phases.
TC 0
ZR 0
ZS 0
Z8 0
ZB 0
Z9 0
EI 1476-5616
UT MEDLINE:32442842
PM 32442842
ER

PT J
AU Su, Yuan
   Yu, Yanni
   Zhang, Ning
TI Carbon emissions and environmental management based on Big Data and
   Streaming Data: A bibliometric analysis.
SO The Science of the total environment
VL 733
BP 138984
EP 138984
DI 10.1016/j.scitotenv.2020.138984
PD 2020-May-12
PY 2020
AB Climate change and environmental management are issues of global
   concern. The advent of the era of Big Data has created a new research
   platform for the assessment of environmental governance and policies.
   However, little is known about Big Data application to climate change
   and environmental management research. This paper adopts bibliometric
   analysis in conjunction with network analysis to systematically evaluate
   the publications on carbon emissions and environmental management based
   on Big Data and Streaming Data using R package and VOSviewer software.
   The analysis involves 274 articles after rigorous screening and includes
   citation analysis, co-citation analysis, and co-word analysis. Main
   findings include (1) Carbon emissions and environmental management based
   on big data and streaming data is an emerging multidisciplinary research
   topic, which has been applied in the fields of computer science, supply
   chain design, transportation, carbon price assessment, environmental
   policy evaluation, and CO2 emissions reduction. (2) This field has
   attracted the attention of nations which are major contributors to the
   world economy. In particular, European and American scholars have made
   the main contributions to this topic, and Chinese researchers have also
   had great impact. (3) The research content of this topic is primarily
   divided into four categories, including empirical studies of specific
   industries, air pollution governance, technological innovation, and
   low-carbon transportation. Our findings suggest that future research
   should bring greater depth of practical and modeling analysis to
   environmental policy assessment based on Big Data.
ZS 0
Z8 0
ZB 0
ZR 0
TC 0
Z9 0
EI 1879-1026
UT MEDLINE:32446050
PM 32446050
ER

PT J
AU Sunday, Michael Oluwatoyin
   Jadoon, Waqar Azeem
   Ayeni, Taiwo Tolulope
   Iwamoto, Yoko
   Takeda, Kazuhiko
   Imaizumi, Yoshitaka
   Arakaki, Takemitsu
   Sakugawa, Hiroshi
TI Heterogeneity and potential aquatic toxicity of hydrogen peroxide
   concentrations in selected rivers across Japan.
SO The Science of the total environment
VL 733
BP 139349
EP 139349
DI 10.1016/j.scitotenv.2020.139349
PD 2020-May-12
PY 2020
AB Hydrogen peroxide (H2O2) is a reactive oxygen species formed in natural
   water. It is reportedly toxic to aquatic organisms with a predicted
   no-effect concentration (PNEC) of about 380nM. In this study, a
   countrywide investigation of H2O2 concentrations in selected rivers
   across Japan was conducted to identify rivers that pose toxicity
   concerns. Twelve rivers with a total catchment area of 13,646km2 were
   selected from different prefectures. Spatial and temporal variation
   studies showed that the H2O2 concentrations (avg. 320nM, n=111) varied
   by two orders of magnitude (range 21-2929nM) across the rivers. The
   Yamato River in Osaka and Nara prefectures and the Kokubu River in Chiba
   Prefecture had the highest concentrations at 276-669nM and 236-2929nM,
   respectively. >75% of the data from the two rivers were either close to
   or exceeded the PNEC. Most of the results for the other rivers were less
   than the PNEC. There was a clear seasonal variation in the H2O2
   concentrations, with the highest values obtained in summer because of
   high solar irradiation. The H2O2 concentration had the highest positive
   correlation (r=0.61, p < 0.01, n=111) with the product of dissolved
   organic carbon and solar radiation intensity, which suggests that these
   two factors in combination are important in determining the H2O2
   concentrations in river water. It was also observed that bigger rivers
   had lower H2O2 concentration and vice-versa. This shows that the size of
   a river may influence its H2O2 concentration. This study is the first
   countrywide survey of H2O2 concentrations in different rivers and
   evaluation of their relationship with the PNEC. The data provide insight
   on the factors influencing the concentrations of H2O2 in river water.
TC 0
ZB 0
ZR 0
Z8 0
ZS 0
Z9 0
EI 1879-1026
UT MEDLINE:32446084
PM 32446084
ER

PT P
AU BAI Y
   XU X
TI Data transfer control management system, has signal emitting module
   connected with data receiving module, external memory provided with
   detection module, where detecting module is connected with data
   receiving module and data output module
PN CN210515288-U
AE GUANGDONG KEHUA QIANSHENG CLOUD COMPUTIN
AB 
   NOVELTY - The utility model claims a data transfer control management
   system, comprising a big data platform and external memory, big data
   platform is equipped with a signal receiving module, a signal receiving
   module connected with the processing module, the processing module is in
   signal connection with a data output module; external memory provided
   with a screening module, filtering module is connected with a signal
   emitting module and a signal transmitting module is in signal connection
   with a data receiving module, an external reservoir is further provided
   with a detecting module, the detecting module at the same time signal is
   connected with the data receiving module and a data output module; The
   beneficial effects are as follows: the screening module of the external
   memory is screening data types, capable of screening needed data to
   transfer, when the data output module outputs the data to the external
   memory, data will pass through the detecting module and the data for
   further security screening, then signal transported to the data
   receiving module, improve the safety in the process of data
   transmission, high automation degree, simple and convenient operation
   and control.
Z9 0
UT DIIDW:202043338J
ER

PT P
AU CAO W
   WANG X
   ZHANG J
TI Beidou positioning communication module, has Beidou communication module
   fixedly welded on circuit board for communicating with remote terminal,
   and power supply module in device requiring power supply connected by
   welding for providing working power supply
PN CN210514636-U
AE NANTONG HAIOU LIFE SAVING & PROTECTION E
AB 
   NOVELTY - The utility model claims a Big Dipper positioning
   communication module, belonging to the communication field of locating,
   comprising a compass card, dipper groove, a central processor module, a
   Beidou positioning module, a Beidou communication module, a Beidou
   antenna, electrical source module, the Beidou Beidou slot for mounting
   card, the Beidou positioning module is used for obtaining the device
   real-time positioning data, the Beidou communication module for
   communicating with a remote terminal, a wireless signal of the Beidou
   antenna and a Beidou communication module bidirectionally connected for
   receiving and sending sent by the remote terminal, the power supply
   input end of the module in the power supply module with the device
   requiring power supply and is used for supplying the working power
   supply. the device has compact structure, good positioning communication
   effect, capable of positioning at offshore emergency communication
   function.
Z9 0
UT DIIDW:2020433517
ER

PT P
AU CHEN F
TI Large data based data collecting system, has instrument main body whose
   outer surface is provided with fixing sleeve, where rear end of
   instrument main body is provided with hanging structure, and supporting
   structure provided with inner thread cylinder
PN CN210513179-U
AE YUNNAN LINGRIT TECHNOLOGY CO LTD
AB 
   NOVELTY - The utility model claims a big data of data collecting system,
   comprising integrating main body, the outer surface of the instrument
   main body with a fixing sleeve, the fixing sleeve of the two sides of
   the outer surface is provided with a supporting structure; the
   supporting structure comprises an inner thread cylinder is set along the
   height direction, movably passes through the thread rod in the inside of
   the inner screw thread cylinder, the lower end of the inner screw thread
   cylinder is open and the upper end is closed, the lower end of the
   threaded rod extends out of the inner side of the inner screw thread
   cylinder, rear end of the outer surface of the integrating main body is
   provided with a hanging structure. The utility model claims a based on
   large data of data collecting system, is provided with supporting
   structure, convenient placed on the wet ground, convenient use, through
   provided with a hanging structure, the movable plate is pulled to the
   back, and it is convenient to be hung using, more flexible and
   comprehensive.
Z9 0
UT DIIDW:202043380S
ER

PT P
AU CHU L
TI Cardiovascular department detector stabilizing mechanism, has fixing
   plate whose bottom part is extended to outer side of detector, and plate
   whose inner side is provided with roller, where top part of roller is
   fixedly connected with bottom part of detector
PN CN210494049-U
AE CHU L
AB 
   NOVELTY - The utility model claims a detecting instrument for
   cardiovascular department stable mechanism, comprising a detecting
   instrument, the front side wall of the detector is fixedly connected
   with a bearing. The utility model is provided with detecting instrument,
   a bearing, a connecting column, a small gear, a transmission gear, a
   locating plate, a big gear, a power gear, a movable plate, a sliding
   sleeve, a sliding rod, a fixing plate, a clamping plate and a roller,
   solves the problem that the cardiovascular detection instrument in order
   to conveniently move. Most of bottom of the cardiovascular detection
   instrument is set with idler wheel, and the idler wheel although
   convenient for the mobile, but also reduces the stability of the
   cardiovascular detector to make it in the using process, easy to shake,
   so that the doctor cannot observe all kinds of data problem
   cardiovascular detector collection. the cardiovascular medical detecting
   instrument stabilizing mechanism, which can fix the roller, increases
   cardiovascular detector stability, improves the practicability of the
   cardiovascular detection instrument, which is convenient for user to
   use.
Z9 0
UT DIIDW:202043200U
ER

PT P
AU FU J
   XU X
   CAI C
   FU Y
TI Big data operating platform device, has transmission rod whose right end
   extends to right side of bearing through bearing, where outer surface of
   transmission rod is fixedly connected with fan that is arranged with
   equal distance
PN CN210515123-U
AE UNIV JIANGSU
AB 
   NOVELTY - The utility model claims a new-type big data operating
   platform device, comprising a box body, the inner wall of the box body
   is fixedly connected with a processor, the upper surface of the
   processor is fixedly connected with a hard disc, the left side of the
   box body is fixedly embedded with data transmission hole, the right end
   of data transmission hole is fixedly connected with the left side of the
   processor; the inner wall of the box body is fixedly connected with a
   clapboard. The new big data operating platform device, blocking the dust
   through a first filter, to avoid short circuit of the circuit caused by
   dust occurs, the air through the refrigerating plate for refrigeration
   and realize the air cooling, the second filter screen for filtering the
   water in the air, avoids the short circuit phenomenon occurs by the
   processor, through the guide plate, a guide pipe and a guide groove is
   discharged cold air to cool the hard disk and processor, is electrified
   to display through the indication lamp to realize the processing device
   heat dispersion, avoid the processor temperature is too high, resulting
   in data operation.
Z9 0
UT DIIDW:202043341X
ER

PT P
AU GAO R
   LEI W
TI Agricultural greenhouse remote monitoring system, has environment
   monitoring module provided with microcontroller, where signal input end
   of microcontroller is connected with temperature sensor for collecting
   temperature data in agricultural greenhouse
PN CN210491904-U
AE UNIV YANAN
AB 
   NOVELTY - The utility model claims a remote monitoring system for
   agricultural greenhouse, comprising a remote terminal, an environment
   monitoring module and a water supply pipe network, a water supply pipe
   network comprises a primary high pressure water branch pipe and a
   secondary high pressure branch, the upper surface of the second-stage
   high pressure water branch pipe is provided with a plurality of short
   pipe, short pipe is installed with a micro-nozzle extends out of the
   ground, the micro-spray head is provided with a protective cover matched
   with the secondary high-voltage branch, the protective cover is composed
   of a top plate, a first side plate and a second side plate, the second
   side plate is provided with a semicircular groove; agricultural
   greenhouse comprises installing the vertical support rod of a
   deformation detector, connected with the transverse connecting rod,
   arc-shaped connecting rod and a transverse tension rod. In the utility
   model, the water supply pipe net is arranged under the ground of
   agricultural greenhouse and save agricultural big shed in upper space,
   reduce agricultural big shed load, agricultural greenhouse deformation,
   safe and reliable monitoring, for each micro-nozzle is equipped with a
   protective cover, avoid plugging damage of micro-spray head when it does
   not work, the soil caused by the micro-spray head, and the installation
   is simple.
Z9 0
UT DIIDW:202042729N
ER

PT P
AU HUANG H
   TANG Y
   JIANG Y
   HOU J
   HUANG G
   PENG S
   CAI X
   ZHANG Z
   MO W
   PAN X
   WANG G
   YANG Y
   LI M
   YANG L
   LIN H
   ZHUGE L
   HOU R
   LI K
TI Large data safety collecting and transmitting system, has data memory
   connected with centralized data transmission device, and first identity
   authentication device connected with second identity authentication
   device
PN CN210515640-U
AE GUANGXI POWER GRID CO LTD; UNIV NORTH CHINA ELECTRIC POWER
AB 
   NOVELTY - The utility model claims a safe collection and transmission
   system of big data, comprising a plurality of data collecting device and
   a data collection device, the data collecting device comprises data
   collecting unit, data encryption device, encryption data transmission
   device; the first identity authentication device, a first safety
   protection device; said data collecting device comprises a second
   identity authentication device, second safety protection device, data
   collecting device and data processing device, a data memory, a
   centralized data transmission device; each of the first identity
   authentication device is respectively connected with the second identity
   authentication device, each of the encryption data transmission device
   is respectively connected with the data collecting device. large data
   collection and transmission function of trusted, complete, no tampering,
   realize safe data of this utility model through identity authentication
   technology, data encryption techniques to ensure the collected.
Z9 0
UT DIIDW:2020433321
ER

PT P
AU MEHTA V J
   MAHALINGAM S S
   VANDER BROEK P J
TI Method for analyzing dataset, involves receiving request to include new
   transformation in transformation script responsive to presenting
   statistical information describing rows of transformed sample that are
   impacted by new transformation
PN US10650020-B1
AE TRIFACTA INC
AB 
   NOVELTY - The method involves presenting the statistical information
   describing rows of the transformed sample that are impacted by the new
   transformation operation. The sample such that the transformed sample is
   updated after applying the transformation script has the threshold
   number of rows impacted by the new transformation operation responsive
   to the statistical information indicating that the number of rows of the
   transformed sample impacted by the new transformation operation does not
   exceed a threshold number. A request is received to include the new
   transformation in the transformation script responsive to presenting the
   statistical information describing rows of the transformed sample that
   are impacted by the new transformation. The new transformation operation
   is added to the transformation script responsive to the request to
   generate an updated transformation script.
   USE - Method for analyzing dataset for analyzing transformations for
   developing transformation scripts for preprocessing data.
   ADVANTAGE - The data preprocessing system presents users with samples of
   data sets and provides the user interface for analyzing the data by
   providing information describing impact of the new transformation
   operation on the dataset.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are included for the
   following:(1) a non-transitory computer readable storage medium storing
   program for analyzing dataset; and(2) a computer-system for analyzing
   dataset.
   DESCRIPTION Of DRAWING(S) - The drawing shows the overall system
   environment for performing big data analysis.Data preprocessing system
   (100)Big data (110)Computer systems (120a-120d)Big data analysis system
   (130)
Z9 0
UT DIIDW:202039425R
ER

PT P
AU WU Y
TI Computer big data server device, has right column whose top end is
   equipped with bracket that is formed as crossed structure, and fan blade
   connected with casing, where side wall of casing is provided with
   multiple fan blades
PN CN210515201-U
AE SHENZHEN QIANHAI KUAHAIXIA CROSS BORDER
AB 
   NOVELTY - The utility model claims a computer big data server device,
   comprising fan blades, a fan cover, a supporting seat, four corners at
   the upper end of the support seat are provided with a right column,
   inner side of the right column is provided with multiple supporting
   plates; four corners of the lower end of the supporting seat are
   equipped with damping, the periphery of the damping column is provided
   with a spring, the lower end of the damping column is provided with a
   universal wheel and the right column and the supporting seat is fixed
   with a corner block, between the adjacent right column is fixedly
   connected with a supporting rod, the top end of the right column is
   equipped with a bracket; is the upper end of the crossed structure, the
   bracket is provided with a motor bracket, the shaft end is equipped with
   a gear; the gear is meshed with the tooth, the tooth is provided with a
   plurality of fan blades, the end connected with the casing of the fan,
   side wall of the fan cover is provided with multiple fan blades, a
   spiral wind fan and fan blade of this utility model through the barrel
   device produces an upward movement, through the heat wind discharged
   upward, covering a wide cooling area, improve the temperature reducing
   effect.
Z9 0
UT DIIDW:202043340A
ER

PT J
AU Andreassen, Anders
   Nachman, Benjamin
TI Neural networks for full phase-space reweighting and parameter tuning
SO PHYSICAL REVIEW D
VL 101
IS 9
AR 091901
DI 10.1103/PhysRevD.101.091901
PD MAY 12 2020
PY 2020
AB Precise scientific analysis in collider-based particle physics is
   possible because of complex simulations that connect fundamental
   theories to observable quantities. The significant computational cost of
   these programs limits the scope, precision, and accuracy of Standard
   Model measurements and searches for new phenomena. We therefore
   introduce Deep neural networks using Classification for Tuning and
   Reweighting (DCTR), a neural network-based approach to reweight and fit
   simulations using all kinematic and flavor information-the full phase
   space. DCTR can perform tasks that are currently not possible with
   existing methods, such as implementing uncertainties on nonperturbative
   models without rerunning the simulation. The core idea behind the new
   approach is to exploit powerful high-dimensional classifiers to reweight
   phase space as well as to identify the best parameters for describing
   data. Numerical examples from e(+) e(-) -> jets demonstrate the fidelity
   of these methods for simulation parameters that have a big and broad
   impact on phase space as well as those that have a minimal and/or
   localized impact. The high fidelity of the full phase-space reweighting
   enables a new paradigm for simulations, parameter tuning, and model
   systematic uncertainties across particle physics and possibly beyond.
Z8 0
ZB 0
ZR 0
TC 0
ZS 0
Z9 0
SN 2470-0010
EI 2470-0029
UT WOS:000531733300002
ER

PT J
AU Teles, Germanno
   Rodrigues, Joel J. P. C.
   Rabelo, Ricardo A. L.
   Kozlov, Sergei A.
TI Comparative study of support vector machines and random forests machine
   learning algorithms on credit operation
SO SOFTWARE-PRACTICE & EXPERIENCE
DI 10.1002/spe.2842
EA MAY 2020
PY 2020
AB Corporate insolvency has significant adverse effects on an economy. With
   the number of multinationals increasing rapidly, corporate bankruptcy
   can severely disrupt the global financial environment. However,
   multinationals do not fail instantaneously; objective strategies
   combined with a rigorous analysis of both qualitative and quantifiable
   data can go a long way in identifying an organization's financial risks.
   Recent advancements in information and communication technologies have
   made data collection and storage an easy task. The challenge becomes
   mining the appropriate data about a company's financial risks and
   implementing it in forecasting a company's insolvency probabilities. In
   recent years, machine learning has been incorporated into big data
   analytics owing to its massive success in learning complex models.
   Machine learning algorithms such as Support Vector Machines (SVM),
   Random Forests (RF), Artificial Neural Networks, Gaussian Processes, and
   Adaptive Learning have been used in the analysis of Big Data to predict
   the financial risks of companies. In this paper, credit scoring is
   explored with regards to data processed using the collateral as an
   independent variable. The obtained results indicate that RF algorithm is
   promising for use in credit risk management. This research shows the
   advantages of the RF approach over the SVM algorithm are its speed and
   operational simplicity, and SVM has the benefit of higher classification
   accuracy than RF. The paper compares the SVM and RF algorithms to
   forecast the recovered value in a credit task. The execution of the
   projected intelligent systems uses tests and algorithms for
   authentication of the projected model.
OI Rodrigues, Joel/0000-0001-8657-3800
Z8 0
TC 0
ZR 0
ZS 0
ZB 0
Z9 0
SN 0038-0644
EI 1097-024X
UT WOS:000531725300001
ER

PT J
AU Trovato, Guglielmo M
TI Non-alcoholic fatty liver disease and Atherosclerosis at a crossroad:
   The overlap of a theory of change and bioinformatics.
SO World journal of gastrointestinal pathophysiology
VL 11
IS 3
BP 57
EP 63
DI 10.4291/wjgp.v11.i3.57
PD 2020-May-12
PY 2020
AB Atherosclerosis (ATH) and non-alcoholic fatty liver disease (NAFLD) are
   medical conditions that straddle a communal epidemiology, underlying
   mechanism and a clinical syndrome that has protean manifestations,
   touching every organ in the body. These twin partners, ATH and NAFLD,
   are seemingly straightforward and relatively simple topics when
   considered alone, but their interdependence calls for more thought. The
   study of the mutual relationship of NAFLD and ATH should involve big
   data analytics approaches, given that they encompass a constellation of
   diseases and are related to several recognized risk factors and health
   determinants and calls to an explicit theory of change, to justify
   intervention. Research studies on the "association between aortic
   stiffness and liver steatosis in morbidly obese patients", published
   recently, sparsely hypothesize new mechanisms of disease, claiming the
   "long shadow of NAFLD" as a risk factor, if not as a causative factor of
   arterial stiffness and ATH. This statement is probably overreaching the
   argument and harmful for the scientific credence of this area of
   medicine. Despite the verification that NAFLD and cardiovascular disease
   are strongly interrelated, current evidence is that NAFLD may be a
   useful indicator for flagging early arteriosclerosis, and not a likely
   causative factor. Greater sustainable contribution by precision medicine
   tools, by validated bioinformatics approaches, is needed for
   substantiating conjectures, assumptions and inferences related to the
   management of big data and addressed to intervention for behavioral
   changes within an explicit theory of change.
ZB 0
TC 0
ZR 0
Z8 0
ZS 0
Z9 0
SN 2150-5330
UT MEDLINE:32435522
PM 32435522
ER

PT J
AU Li, Hui-Ping
   Wickham, Jacob D
   Bushley, Kathryn
   Wang, Zhi-Gang
   Zhang, Bin
   Sun, Jiang-Hua
TI New Approaches in Urban Forestry to Minimize Invasive Species Impacts:
   The Case of Xiongan New Area in China.
SO Insects
VL 11
IS 5
DI 10.3390/insects11050300
PD 2020 May 12
PY 2020
AB China is implementing an extensive urban forestry plan in Xiongan New
   Area (XNA), a new city in Hebei province. The city has been designated
   to serve Beijing's noncapital functions and promote the integration of
   the broader Beijing-Tianjin-Hebei city-region. As part of a green
   initiative to minimize environmental impacts and its carbon footprint, a
   massive urban forestry system has been planned on an unprecedented
   scale, expected to cover over 600 km2 by 2030. Using science to inform
   policy, one major goal is to simultaneously minimize impacts of invasive
   species, while making urban forests more resilient to potential invasive
   species threats. In this review, we introduce these urban forestry plans
   such as basic concepts and principles for afforestation, tree species to
   be planted, delineation of existing pests already established, and
   expected forest invasive species of concern threatening the new area.
   Finally, we introduce a framework for invasive pest management
   strategies in XNA based on a "big data" approach and decision system to
   minimize impacts of invasive species. This new approach to urban
   forestry has the potential to become an exemplary global model for urban
   forestry planning, one that integrates research activities focused on
   forest health surveys and monitoring with sustainable forestry
   management. Finally, we provide an overview of the forest health policy
   required for the design of an unprecedentedly large new urban forest
   from initial planning to full implementation of an integrated forest
   management program.
Z8 0
ZB 0
ZS 0
ZR 0
TC 0
Z9 0
SN 2075-4450
UT MEDLINE:32408656
PM 32408656
ER

PT J
AU Tragomalou, Athanasia
   Moschonis, George
   Manios, Yannis
   Kassari, Penio
   Ioakimidis, Ioannis
   Diou, Christos
   Stefanopoulos, Leandros
   Lekka, Eirini
   Maglaveras, Nicos
   Delopoulos, Anastasios
   Charmandari, Evangelia
TI Novel e-Health Applications for the Management of Cardiometabolic Risk
   Factors in Children and Adolescents in Greece.
SO Nutrients
VL 12
IS 5
DI 10.3390/nu12051380
PD 2020 May 12
PY 2020
AB Obesity in childhood and adolescence represents a major health problem.
   Novel e-Health technologies have been developed in order to provide a
   comprehensive and personalized plan of action for the prevention and
   management of overweight and obesity in childhood and adolescence. We
   used information and communication technologies to develop a "National
   Registry for the Prevention and Management of Overweight and Obesity" in
   order to register online children and adolescents nationwide, and to
   guide pediatricians and general practitioners regarding the management
   of overweight or obese subjects. Furthermore, intelligent multi-level
   information systems and specialized artificial intelligence algorithms
   are being developed with a view to offering precision and personalized
   medical management to obese or overweight subjects. Moreover, the Big
   Data against Childhood Obesity platform records behavioral data
   objectively by using inertial sensors and Global Positioning System
   (GPS) and combines them with data of the environment, in order to assess
   the full contextual framework that is associated with increased body
   mass index (BMI). Finally, a computerized decision-support tool was
   developed to assist pediatric health care professionals in delivering
   personalized nutrition and lifestyle optimization advice to overweight
   or obese children and their families. These e-Health applications are
   expected to play an important role in the management of overweight and
   obesity in childhood and adolescence.
ZR 0
ZS 0
Z8 0
ZB 0
TC 0
Z9 0
EI 2072-6643
UT MEDLINE:32408523
PM 32408523
ER

PT J
AU Jafari Dehkordi, M.
   Sadeghiyan, B.
TI Reconstruction of C&C channel for P2P botnet
SO IET Communications
VL 14
IS 8
BP 1318
EP 26
DI 10.1049/iet-com.2018.5286
PD 12 May 2020
PY 2020
AB Breaking down botnets has always been a big challenge. The robustness of
   command and control (C&C) channels is increased, and the detection of
   botmaster is harder in peer-to-peer (P2P) botnets. In this study, the
   authors proposed a probabilistic method to reconstruct the topologies of
   the C&C channel for P2P botnets. Due to the geographic dispersion of P2P
   botnet members, it is not possible to supervise all members, and there
   does not exist all necessary data for applying other graph
   reconstruction methods. So far, no general method has been introduced to
   reconstruct C&C channel topology for all type of P2P botnet. In their
   method, the probability of connections between bots is estimated by
   using the inaccurate receiving times of several cascades, network model
   parameters of C&C channel, and end-to-end delay distribution of the
   Internet. The receiving times can be collected by observing the external
   reaction of bots to commands. The results of their simulations show that
   more than 90% of the edges in a 1000-member network with node degree
   mean 50, have been accurately estimated by collecting the inaccurate
   receiving times of 22 cascades. In case the receiving times of just half
   of the bots are collected, this accuracy of estimation is obtained by
   using 95 cascades.
Z8 0
ZS 0
ZB 0
ZR 0
TC 0
Z9 0
SN 1751-8628
UT INSPEC:19527342
ER

PT J
AU Munir, Rana Faisal
   Abello, Alberto
   Romero, Oscar
   Thiele, Maik
   Lehner, Wolfgang
TI Configuring Parallelism for Hybrid Layouts Using Multi-Objective
   Optimization.
SO Big data
DI 10.1089/big.2019.0068
PD 2020-May-12
PY 2020
AB Modern organizations typically store their data in a raw format in data
   lakes. These data are then processed and usually stored under hybrid
   layouts, because they allow projection and selection operations. Thus,
   they allow (when required) to read less data from the disk. However,
   this is not very well exploited by distributed processing frameworks
   (e.g., Hadoop, Spark) when analytical queries are posed. These
   frameworks divide the data into multiple partitions and then process
   each partition in a separate task, consequently creating tasks based on
   the total file size and not the actual size of the data to be read. This
   typically leads to launching more tasks than needed, which, in turn,
   increases the query execution time and induces significant waste of
   computing resources. To allow a more efficient use of resources and
   reduce the query execution time, we propose a method that decides the
   number of tasks based on the data being read. To this end, we first
   propose a cost-based model for estimating the size of data read in
   hybrid layouts. Next, we use the estimated reading size in a
   multi-objective optimization method to decide the number of tasks and
   computational resources to be used. We prototyped our solution for
   Apache Parquet and Spark and found that our estimations are highly
   correlated (0.96) with the real executions. Further, using TPC-H we show
   that our recommended configurations are only 5.6% away from the Pareto
   front and provide 2.1*speedup compared with default solutions.
ZB 0
TC 0
ZR 0
Z8 0
ZS 0
Z9 0
EI 2167-647X
UT MEDLINE:32397735
PM 32397735
ER

PT J
AU Woon, Luke Sy-Cherng
   Sidi, Hatta Bin
   Ravindran, Arun
   Gosse, Paula Junggar
   Mainland, Roslyn Laurie
   Kaunismaa, Emily Samantha
   Hatta, Nurul Hazwani
   Arnawati, Puteri
   Zulkifli, Amelia Yasmin
   Mustafa, Norlaila
   Leong Bin Abdullah, Mohammad Farris Iman
TI Depression, anxiety, and associated factors in patients with diabetes:
   evidence from the anxiety, depression, and personality traits in
   diabetes mellitus (ADAPT-DM) study.
SO BMC psychiatry
VL 20
IS 1
BP 227
EP 227
DI 10.1186/s12888-020-02615-y
PD 2020 May 12
PY 2020
AB BACKGROUND: Depression and anxiety are common psychiatric complications
   affecting patients with diabetes mellitus. However, data on the
   prevalence of depression, anxiety, and associated factors among
   Malaysian diabetic patients is scarce. The Anxiety, Depression, and
   Personality Traits in Diabetes Mellitus (ADAPT-DM) study aimed to
   determine the prevalence of depression and anxiety, and their associated
   factors in the Malaysian diabetic population.
   METHODS: This cross-sectional study recruited 300 diabetic patients via
   convenience sampling from the Endocrine outpatient clinic of Universiti
   Kebangsaan Malaysia Medical Centre, a tertiary referral healthcare
   facility in Kuala Lumpur. Socio-demographic characteristics and clinical
   history were obtained from each participant. The Generalised Anxiety
   Disorder-7 (GAD-7) was administered to assess anxiety symptoms, the Beck
   Depression Inventory (BDI) to assess depressive symptoms, the Big Five
   Inventory (BFI) to evaluate personality traits, and the World Health
   Organization Quality of Life-BREF (WHOQOL-BREF) to measure quality of
   life (QOL). Stepwise multiple logistic regression analyses were
   performed to determine the association between various factors, and
   depression and anxiety.
   RESULTS: The prevalence of depression was 20% (n=60) while anxiety was
   9% (n=27). Co-morbid depression (adjusted odds ratio [OR]=9.89, 95%
   confidence interval [CI]=2.63-37.14, p=0.001) and neuroticism (adjusted
   OR=11.66, 95% CI=2.69-50.47, p=0.001) increased the odds of developing
   anxiety, while conscientiousness (adjusted OR=0.45, 95% CI=0.23-0.80,
   p=0.004) and greater psychological-related QOL (adjusted OR=0.47, 95%
   CI=0.29-0.75, p=0.002) were protective. Co-morbid anxiety (adjusted
   OR=19.83, 95% CI=5.63-69.92, p<0.001) increased the odds of depression,
   while older age (adjusted OR=0.96, 95% CI=0.93-0.98, p=0.002), social
   relationship-related QOL (adjusted OR=0.84, 95% CI=0.71-.0.99, p=0.047),
   and physical health-related QOL (adjusted OR=0.69, 95% CI=0.58-0.83,
   p<0.001) were protective.
   CONCLUSIONS: The study findings signify the need to screen for co-morbid
   depression and anxiety, as well as personality traits and QOL, and to
   include psychosocial interventions when planning a multidisciplinary
   approach to managing diabetes.
OI Leong Bin Abdullah, Mohammad Farris Iman/0000-0002-7762-4052
ZS 0
ZR 0
ZB 0
TC 0
Z8 0
Z9 0
EI 1471-244X
UT MEDLINE:32397976
PM 32397976
ER

PT J
AU Seaby, Eleanor G
   Ennis, Sarah
TI Challenges in the diagnosis and discovery of rare genetic disorders
   using contemporary sequencing technologies.
SO Briefings in functional genomics
DI 10.1093/bfgp/elaa009
PD 2020-May-12
PY 2020
AB Next generation sequencing (NGS) has revolutionised rare disease
   diagnostics. Concomitant with advancing technologies has been a rise in
   the number of new gene disorders discovered and diagnoses made for
   patients and their families. However, despite the trend towards whole
   exome and whole genome sequencing, diagnostic rates remain suboptimal.
   On average, only ~30% of patients receive a molecular diagnosis.
   National sequencing projects launched in the last 5 years are
   integrating clinical diagnostic testing with research avenues to widen
   the spectrum of known genetic disorders. Consequently, efforts to
   diagnose genetic disorders in a clinical setting are now often shared
   with efforts to prioritise candidate variants for the detection of new
   disease genes. Herein we discuss some of the biggest obstacles
   precluding molecular diagnosis and discovery of new gene disorders. We
   consider bioinformatic and analytical challenges faced when interpreting
   next generation sequencing data and showcase some of the newest tools
   available to mitigate these issues. We consider how incomplete
   penetrance, non-coding variation and structural variants are likely to
   impact diagnostic rates, and we further discuss methods for uplifting
   novel gene discovery by adopting a gene-to-patient-based approach.
ZR 0
Z8 0
ZB 0
ZS 0
TC 0
Z9 0
EI 2041-2657
UT MEDLINE:32393978
PM 32393978
ER

PT J
AU Wan, Xing
   Wang, Nianxin
   Liu, Ben Shaw-Ching
TI Impact of O2O platform multihoming and vertical integration on
   performance of local service firms - a quantile regression approach
SO INTERNET RESEARCH
DI 10.1108/INTR-03-2019-0087
EA MAY 2020
PY 2020
AB Purpose This study takes the cinema industry as the research context and
   investigates the impact of online to offline (O2O) platforms on cinemas'
   performance. Specifically, the purposes of this paper are threefold:
   first, to study the influence of platform multihoming on cinemas'
   performance; second, to examine the interaction impact of platform
   multihoming and vertical integration; third, to investigate how the
   influence of platform multihoming varies with cinemas' performance.
   Design/methodology/approach This study collects data from 1918 cinemas
   in China, employs quantile regressions to estimate the model and test
   the proposed hypotheses and adopts an instrumental variable method to
   examine the robustness of our results. Findings The findings confirm the
   positive role of platform multihoming for cinemas' performance. However,
   when a cinema has low-degree platform multihoming, the cinema's vertical
   integration is positively associated with its performance; when a cinema
   has high-degree platform multihoming, the cinema's vertical integration
   is negatively associated with its performance. Furthermore, results from
   quantile regressions indicate that low-performance cinemas benefit more
   than high-performance cinemas from employing platform multihoming
   strategy. Research limitations/implications This paper extends previous
   research by investigating the impact of platform multihoming on
   heterogeneous firms and the impact of interaction between platform
   multihoming and vertical integration. The findings imply that the impact
   of platform multihoming on firms' performance depends on firms'
   performance attributes and their vertical relationships. Practical
   implications Platform multihoming can be a double-edged sword for local
   service firms. When multihoming platforms, a local service firm should
   think about the fit between platforms and its own attributes, and
   identify the potential conflict between platform relationships and
   traditional relationships of industrial organization. Originality/value
   There is a growing interest in understanding platforms' role in the
   digital economy. The impact of platform participation on local service
   firms' performance is not sufficiently investigated. Previous research
   rarely addressed the impact by incorporating local service firms'
   performance attributes and the existing relationships of industrial
   organization.
TC 0
ZR 0
ZS 0
Z8 0
ZB 0
Z9 0
SN 1066-2243
UT WOS:000532301700001
ER

PT J
AU Adi, Erwin
   Anwar, Adnan
   Baig, Zubair
   Zeadally, Sherali
TI Machine learning and data analytics for the IoT
SO NEURAL COMPUTING & APPLICATIONS
DI 10.1007/s00521-020-04874-y
EA MAY 2020
PY 2020
AB The Internet of Things (IoT) applications have grown in exorbitant
   numbers, generating a large amount of data required for intelligent data
   processing. However, the varying IoT infrastructures (i.e., cloud, edge,
   fog) and the limitations of the IoT application layer protocols in
   transmitting/receiving messages become the barriers in creating
   intelligent IoT applications. These barriers prevent current intelligent
   IoT applications to adaptively learn from other IoT applications. In
   this paper, we critically review how IoT-generated data are processed
   for machine learning analysis and highlight the current challenges in
   furthering intelligent solutions in the IoT environment. Furthermore, we
   propose a framework to enable IoT applications to adaptively learn from
   other IoT applications and present a case study in how the framework can
   be applied to the real studies in the literature. Finally, we discuss
   the key factors that have an impact on future intelligent applications
   for the IoT.
ZR 0
Z8 0
TC 0
ZB 0
ZS 0
Z9 0
SN 0941-0643
EI 1433-3058
UT WOS:000531801300002
ER

PT J
AU McMahon, Peter B
   Brown, Craig J
   Johnson, Tyler D
   Belitz, Kenneth
   Lindsey, Bruce D
TI Fluoride occurrence in United States groundwater.
SO The Science of the total environment
VL 732
BP 139217
EP 139217
DI 10.1016/j.scitotenv.2020.139217
PD 2020-May-11
PY 2020
AB Data from 38,105 wells were used to characterize fluoride (F) occurrence
   in untreated United States (U.S.) groundwater. For domestic wells
   (n=11,032), water from which is generally not purposely fluoridated or
   monitored for quality, 10.9% of the samples have F concentrations
   >0.7mg/L (U.S. Public Health Service recommended optimal F concentration
   in drinking water for preventing tooth decay) (87% are <0.7mg/L); 2.6%
   have F>2mg/L (EPA Secondary Maximum Contaminant Level, SMCL); and 0.6%
   have F>4mg/L (EPA MCL). The data indicate the biggest concern with F in
   domestic wells at the national scale could be one of under consumption
   of F with respect to the oral-health benchmark (0.7mg/L). Elevated F
   concentrations relative to the SMCL and MCL are regionally important,
   particularly in the western U.S. Statistical comparisons of potentially
   important controlling factors in four F-concentration categories
   (<0.1-0.7mg/L; >0.7-2mg/L; >2-4mg/L; >4mg/L) at the national scale
   indicate the highest F-concentration category is associated with
   groundwater that has significantly greater pH values, TDS and alkalinity
   concentrations, and well depths, and lower Ca/Na ratios and mean annual
   precipitation, than the lowest F-concentration category. The relative
   importance of the controlling factors appears to be regionally variable.
   Three case studies illustrate the spatial variability in controlling
   factors using groundwater-age (groundwater residence time),
   water-isotope (evaporative concentration), and water-temperature
   (geothermal processes) data. Populations potentially served by domestic
   wells with F concentrations <0.7, >0.7, >2, and >4mg/L are estimated to
   be ~28,200,000, ~3,110,000; ~522,000; and ~172,000 people, respectively,
   in 40 principal aquifers with at least 25F analyses per aquifer.
Z8 0
ZS 0
ZR 0
TC 0
ZB 0
Z9 0
EI 1879-1026
UT MEDLINE:32438175
PM 32438175
ER

PT J
AU Kinra, Aseem
   Hald, Kim Sundtoft
   Mukkamala, Raghava Rao
   Vatrapu, Ravi
TI An unstructured big data approach for country logistics performance
   assessment in global supply chains
SO INTERNATIONAL JOURNAL OF OPERATIONS & PRODUCTION MANAGEMENT
DI 10.1108/IJOPM-07-2019-0544
EA MAY 2020
PY 2020
AB Purpose The purpose of this study is to explore the potential for the
   development of a country logistics performance assessment approach based
   upon textual big data analytics. Design/methodology/approach The study
   employs design science principles. Data were collected using the Global
   Perspectives text corpus that describes the logistics systems of 20
   countries from 2006-2014. The extracted texts were processed and
   analysed using text analytic techniques, and domain experts were
   employed for training and developing the approach. Findings The
   developed approach is able to generate results in the form of logistics
   performance assessments. It contributes towards the development of more
   informed weights of the different country logistics performance
   categories. That said, a larger text corpus and iterative classifier
   training is required to produce a more robust approach for benchmarking
   and ranking. Practical implications When successfully developed and
   implemented, the developed approach can be used by managers and
   government bodies, such as the World Bank and its stakeholders, to
   complement the Logistics Performance Index (LPI). Originality/value A
   new and unconventional approach for logistics system performance
   assessment is explored. A new potential for textual big data analytic
   applications in supply chain management is demonstrated. A contribution
   to performance management in operations and supply chain management is
   made by demonstrating how domain-specific text corpora can be
   transformed into an important source of performance information.
OI Kinra, Aseem/0000-0003-0157-3735
ZB 0
ZR 0
Z8 0
TC 0
ZS 0
Z9 0
SN 0144-3577
EI 1758-6593
UT WOS:000531841800001
ER

PT J
AU Bu, Daniel D.
   Liu, Shelley H.
   Liu, Bian
   Li, Yan
TI Achieving Value in Population Health Big Data
SO JOURNAL OF GENERAL INTERNAL MEDICINE
DI 10.1007/s11606-020-05869-0
EA MAY 2020
PY 2020
AB Several population health big data projects have been initiated in the
   USA recently. These include the County Health Rankings & Roadmaps (CHR)
   initiated in 2010, the 500 Cities Project initiated in 2016, and the
   City Health Dashboard project initiated in 2017. Such projects provide
   data on a range of factors that determine health-such as socioeconomic
   factors, behavioral factors, health care access, and environmental
   factors-either at the county or city level. They provided
   state-of-the-art data visualization and interaction tools so that
   clinicians, public health practitioners, and policymakers can easily
   understand population health data at the local level. However, these
   recent initiatives were all built from data collected using
   long-standing and extant public health surveillance systems from
   organizations such as the Centers for Disease Control and Prevention and
   the U.S. Census Bureau. This resulted in a large extent of similarity
   among different datasets and a potential waste of resources. This
   perspective article aims to elaborate on the diminishing returns of
   creating more population health datasets and propose potential ways to
   integrate with clinical care and research, driving insights
   bidirectionally, and utilizing advanced analytical tools to improve
   value in population health big data.
OI Li, Yan/0000-0001-6155-0389
ZS 0
ZR 0
ZB 0
Z8 0
TC 0
Z9 0
SN 0884-8734
EI 1525-1497
UT WOS:000531793200002
PM 32394140
ER

PT J
AU Jin, Shiqiang
   Goh, Gyuhyeong
TI Bayesian selection of best subsets via hybrid search
SO COMPUTATIONAL STATISTICS
DI 10.1007/s00180-020-00996-y
EA MAY 2020
PY 2020
AB Over the past decades, variable selection for high-dimensional data has
   drawn increasing attention. With a large number of predictors, there
   rises a big challenge for model fitting and prediction. In this paper,
   we develop a new Bayesian method of best subset selection using a hybrid
   search algorithm that combines a deterministic local search and a
   stochastic global search. To reduce the computational cost of evaluating
   multiple candidate subsets for each update, we propose a novel strategy
   that enables us to calculate exact marginal likelihoods of all neighbor
   models simultaneously in a single computation. In addition, we establish
   model selection consistency for the proposed method in the
   high-dimensional setting in which the number of possible predictors can
   increase faster than the sample size. Simulation study and real data
   analysis are conducted to investigate the performance of the proposed
   method.
OI Goh, Gyuhyeong/0000-0002-1685-3927
Z8 0
ZB 0
ZR 0
ZS 0
TC 0
Z9 0
SN 0943-4062
EI 1613-9658
UT WOS:000531789600001
ER

PT J
AU Garg, Pardeep
   Sharma, Sunildatt
TI Identification of CpG Islands in DNA Sequences Using Short-Time Fourier
   Transform
SO INTERDISCIPLINARY SCIENCES-COMPUTATIONAL LIFE SCIENCES
DI 10.1007/s12539-020-00370-y
EA MAY 2020
PY 2020
AB In the era of big data analysis, genomics data analysis is highly needed
   to extract the hidden information present in the DNA sequences. One of
   the important hidden features present in the DNA sequences is CpG
   islands. CpG Islands are important as these are used as gene markers and
   also these are associated with cancer etc. Therefore, various methods
   have been reported for the identification of CpG islands in DNA
   sequences. The key contributions of this work are (i) extraction of the
   periodicity feature associated with CpG islands using Short-time Fourier
   transform (ii) a short-time Fourier transform-based algorithm has been
   proposed for the identification of CpG Islands in DNA sequences. The
   results of the proposed algorithm amply demonstrate its better
   performance as compared to other reported methods on CpG islands
   detection.
ZR 0
ZB 0
Z8 0
ZS 0
TC 0
Z9 0
SN 1913-2751
EI 1867-1462
UT WOS:000531739900002
PM 32394270
ER

PT J
AU Ding, Weilong
   Xia, Yanqing
   Wang, Zhe
   Chen, Zhenyu
   Gao, Xingyu
TI An ensemble-learning method for potential traffic hotspots detection on
   heterogeneous spatio-temporal data in highway domain
SO JOURNAL OF CLOUD COMPUTING-ADVANCES SYSTEMS AND APPLICATIONS
VL 9
IS 1
AR 25
DI 10.1186/s13677-020-00170-1
PD MAY 11 2020
PY 2020
AB Inter-city highway plays an important role in modern urban life and
   generates sensory data with spatio-temporal characteristics. Its current
   situation and future trends are valuable for vehicles guidance and
   transportation security management. As a domain routine analysis, daily
   detection of traffic hotspots faces challenges in efficiency and
   precision, because huge data deteriorates processing latency and many
   correlative factors cannot be fully considered. In this paper, an
   ensemble-learning based method for potential traffic hotspots detection
   is proposed. Considering time, space, meteorology, and calendar
   conditions, daily traffic volume is modeled on heterogeneous data, and
   trends predictive error can be reduced through gradient boosting
   regression technology. Using real-world data from one Chinese provincial
   highway, extensive experiments and case studies show our methods with
   second-level executive latency with a distinct improvement in predictive
   precision.
ZB 0
ZS 0
ZR 0
TC 0
Z8 0
Z9 0
EI 2192-113X
UT WOS:000531788500001
ER

PT J
AU Maghsoodi, Abtin Ijadi
   Riahi, Dara
   Herrera-Viedma, Enrique
   Zavadskas, Edmundas Kazimieras
TI An integrated parallel big data decision support tool using the
   W-CLUS-MCDA: A multi-scenario personnel assessment
SO KNOWLEDGE-BASED SYSTEMS
VL 195
AR 105749
DI 10.1016/j.knosys.2020.105749
PD MAY 11 2020
PY 2020
AB One of the most primary issues that organizations have to deal with is
   incorporating massive structured data problems, simultaneously.
   Additionally, a vital division in any organization is the department of
   human resources (HR), which is in charge of the recruitment and
   personnel selection procedures. Due to the nature of the personnel
   assessment problems, which include multiple candidates as alternatives
   along with various complex evaluating criteria, these types of problems
   can be tackled by the aid of multi-attribute decision making (MADM)
   techniques. Moreover, in mega-structured organizations, the procedure of
   personnel selection contains massive structures of data due to the
   number of potential candidates for job positions in various
   sub-divisions and departments. Therefore, the personnel selection
   problem in such environments can be subjected as a big data problem
   which should be handled prudently to save time and cost. The main
   objective of the current study is to extend the CLUS-MCDA approach
   (CLUSter analysis for improving Multiple Criteria Decision Analysis) and
   integrate it with the Best-Worst Method (BWM) and a specific structure
   to solve multi-scenario big data decision-making problems. In this
   study, to validate the practicality and reliability of the W-CLUSMCDA
   approach, multiple personnel selection and risk assessment problems have
   been investigated with various scenarios within several departments,
   simultaneously. This study has also introduced the concept of
   multi-scenario parallel decision making (PDM) within the context of MADM
   methodology using a data-driven decision-making approach solving various
   big data problems. (C) 2020 Elsevier B.V. All rights reserved.
RI Maghsoodi, Abtin Ijadi/R-5475-2016
Z8 0
TC 0
ZS 0
ZR 0
ZB 0
Z9 0
SN 0950-7051
EI 1872-7409
UT WOS:000523561500030
ER

PT J
AU Shen, Yanmei
   Zhang, Wenyu
   Chan, Bella Siu Man
   Zhang, Yaru
   Meng, Fanchao
   Kennon, Elizabeth A
   Wu, Hanjing Emily
   Luo, Xuerong
   Zhang, Xiangyang
TI Detecting risk of suicide attempts among Chinese medical college
   students using a machine learning algorithm.
SO Journal of affective disorders
VL 273
BP 18
EP 23
DI 10.1016/j.jad.2020.04.057
PD 2020-May-11
PY 2020
AB BACKGROUND: Suicide has become one of the most prominent concerns for
   public health and wellness; however, detecting suicide risk factors
   among individuals remains a big challenge. The aim of this study was to
   develop a machine learning algorithm that could effectively and
   accurately identify the probability of suicide attempts in medical
   college students.
   METHODS: A total of 4,882 medical students were enrolled in this
   cross-sectional study. Self-report data on socio-demographic and
   clinical characteristics were collected online via website or through
   the widely used social media app, WeChat. 5-fold cross validation was
   used to build a random forest model with 37 suicide attempt predictors.
   Model performance was measured for sensitivity, specificity, area under
   the curve (AUC), and accuracy. All analyses were conducted in MATLAB.
   RESULTS: The random forest model achieved good performance [area under
   the curve (AUC)=0.9255] in predicting suicide attempts with an accuracy
   of 90.1% (SD=0.67%), sensitivity of 73.51% (SD=2.33%) and specificity of
   91.68% (SD=0.82%).
   LIMITATION: The participants are primarily females and medical students.
   CONCLUSIONS: This study demonstrates that the random forest model has
   the potential to predict suicide attempts among medical college students
   with high accuracy. Our findings suggest that application of the machine
   learning model may assist in improving the efficiency of suicide
   prevention.
ZS 0
ZB 0
Z8 0
ZR 0
TC 0
Z9 0
EI 1573-2517
UT MEDLINE:32421600
PM 32421600
ER

PT J
AU Awadallah, Abdelmoneim A.
   Elsaid, Haitham M.
TI Investigating the impact of macro-economic changes on auditors'
   assessments of audit risk: a field study
SO JOURNAL OF APPLIED ACCOUNTING RESEARCH
DI 10.1108/JAAR-10-2019-0149
EA MAY 2020
PY 2020
AB Purpose The study aims at examining whether or not poor macro-economic
   conditions can lead auditors to change their risk management policies
   when performing an audit. Design/methodology/approach The present study
   is based on a questionnaire distributed to auditors working at the
   branches of the big four audit firms in Egypt over two rounds under
   different economic conditions. The responses in each of the two rounds
   were analyzed to identify any similarities or differences in auditors'
   behavior when performing analytical procedures under different economic
   conditions. Findings Auditors appear to alter their risk management
   strategies during challenging economic times. The present study results
   suggest that auditors increase their dependence on non-financial data
   and information as supporting evidence when assessing audit risk during
   times of economic difficulties. The findings also show that when the
   macro-economic trends are declining, audit firms tend to assign the
   performance of analytical procedures to more experienced audit personnel
   (i.e. senior auditors, audit managers and partners) with less of this
   work being done by the audit staff. Research limitations/implications
   The present study is based on a sample of 40 respondents. It is
   recommended for future research to use a larger sample size as results
   may differ for a greater sample. The present research did not consider
   the effect of auditors' specialization in a certain industry on the
   audit judgment during an audit engagement. Future research would examine
   the impact of auditors' industry specialization on audit judgments
   during periods of unfavorable economic conditions. The present study is
   based on a survey that aims at capturing auditors' perception. Further
   research would use other research techniques (e.g. laboratory
   experiment) to examine the effect of the general economic conditions on
   auditors' assessment of audit risk. Practical implications Auditors need
   to give sufficient attention to the analyses of non-financial
   information of their audit clients during the performance of the
   analytical procedures under unstable economic conditions rather than
   depending solely on financial information. Moreover, audit firms could
   use a much richer labor mix for audit teams through increasing their
   reliance on experienced senior auditors, audit managers and partners
   during periods of deteriorating macro-economic conditions to mitigate
   risk and improve audit judgment. Originality/value This study adds to
   the scarce literature in developing countries investigating the
   influence of external economic factors on the audit process. The present
   research provides information to practitioners and educators about risk
   management policies that could be considered in case of performing
   analytical procedures during an audit conducted under poor economic
   conditions.
ZS 0
TC 0
ZR 0
ZB 0
Z8 0
Z9 0
SN 0967-5426
EI 1758-8855
UT WOS:000531540300001
ER

PT J
AU Onisai, Minodora
   Dumitru, Adrian
   Iordan, Iuliana
   Aliuș, Catalin
   Teodor, Oana
   Alexandru, Adrian
   Gheorghița, Daniela
   Antoniac, Iulian
   Nica, Adriana
   Mihailescu, Alexandra-Ana
   Gradinaru, Sebastian
TI Synchronous Multiple Breast Cancers-Do We Need to Reshape Staging?
SO Medicina (Kaunas, Lithuania)
VL 56
IS 5
DI 10.3390/medicina56050230
PD 2020 May 11
PY 2020
AB Background and Objectives: Current recommendations and treatment
   regimens in breast cancer are a reflection of its heterogeneity on
   multiple levels including histological subtypes, grading, molecular
   profiling, and numerous prognostic indices. Although based on extensive
   research, current guidelines are not explicit in the case of surgical
   specimens showing various degrees of mismatch between different parts of
   the same tumor and even more so between multicentric lesions.
   Synchronous breast cancer is the ideal prototype for studying inter- and
   intra-tumoral heterogeneity, therefore we envisaged that a study on
   patients with multicentric and multifocal lesions could contribute to
   the reshaping of the staging, prognosis, and treatment of breast
   malignancies. Material and Methods: A prospective observational study
   was conducted between January 2013 and May 2017 on 235 patients
   diagnosed with breast cancer (BC) and surgically treated at Emergency
   University Hospital, Bucharest. Thirty-seven patients had multiple
   breast tumors and were eligible for assessment of the heterogeneity of
   their lesions. Results: 6 were multicentric and 31 multifocal. The
   number of foci varied from 2 to 11. We encountered numerous mismatches
   between the index and the secondary tumors, as follows: 3 cases (8.1%)
   with histopathological mismatch, 13 (35.1%) with different grades of
   differentiation, 11 (29.8%) with ER (Estrogen Receptors) status
   mismatch, 12 (32.4%) with PR (Progesterone Receptors) status mismatch, 8
   (21.6%) with molecular phenotype mismatch, and 17 (45.9%) cases with
   variable Ki-67. After careful analysis of index and secondary tumors,
   apart from the mismatches reported above, we discovered that the
   secondary tumors were actually dominant in 5 cases (13.5%), and
   therefore at least those cases had to be reclassified/restaged, as the
   supplementary data commanded changes in the therapeutic decision.
   Conclusions: For synchronous breast tumors, the current
   Tumor-Node-Metastasis (TNM) staging system ignores not only the
   histopathological and immunohistochemical characteristics of the
   secondary foci, but also their size. When secondary lesions are more
   aggressive or their cumulative mass is significantly bigger than that of
   the index tumor, the treatment plan should be adapted accordingly. We
   believe that information obtained from examining secondary foci in
   synchronous breast cancer and assessment of the cumulative tumoral mass
   should be reflected in the final staging and definitive treatment. The
   clinical benefit of staging the patients based on the most aggressive
   tumor and the cumulative tumoral burden rather than according to the
   biggest single tumor, will avoid under-treatment in cases with
   multifocal/multicentric BC displaying intertumoral mismatch.
Z8 0
TC 0
ZB 0
ZR 0
ZS 0
Z9 0
EI 1648-9144
UT MEDLINE:32403360
PM 32403360
ER

PT J
AU Rizzato, Silvia
   Leo, Angelo
   Monteduro, Anna Grazia
   Chiriaco, Maria Serena
   Primiceri, Elisabetta
   Sirsi, Fausto
   Milone, Angelo
   Maruccio, Giuseppe
TI Advances in the Development of Innovative Sensor Platforms for Field
   Analysis.
SO Micromachines
VL 11
IS 5
DI 10.3390/mi11050491
PD 2020 May 11
PY 2020
AB Sustainable growth, environmental preservation, and improvement of life
   quality are strategic fields of worldwide interest and cornerstones of
   international policies. Humanity health and prosperity are closely
   related to our present choices on sustainable development. The main
   sources of pollution concern industry, including mining, chemical
   companies, and refineries, wastewater treatment; and consumers
   themselves. In order to guide and evaluate the effects of environmental
   policies, diffuse monitoring campaigns and detailed (big) data analyses
   are needed. In this respect, the development and availability of
   innovative sensor platforms for field analysis and remote sensing are of
   crucial relevance. In this review, we provide an overview of the area,
   analyzing the major needs, available technologies, novel approaches, and
   perspectives. Among environmental pollutants that threaten the
   biosphere, we focus on inorganic and organic contaminants, which affect
   air and water quality. We describe the technologies for their assessment
   in the environment and then draw some conclusions and mention future
   perspectives opened by the integration of sensing technologies with
   robotics and the Internet of Things. Without the ambition to be
   exhaustive in such a rapidly growing field, this review is intended as a
   support for researchers and stakeholders looking for current,
   state-of-the-art, and key enabling technologies for environmental
   monitoring.
ZB 0
ZR 0
Z8 0
ZS 0
TC 0
Z9 0
SN 2072-666X
UT MEDLINE:32403362
PM 32403362
ER

PT J
AU Sun, Bo
   Zhang, Yang
   Zhou, Qiming
   Gao, Duo
TI Street-Scale Analysis of Population Exposure to Light Pollution Based on
   Remote Sensing and Mobile Big Data-Shenzhen City as a Case.
SO Sensors (Basel, Switzerland)
VL 20
IS 9
DI 10.3390/s20092728
PD 2020 May 11
PY 2020
AB Most studies on light pollution are based on light intensity retrieved
   from nighttime light (NTL) remote sensing with less consideration of the
   population factors. Furthermore, the coarse spatial resolution of
   traditional NTL remote sensing data limits the refined applications in
   current smart city studies. In order to analyze the influence of light
   pollution on populated areas, this study proposes an index named
   population exposure to light pollution (PELP) and conducts a
   street-scale analysis to illustrate spatial variation of PELP among
   residential areas in cites. By taking Shenzhen city as a case,
   multi-source data were combined including high resolution NTL remote
   sensing data from the Luojia 1-01 satellite sensor, high-precision
   mobile big data for visualizing human activities and population
   distribution as well as point of interest (POI) data. Results show that
   the main influenced areas of light pollution are concentrated in the
   downtown and core areas of newly expanded areas with obvious deviation
   corrected like traditional serious light polluted regions (e.g., ports).
   In comparison, commercial-residential mixed areas and village-in-city
   show a high level of PELP. The proposed method better presents the
   extent of population exposure to light pollution at a fine-grid scale
   and the regional difference between different types of residential areas
   in a city.
RI Zhou, Qiming/N-8735-2016
OI Zhou, Qiming/0000-0003-0934-0602
ZS 0
TC 0
Z8 0
ZB 0
ZR 0
Z9 0
EI 1424-8220
UT MEDLINE:32403250
PM 32403250
ER

PT J
AU Zolfaghari Emameh, Reza
   Kuuslahti, Marianne
   Nosrati, Hassan
   Lohi, Hannes
   Parkkila, Seppo
TI Assessment of databases to determine the validity of beta- and
   gamma-carbonic anhydrase sequences from vertebrates.
SO BMC genomics
VL 21
IS 1
BP 352
EP 352
DI 10.1186/s12864-020-6762-2
PD 2020 May 11
PY 2020
AB BACKGROUND: The inaccuracy of DNA sequence data is becoming a serious
   problem, as the amount of molecular data is multiplying rapidly and
   expectations are high for big data to revolutionize life sciences and
   health care. In this study, we investigated the accuracy of DNA sequence
   data from commonly used databases using carbonic anhydrase (CA) gene
   sequences as generic targets. CAs are ancient metalloenzymes that are
   present in all unicellular and multicellular living organisms. Among the
   eight distinct families of CAs, including alpha, beta, gamma, delta,
   zeta, eta, theta, and iota, only alpha-CAs have been reported in
   vertebrates.
   RESULTS: By an in silico analysis performed on the NCBI and Ensembl
   databases, we identified several beta- and gamma-CA sequences in
   vertebrates, including Homo sapiens, Mus musculus, Felis catus, Lipotes
   vexillifer, Pantholops hodgsonii, Hippocampus comes, Hucho hucho,
   Oncorhynchus tshawytscha, Xenopus tropicalis, and Rhinolophus sinicus.
   Polymerase chain reaction (PCR) analysis of genomic DNA persistently
   failed to amplify positive beta- or gamma-CA gene sequences when Mus
   musculus and Felis catus DNA samples were used as templates. Further
   BLAST homology searches of the database-derived "vertebrate" beta- and
   gamma-CA sequences revealed that the identified sequences were
   presumably derived from gut microbiota, environmental microbiomes, or
   grassland ecosystems.
   CONCLUSIONS: Our results highlight the need for more accurate and fast
   curation systems for DNA databases. The mined data must be carefully
   reconciled with our best knowledge of sequences to improve the accuracy
   of DNA data for publication.
TC 0
ZS 0
Z8 0
ZR 0
ZB 0
Z9 0
EI 1471-2164
UT MEDLINE:32393172
PM 32393172
ER

PT J
AU Muluneh, Chalachew
   Hailu, Tadesse
   Alemu, Getaneh
TI Prevalence and Associated Factors of Soil-Transmitted Helminth
   Infections among Children Living with and without Open Defecation
   Practices in Northwest Ethiopia: A Comparative Cross-Sectional Study.
SO The American journal of tropical medicine and hygiene
DI 10.4269/ajtmh.19-0704
PD 2020-May-11
PY 2020
AB Soil-transmitted helminth (STH) infections cause devastating effect in
   human health. School-age children (SAC) account for the highest
   prevalence of STH infections in sub-Sahara. Open defecation practicing
   might be the major contributing factor, and creating an open
   defecation-free (ODF) declared community is also a big challenge. This
   study aimed to assess the prevalence of STH infections and associated
   factors among SAC in ODF declared and open defecation-practicing
   kebeles. A comparative cross-sectional study was conducted among 806 SAC
   from January 2019 to April 2019. Questionnaire-based data were collected
   using a structured questionnaire. Stool samples were collected and
   processed via the Kato-Katz technique. Prevalence and associated factors
   were computed with descriptive statistics and regression, respectively.
   Variables with a P-value < 0.05 were considered as significantly
   associated. This study revealed that the prevalence of STH infections in
   open defecation-practicing and ODF declared kebeles were 38.9% and
   30.0%, respectively. Wearing open shoes, wearing shoes sometimes, and
   playing with soil were significantly associated (P < 0.01) with STH
   infections in ODF declared kebeles. Similarly, wearing shoes sometimes,
   not using latrine, and playing with soil were also significantly
   associated (P < 0.01) with STH infections in open defection-practicing
   kebeles. In conclusion, lower prevalence of STH infections was recorded
   in ODF declared than in open defection-practicing kebeles. Wearing shoes
   sometimes, playing with soil, and not using latrine were associated with
   STH infections. Therefore, creating an ODF environment and community
   awareness should be strengthened.
Z8 0
ZR 0
TC 0
ZB 0
ZS 0
Z9 0
EI 1476-1645
UT MEDLINE:32394879
PM 32394879
ER

PT J
AU Gao, Hongjun
   Wang, Renjun
   Liu, Youbo
   Wang, Lingfeng
   Xiang, Yingmeng
   Liu, Junyong
TI Data-driven distributionally robust joint planning of distributed energy
   resources in active distribution network
SO IET GENERATION TRANSMISSION & DISTRIBUTION
VL 14
IS 9
BP 1653
EP 1662
DI 10.1049/iet-gtd.2019.1565
PD MAY 11 2020
PY 2020
AB With the increasing penetration of distributed energy resources (DERs)
   in the active distribution network (ADN), how to enable joint planning
   of DERs under the uncertainty of distributed generations (DGs) has
   become a challenging problem. This study establishes a two-stage joint
   planning model considering doubly-fed induction generator, photovoltaics
   (PVs) with the ancillary services of PV inverter, distributed energy
   storage systems and different types of controllable loads in the ADN. To
   address the uncertainties of DGs, a two-stage data-driven
   distributionally robust planning model is constructed. The proposed
   model is solved in a 'master and sub-problem' framework by
   column-and-constraint generation algorithm, where the master problem is
   to minimise the total cost and find the optimal planning decision under
   the worst probability distributions, and the sub-problem is to find the
   worst probability distribution of given uncertain scenarios. Besides,
   the original mixed-integer non-linear planning problem is converted into
   a mixed-integer second-order cone programming problem through
   second-order cone relaxation, Big-M and piecewise linearisation method.
   The numerical results based on 33-bus system verify the effectiveness of
   the proposed model.
ZB 0
Z8 0
ZS 0
ZR 0
TC 0
Z9 0
SN 1751-8687
EI 1751-8695
UT WOS:000528894100005
ER

PT J
AU Meng, X J
   Wang, X W
   Gu, J
   Yin, H L
   Zhang, X
   Qian, Y H
TI [Study on HIV testing behavior among men who have sex with men based on
   structural equation model].
SO Zhonghua liu xing bing xue za zhi = Zhonghua liuxingbingxue zazhi
VL 41
IS 5
BP 758
EP 763
DI 10.3760/cma.j.cn112338-20190702-00485
PD 2020-May-10
PY 2020
AB Objective: To analyze HIV testing behaviors and associated factors in
   men who have sex with men (MSM) and provide evidence for making
   intervention on promoting HIV testing. Methods: Our observational study
   was conducted between April and June, 2018 in Wuxi, Jiangsu province in
   MSM. A self-completed questionnaire was used to collect the information
   about their socio-demographic characteristics, sexual behaviors,
   acceptance of intervention services, psychological status and HIV
   testing behaviors. Structural equation model (SEM) was chosen to fit
   data and the model was modified to analyze the relationships between
   variables. Results: A total of 410 MSM were enrolled in our study, among
   whom 72.9%(299/410) were aware of the necessity of HIV testing and
   69.0%(283/410) reported having HIV tests in the last year. A modified
   structural equation model presented good fitting results with fitting
   index of root mean square error of approximation (RMSEA)was 0.065,
   normed fit index (NFI) was 0.946, relative fit index (RFI) was 0.922,
   Tucker-Lewis index (TLI) was 0.968 and comparative fit index (CFI) was
   0.952. Results of SEM showed that intervention service was the factor
   with the largest standardized total effect value of 0.57 associated with
   HIV testing behaviors among MSM. Among intervention services, HIV
   testing reminding had the biggest factor loading of 0.88. Psychological
   status scores played a negative role in HIV testing behaviors among MSM
   with the path coefficient value of -0.33. Conclusions: The awareness and
   testing rate of HIV among MSM population need to be further improved.
   While effective measures are implemented to promote HIV testing among
   MSM, more attention should be paid to the mental health problems of MSM.
AB 目的： 分析MSM人群HIV检测行为的影响因素，为制定促进该人群检测HIV的干预措施提供依据。 方法：
   2018年4-6月，通过滚雪球的方法在江苏省无锡市招募MSM研究对象。采取面对面问卷调查的方式，收集研究对象的人口学信息、性行为特征、接受干预服
   务情况、心理状态和HIV检测情况等。利用结构方程模型对数据进行拟合并对拟合后的模型进行修正，分析各变量间的关系和影响程度。 结果：
   共招募研究对象MSM
   410人，认为自己有必要检测HIV占72.9%（299/410），最近1年HIV检测占69.0%（283/410）。修正后的结构方程模型拟合较好
   ，拟合指数主要结果分别为近似误差均方根（RMSEA）=0.065、规范拟合指数（NFI）=0.946、相对拟合指数（RFI）=0.922、Tuc
   ker-Lewis指数（TLI）=0.968、比较拟合指数（CFI）=0.952。模型拟合结果显示，对MSM人群HIV检测行为标准化总效应最高的
   变量为干预服务，路径系数为0.57；而在干预服务中，HIV检测提醒的因子载荷最大，为0.88。心理状态评分对MSM人群HIV检测行为的标准化总效
   应呈负向关系，路径系数为-0.33。 结论：
   MSM人群HIV检测意识和检测率有待进一步提高，在采取有效措施促进MSM进行检测的同时，应关注MSM人群心理健康问题。.
ZB 0
ZS 0
ZR 0
TC 0
Z8 0
Z9 0
SN 0254-6450
UT MEDLINE:32447921
PM 32447921
ER

PT J
AU Puig, Josep
   Biarnes, Carles
   Pedraza, Salvador
   Vilanova, Joan C
   Pamplona, Reinald
   Fernandez-Real, Jose Manuel
   Brugada, Ramon
   Ramos, Rafel
   Coll-de-Tuero, Gabriel
   Calvo-Perxas, Laia
   Serena, Joaquin
   Ramio-Torrenta, Lluis
   Gich, Jordi
   Gallart, Lluis
   Portero-Otin, Manel
   Alberich-Bayarri, Angel
   Jimenez-Pastor, Ana
   Camacho-Ramos, Eduardo
   Mayneris-Perxachs, Jordi
   Pineda, Victor
   Font, Raquel
   Prats-Puig, Anna
   Gacto, Mariano-Luis
   Deco, Gustavo
   Escrichs, Anira
   Clotet, Bonaventura
   Paredes, Roger
   Negredo, Eugenia
   Triaire, Bruno
   Rodriguez, Manuel
   Heredia-Escamez, Alberto
   Coronado, Rafael
   de Graaf, Wolter
   Prevost, Valentin
   Mitulescu, Anca
   Daunis-I-Estadella, Pepus
   Thio-Henestrosa, Santiago
   Miralles, Felip
   Ribas-Ripoll, Vicent
   Puig-Domingo, Manel
   Essig, Marco
   Figley, Chase R
   Figley, Teresa D
   Albensi, Benedict
   Ashraf, Ahmed
   Reiber, Johan H C
   Schifitto, Giovanni
   Md Nasir, Uddin
   Leiva-Salinas, Carlos
   Wintermark, Max
   Nael, Kambiz
   Vilalta-Franch, Joan
   Barretina, Jordi
   Garre-Olmo, Josep
TI The aging imageomics study: rationale, design and baseline
   characteristics of the study population.
SO Mechanisms of ageing and development
BP 111257
EP 111257
DI 10.1016/j.mad.2020.111257
PD 2020-May-10
PY 2020
AB Biomarkers of aging are urgently needed to identify individuals at high
   risk of developing age-associated disease or disability. Growing
   evidence from population-based studies points to whole-body magnetic
   resonance imaging's (MRI) enormous potential for quantifying subclinical
   disease burden and for assessing changes that occur with aging in all
   organ systems. The Aging Imageomics Study aims to identify biomarkers of
   human aging by analyzing imaging, biopsychosocial, cardiovascular,
   metabolomic, lipidomic, and microbiomic variables. This study recruited
   1030 participants aged ≥ 50 years (mean 67, range 50-96 years) that
   underwent structural and functional MRI to evaluate the brain, large
   blood vessels, heart, abdominal organs, fat, spine, musculoskeletal
   system and ultrasonography to assess carotid intima-media thickness and
   plaques. Patients were notified of incidental findings detected by a
   certified radiologist when necessary. Extensive data were also collected
   on anthropometrics, demographics, health history, neuropsychology,
   employment, income, family status, exposure to air pollution and
   cardiovascular status. In addition, several types of samples were
   gathered to allow for microbiome, metabolomic and lipidomic profiling.
   Using big data techniques to analyze all the data points from biological
   phenotyping together with health records and lifestyle measures, we aim
   to cultivate a deeper understanding about various biological factors
   (and combinations thereof) that underlie healthy and unhealthy aging.
Z8 0
ZS 0
ZR 0
TC 0
ZB 0
Z9 0
EI 1872-6216
UT MEDLINE:32437737
PM 32437737
ER

PT J
AU Salles, Angeles
   Park, Sangwook
   Sundar, Harshavardhan
   Macias, Silvio
   Elhilali, Mounya
   Moss, Cynthia F.
TI Neural Response Selectivity to Natural Sounds in the Bat Midbrain
SO NEUROSCIENCE
VL 434
BP 200
EP 211
DI 10.1016/j.neuroscience.2019.11.047
PD MAY 10 2020
PY 2020
AB Little is known about the neural mechanisms that mediate differential
   action-selection responses to communication and echolocation calls in
   bats. For example, in the big brown bat, frequency modulated (FM)
   food-claiming communication calls closely resemble FM echolocation
   calls, which guide social and orienting behaviors, respectively. Using
   advanced signal processing methods, we identified fine differences in
   temporal structure of these natural sounds that appear key to auditory
   discrimination and behavioral decisions. We recorded extracellular
   potentials from single neurons in the midbrain inferior colliculus (IC)
   of passively listening animals, and compared responses to playbacks of
   acoustic signals used by bats for social communication and echolocation.
   We combined information obtained from spike number and spike triggered
   averages (STA) to reveal a robust classification of neuron selectivity
   for communication or echolocation calls. These data highlight the
   importance of temporal acoustic structure for differentiating
   echolocation and food-claiming social calls and point to general
   mechanisms of natural sound processing across species. (C) 2019 IBRO.
   Published by Elsevier Ltd. All rights reserved.
OI Sundar, Harshavardhan/0000-0002-8305-7701; Salles,
   Angeles/0000-0002-5726-4256
ZB 0
ZR 0
Z8 0
TC 0
ZS 0
Z9 0
SN 0306-4522
EI 1873-7544
UT WOS:000526929900018
PM 31918008
ER

PT J
AU Ujuagu, Akunna Francess
   Wang, Ziteng
   Morita, Shin-Ichi
TI Automatic Background Removal and Correction of Systematic Error Caused
   by Noise Expecting Bio-Raman Big Data Analysis.
SO Analytical sciences : the international journal of the Japan Society for
   Analytical Chemistry
VL 36
IS 5
BP 511
EP 514
DI 10.2116/analsci.20C005
PD 2020-May-10
PY 2020
AB Spectral pretreatments, such as background removal from Raman big data,
   are crucial to have a smooth link to advanced spectral analysis.
   Recently, we developed an automated background removal method, where we
   considered the shortest length of a spectrum by changing the scaling
   factor of the background spectrum. Here, we propose a practical way to
   correct the systematic error caused by noise from measurements. This
   correction has been realized to be more effective and accurate for
   automatic background removal.
ZS 0
ZR 0
ZB 0
Z8 0
TC 0
Z9 0
EI 1348-2246
UT MEDLINE:32307345
PM 32307345
ER

PT J
AU Radecki-Pawlik, Artur
   Walega, Andrzej
   Mlynski, Dariusz
   Mlocek, Wojciech
   Kokoszka, Rafal
   Tokarczyk, Tamara
   Szalinskae, Wiwiana
TI Seasonality of mean flows as a potential tool for the assessment of
   ecological processes: Mountain rivers, Polish Carpathians
SO SCIENCE OF THE TOTAL ENVIRONMENT
VL 716
AR 136988
DI 10.1016/j.scitotenv.2020.136988
PD MAY 10 2020
PY 2020
AB The classification of river catchments according to their hydrological
   regime is crucial elements of regionalisation. In absence of
   hydrological data, the regionalisation of catchment method may be used
   to asses many flows characteristics like regime or design flow and thus
   provide help in the analysis of hydrological and ecological processes
   and also in the management of water resources. Correct clarification of
   catchments requires knowledge about the main factors that influence on
   river regime, like meteorologic conditions, land cover/land use,
   geology, soil properties terrain features, human activities.
   The aim of the study was to analyse the relationship between selected
   catchment attributes along with precipitation climatology and
   seasonality of mean flows (MQ) in the mountainous rivers in the Upper
   Vistula basin (the biggest and the most important river in Poland) and
   regionalisation catchments based on seasonality index. To achieve the
   objective of the study, we concentrated on the mountain stream and river
   catchments that are regionalised to the Upper Vistula basin (all of
   which are Vistula tributaries) and we employed the Colwell's seasonality
   index in an attempt to clear up the said ecohydrological measures.
   The study confirmed that in mountainous catchments, where response time
   to rainfall is shorter due to larger slopes, higher seasonality of mean
   monthly discharges, as expressed by the seasonality index M, is
   observed. In this case, variability of seasonal rainfall affected
   seasonality of MQ. In case of smaller slopes and large forest cover and
   catchment areas, seasonality of flows was lower.
   The innovative aspect of the presented study is the attempt to correlate
   the Colwell's seasonality index with the physiographic and
   meteorological characteristics of the catchment. Until now, the
   characteristics of the catchments have been used as factors
   differentiating the hydrological regime of the catchments, thus allowing
   for agglomeration of similar catchments. Our results foster better
   understanding of the natural processes in the river basin, which
   definitely would help in better management of the environment and its
   relationship with huge number of people living there and depend on it.
   These results show that the regression tree methods based on CART
   algorithm can be used as effective tool for classification of
   catchments. (C) 2020 Elsevier B.V. All rights reserved.
OI Walega, Andrzej/0000-0001-6839-4745; Mlocek,
   Wojciech/0000-0001-8990-4070; /0000-0002-6486-1016
TC 0
ZS 0
Z8 0
ZR 0
ZB 0
Z9 0
SN 0048-9697
EI 1879-1026
UT WOS:000519987300120
PM 32059323
ER

PT J
AU Zhu, Qingyuan
   Li, Xingchen
   Li, Feng
   Zhou, Dequn
TI The potential for energy saving and carbon emission reduction in China's
   regional industrial sectors
SO SCIENCE OF THE TOTAL ENVIRONMENT
VL 716
AR 135009
DI 10.1016/j.scitotenv.2019.135009
PD MAY 10 2020
PY 2020
AB Rapid economic growth of China's industry has brought many problems.
   Among them, the problems of energy shortage and environmental pollution
   have become increasingly serious. The quick development of the big data
   has brought new challenges and opportunities for environmental
   management. In this paper, we propose a new data envelopment analysis
   (DEA) model to analyze the energy and environmental efficiency of
   industrial sectors from China's 30 provincial-level regions in order to
   determine the potential and route for energy saving (ES) and carbon
   emission reduction (CER). The new DEA model not only considers the
   dynamic data, but also involves the technology heterogeneity and closest
   targets, which could achieve the potential or provide the route for ES
   and CER step by step with least effort. The new approach is illustrated
   by using the regional industrial dataset of China and some implications
   for ES and CER are proposed. (C) 2019 Elsevier B.V. All rights reserved.
RI Li, Feng/J-8822-2013
OI Li, Feng/0000-0002-4387-423X
Z8 0
TC 3
ZB 0
ZS 0
ZR 0
Z9 3
SN 0048-9697
EI 1879-1026
UT WOS:000519987300139
PM 31839293
ER

PT J
AU Mendes, Douglas L. S.
   Rabelo, Ricardo A. L.
   Veloso, Artur F. S.
   Rodrigues, Joel J. P. C.
   dos Reis Junior, Jose, V
TI An adaptive data compression mechanism for smart meters considering a
   demand side management scenario
SO JOURNAL OF CLEANER PRODUCTION
VL 255
AR 120190
DI 10.1016/j.jclepro.2020.120190
PD MAY 10 2020
PY 2020
AB This work proposes an adaptive data compression mechanism to reduce the
   flow in the communication infrastructure of the advanced metering
   infrastructure (AMI), providing a more agile communication and thus
   allowing the scalability of the internet of things (IoT) applications in
   the demand side management (DSM) scenario, to automate consumption
   management and distributed power generation. Such a mechanism is built
   into a smart meter (SM) and aims to reduce the amount of data sent to an
   electric power company (EPC). Additionally, this mechanism makes use of
   curve adjustment to find, in an adaptive way in run time, a functional
   model, among the available options, that best adapts to the consumption
   measures inferred by the SM. The experiments present compression rates
   where the data recovered by the functional model respect a
   pre-established error threshold. Thus, allowing the scalability of DSM
   applications in this infrastructure. Therefore, it can to be stated that
   the presence of the data compression mechanism proposed in this work is
   satisfactorily adequate for the DSM scenario of consumption and
   distributed generation achieving compression rates close to 96%, as well
   as provides the possibility of being adapted to other contexts, such as
   WSN. (C) 2020 Elsevier Ltd. All rights reserved.
RI de Andrade Lira Rabelo, Ricardo/AAN-3551-2020; Rodrigues, Joel/
OI de Andrade Lira Rabelo, Ricardo/0000-0003-1482-6404; Rodrigues,
   Joel/0000-0001-8657-3800
ZS 0
ZB 0
Z8 0
TC 0
ZR 0
Z9 0
SN 0959-6526
EI 1879-1786
UT WOS:000520953200008
ER

PT J
AU Elleuch, Wiam
   Wali, Ali
   Alimi, Adel M.
TI Neural congestion prediction system for trip modelling in heterogeneous
   spatio-temporal patterns
SO INTERNATIONAL JOURNAL OF SYSTEMS SCIENCE
DI 10.1080/00207721.2020.1760957
EA MAY 2020
PY 2020
AB Until recently, urban cities have faced an increasing demand for an
   efficient system able to help drivers to discover the congested roads
   and avoid the long queues. In this paper, an Intelligent Traffic
   Congestion Prediction System (ITCPS) was developed to predict traffic
   congestion states in roads. The system embeds a Neural Network
   architecture able to handle the variation of traffic changes. It takes
   into account various traffic patterns in urban regions as well as
   highways during workdays and free-days. The developed system provides
   drivers with the fastest path and the estimated travel time to reach
   their destination. The performance of the developed system was tested
   using a big and real-world Global Positioning System (GPS) database
   gathered from vehicles circulating in Sfax city urban areas, Tunisia as
   well as the highways linking Sfax and other Tunisian cities. The results
   of congestion and travel time prediction provided by our system show
   promise when compared to other non-parametric techniques. Moreover, our
   model performs well even in cross-regions whose data were not used
   during training phase.
Z8 0
ZS 0
ZB 0
TC 0
ZR 0
Z9 0
SN 0020-7721
EI 1464-5319
UT WOS:000533709700001
ER

PT J
AU Melender, Hanna-Leena
   Hokka, Minna
   Saarto, Tiina
   Lehto, Juho T.
TI The required competencies of physicians within palliative care from the
   perspectives of multi-professional expert groups: a qualitative study
SO BMC PALLIATIVE CARE
VL 19
IS 1
AR 65
DI 10.1186/s12904-020-00566-5
PD MAY 9 2020
PY 2020
AB Background Although statements on the competencies required from
   physicians working within palliative care exist, these requirements have
   not been described within different levels of palliative care provision
   by multi-professional workshops, comprising representatives from working
   life. Therefore, the aim of this study was to describe the competencies
   required from physicians working within palliative care from the
   perspectives of multi-professional groups of representatives from
   working life. Methods A qualitative approach, using a workshop method,
   was conducted, wherein the participating professionals and
   representatives of patient organizations discussed the competencies that
   are required in palliative care, before reaching and documenting a
   consensus. The data (n = 222) was collected at workshops held in
   different parts of Finland and it was analyzed using a qualitative
   content analysis method. Results The description of the competencies
   required of every physician working within palliative care at the
   general level included 13 main categories and 50 subcategories in total.
   'Competence in advanced care planning and decision-making' was the main
   category which was obtained from the highest number of reduced
   expressions from the original data (f = 125). Competence in social
   interactions was another strong main category (f = 107). In specialist
   level data, six main categories with 22 subcategories in total were
   found. 'Competence in complex symptom management' was the main category
   which was obtained from the biggest number of reduced expressions (f =
   46). A notable association between general level and specialist level
   data was related to networking, since one of the general level
   categories was 'Competence in consultations and networking' (f = 34) and
   one of the specialist level categories was 'Competence to offer
   consultative and educational support to other professionals' (f = 30).
   Moreover, part of the specialist level results were subcategories which
   belonged to the main categories produced from the general level data.
   Conclusions The competencies described in this study emphasize
   decision-making, social interactions and networking. It is important to
   listen to the voices of the working-life representatives when planning
   curricula. Moreover, the views of the working-life representatives
   inform how the competencies gained during their education meet the
   challenges of the ordinary work.
ZS 0
TC 0
ZR 0
Z8 0
ZB 0
Z9 0
SN 1472-684X
UT WOS:000533336800001
PM 32386513
ER

PT J
AU Kwag, Sungil
   Lee, Woo Jin
   Ko, Young Dae
TI Optimal seat allocation strategy for e-sports gaming center
SO INTERNATIONAL TRANSACTIONS IN OPERATIONAL RESEARCH
DI 10.1111/itor.12809
EA MAY 2020
PY 2020
AB This paper investigates the seat allocation issues for an e-sports
   gaming center where people generally visit in groups to play games while
   eating. According to the data analysis, as the number of customers in a
   group gets larger, the revenue per person tends to get higher. The data
   analysis to identify the information, such as revenue and the stay time
   of customers is conducted, and operations research is applied to derive
   the optimal seat allocation strategy. Through a numerical experiment
   with actual data, it is discovered that small groups of customers can
   also be prioritized in the same way as groups with larger numbers due to
   the fluctuating revenue generated by each group of customers during
   every timeslot. Furthermore, the opportunity cost that occurs by
   blocking customers even if there are available seats to accommodate the
   larger groups of customers who provide bigger revenue at various
   timeslots is considered.
OI Ko, Young Dae/0000-0003-4069-3473
ZR 0
Z8 0
TC 0
ZS 0
ZB 0
Z9 0
SN 0969-6016
EI 1475-3995
UT WOS:000531040700001
ER

PT J
AU Luft, Friedrich C.
TI Biomarkers and predicting acute kidney injury
SO ACTA PHYSIOLOGICA
AR e13479
DI 10.1111/apha.13479
EA MAY 2020
PY 2020
AB Aim How can we convert biomarkers into reliable, validated laboratory
   tests? Glomerular filtration rate (GFR) estimators exist for more than a
   century. The first utilitarian biomarkers were endogenously produced
   urea and creatinine. Clinicians then developed simple tests to determine
   whether or not renal tubular function was maintained. Are there faster
   and better tests that reflect decreased renal function and increased
   acute kidney injury (AKI) risk?
   Methods We inspect earlier, and recently propagated biomarkers. Cystatin
   C reflects GFR and is not confounded by muscle mass. Direct GFR and
   plasma volume can now be measured acutely within 3 hours. Better yet
   would be tests that give information before GFR decreases and prior to
   urea, creatinine, and cystatin C increases. Prospective tests
   identifying those persons likely to develop AKI would be helpful. Even
   more utilitarian would be a test that also suggests a therapeutic
   avenue.
   Results A number of highly provocative biomarkers have recently been
   proposed. Moreover the application of big data from huge electronic
   medical records promise new directions in identifying and dealing with
   AKI.
   Conclusions Pipedreams are in the pipeline; the novel findings require
   immediate testing, verification, and perhaps application. Future
   research promises to make such dreams come true.
TC 0
ZR 0
ZB 0
Z8 0
ZS 0
Z9 0
SN 1748-1708
EI 1748-1716
UT WOS:000531100300001
PM 32311830
ER

PT J
AU Ashraf, Imran
   Hur, Soojung
   Park, Yongwan
TI Enhancing Performance of Magnetic Field Based Indoor Localization Using
   Magnetic Patterns from Multiple Smartphones.
SO Sensors (Basel, Switzerland)
VL 20
IS 9
DI 10.3390/s20092704
PD 2020 May 09
PY 2020
AB Wide expansion of smartphones triggered a rapid demand for precise
   localization that can meet the requirements of location-based services.
   Although the global positioning system is widely used for outdoor
   positioning, it cannot provide the same accuracy for the indoor. As a
   result, many alternative indoor positioning technologies like Wi-Fi,
   Bluetooth Low Energy (BLE), and geomagnetic field localization have been
   investigated during the last few years. Today smartphones possess a rich
   variety of embedded sensors like accelerometer, gyroscope, and
   magnetometer that can facilitate estimating the current location of the
   user. Traditional geomagnetic field-based fingerprint localization,
   although it shows promising results, it is limited by the fact that
   various smartphones have embedded magnetic sensors from different
   manufacturers and the magnetic field strength that is measured from
   these smartphones vary significantly. Consequently, the localization
   performance from various smartphones is different even when the same
   localization approach is used. So devising an approach that can provide
   similar performance with various smartphones is a big challenge.
   Contrary to previous works that build the fingerprint database from the
   geomagnetic field data of a single smartphone, this study proposes using
   the geomagnetic field data collected from multiple smartphones to make
   the geomagnetic field pattern (MP) database. Many experiments are
   carried out to analyze the performance of the proposed approach with
   various smartphones. Additionally, a lightweight threshold technique is
   proposed that can detect user motion using the acceleration data.
   Results demonstrate that the localization performance for four different
   smartphones is almost identical when tested with the database made using
   the magnetic field data from multiple smartphones than that of which
   considers the magnetic field data from only one smartphone. Moreover,
   the performance comparison with previous research indicates that the
   overall performance of smartphones is improved.
OI Ashraf, Imran/0000-0002-8271-6496
ZB 0
TC 0
ZR 0
ZS 0
Z8 0
Z9 0
EI 1424-8220
UT MEDLINE:32397444
PM 32397444
ER

PT P
AU BAO F
   HUANG Z
   ZHANG M
TI Method for using customer credit level evaluation system based on big
   data technology comprises using AHP analysis, collecting customer files,
   collecting data, collecting different information, dividing sample
   customer, calculating result
PN CN111127186-A
AE YUNNAN GRID CO LTD INFORMATION CENT
AB 
   NOVELTY - The method comprises using the AHP analysis to establish a
   structural system of customer credit evaluation level at application
   layer, collecting the customer files dynamically and electricity
   performance and customer credit behavior in credit reporting agency at
   infrastructure layer, collecting the data is checked and governed
   according to requirement of data quality before calculations and
   modeling at basic software layer, collecting the different information
   standard by different system, using the step to establish a structural
   system of customer credit rating levels to support the model to build a
   calculation model, dividing the sample customers into observation period
   and forecast period according to time dimension, calculating the result
   of model, releasing the customer credit evaluation level. The system
   includes application layer, model supporting layer, basic software layer
   and infrastructure layer. The infrastructure layer includes database
   server and application server.
   USE - Method for using customer credit level evaluation system based on
   big data technology.
   ADVANTAGE - The method: forms a more systematic and hierarchical scoring
   system; and solves the problem of lack of calculation and data
   processing defects of the existing credit evaluation system.
   DESCRIPTION Of DRAWING(S) - The drawing shows a schematic representation
   of the method for using customer credit level evaluation system based on
   big data technology (Drawing includes non-English language text).
Z9 0
UT DIIDW:2020411440
ER

PT P
AU CAI J
   WANG J
   WANG T
   CAO Z
   SHAO Z
TI Processing service based on big data by using electronic device,
   comprises selecting and generating target project to be reviewed
   according to project configuration in response to project creation
   request of enterprise
PN CN111126848-A
AE HAOHUO KUNSHAN NETWORK TECHNOLOGY CO LTD
AB 
   NOVELTY - Processing service based on big data comprises selecting and
   generating the target project to be reviewed according to the project
   configuration in response to the project creation request of the
   enterprise, if an audit trigger event of the target project is detected,
   then obtaining a basic information of the project-creating enterprise
   and the configuration information of the target project, determining the
   project configuration information according to the project configuration
   selection, if the basic information of the enterprise matches the
   configuration information of the target project, then determining that
   the target project passes the review.
   USE - The method is useful for processing service based on big data by
   using electronic device (claimed).
   ADVANTAGE - The method: ensures the authenticity of the created target
   project; and realizes the efficient management of the enterprise created
   project.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for:(1)
   service processing device based on big data; and(2) computer-readable
   storage medium comprising a set of instructions for processing service
   based on big data.
   DESCRIPTION Of DRAWING(S) - The drawing shows a flowchart illustrating
   the method for processing service based on big data by using electronic
   device (Drawing includes non-English language text).
Z9 0
UT DIIDW:2020411527
ER

PT P
AU CHEN Y
TI Smart wiper start method for vehicle, involves capturing video,
   collecting data and acquiring image and started smart learning and
   collecting video in real time with timeline mark obtained through front
   windshield
PN CN111114495-A
AE CHEN Y
AB 
   NOVELTY - The method involves capturing video and a data is collected.
   An image is acquired and started a smart learning. A camera is placed
   near a position of a front view mirror in a car is used to collect a
   video in real time with a timeline mark obtained through a front
   windshield and is consistent with a drivers field of view. The video is
   sent to a vehicle controller in real time. A detection is made whether a
   stepless speed regulation device is turned. A rotation start time and a
   rotation end time is sent to the vehicle controller.
                       USE - Smart wiper start method for vehicle.
   ADVANTAGE - The excessive information collection, processing and
   analysis on the vehicle side is not needed. The burden on the side of
   the car is reduced. The cloud server performed smart deep learning based
   on big data. The neural model that mets the needs of users is obtained
   and sent the neural model to the car side in software. The software on
   the vehicle side is installed and run to realized the fully automatic
   and smart start function of the wiper with very high user experience.
   The wiper be turned on in time and stabilized at the speed of user
   needs.
   DESCRIPTION Of DRAWING(S) - The drawing shows a flowchart illustrating
   the smart wiper start method. (Drawing includes non-English language
   text)
Z9 0
UT DIIDW:202041444C
ER

PT P
AU CUI H
TI Big data alarm platform system, has detection device, storage device is
   provided, integrated device, and protection device is provided,
   detecting device is used for obtaining data output by gateway device,
   integrated apparatus is provided
PN CN111131177-A
AE SHENZHEN GEESUNN TECHNOLOGY CO LTD
AB 
   NOVELTY - The big data alarm platform system comprises a detection
   device. A storage device is provided. A integrated device, and a
   protection device is provided. The detecting device is used for
   obtaining a data output by a gateway device. A malicious website of the
   malicious data is obtained. A user is prompted that the malicious data
   is the output data. The storage device is provided for storing malicious
   data of malicious website. A integrated apparatus is provided for
   performing integrated processing of a history data information. The
   defense device is provided for generating the defense data that is
   matched with the malicious data.
                       USE - Big data alarm platform system.
   ADVANTAGE - Big data alarm platform system implements malicious data
   real-time monitoring. The technology intercepts malicious data, ensuring
   the safety of data transmission.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for a big data
   warning platform method.
   DESCRIPTION Of DRAWING(S) - The drawing shows the schematic view of the
   big data alarm platform system. (Drawing includes non-English language
   text).
Z9 0
UT DIIDW:202041789S
ER

PT P
AU DUAN Z
   ZHANG X
   WANG L
   LIU L
   LI C
   TAO P
   MA H
   ZHAO P
TI Power supply station evaluation and analysis system has full-power
   supply configuration calculation unit that generates power supply
   configuration recommendations system output display unit outputs to
   terminal to display result
PN CN111126753-A
AE STATE GRID HEBEI ELECTRIC POWER CO LTD; STATE GRID CORP CHINA; STATE
   GRID HEBEI ENERGY TECHNOLOGY SERVI
AB 
   NOVELTY - The system has a evaluation unit for the number of power
   supply stations for the usage of the power supply station, a
   preprocessing unit for the optimized data of the power station, a
   calculation unit for the configuration optimization coefficient, and for
   the recommendation of the full-power station, and a system output
   display unit. The quantity evaluation unit of the power supply station
   and the usage of the power supply station. The evaluation unit and the
   type evaluation unit of the power supply station respectively transmit
   data to the optimized data preprocessing unit of the power supply
   station for preprocessing. The pre-processed data is optimized by the
   configuration optimization coefficient calculation unit, and the
   full-power supply configuration recommendation calculation unit
   generates the power supply configuration recommendations. The system
   output display unit outputs to the terminal to display the result.
   USE - Power supply station evaluation and analysis system based on big
   data technology.
   ADVANTAGE - The problems of low analysis data quality, lack of analysis
   system and lack of data algorithm in the evaluation method of the power
   supply station are solved by the power supply station evaluation and
   analysis system.
   DESCRIPTION Of DRAWING(S) - The drawing shows a block flow diagram of
   the power supply station evaluation and analysis system. (Drawing
   includes non-English language text)
Z9 0
UT DIIDW:202042665J
ER

PT P
AU GAO J
   WANG M
   TANG P
TI Anti-malicious attack system based on big data analysis comprises
   information recording module to collect information, model processing
   module to process collected information and information processing
   module to build anti-attack system
PN CN111131174-A
AE XIAMEN YITONGLING INFORMATION TECHNOLOGY
AB 
   NOVELTY - Anti-malicious attack system based on big data analysis
   comprises information record collection module, model processing module,
   and information processing module. The information recording module is
   used to collect information. The model processing module is used to
   process the collected information. The information processing module is
   used to build an anti-attack system according to the result of the model
   processing module.
     USE - Used as anti-malicious attack system based on big data analysis.
   ADVANTAGE - The system cannot directly enter back-end server for
   parameter legalization verification, which reduces load pressure of
   back-end business server and prevent malicious attacks.
Z9 0
UT DIIDW:202041789V
ER

PT P
AU HE H
   LI R
   ZHOU X
TI Method for invoking big data interface, involves obtaining data
   corresponding to big data interface from memory, and sending data
   corresponding to interface to terminal if data corresponding to big data
   interface is cached in memory
PN CN111124555-A
AE SHENZHEN QIANHAI HUANRONG LIANYI INFORMA
AB 
   NOVELTY - The method involves determining (S1) whether a data
   corresponding to a big data interface is cached in a memory if a call
   request to the big data interface sent by a terminal is received in
   which a data amount of the data corresponding to the big data interface
   is greater than a preset data amount threshold. The data corresponding
   to the big data interface is obtained from the memory and is sent (S2)
   to the terminal if the data corresponding to the big data interface is
   cached in the memory.
   USE - Method for invoking big data interface using invoking device
   through computer device (all claimed).
   ADVANTAGE - Since the data corresponding to the big data interface is
   obtained from the memory, the data reading process of the big data
   interface is improved, the resource consumption is reduced, the return
   time of the big data interface is improved and the stability of the
   system is ensured.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are included for the
   following:(1) an invoking device; and(2) a computer-readable storage
   medium storing program for invoking big data interface.
   DESCRIPTION Of DRAWING(S) - The drawing shows a flowchart illustrating a
   method for invoking a big data interface. (Drawing includes non-English
   language text)Step for determining whether a data corresponding to a big
   data interface is cached in a memory if a call request to the big data
   interface sent by a terminal is received (S1)Step for sending data
   corresponding to the big data interface to the terminal (S2)
Z9 0
UT DIIDW:202041209K
ER

PT P
AU HE Y
   WAN Y
   HUO Y
TI Method for storing data to electronic device, involves using transport
   tool to transport data file to master node of distributed database
   cluster, and writing data file to distributed database cluster
PN CN111125013-A
AE BEIJING RUN TECHNOLOGIES CO LTD
AB 
   NOVELTY - The method involves using a storage component in a distributed
   big data processing system to store data to be stored in a distributed
   stream processing platform. A stream processing framework is used to
   read the data to be stored in the stream processing platform. Data file
   in a set format is generated according to the data to be stored. A
   transport tool is used to transport the data file to the master node of
   a distributed database cluster. A loading program is started by a
   distributed database cluster. Data file is write to the distributed
   database cluster.
           USE - Method for storing data to an electronic device (claimed).
   ADVANTAGE - The method enables performing the data storage through the
   data loading mode provided by the distributed database cluster so as to
   improve the performance of data storage.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the
   following:(1) a device for storing data to electronic device; and(2) a
   computer-readable storage medium for storing a set of instructions for
   executing a method for storing data to electronic device.
   DESCRIPTION Of DRAWING(S) - The drawing shows a flow chart illustrating
   the method for storing data to electronic device (Drawing includes
   non-English language text).
Z9 0
UT DIIDW:202041197S
ER

PT P
AU HU Y
   CHEN X
TI Result backtracking method comprises receiving the first backtracking
   request sent by the electronic device, inputting corresponding metadata
   into pre-trained big data platform and sending corresponding data source
   to the electronic device
PN CN111125472-A
AE BEIJING MINGLUE SOFTWARE SYSTEM CO LTD
AB 
   NOVELTY - Result backtracking method comprises receiving the first
   backtracking request sent by the electronic device, sending all
   pre-stored model data to the electronic device for display in response
   to the first backtracking request, receiving a second backtracking
   request, which needs to backtrack the data to be backtracked from all
   the model data sent by the electronic device, where the second
   backtracking request includes the identifier of the data to be
   backtracked, searching for metadata corresponding to the identifier
   based on the first correspondence between the pre-stored identifier and
   the metadata of the data source in response to the second backtracking
   request, inputting the corresponding metadata into a pre-trained big
   data platform to make the big data platform finds a data source
   corresponding to the corresponding metadata from the data storage system
   based on the corresponding metadata and sending the corresponding data
   source to the electronic device.
                       USE - The method is useful for result backtracking.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for:(1)
   result tracing device;(2) electronic device; and(3) storage medium,
   comprising a set of instructions for result backtracking method.
   DESCRIPTION Of DRAWING(S) - The drawing shows a flowchart illustrating
   the method for backtracking results (Drawing includes non-English
   language text).
Z9 0
UT DIIDW:202041186G
ER

PT P
AU HUA J
TI Intelligent underground security system based on big data technology
   comprises face information big data platform, face recognition system
   and access control system both installed at gate of underground entrance
   and local server
PN CN111127731-A
AE HUA J
AB 
   NOVELTY - Intelligent underground security system based on big data
   technology comprises face information big data platform, which includes
   cloud server on which face recognition system software is installed and
   running, cloud server has a cloud database, and cloud database stores
   face information of persons suspected of endangering public safety. A
   face recognition system with camera and installed at gate of underground
   entrance and realizes communication connection between each other
   through wireless public network and cloud server of face information big
   data platform. A local server is installed and running both facial
   recognition system software and intelligent security system software and
   distributed in area of underground station communication device. An
   access control system with control module is installed at gate of
   underground entrance. The control module of access control system is
   connected with each other through a network communication device and a
   local server.
                     USE - Used as intelligent underground security system.
   ADVANTAGE - The system solves the technical problem that it is currently
   impossible to realize intelligent identification and prevent persons
   suspected of endangering public safety from entering the underground.
Z9 0
UT DIIDW:2020411300
ER

PT P
AU JIN C
TI Big data processing and analysis-based smart transportation control
   method involves transmitting overload information and positioning data
   of truck in real time to traffic management terminal connected to
   traffic management center
PN CN111127896-A
AE SUZHOU SHUIYI DATA TECHNOLOGY CO LTD
AB 
   NOVELTY - The method involves controlling (S5) a blocking ignition
   device is provided inside a truck where a car exceeding a nuclear load
   is located to start a cut-off of the connected ignition device. A
   warning message is sent to a registration supply terminal bound to the
   registration of the truck. A positioning unit is controlled (S6) to
   provided inside the truck to start real-time acquisition of positioning
   data. An overload information and positioning data of the truck is
   transmitted to the connected and demanded address information in real
   time to the connected traffic management center adapted to the required
   address information for record. The overload information and positioning
   data of the truck in real time is transmitted (S7) to a traffic
   management terminal connected to the traffic management center.
   USE - Big data processing and analysis-based smart transportation
   control method.
   ADVANTAGE - The ignition device of the truck is cut off by the blocking
   ignition device inside the truck so as to avoid the truck from driving
   overweight.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for a smart
   transportation control system based on big data processing and analysis.
   DESCRIPTION Of DRAWING(S) - The drawing shows a flowchart illustrating
   the big data processing and analysis based smart transportation control
   method. (Drawing includes non-English language text)Step for obtaining
   real time truck terminal information (S3)Step for controlling weight
   detection platform (S4)Step for controlling blocking ignition device
   (S5)Step for controlling positioning unit (S6)Step for transmitting
   overload information and positioning data (S7)
Z9 0
UT DIIDW:202041861R
ER

PT P
AU JIN Y
   LI P
   LOU W
   WANG Q
   JIANG Y
   SHEN H
   ZHANG W
   PAN Z
   TAO C
   FENG L
   WANG L
   YANG W
   CHEN Y
   ZHENG Z
   KE F
   MAO Q
   LI L
   KONG X
TI Big data recommendation algorithm based customer channel drainage
   method, involves formulating differentiated diversion strategies to
   achieve customer channel diversion and precision marketing services
PN CN111127080-A
AE STATE GRID ZHEJIANG TAIZHOU HUANGYAN DIS
AB 
   NOVELTY - The method involves establishing a customer channel drainage
   model centered on a customer end. Customer's tendency is analyzed to use
   a terminal equipment for business. Customer usage information of
   multiple electronic channels is integrated. Correlation matrix of
   customer-customer characteristics indicators is generated. Non-online
   similarity matrix between state Grid customers and state Grid customers
   are adopted with customer-based collaborative filtering-Pearson
   correlation coefficient analysis algorithm to obtain a target customer
   group with high similarity to the characteristic indicators of online
   State Grid APP customers Potential customer groups. Differentiated
   diversion strategies are formulated to achieve the customer channel
   diversion and precision marketing services based on customer
   characteristics and business application scenarios.
   USE - Big data recommendation algorithm based customer channel drainage
   method.
   ADVANTAGE - The method enables integrating the customer usage
   information of electronic channels to subdivide the customer group,
   effectively to provide guidance for the development and marketing of the
   electronic channels, thus achieving the drainage of customer channels in
   effective and scientific manner and avoiding deviation.
   DESCRIPTION Of DRAWING(S) - The drawing shows a flow diagram
   illustrating the big data recommendation algorithm based customer
   channel drainage method (Drawing includes non-English language text).
Z9 0
UT DIIDW:202041146J
ER

PT P
AU LI D
   WU G
   LUO Y
   YANG L
   WU Z
   MAO Z
   CUI Y
TI Method for making irrigation decision based on big data by using server
   comprises obtaining farmland environmental monitoring, construct
   irrigation forecast model, using irrigation forecast model, using
   pre-trained irrigation decision model
PN CN111126662-A
AE CAMCE WHU DESIGN & RES CO LTD
AB 
   NOVELTY - The method comprises (s100) obtaining the farmland
   environmental monitoring data, (s200) construct an irrigation forecast
   model based on farmland environmental monitoring data, using the
   irrigation forecast model to determine the predicted irrigation water
   demand of the farmland, (s300) according to the predicted irrigation
   water demand of the farmland and attribute information of each field in
   the farmland, using the pre-trained irrigation decision model to
   determine the target irrigation water volume for each field in the
   farmland.
   USE - Method for making irrigation decision based on big data by using
   server (claimed).
   ADVANTAGE - The method can increase utilization of irrigation water
   resource.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for :(1)
   irrigation decision-making device based on big data comprising a data
   obtaining module, an irrigation water demand prediction module and an
   irrigation decision making module; and(2) computer-readable storage
   medium comprising a set of instructions for making irrigation decision
   based on big data.
   DESCRIPTION Of DRAWING(S) - The drawing shows a flow diagram
   illustrating the method for making irrigation decision based on big data
   by using server (Drawing includes non-English language text).
Z9 0
UT DIIDW:202041156H
ER

PT P
AU LI W
   CHENG J
TI Big data storage analysis query system comprises distributed data
   storage architecture providing high throughput to access data of
   applications and distributed data analysis architecture completes
   large-scale data processing operations
PN CN111125248-A
AE XIEYI NETWORK TECHNOLOGY SHANGHAI CO LTD
AB 
   NOVELTY - Big data storage analysis query system comprises distributed
   data storage architecture provide high throughput to access data of
   applications with very large data sets. Distributed data analysis
   architecture is general-purpose engine, which is used to complete
   large-scale data processing operations. Distributed data search
   architecture is used in distributed massive data search engines in
   various scenarios.
                      USE - Used as big data storage analysis query system.
   ADVANTAGE - The system improves efficiency and saves time through
   distributed storage and query, and multiple nodes store and query and
   has rich analysis type, supports various data samples, and supports
   distributed analysis, greatly improves analysis speed. The query in the
   massive data, compared with the traditional database is a full table
   scan, slow time, distributed query technology, the same data can reach
   the speed of seconds.
   DESCRIPTION Of DRAWING(S) - The drawing shows a schematic representation
   of big data storage analysis query system (Drawing includes non-English
   language text).
Z9 0
UT DIIDW:202041191S
ER

PT P
AU LI Y
   ZHANG W
   WANG Z
   LI W
   CHAI Y
   YU Y
TI Full-source traceability supervision method of ticket flow three-chain
   cross-validation product security comprises establishing reliable
   three-chain collaborative blockchain security management and control
   system
PN CN111127047-A
AE UNIV YANTAI
AB 
   NOVELTY - Full-source traceability supervision method of ticket flow
   three-chain cross-validation product security comprises (i) building the
   underlying data platform of the blockchain; (ii) utilizing blockchain
   technology, interface technology, barcode, radio-frequency
   identification technology, and smart contracts to build three parallel
   data sub-chains i.e. electronic invoice chain, financial payment chain
   and logistics supply chain, which are used to store, query, trace and
   analyze product's electronic invoice data information, payment data
   information and logistics supply information, respectively; (iii)
   opening up three data sub-chains horizontally through underlying
   interface technology of blockchain and establishing a three-chain
   collaborative data platform; (iv) establishing cross-validation and
   multi-party collaborative computing model of three-chain full-process
   big data cluster; and (v) establishing reliable three-chain
   collaborative blockchain security management and control system.
   USE - The method is useful for full-source traceability supervision of
   ticket flow three-chain cross-validation product security.
   ADVANTAGE - The method utilizes the blockchain technology to open up the
   data channel from point to net to realize the penetration safety
   monitoring and scientific and efficient management of food, medicine,
   dangerous and other products.
   DESCRIPTION Of DRAWING(S) - The drawing shows a schematic diagram of
   full-source traceability supervision method of ticket flow three-chain
   cross-validation product security (Drawing includes non-English language
   text).
Z9 0
UT DIIDW:2020411479
ER

PT P
AU LIU F
TI Embedded hidden terminal for artificial intelligence home information
   processing based on big data comprises mounting frame body provided with
   first and second fixed frame, threaded rod provided with groove and
   clamping slot
PN CN111120836-A
AE NAOGU ARTIFICIAL INTELLIGENCE RES INST
AB 
   NOVELTY - Embedded hidden terminal for artificial intelligence home
   information processing based on big data comprises mounting frame body
   (1) provided with groove (3) and threaded rod (2). The first fixed frame
   (4) is attached to inner wall of mounting frame body. An embedded hidden
   terminal body is provided in first and second fixing frame (5). A baffle
   plate is provided inside fixing plate and first limit block provided
   with second limiting groove. The outer end screw of baffle is installed
   with connecting spring and connecting rope with second limiting block.
   The inner bearing of second fixing frame is installed with rotating rod.
   A clamping rod is installed on outer side of rotating rod and second
   clamping slot is opened inside second fixing frame with first clamping
   slot. A clamping lever is arranged inside first clamping slot screwed
   with magnet pieces. The inner side of connecting rope is connected with
   guide wheel. A connecting block is installed on first fixing frame and
   threaded rod.
   USE - Used as embedded hidden terminal for artificial intelligence home
   information processing based on big data.
                       ADVANTAGE - The terminal is convenient to install.
   DESCRIPTION Of DRAWING(S) - The drawing shows a schematic representation
   of embedded hidden terminal for artificial intelligence home information
   processing based on big data.Mounting frame body (1)Threaded rod
   (2)Groove (3)First fixed frame (4)Second fixing frame (5)
Z9 0
UT DIIDW:2020421327
ER

PT P
AU LIU X
   NING Z
TI Method for performing scene extraction based on big data, involves
   dividing operation information in log text to obtain scene operation
   sequence to determine users operation scene according to scene operation
   sequence
PN CN111124925-A
AE BANMA NETWORK TECHNOLOGY CO LTD
AB 
   NOVELTY - The method involves extracting (S201) a users log text from a
   pre-established corpus in which the log text include users operation
   information in operation scenario in a vehicle. A word segmentation is
   performed on the sentences in the log text and each word is converted
   (S202) into a word vector through a pre-established word vector model.
   The operation information in the log text is divided (S204) to obtain a
   scene operation sequence to determine the users operation scene
   according to a scene operation sequence according to a category label
   corresponding to each word vector.
   USE - Method for performing scene extraction based on big data using
   scene extraction device (claimed).
   ADVANTAGE - The method quickly and accurately extracts the users common
   scene operation sequence and abnormal operation sequence from the beta
   test.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are included for the
   following:(1) a scene extraction device; and(2) a computer-readable
   storage medium storing program for performing scene extraction based on
   big data.
   DESCRIPTION Of DRAWING(S) - The drawing shows a flowchart illustrating a
   scene extraction method based on big data. (Drawing includes non-English
   language text)Step for extracting a users log text from a
   pre-established corpus (S201)Step for converting each word into a word
   vector (S202)Step for using model to obtain the category label of each
   word vector (S203)Step for dividing operation information in the log
   text to obtain a scene operation sequence to determine the users
   operation scene according to a scene operation sequence (S204)
Z9 0
UT DIIDW:202041199V
ER

PT P
AU LOU J
TI Road violation integrated device, has voice prompt device fixedly
   installed on bottom part of large screen display, and power supply wire
   connected with decibel measurer, high-definition camera, weighing
   device, large screen display and prompting device
PN CN210488786-U
AE HUANG J
AB 
   NOVELTY - The utility model claims a road illegal integrated device,
   comprising a decibel meter, a high-definition camera, a weighing device,
   a large screen display, a voice prompt device, data cable and power
   supply wire; big-screen display through data wire respectively connected
   with the decibel measurer and weighing device, a high-definition camera
   is fixed on the measuring instrument, voice prompt device is fixedly
   installed on the large screen display bottom, power line respectively
   connected to the decibel measurer, a high-definition camera, a weighing
   device, a large screen display and voice prompting device The utility
   model has reasonable structure, the weighing device and at the same time
   the city road section can effectively detect whether the vehicle is
   overloaded and generate noise, once the violation, it can indicate the
   vehicle has been violated, and been transmitted to the website by the
   camera recording, display screen can be instant decibel number, vehicle
   weight and picture with the violation vehicle vehicle licence plate
   number displayed on the screen, so that the passing vehicle to observe
   traffic regulations.
Z9 0
UT DIIDW:202042595S
ER

PT P
AU SUN H
   CAO H
   SUN W
TI Intelligent traffic management system based on big data, has real-time
   planning module whose output terminal is connected to input terminal of
   route issuing module which is connected to input terminal of driver
   login terminal
PN CN111127886-A
AE HEFEI JINYUTANG CULTURAL MEDIA CO LTD
AB 
   NOVELTY - The system has a camera monitoring module (1) whose output
   terminal is connected to the input terminal of a vehicle density
   analysis system (3). The output terminal of the vehicle density analysis
   system is connected to the input terminal of a road congestion density
   update library (4). The output terminal of the road congestion density
   update library is connected to the input terminal of a central
   processing module (5). The output end of the central processing module
   and a real-time planning module (6) realize a bidirectional connection.
   The output terminal of a driver login terminal (2) is connected to the
   input terminal of a trip upload module (7). The output terminal of the
   real-time planning module is connected to the input terminal of a route
   issuing module (8). The output terminal of the route issuing module is
   connected to the input terminal of the driver login terminal.
             USE - Intelligent traffic management system based on big data.
   ADVANTAGE - The intelligent traffic management system based on big data
   provides a good guide to the driver itinerary, and promptly reminds the
   driver to change the route when the traffic situation changes. The
   traffic burden is well distributed, the concentrated driving of vehicles
   on a certain road is avoided, which saves a lot of time for travelers.
   The horizontal and vertical green lights length of time is well
   distributed at the intersection, according to the horizontal and
   vertical traffic flow, which greatly improves the efficiency of vehicle
   traffic.
   DESCRIPTION Of DRAWING(S) - The drawing shows a block diagram of the
   intelligent traffic management system based on big data. (Drawing
   includes non-English language text)Camera monitoring module (1)Driver
   login terminal (2)Vehicle density analysis system (3)Road congestion
   density update library (4)Central processing module (5)Real-time
   planning module (6)Trip upload module (7)Route issuing module (8)
Z9 0
UT DIIDW:2020411269
ER

PT P
AU WANG H
   LIU L
   PANG X
   DI Z
   XIANG H
   ZHANG D
   WANG N
   SONG W
   XING Y
TI Smart motorway integrated management platform based on big traffic data
   comprises digital motorway module and smart construction module provided
   with engineering construction system and smart maintenance module to
   call maintenance data
PN CN111125286-A
AE SHANDONG LUKE HIGHWAY INFORMATION CONSUL
AB 
   NOVELTY - Smart motorway integrated management platform based on big
   traffic data comprises digital motorway module to obtain road network
   linear data and attribute data to build a road network map. In the road
   network map, there is one-to-one correspondence between network linear
   data and attribute data and road construction, road maintenance, road
   condition events and video images to provide data interface service for
   linkage query of motorway construction data, maintenance data and road
   condition data. A smart construction module is used to call the motorway
   construction data in the engineering construction system through the
   interface and display it on the road network map in real time. Smart
   maintenance module is used to call the maintenance data in the
   maintenance system. Road network monitoring module is used to obtain
   road condition events, motorway condition information processing
   platform, motorway video monitoring system and traffic modulation
   system.
   USE - Used as smart motorway integrated management platform based on big
   traffic data.
   DESCRIPTION Of DRAWING(S) - The drawing shows a schematic representation
   of the smart motorway integrated management platform based on big
   traffic data.
Z9 0
UT DIIDW:202041190U
ER

PT P
AU WANG H
   TANG Y
   CAI Y
TI Evaluating natural resource value based on big data includes
   establishing category value matrix, regional value matrix, growth cycle
   value matrix and temperature value matrix, setting equivalent value
   matrix and determining natural resource
PN CN111126353-A
AE JIANGSU XINGYUE SURVEYING & MAPPING TECH
AB 
   NOVELTY - Evaluating natural resource value based on big data, includes:
   establishing category value matrix Ai according to different natural
   resources by category construction model; establishing regional value
   matrix Gi based on different regional information by regional
   construction module; establishing growth cycle value matrix Ti according
   to growth time of different natural resources by growth cycle building
   module; establishing temperature value matrix t based on real-time
   temperature information by temperature building module; setting
   equivalent value matrix K according to natural resource's market
   circulation value by equivalent value module; determining first natural
   resource by confirmation module; repeating above steps to determine the
   second natural resource value amount V2; and repeating N times and
   obtaining average natural resource value V0 according to the weighted
   algorithm.
   USE - The method is useful for evaluating natural resource value based
   on big data.
   DESCRIPTION Of DRAWING(S) - The drawing shows a flowchart illustrating
   the method for evaluating natural resource value based on big data
   (Drawing includes non-English language text).
Z9 0
UT DIIDW:2020411640
ER

PT P
AU WANG J
   ZHANG H
TI City security monitoring platform based on blockchain comprises using
   slave node for encrypting and distributed storage of security data
   through encryption algorithm, and using hash node to store algorithms
   and verification information
PN CN111131795-A
AE JIANGSU RONGZER INFORMATION TECHNOLOGY
AB 
   NOVELTY - City security monitoring platform based on blockchain
   comprises where a security monitoring system comprises multiple cameras
   in public areas of the urban, using camera for security data,
   transmitting security data to the big data processing system through the
   network by using network transmission system, dividing security data
   into multiple categories by using big data processing system, and
   sending them to the data storage system, where data storage system
   comprises a master node, a slave node and a hash node, and using the
   master node to distribute and manage the slave node and the hash node,
   using slave node for encrypting and distributed storage of security data
   through an encryption algorithm, using hash node to store algorithms,
   rules and verification information.
       USE - Used as city security monitoring platform based on blockchain.
      ADVANTAGE - The platform has high working efficiency and safe access.
   DESCRIPTION Of DRAWING(S) - The drawing shows a schematic representation
   of the city security monitoring platform based on blockchain (Drawing
   includes non-English language text).
Z9 0
UT DIIDW:202041774S
ER

PT P
AU WANG Z
   WANG W
   ZHANG K
TI System for performing big data intelligent modeling based on dynamic
   metadata, has metadata collection module and big data engine module in
   which collection module constructs and loads metadata as initial
   metadata into modeling process
PN CN111125052-A
AE BEIJING HUARU SCI & TECHNOLOGY CO LTD
AB 
   NOVELTY - The system has a metadata collection module, a metadata
   algorithm library module, an anomaly detection module, a visualization
   module and a big data engine module in which the metadata collection
   module constructs and loads the metadata of a data source as initial
   metadata into the modeling process. The anomaly detection module
   implements anomaly detection in modeling process design and includes an
   anomaly detection library and an anomaly detection engine.
   USE - System for performing big data intelligent modeling based on
   dynamic metadata.
   ADVANTAGE - The system provides good real-time performance and high
   reliability to realize real-time early warning of error process
   connection and improve modeling efficiency.
   DESCRIPTION Of DRAWING(S) - The drawing shows a schematic diagram of a
   system structure of a big data intelligent modeling system based on
   dynamic metadata. (Drawing includes non-English language text)
Z9 0
UT DIIDW:202041196T
ER

PT P
AU XIAO Q
   HE H
TI State monitoring method for encryption machine data to secure
   transaction information in financial banks involves detecting data to
   encrypt, determine process threshold to create new detection process, or
   end the process when limit exceeds
PN CN111130926-A
AE CHINA CONSTR BANK CORP
AB 
   NOVELTY - The state monitoring method involves detection server to
   creates a detection process for sending a detection instruction to the
   encryption machine. The detection server receives the return parameters
   generated by the encryption machine according to the detection
   instructions. The detection server analyzes the return parameters to
   obtain the operating state of the encryption machine. The detection
   server creates a detection process, the state monitoring method to check
   the number of detection processes running in the detection server, and
   set in advance to compare the thresholds, if the number of running
   detection processes in the detection server is less than the threshold,
   to create detection process. When the number of detection processes
   running in the detection server is greater than or equal to the
   threshold, Then end the task directly.
   USE - State monitoring method for encryption machine data to ensure the
   secure interaction of transaction information in financial institutions
   such as banks, Union-Pay and third-party payment.
   ADVANTAGE - The detection results are visually displayed, and the
   abnormal state alarm is helpful for the operation and maintenance
   personnel to analyze the health state of the encryption machine, and
   handle the abnormal encryption machine in advance to improve the
   availability of the system. The bypass detection method is versatile and
   can be applied to various types of encryption machines. The conditional
   inspection strategy and the connectivity inspection strategy are used to
   assist detection to ensure that the bypass detection method will not
   affect the normal operation of the encryption machine. In addition, with
   the help of big data processing methods, the detection results are
   visually displayed, and the abnormal state alarm is helpful for the
   operation and maintenance personnel to analyze the health state of the
   encryption machine, and handle the abnormal encryption machine in
   advance to improve the availability of the system.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are included for the
   following:(1) a state monitoring system; and(2) a computer storage
   medium.
   DESCRIPTION Of DRAWING(S) - The drawing shows a flow-chart of a State
   monitoring method for encryption business machine data. (Drawing
   includes non-English language text).
Z9 0
UT DIIDW:2020417966
ER

PT P
AU XU G
   LI J
   LI Y
   SHEN Z
TI Predicting multiple incoming cars based on big data in tourist car park
   comprises collecting traffic flow data information, uploading traffic
   flow data collected by each electric police bay, and displaying each car
   park in scenic spot
PN CN111127882-A
AE GUIZHOU ZHICHENG TECHNOLOGY CO LTD
AB 
   NOVELTY - Predicting multiple incoming cars based on big data in tourist
   car park comprises setting multiple electric police bayonet on all roads
   passing via scenic car park and within intersection with roads passing
   via scenic car park within radius of 5-10 kilometers around scenic car
   park, collecting traffic flow data information including vehicle
   information, location of vehicles electric police bay, direction of
   vehicle, distance from car park of scenic spot, uploading traffic flow
   data collected by each electric police bay, predicting multiple cars
   arriving at each car park after certain time in future based on parking
   number parking algorithm by data analysis platform, sending prediction
   results to each car park display platform in scenic spot, displaying
   each car park in scenic spot, publishing predicted multiple incoming
   cars and sending parking warning based on comparison of predicted
   multiple vehicles received and actual remaining parking spaces in car
   park.
   USE - The method is useful for predicting multiple incoming cars based
   on big data in tourist car park.
   ADVANTAGE - The method: is convenient for the car park manager to do car
   park management and planning in advance; avoids traffic jams caused by
   insufficient parking spaces; and improves the standardized management
   level of scenic spots.
   DESCRIPTION Of DRAWING(S) - The drawing shows a schematic illustration
   of the method for predicting multiple incoming cars based on big data in
   tourist car park (Drawing includes non-English language text).
Z9 0
UT DIIDW:202041126D
ER

PT P
AU XUE Z
   XUE S
   LIANG W
   LIU S
   FAN M
   YANG G
TI Large data based virtual passenger flow analysis system, has big data
   analysis module and process improvement module connected with each
   other, where process improvement module and validity evaluation module
   connected with each other
PN CN111125191-A
AE SHANGHAI WOZI INFORMATION TECHNOLOGY CO
AB 
   NOVELTY - The system has a demand data identifying module (2) fixed with
   a big data collecting module (3). A data storage module (4) is connected
   with a server module (5). The server module is fixed with a big data
   analysis module (6). The big data analysis module and a process
   improvement module (7) are connected with each other. The process
   improvement module and a validity evaluation module (8) are connected
   with each other.
             USE - Large data based virtual passenger flow analysis system.
   ADVANTAGE - The system reduces problem of insufficient data collection
   process and insufficient data analysis so as to makes results of
   analysis more effective and conclusions drawn more persuasive.
   DESCRIPTION Of DRAWING(S) - The drawing shows a block diagram of the
   large data based virtual passenger flow analysis system (Drawing
   includes non-English language text).Demand data identifying module
   (2)Big data collecting module (3)Data storage module (4)Server module
   (5)Big data analysis module (6)Process improvement module (7)Validity
   evaluation module (8)
Z9 0
UT DIIDW:2020411937
ER

PT P
AU ZHANG G
   LI G
   LI X
TI Big data analysis system useful for computer verification code
   technology comprises central processing module set with power module and
   data collecting module, and display module fixed to electrical output of
   central processing module
PN CN111131230-A
AE UNIV HEFEI
AB 
   NOVELTY - Big data analysis system comprises a central processing module
   (100) is electrically set with a power module (110) and a data
   collecting module. The central processing module is bidirectionally set
   with a storage module II (120), a data analyzing module (130), a
   communication module (140) and a transceiver module II. The
   communication module is set with a remote terminal. A display module is
   fixed to the electrical output of the central processing module. The
   transceiver module II is fixed to a large database. The large database
   comprises a microprocessor is connected to a server, a transceiver
   module I, a storage module I, an encryption module, and a verification
   module. The display module is a touchable in-plane switching (IPS)
   liquid crystal display.
   USE - The big data analysis system is useful for computer verification
   code technology.
   ADVANTAGE - The system: utilizes remote terminal to realize data
   sharing; and improves the overall effect of data security.
   DESCRIPTION Of DRAWING(S) - The drawing shows a schematic representation
   of the big data analysis system for computer verification code
   technology (Drawing includes non-English language text).Central
   processing module (100)Power module (110)Storage module II (120)Data
   analyzing module (130)Communication module (140)
Z9 0
UT DIIDW:202041788J
ER

PT P
AU ZHANG P
   DING H
   GU N
   LU T
TI Evaluating distributed combined credit, comprises dividing data set
   required for training model using distributed bipartite mean clustering
   based on variable weighting, dividing data set required for training
   model, and dividing users
PN CN111127184-A
AE UNIV FUDAN
AB 
   NOVELTY - Evaluating distributed combined credit, comprises (i) dividing
   the data set required for training the model using a distributed
   bipartite mean clustering method based on variable weighting, dividing
   the data set required for training the model, and dividing users into
   clusters with similar credit in, and (ii) generating the evaluation
   credit classification model, using a combination technique based on
   variable weighted clustering to model user characteristic data, dividing
   users into different clusters according to similarity, training any two
   clustered discriminant classifiers between different categories,
   combining the classification results through a weighted strategy to
   build a user credit evaluation model, and using the model to
   automatically discriminate the credit status based on user
   characteristic data.
     USE - The method is useful for evaluating distributed combined credit.
   ADVANTAGE - The method improves the calculation efficiency and
   scalability of the credit evaluation method, and the applicability in
   the application of big data credit evaluation.
   DESCRIPTION Of DRAWING(S) - The drawing shows a flowchart illustrating
   the method for evaluating distributed combined credit (Drawing includes
   non-English language text).
Z9 0
UT DIIDW:2020411442
ER

PT P
AU ZHANG X
TI Construction worker analysis system based on big data, comprises and
   information recording unit to enter basic information of construction
   workers and recording unit to record and update comprehensive
   performance of construction workers
PN CN111126874-A
AE CHONGQING NENGGONG TECHNOLOGY DEV CO LTD
AB 
   NOVELTY - Construction worker analysis system based on big data,
   comprises and information recording unit to enter the basic information
   of construction workers. A recording unit is set to record and update
   the comprehensive performance, work experience, trustworthiness, and
   cultural level and professional skills of construction workers. An
   evaluation unit is set to score comprehensive performance, work
   experience, trustworthiness, cultural level and professional skills of
   construction workers according to preset scoring standards and classify
   construction workers according to their labor service companies,
   calculate average score of comprehensive score of construction workers
   of each labor service company and generate a comprehensive ranking table
   of reliability of each labor service company and to classify
   construction workers, calculate average score of construction workers
   comprehensive scores in each region and generate a comprehensive
   reliability ranking table for each region.
       USE - Used as construction worker analysis system based on big data.
   ADVANTAGE - The system can quickly recruit corresponding talents
   according to construction workers, labor companies, regions or types of
   work.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for
   analysis method of construction workers based on big data.
   DESCRIPTION Of DRAWING(S) - The drawing shows a block diagram of the
   construction worker analysis system based on big data (Drawing includes
   non-English language text).
Z9 0
UT DIIDW:202041151H
ER

PT P
AU ZHANG X
   ZHANG Z
TI Evaluating data risk control based on simulation includes establishing
   corresponding risk control strategy, performing historical data
   backtracking on data source and determining whether data source to be
   evaluated is shortlisted
PN CN111127195-A
AE CITIC AIBANK CORP LTD
AB 
   NOVELTY - Evaluating data risk control based on simulation includes:
   (S1) establishing credit approval simulation system and establishing
   corresponding risk control strategy for data source to be evaluated;
   (S2) using credit approval simulation system and actual big data risk
   control system to perform historical data backtracking on data source to
   be evaluated; (S3) determining whether data source to be evaluated is
   shortlisted according to first simulation result and first actual
   result, and if so, perform step (S4); (S4) using credit approval
   simulation system and online evaluation of the data source mean of the
   data source to be evaluated based on the risk control strategy, and
   obtaining second simulation result, using the actual big data risk
   control system and based on risk control strategy performing online
   evaluation of the data source to be evaluated; and (S5) determining
   whether data source to be evaluated continues to be called and whether
   data is subject to second bargaining.
   USE - The method is useful for evaluating data risk control based on
   simulation.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for:(1)
   device for evaluating data risk control based on simulation; and(2)
   computer-readable storage medium comprising a set of instructions for
   evaluating data risk control based on simulation.
   DESCRIPTION Of DRAWING(S) - The drawing shows a flowchart illustrating
   block diagram of evaluating data risk control based on simulation
   (Drawing includes non-English language text).Establishing credit
   approval simulation system and establishing corresponding risk control
   strategy for data source to be evaluated (S1)Perform historical data
   backtracking on data source to be evaluated (S2)Determining whether data
   source to be evaluated (S3)Using credit approval simulation system and
   online evaluation of the data source mean of the data source
   (S4)Determining whether data source to be evaluated continues to be
   called and whether data is subject to second bargaining (S5)
Z9 0
UT DIIDW:202041143R
ER

PT P
AU ZHAO K
   WANG F
TI Intelligent dynamic balancing instrument for power station pumps based
   on internet big data comprises vibration tester that can collect data
   offline and a portable computer with laser, and vibration tester used to
   collect vibration data
PN CN111122052-A
AE DATANG NORTHEAST ELECTRIC POWER TEST RES
AB 
   NOVELTY - Intelligent dynamic balancing instrument for power station
   pumps based on internet big data comprises a vibration tester that can
   collect data offline and a portable computer with laser. The vibration
   tester is used to collect the vibration data of the multi-stage
   centrifugal pumps on the site, and upload the collected vibration data
   to the vibration big data center through the internet for comparison and
   analysis with the vibration big data to obtain the multi-stage
   centrifugal pump weighting scheme. The portable computer is used to
   obtain the multi-stage centrifugal pump weighting scheme pushed by the
   vibration big data center through the Internet, so that field testers
   can perform weighting and correction under the laser guidance according
   to the multi-stage centrifugal pump weighting scheme until the vibration
   value is reduced to within the acceptable range.
   USE - Used as intelligent dynamic balancing instrument for power station
   pumps based on internet big data.
   ADVANTAGE - The instrument: realize non-expert online intelligent
   dynamic balancing; greatly improve the efficiency of dynamic balancing;
   and reduce the dependence of experts.
   DESCRIPTION Of DRAWING(S) - The drawing shows a flow chart of applying
   the present invention to perform a dynamic balancing test of a
   multistage centrifugal pump in a power station (Drawing includes
   non-English language text).
Z9 0
UT DIIDW:202041268E
ER

PT P
AU ZHAO W
   WU X
   FAN G
   ZHAO L
   WANG Y
   BAI J
   NIU J
   WAN C
   XIONG X
   CHEN F
   QI X
TI Secondary security measure method for intelligent stations, involves
   reading the substation configuration description file of the substation
   and analyzing to obtain the configuration information of the intelligent
   substation
PN CN111126798-A
AE GUIZHOU POWER GRID CO LTD
AB 
   NOVELTY - The secondary security measure method involves reading the
   substation configuration description (SCD) file of the substation and
   analyzing to obtain the configuration information of the intelligent
   substation. The configuration information of the intelligent substation
   conform is verified to specifications. The IED device is to be
   simulated, and the simulation system is called to simulate the IED
   device, and the operating state and real-time data of the improvised
   explosive device (IED) device is simulated. The automatically generated
   security measure content is automatically associated with big data. The
   security measures are automatically generated according to the security
   condition data of the IED device.
          USE - Secondary security measure method for intelligent stations.
   ADVANTAGE - Safe and reliable secondary maintenance safety measures
   implement support and application system support systems, which have
   inestimable economic benefits.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for a secondary
   safety measurement system for intelligent stations.
   DESCRIPTION Of DRAWING(S) - The drawing shows a flowchart of secondary
   security measure method for intelligent stations. (Drawing includes
   non-English language text).
Z9 0
UT DIIDW:202043501L
ER

PT P
AU ZHAO Z
   YANG G
TI Temperature-sensitive intelligent wearable monitoring device comprises
   smart wearable units provided with movement and casing, mainboard unit
   provided with main control module and 5G mobile communication network
   with terminal server
PN CN111128397-A
AE ZHAO Z
AB 
   NOVELTY - Temperature-sensitive intelligent wearable monitoring device
   comprises two smart wearable units including movement fixedly installed
   in a casing installed on connection piece and includes motherboard unit,
   miniature camera and electronic ink screen and power unit. The mainboard
   unit includes main control module, body temperature monitoring module,
   position monitoring module, Near Field Communication (NFC) module,
   encryption module, comparison verification module, storage module and
   wireless communication module. The movement also includes vital sign
   collection module. The vital sign collection module is provided with
   sensing end attached to wearer's skin. The personal information includes
   identity information, blood type, underlying disease type, original area
   information and go-to area information. The wireless communication
   module can be connected to terminal server through Fifth Generation (5G)
   mobile communication network.
   USE - Used as temperature-sensitive intelligent wearable monitoring
   device.
   ADVANTAGE - The device: has reasonable and compact structure; can
   monitor the wearer's body temperature and position information in real
   time; realize real-time monitoring of the wearer through Fifth
   Generation network combined with big data information retrieval
   technology and personnel management and control of each isolation area;
   register relevant information; check relevant records; ensures control
   and deployment; and is safe, labor-saving, simple and efficient.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for
   monitoring using temperature-sensitive intelligent wearable monitoring
   device.
   DESCRIPTION Of DRAWING(S) - The drawing shows a schematic representation
   of the temperature-sensitive intelligent wearable monitoring device.
Z9 0
UT DIIDW:202041851J
ER

PT P
AU ZHOU C
TI Scheduling task for big data clusters based on node labels has
   configuring node labels for host nodes, collecting host information,
   changing state of node label, changing non-healthy node label and
   scheduling big data task to run on queue
PN CN111124765-A
AE ZHONGYING YOUCHUANG INFORMATION TECHNOLO
AB 
   NOVELTY - Scheduling task for big data clusters based on node labels
   comprises configuring node labels for the host nodes of the big data
   cluster, associating the node label with the task queue, collecting host
   information corresponding to the node label regularly, changing the
   state of the node label according to the host information, changing the
   node label corresponding to the problem host to a non-healthy node label
   when a problem host is found based on the host information, changing the
   corresponding non-healthy node label to a normal host node label when it
   is found that the host corresponding to the non-healthy node label has
   returned to normal according to the host information, allowing the
   corresponding non-healthy node label changing to a normal host node
   label, scheduling the big data task to run on the configured task queue
   and corresponding the big data task is not scheduled to run on the host
   node to the non-healthy node label in the process of running on task
   force.
   USE - The method is useful for scheduling task for big data clusters
   based on node labels.
   ADVANTAGE - The method improves the performance and stability of big
   data tasks.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for node
   data-based task scheduling system for big data clusters.
   DESCRIPTION Of DRAWING(S) - The drawing shows a flowchart of a method
   for scheduling a big data cluster task based on node labels (Drawing
   includes non-English language text).
Z9 0
UT DIIDW:2020412043
ER

PT P
AU ZHOU Y
   YUAN L
   QIAN Q
   LI C
TI Flexible piezoelectric sensor array based pulse diagnosis instrument has
   collection module set to collect and process voltage signals, and
   display module set to display processing result of data analysis
   processing module
PN CN111110207-A
AE UNIV WENZHOU CHINESE ACAD SCI INST
AB 
   NOVELTY - The instrument has a cuff inflation and deflation control
   module that is used to inflate and deflate the airbag in the cuff device
   to achieve the process of pressurization. A piezoelectric signal
   collection module is used for collecting and processing voltage signals.
   A data processing and analysis module is used for feature extraction of
   voltage signal data, a comparative analysis with different types of
   pulse signal features in the database, and the analysis results are
   saved and transmitted to the display module for display. The display
   module is used to display the processing result of the data analysis
   processing module.
   USE - Flexible piezoelectric sensor array based pulse diagnosis
   instrument.
   ADVANTAGE - The whole instrument is compact in structure, small in size,
   light in weight and easy to carry, and is used for health monitoring in
   daily life, feature analysis based on big data, and promotes the
   objective development of pulse diagnosis in traditional Chinese
   medicine.
   DESCRIPTION Of DRAWING(S) - The drawing shows a block diagram of the
   flexible piezoelectric sensor array based pulse diagnosis instrument.
   (Drawing includes non-English language text)
Z9 0
UT DIIDW:202041542S
ER

PT P
TI Electronic drive system used for processing big data signal comprises an
   electronic driver device used for receiving the pushing control command,
   the electronic driving device has a signal converter and a direct
   current brushless motor
PN CN111113483-A
AE LI J
AB 
   NOVELTY - The electronic drive system comprises an electronic driver
   device used for receiving the pushing control command. A mechanical arm
   drive is connected to the pushing conveying belt for conveying material
   on the conveyor belt. The electronic driving device is used for
   receiving the command for reliable material. The electronic driving
   device has signal converter and a direct current brushless motor. The
   signal converter is connected with the direct current brushless motor. A
   mechanical arm is arranged above the conveying belt and is connected
   with the electronic driving device.
         USE - Electronic drive system used for processing big data signal.
   ADVANTAGE - Avoid the adverse influence of abnormal material caused by
   the production process.
   DESCRIPTION Of DRAWING(S) - The drawing shows a schematic view of the
   conveying belt.
Z9 0
UT DIIDW:202042158W
ER

PT P
TI Large data people flow statistics device, has first transverse plate
   whose lower part is provided with infrared ray emitter, and second
   transverse plate whose front surface wall is provided with power button,
   where emitter and sensor are connected with button
PN CN210488592-U
AE SHANGHAI FEICHEN ELECTRONIC TECHNOLOGY
AB 
   NOVELTY - The utility model claims a big data people flow statistics
   device, comprising a first lateral board and a second lateral board, and
   the first transverse plate and second transverse plate are provided with
   a sliding groove, two inside of the sliding groove are glidingly
   connected with two sliding blocks; four of the sliding block between two
   fixedly connected with a fixing rod, the lower part of the first
   transverse plate is provided with an infrared ray emitter, outside of
   the infrared ray emitter is equipped with a protective shell, the front
   wall of the protective shell is provided with a radiating hole, the
   inside of the heat dissipation hole is provided with a dustproof net.
   the inside of the second transverse plate is provided with an infrared
   sensor, big data of people flow statistics device of this utility model,
   the sliding block in the sliding groove, the adjustable two position and
   distance of the fixed rod, the two fixing rods are provided to a
   distance of only allows one person to pass, avoid the big data people
   flow counting device can be off by many people, not convenient for
   calculating accuracy of the flow.
Z9 0
UT DIIDW:202042597J
ER

PT P
AU CHANG Y
TI Timing drive command big data trigger system comprises timing drive
   device for receiving the revised time interval, and water vapor ejection
   device perform a water vapor eruption action, when receiving electronic
   drive command
PN CN111123757-A
AE CHANG Y
AB 
   NOVELTY - The timing drive command big data trigger system comprises a
   timing drive device for receiving the revised time interval and
   periodically sending electronic drive commands according to the revised
   time interval. A water vapor ejection device perform a water vapor
   eruption action, when receiving an electronic drive command. A visual
   collection device is set above the queuing place decide whether to start
   the timing visual collection of the queuing place under the control of
   the management operation to obtain the current captured image. The
   frequency of the visual acquisition device acquisition operation is more
   than ten times the frequency of the electronic drive commands of the
   timing drive device.
                       USE - Timing drive command big data trigger system.
   ADVANTAGE - The existing water resources are fully utilized, and the
   cooling effect on site is guaranteed.
   DESCRIPTION Of DRAWING(S) - The drawing shows a schematic view of timing
   drive command big data trigger system.
Z9 0
UT DIIDW:202042646F
ER

PT P
AU CHEN J
   SONG H
TI Ranching communication network system, comprises electronic collar
   regularly collects body temperature of cattle, and collector sends data
   to the concentrator through repeater, and big data platform analyzes
   temperature of cattle
PN CN111132033-A
AE SHANGHAI SUNRAY ELECTRONICS TECHNOLOGY
AB 
   NOVELTY - The system comprises a electronic collar regularly collects
   the body temperature of cattle. The body temperature and exercise steps
   data is regularly sent to the collector. The collector sends the data to
   the concentrator through the repeater. A concentrator sends the data to
   the big data platform. The big data platform analyzes the temperature of
   the cattle and sheep exercise step data to monitor the growth of cattle
   and sheep in time. The electronic collar is worn on the neck of each cow
   and sheep and includes a battery, a pedometer chip, a temperature sensor
   and an electronic collar wireless communication module.
                       USE - Ranching communication network system.
   ADVANTAGE - Solves the problem of uploading cattle and sheep data
   without the coverage of the base station in the pasture and adjusts the
   number of repeaters according to the distance. The mesh network is
   self-organizing and self-maintaining, without human participation, and
   improves work efficiency.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for a networking
   method for a ranch communication network.
   DESCRIPTION Of DRAWING(S) - The drawing shows a block diagram of a
   ranching communication network system. (Drawing includes non-English
   language text).
Z9 0
UT DIIDW:2020417694
ER

PT P
AU HUANG H
   DAI J
   LIANG Y
   CHEN Y
TI Product recommendation algorithm has set of instructions for obtaining
   user data from an operator big data system, obtaining push mark
   according to user setting demand information, and pushing commodity
   information to user
PN CN111127164-A
AE UNIV SHAOGUAN
AB 
   NOVELTY - The algorithm has a set of instructions for obtaining user
   data from an operator big data system, the user data includes user ID,
   user number and user setting demand information. The user ID and user
   number are used to identify a unique user from the user identity
   database. The user setting demand information is used by the user to
   write the preference feature information of the required commodity.
   First push mark is obtained according to the user setting demand
   information. Product information is marked on the first push mark as the
   first product information. User browsing time and number of times for
   the third commodity information is obtained. Product information is
   obtained and included with first product information, second product
   information and third product information with a longer browsing time.
   Fourth commodity information is obtained through commodity information
   with a longer browsing time. The fourth commodity information is pushed
   to a user.
                       USE - Product recommendation algorithm.
Z9 0
UT DIIDW:202041144G
ER

PT P
AU JIN S
TI Logistics distribution system based on big data discrete values has
   delivery terminal to identify current delivery date, obtains delivery
   location and delivery time classification according to current delivery
   date
PN CN111126711-A
AE JIN S
AB 
   NOVELTY - Logistics distribution system based on big data discrete
   values comprises a user terminal to send receipt location and receipt
   time to a service terminal each time a receipt is received. The service
   terminal classifies the delivery location and the delivery time
   according to the date and a delivery terminal scans the items and
   obtains item information. The delivery terminal identifies the current
   delivery date, and the delivery terminal obtains the delivery location
   and delivery time classification according to the current delivery date.
   A distribution terminal calculates the discrete value of the overall
   receipt time according to the overall receipt time. The delivery
   terminal uses the delivery time corresponding to the current delivery
   date to calculate discrete value of the delivery time of the current
   delivery date, delivers the goods according to the delivery location
   corresponding to the current delivery location.
   USE - Used as logistics distribution system based on big data discrete
   values.
   DESCRIPTION Of DRAWING(S) - The drawing shows a frame diagram of the
   logistics distribution system based on big data discrete values (Drawing
   includes non-English language text).
Z9 0
UT DIIDW:2020411557
ER

PT P
AU LI M
   LIANG Y
TI Traffic big data analysis based traffic control device, has fixing
   sleeve fixedly connected with mounting plate that is symmetrically and
   fixedly connected with supporting plate, where two sides of side wall of
   plate are connected with solar panel
PN CN210488783-U
AE LI M
AB 
   NOVELTY - The utility model claims a traffic control device technology
   field, and claims a traffic control device based on traffic big data
   analysis, comprising a base, the upper end of the base is provided with
   a bottom plate, the bottom plate is fixedly connected with an adjusting
   sleeve; the adjusting sleeve is in sliding connection with the lifting
   rod, the lifting rod is fixedly sleeved with a chassis, four vertical
   side walls of said case are equipped with traffic signal lamp; the
   lifting sleeve is provided with a fixing sleeve far away from one end of
   the base, the annular side wall of the fixing sleeve is symmetrically
   provided with a fixing groove; the fixing groove is glidingly connected
   with a fixing block, the rod wall of the lifting rod is provided with a
   fixing hole. The utility model is convenient for the solar panel
   detachably on the traffic control device, which is good for cleaning the
   solar panel on the impurities such as dust, and convenient for lamp and
   the case of the traffic signal lamp is separated, easy cleaning of the
   traffic signal lamp, the illumination effect of the signal lamp is
   better.
Z9 0
UT DIIDW:2020416734
ER

PT P
AU LI Y
   ZHOU B
   SHEN Z
TI Cleaning generic names of medicines based on big data by using server
   comprises building standard common name database, matching generic name
   of medical enterprise with standard generic name data, and updating
   standard common name database
PN CN111125076-A
AE WUHAN HAIYUN HEALTH TECHNOLOGY CO LTD
AB 
   NOVELTY - Cleaning generic names of medicines based on big data by using
   a server comprises building a standard common name database, using web
   crawler technology to crawl the generic name data of medicines,
   obtaining the common name data of the cleaned drugs, combining the
   crawled generic name data of the medicine with the cleaned generic name
   data, cleaning to obtain standard common name data, importing the
   standard common name data into the standard common name database,
   cleaning the common name of each medical enterprise data, matching the
   generic name of the medical enterprise with the standard generic name
   data in the standard generic name database, entering the corresponding
   database if the matching requirements are met, and updating the standard
   common name database.
   USE - The method is useful for cleaning generic names of medicines based
   on big data by using a server.
   ADVANTAGE - The method: ensures the automatic cleaning of the common
   name in each medical enterprise data on the basis of ensuring accuracy;
   and reduces manpower input and reduces the cleaning cost of the generic
   name of the drug.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMs are also included for:(1)
   cleaning system for generic names of medicines based on big data; and(2)
   computer-readable storage medium comprising a set of instructions for
   cleaning generic names of medicines based on big data by using a server.
   DESCRIPTION Of DRAWING(S) - The drawing shows a flowchart illustrating
   the method for cleaning generic names of medicines based on big data by
   using a server (Drawing includes non-English language text).
Z9 0
UT DIIDW:2020411968
ER

PT P
AU LIN G
   WANG H
   WANG W
TI Neural mental disease emerging mutation information knowledge platform,
   has data visualization and access layer adopting WEB interface to
   drawing/displaying mapping inquired data in real-time manner
PN CN111128308-A
AE SHANGHAI MENTAL HEALTH CENT SHANGHAI PSY
AB 
   NOVELTY - The platform has a data collecting and processing layer in
   connection with multi-dimensional data storage layers. The data
   collecting and processing layer is provided with a multi-dimensional
   data collecting module and a data analyzing module and a data storage
   module. The multi-dimensional data collecting module collects historical
   neural mental disease emerging mutation data information that is
   transmitted to the data analyzing module for collecting mutation data
   and a sample identifier. The multi-dimensional data storage layer is
   made of a big data platform that is controlled by using a high
   performance Non-SQL (NoSQL) database management system. A de- redundancy
   processing module adopts built-in script of a Python (RTM: High-level
   programming language) to realize mutation, gene and expression data. A
   data visualization and access layer adopts a WEB interface to
   drawing/displaying a mapping inquired data in real- time manner.
   USE - Neural mental disease emerging mutation information knowledge
   platform.
   ADVANTAGE - The data visualization and access layer adopts the WEB
   interface to drawing/displaying a mapping inquired data in real- time
   manner so as to improve visualization efficiency of scientific research.
   DESCRIPTION Of DRAWING(S) - The drawing shows a schematic representation
   of the neural mental disease emerging mutation information knowledge
   platform (Drawing includes non-English language text).
Z9 0
UT DIIDW:202041853U
ER

PT P
AU SHI S
TI Particle mobile robot group under artificial intelligence big data
   comprises vehicle body includes load-bearing frame, shell plate provided
   around load-bearing frame and mobile robot control system provided on
   carrying frame
PN CN111123953-A
AE UNIV HARBIN ENGINEERING
AB 
   NOVELTY - Particle mobile robot group under artificial intelligence big
   data comprises a mobile robots composed of a vehicle body, a power
   device, a walking mechanism, an image collecting system and a mobile
   robot control system. The vehicle body includes a load-bearing frame. A
   shell plate is provided around the load-bearing frame. The mobile robot
   control system is provided on the carrying frame and is connected with a
   walking mechanism and the image acquisition system. The power supply
   device is for powering a mobile robot fixed on the carrying frame. The
   mobile robot is controlled by (a) using image acquisition system of the
   mobile robot collects images and performing denoising on collected
   images; (b) stroking control of the mobile robot group, so that the
   mobile robot travels within the planned path channel; (c) posture
   monitoring of the mobile robot group during the trip;(iv) repeating
   steps (b)-(c) until the mobile robot group stops working.
   USE - Used as particle mobile robot group under artificial intelligence
   big data.
   ADVANTAGE - The big data achieves design and stability analysis of
   mobile robot control system and stable control of mobile robots;
   optimizes the parameters in the control law; eliminates the problem of
   manual selection of parameters; and simplifies the difficulty of mobile
   robot group control.
   DESCRIPTION Of DRAWING(S) - The drawing shows a flowchart illustrating
   the method for particle mobile robot group under artificial intelligence
   big data (Drawing includes non-English language text).
Z9 0
UT DIIDW:202041223V
ER

EF